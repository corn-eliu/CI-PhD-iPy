{
 "metadata": {
  "name": "",
  "signature": "sha256:6e8313b6d08e164519c9d051f97040670b737603da73bb11d423dfbadf9ff2f5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Imports and defines\n",
      "%pylab\n",
      "import numpy as np\n",
      "import sys\n",
      "import scipy as sp\n",
      "from IPython.display import clear_output\n",
      "\n",
      "import cv2\n",
      "import time\n",
      "import os\n",
      "import scipy.io as sio\n",
      "import glob\n",
      "import itertools\n",
      "\n",
      "from PIL import Image\n",
      "from PySide import QtCore, QtGui\n",
      "\n",
      "import GraphWithValues as gwv\n",
      "import VideoTexturesUtils as vtu\n",
      "import SemanticsDefinitionTabGUI as sdt\n",
      "import SemanticLoopingTabGUI as slt\n",
      "import opengm\n",
      "import soundfile as sf\n",
      "\n",
      "from matplotlib.patches import Rectangle\n",
      "\n",
      "import shutil, errno\n",
      "\n",
      "def copyanything(src, dst):\n",
      "    try:\n",
      "        shutil.copytree(src, dst)\n",
      "    except OSError as exc: # python >2.5\n",
      "        if exc.errno == errno.ENOTDIR:\n",
      "            shutil.copy(src, dst)\n",
      "        else: raise\n",
      "\n",
      "app = QtGui.QApplication(sys.argv)\n",
      "\n",
      "DICT_SEQUENCE_NAME = 'semantic_sequence_name'\n",
      "DICT_BBOXES = 'bboxes'\n",
      "DICT_FOOTPRINTS = 'footprints' ## same as bboxes but it indicates the footprint of the sprite on the ground plane\n",
      "DICT_BBOX_ROTATIONS = 'bbox_rotations'\n",
      "DICT_BBOX_CENTERS = 'bbox_centers'\n",
      "DICT_FRAMES_LOCATIONS = 'frame_locs'\n",
      "DICT_MASK_LOCATION = 'frame_masks_location'\n",
      "DICT_SEQUENCE_FRAMES = 'sequence_frames'\n",
      "DICT_SEQUENCE_IDX = 'semantic_sequence_idx' # index of the instantiated sem sequence in the list of all used sem sequences for a synthesised sequence\n",
      "DICT_DESIRED_SEMANTICS = 'desired_semantics' # stores what the desired semantics are for a certain sprite \n",
      "#(I could index them by the frame when the toggle happened instead of using the below but maybe ordering is important and I would lose that using a dict)\n",
      "DICT_FRAME_SEMANTIC_TOGGLE = 'frame_semantic_toggle'# stores the frame index in the generated sequence when the desired semantics have changed\n",
      "DICT_ICON_TOP_LEFT = \"icon_top_left\"\n",
      "DICT_ICON_FRAME_KEY = \"icon_frame_key\"\n",
      "DICT_ICON_SIZE = \"icon_size\"\n",
      "DICT_REPRESENTATIVE_COLOR = 'representative_color'\n",
      "DICT_OFFSET = \"instance_offset\"\n",
      "DICT_SCALE = \"instance_scale\"\n",
      "DICT_FRAME_SEMANTICS = \"semantics_per_frame\"\n",
      "DICT_USED_SEQUENCES = \"used_semantic_sequences\"\n",
      "DICT_SEQUENCE_INSTANCES = \"sequence_instances\"\n",
      "DICT_SEQUENCE_BG = \"sequence_background_image\"\n",
      "DICT_SEQUENCE_LOCATION = \"sequence_location\"\n",
      "DICT_PATCHES_LOCATION = \"sequence_preloaded_patches_location\"\n",
      "DICT_TRANSITION_COSTS_LOCATION = \"sequence_precomputed_transition_costs_location\"\n",
      "\n",
      "GRAPH_MAX_COST = 10000000.0\n",
      "\n",
      "dataPath = \"/home/ilisescu/PhD/data/\"\n",
      "\n",
      "dataSet = \"havana/\"\n",
      "# dataPath = \"/media/ilisescu/Data1/PhD/data/\"\n",
      "# dataSet = \"clouds_subsample10/\"\n",
      "# dataSet = \"theme_park_cloudy/\"\n",
      "# dataSet = \"theme_park_sunny/\"\n",
      "formatString = \"{:05d}.png\"\n",
      "\n",
      "TL_IDX = 0\n",
      "TR_IDX = 1\n",
      "BR_IDX = 2\n",
      "BL_IDX = 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: TkAgg\n",
        "Populating the interactive namespace from numpy and matplotlib\n",
        "[[ 0.98846721  0.01153279]\n",
        " [ 0.92358888  0.07641112]\n",
        " [ 0.79012346  0.20987654]\n",
        " [ 0.6033125   0.3966875 ]\n",
        " [ 0.3966875   0.6033125 ]\n",
        " [ 0.20987654  0.79012346]\n",
        " [ 0.07641112  0.92358888]\n",
        " [ 0.01153279  0.98846721]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for sprite in np.sort(glob.glob(dataPath + dataSet + \"semantic_sequence*.npy\"))[0:] :\n",
      "#     ## for a given semantic sequence, load all frames and precompute visible patches (for fast rendering)\n",
      "#     seqLoc = dataPath + dataSet\n",
      "#     sequence = np.load(sprite).item()\n",
      "#     seqName = sequence[DICT_SEQUENCE_NAME]\n",
      "# #     sequence[DICT_MASK_LOCATION] = seqLoc+seqName+\"-maskedFlow-blended/\"\n",
      "# #     currentSequencePatches = {}\n",
      "# #     for frameKey in np.sort(sequence[DICT_FRAMES_LOCATIONS].keys()) :\n",
      "# #         frameName = sequence[DICT_FRAMES_LOCATIONS][frameKey].split(os.sep)[-1]\n",
      "# #         maskDir = sequence[DICT_MASK_LOCATION]\n",
      "\n",
      "# #         if os.path.isdir(maskDir) and os.path.exists(maskDir+\"/\"+frameName) :\n",
      "# #             im = np.array(cv2.imread(maskDir+\"/\"+frameName, cv2.CV_LOAD_IMAGE_UNCHANGED), dtype=np.uint8)\n",
      "\n",
      "# #             visiblePixels = np.argwhere(im[:, :, -1] != 0)\n",
      "# #             topLeft = np.min(visiblePixels, axis=0)\n",
      "# #             patchSize = np.max(visiblePixels, axis=0) - topLeft + 1\n",
      "\n",
      "# #             currentSequencePatches[frameKey] = {'top_left_pos':topLeft, 'sprite_colors':im[visiblePixels[:, 0], visiblePixels[:, 1], :], \n",
      "# #                                                'visible_indices': visiblePixels-topLeft, 'patch_size': patchSize}\n",
      "\n",
      "# #         sys.stdout.write('\\r' + \"Loaded image \" + np.string_(len(currentSequencePatches)) + \" (\" + np.string_(len(sequence[DICT_FRAMES_LOCATIONS])) + \")\")\n",
      "# #         sys.stdout.flush()\n",
      "\n",
      "# #     sequence[DICT_PATCHES_LOCATION] = seqLoc+\"preloaded_patches-\"+seqName+\".npy\"\n",
      "# #     np.save(sequence[DICT_PATCHES_LOCATION], currentSequencePatches)\n",
      "# #     np.save(seqLoc+\"semantic_sequence-\"+seqName+\".npy\", sequence)\n",
      "# #     print \n",
      "\n",
      "#     ## \"computing\" the hacky transitino matrix for the car sprites --> assuming the invisible frame is the last one\n",
      "#     k = len(sequence[DICT_FRAME_SEMANTICS])\n",
      "#     timeConstraint = np.eye(k, k=1)\n",
      "#     timeConstraint[-1, -1] = 1.0 ## the last one can stay in place\n",
      "#     timeConstraint[-1, 0] = 1.0 ## the last one can go to the first one\n",
      "#     timeConstraint[-2, 0] = 1.0 ## the second to last can go to the first one\n",
      "#     timeConstraint = (1.0 - timeConstraint)*maxCost\n",
      "# #     gwv.showCustomGraph(timeConstraint)\n",
      "# #     sequence[DICT_TRANSITION_COSTS_LOCATION] = seqLoc+\"transition_costs-\"+seqName+\".npy\"\n",
      "# #     np.save(sequence[DICT_TRANSITION_COSTS_LOCATION], timeConstraint)\n",
      "# #     np.save(seqLoc+\"semantic_sequence-\"+seqName+\".npy\", sequence)\n",
      "\n",
      "\n",
      "#     print sequence[DICT_SEQUENCE_NAME]\n",
      "#     print sequence.keys()\n",
      "#     print len(sequence[DICT_BBOX_CENTERS]), len(sequence[DICT_FOOTPRINTS]), len(sequence[DICT_BBOX_ROTATIONS]), len(sequence[DICT_FRAME_SEMANTICS]),\n",
      "#     print len(sequence[DICT_BBOXES]), len(sequence[DICT_FRAMES_LOCATIONS])\n",
      "# #     np.save(sprite, sequence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for seq in np.sort(glob.glob(dataPath + dataSet + \"generatedSequence*.npy\"))[0:] :\n",
      "#     s = np.load(seq)\n",
      "#     for i in xrange(len(s)) :\n",
      "#         s[i][DICT_SEQUENCE_NAME] = s[i][\"sprite_name\"]\n",
      "#         del s[i][\"sprite_name\"]\n",
      "#         s[i][DICT_SEQUENCE_IDX] = s[i][\"sprite_idx\"]\n",
      "#         del s[i][\"sprite_idx\"]\n",
      "#     print len(s), seq\n",
      "# #     np.save(seq, s)\n",
      "# #     s[DICT_SEQUENCE_NAME] = s[\"sprite_name\"]\n",
      "# #     del s[\"sprite_name\"]\n",
      "# #     np.save(sprite, s)\n",
      "# #     print s[DICT_SEQUENCE_NAME]\n",
      "# #     s[DICT_SEQUENCE_LOCATION] = dataPath+dataSet+\"semantic_sequence-\"+s[DICT_SEQUENCE_NAME]+\".npy\"\n",
      "# #     print sprite, s[DICT_SEQUENCE_NAME]\n",
      "# #     print s.keys()\n",
      "# #     print s[DICT_SEQUENCE_LOCATION]\n",
      "# #     print len(s[DICT_BBOX_CENTERS])\n",
      "# #     np.save(s[DICT_SEQUENCE_LOCATION], s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# #### computes inter sprite compatibilities as bbox distances\n",
      "# baseLoc = \"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/\"\n",
      "# synthSequence = np.load(baseLoc+\"synthesised_sequence.npy\").item()\n",
      "\n",
      "# for seq1Idx in xrange(len(synthSequence[DICT_USED_SEQUENCES])) :\n",
      "#     for seq2Idx in xrange(seq1Idx, len(synthSequence[DICT_USED_SEQUENCES])) :\n",
      "#         seq1 = np.load(synthSequence[DICT_USED_SEQUENCES][seq1Idx]).item()\n",
      "#         seq2 = np.load(synthSequence[DICT_USED_SEQUENCES][seq2Idx]).item()\n",
      "        \n",
      "# #         print seq1[DICT_SEQUENCE_NAME], seq2[DICT_SEQUENCE_NAME]\n",
      "#         print \"inter_sequence_compatibility-bbox_dist-\" + seq1[DICT_SEQUENCE_NAME] + \"--\" + seq2[DICT_SEQUENCE_NAME] + \".npy\"\n",
      "        \n",
      "        \n",
      "\n",
      "#         bboxDistance = np.zeros((len(seq1[DICT_BBOXES]), len(seq2[DICT_BBOXES])))\n",
      "#         avgTime = 0.0\n",
      "#         for i, iKey in enumerate(np.sort(seq1[DICT_BBOXES].keys())[0:]) :\n",
      "#             t = time.time()\n",
      "#             if iKey not in seq1[DICT_FRAMES_LOCATIONS] :\n",
      "#                 bboxDistance[i, :] = 10000.0\n",
      "#             else :\n",
      "#                 for j, jKey in enumerate(np.sort(seq2[DICT_BBOXES].keys())[0:]) :\n",
      "#                     if jKey not in seq2[DICT_FRAMES_LOCATIONS] :\n",
      "#                         bboxDistance[i, j] = 10000.0\n",
      "#                     else :\n",
      "#                         bboxDistance[i, j] = getSpritesBBoxDist(seq1[DICT_BBOX_ROTATIONS][iKey],\n",
      "#                                                                 seq1[DICT_BBOXES][iKey],\n",
      "#                                                                 seq2[DICT_BBOXES][jKey])\n",
      "\n",
      "#             avgTime = (avgTime*i + time.time()-t)/(i+1)\n",
      "#             remainingTime = avgTime*(len(seq1[DICT_BBOXES])-i-1)/60.0\n",
      "\n",
      "#             if np.mod(i, 5) == 0 :\n",
      "#                 sys.stdout.write('\\r' + \"Done row \" + np.string_(i) + \" of \" + np.string_(len(seq1[DICT_BBOXES])) +\n",
      "#                                  \" (avg time: \" + np.string_(avgTime) + \" secs --- remaining: \" +\n",
      "#                                  np.string_(int(np.floor(remainingTime))) + \":\" + np.string_(int((remainingTime - np.floor(remainingTime))*60)) + \")\")\n",
      "#                 sys.stdout.flush()\n",
      "#         print        \n",
      "#         np.save(baseLoc + \"inter_sequence_compatibility-bbox_dist-\" + seq1[DICT_SEQUENCE_NAME] + \"--\" + seq2[DICT_SEQUENCE_NAME] + \".npy\", bboxDistance)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Window(QtGui.QWidget):\n",
      "    def __init__(self):\n",
      "        super(Window, self).__init__()\n",
      "        \n",
      "        self.createGUI()\n",
      "        \n",
      "        self.showLoading(False)\n",
      "        \n",
      "        self.setWindowTitle(\"Looping the Unloopable\")\n",
      "        self.resize(1920, 950)\n",
      "        \n",
      "        self.readyForVT = False\n",
      "        self.firstLoad = True\n",
      "        self.dataLocation = \"\"\n",
      "    \n",
      "    def openSequence(self) :\n",
      "        return \n",
      "        \n",
      "    def tabChanged(self, tabIdx) :\n",
      "        if tabIdx == 0 :\n",
      "            self.semanticsDefinitionTab.setFocus()\n",
      "        elif tabIdx == 1 :\n",
      "            self.semanticLoopingTab.setFocus()\n",
      "\n",
      "    def closeEvent(self, event) :\n",
      "        self.semanticLoopingTab.cleanup()\n",
      "            \n",
      "    def showLoading(self, show) :\n",
      "        if show :\n",
      "            self.loadingLabel.setText(\"Loading... Please wait\")\n",
      "            self.loadingWidget.setVisible(True)\n",
      "            self.infoLabel.setVisible(False)\n",
      "        else :\n",
      "            self.loadingWidget.setVisible(False)\n",
      "            self.infoLabel.setVisible(True)\n",
      "            \n",
      "#     def lockGUI(self, lock):\n",
      "        \n",
      "#         self.openVideoButton.setEnabled(False)#not lock)\n",
      "#         self.openSequenceButton.setEnabled(not lock)\n",
      "        \n",
      "#         if self.readyForVT :\n",
      "#             self.videoTexturesTab.lockGUI(lock)\n",
      "#         else :\n",
      "#             self.videoTexturesTab.lockGUI(True)\n",
      "#             if self.tabWidget.currentIndex() == 1 and not self.firstLoad :\n",
      "#                 QtGui.QMessageBox.warning(self, \"Pre-processing not ready\",\n",
      "#                         \"<p align='center'>The pre-processing step has not been completed<br>\"\n",
      "#                         \"Please return to the pre-processing tab and compute a distance matrix</p>\")\n",
      "#                 self.tabWidget.setCurrentIndex(0)\n",
      "            \n",
      "#         self.preProcessingTab.lockGUI(lock)\n",
      "#         self.labellingTab.lockGUI(lock)\n",
      "        \n",
      "    def createGUI(self) :\n",
      "        \n",
      "        ## WIDGETS ##\n",
      "\n",
      "        self.infoLabel = QtGui.QLabel(\"No data loaded\")\n",
      "        self.infoLabel.setSizePolicy(QtGui.QSizePolicy.Minimum, QtGui.QSizePolicy.Minimum)\n",
      "        self.infoLabel.setAlignment(QtCore.Qt.AlignLeft | QtCore.Qt.AlignTop)\n",
      "        \n",
      "#         self.openVideoButton = QtGui.QPushButton(\"Open &Video\")\n",
      "#         self.openVideoButton.setEnabled(False)\n",
      "        self.openSequenceButton = QtGui.QPushButton(\"Open &Sequence\")\n",
      "        \n",
      "        self.loadingLabel = QtGui.QLabel(\"Loading... Please wait!\")\n",
      "        self.loadingLabel.setSizePolicy(QtGui.QSizePolicy.Minimum, QtGui.QSizePolicy.Minimum)\n",
      "        self.loadingLabel.setAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignTop)\n",
      "        movie = QtGui.QMovie(\"loader.gif\")\n",
      "        self.loadingSpinner = QtGui.QLabel()\n",
      "        self.loadingSpinner.setSizePolicy(QtGui.QSizePolicy.Minimum, QtGui.QSizePolicy.Minimum)\n",
      "        self.loadingSpinner.setAlignment(QtCore.Qt.AlignHCenter | QtCore.Qt.AlignBottom)\n",
      "        self.loadingSpinner.setMovie(movie)\n",
      "        movie.start()\n",
      "        \n",
      "#         self.semanticsDefinitionTab = sdt.SemanticsDefinitionTab(self, \"/media/ilisescu/Data1/PhD/data/theme_park_sunny/\")#dataPath+dataSet)\n",
      "#         self.semanticsDefinitionTab = sdt.SemanticsDefinitionTab(self, \"/media/ilisescu/Data1/PhD/data/windows/\")#dataPath+dataSet)\n",
      "        self.semanticsDefinitionTab = sdt.SemanticsDefinitionTab(self, \"/media/ilisescu/Data1/PhD/data/digger/\")#dataPath+dataSet)\n",
      "        \n",
      "#         self.semanticLoopingTab = SemanticLoopingTab(self, 100, dataPath+\"synthesisedSequences/waveFull/synthesised_sequence.npy\")\n",
      "#         self.semanticLoopingTab = SemanticLoopingTab(self, 100, dataPath+\"synthesisedSequences/waveFullBusier/synthesised_sequence.npy\")\n",
      "#         self.semanticLoopingTab = SemanticLoopingTab(self, 250, dataPath+\"synthesisedSequences/theme_park/synthesised_sequence.npy\")\n",
      "#         self.semanticLoopingTab = SemanticLoopingTab(self, 250, dataPath+\"synthesisedSequences/theme_park_mixedCompatibility/synthesised_sequence.npy\")\n",
      "#         self.semanticLoopingTab = SemanticLoopingTab(self, 250, dataPath+\"synthesisedSequences/tetris/synthesised_sequence.npy\")\n",
      "        self.semanticLoopingTab = slt.SemanticLoopingTab(self, 500, dataPath+\"synthesisedSequences/havana_new_semantics/synthesised_sequence.npy\")\n",
      "#         self.semanticLoopingTab = SemanticLoopingTab(self, 100, dataPath+\"synthesisedSequences/multipleCandles/synthesised_sequence.npy\")\n",
      "\n",
      "        self.tabWidget = QtGui.QTabWidget()\n",
      "        self.tabWidget.addTab(self.semanticsDefinitionTab, self.tr(\"Define Semantics\"))\n",
      "        self.tabWidget.addTab(self.semanticLoopingTab, self.tr(\"Loop Semantics\"))\n",
      "        \n",
      "        ## SIGNALS ##\n",
      "        \n",
      "        self.openSequenceButton.clicked.connect(self.openSequence)\n",
      "        \n",
      "        self.tabWidget.currentChanged.connect(self.tabChanged)\n",
      "        \n",
      "        ## LAYOUTS ##\n",
      "        \n",
      "        mainBox = QtGui.QGroupBox(\"Main Controls\")\n",
      "        mainBox.setStyleSheet(\"QGroupBox { margin: 5px; border: 2px groove gray; border-radius: 3px; } QGroupBox::title {left: 15px; top: -7px; font: bold;}\")\n",
      "        mainBoxLayout = QtGui.QHBoxLayout()\n",
      "        \n",
      "        self.loadingWidget = QtGui.QWidget()\n",
      "        loadingLayout = QtGui.QHBoxLayout()\n",
      "        loadingLayout.addWidget(self.loadingSpinner)\n",
      "        loadingLayout.addWidget(self.loadingLabel)\n",
      "        self.loadingWidget.setLayout(loadingLayout)\n",
      "        \n",
      "        mainBoxLayout.addWidget(self.loadingWidget)\n",
      "        mainBoxLayout.addWidget(self.infoLabel)\n",
      "        mainBoxLayout.addStretch()\n",
      "        \n",
      "        buttonLayout = QtGui.QVBoxLayout()\n",
      "        buttonLayout.addWidget(self.openSequenceButton)\n",
      "        \n",
      "        mainBoxLayout.addLayout(buttonLayout)\n",
      "        mainBox.setLayout(mainBoxLayout)\n",
      "        \n",
      "        mainLayout = QtGui.QVBoxLayout()\n",
      "        mainLayout.addWidget(self.tabWidget)\n",
      "        mainLayout.addWidget(mainBox)\n",
      "        self.setLayout(mainLayout)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compatibilityMats = {}\n",
      "# compatibilityMats[\"00\"] = np.exp(-np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-black_car1--black_car1.npy\")/50)*10.0\n",
      "# compatibilityMats[\"01\"] = np.exp(-np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-black_car1--blue_car1.npy\")/50)*10.0\n",
      "# compatibilityMats[\"11\"] = np.exp(-np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-blue_car1--blue_car1.npy\")/50)*10.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# synthSeq = np.load(dataPath+\"synthesisedSequences/havanaComplex/synthesised_sequence.npy\").item()\n",
      "# synthSeq = np.load(dataPath+\"synthesisedSequences/theme_park/synthesised_sequence.npy\").item()\n",
      "synthSeq = np.load(dataPath+\"synthesisedSequences/theme_park_mixedCompatibility/synthesised_sequence.npy\").item()\n",
      "usedSequences = synthSeq[DICT_USED_SEQUENCES]\n",
      "semanticSequences = []\n",
      "for sequence in usedSequences :\n",
      "    semanticSequences.append(np.load(sequence).item())\n",
      "\n",
      "compatibilityMats = {}\n",
      "baseLoc = \"/\".join(semanticSequences[0][DICT_SEQUENCE_LOCATION].split(\"/\")[:-1])+\"/\"\n",
      "print baseLoc\n",
      "for i in xrange(len(semanticSequences)) :\n",
      "    for j in xrange(i, len(semanticSequences)) :\n",
      "        print \n",
      "        print np.string_(i)+\"-\"+np.string_(j), semanticSequences[i][DICT_SEQUENCE_NAME], semanticSequences[j][DICT_SEQUENCE_NAME]\n",
      "        correctLoc = baseLoc+\"inter_sequence_compatibility-bbox_dist-\"+semanticSequences[i][DICT_SEQUENCE_NAME]+\"--\"+semanticSequences[j][DICT_SEQUENCE_NAME]+\".npy\"\n",
      "        transposedLoc = baseLoc+\"inter_sequence_compatibility-bbox_dist-\"+semanticSequences[j][DICT_SEQUENCE_NAME]+\"--\"+semanticSequences[i][DICT_SEQUENCE_NAME]+\".npy\"\n",
      "        \n",
      "#         print correctLoc\n",
      "#         print transposedLoc\n",
      "        if os.path.isfile(correctLoc) :\n",
      "            print \"using correct\", correctLoc\n",
      "            compatibilityMats[np.string_(i)+\"-\"+np.string_(j)] = np.exp(-np.load(correctLoc)/50)*10.0\n",
      "            continue\n",
      "        print \"skipping correct\"\n",
      "        \n",
      "        if os.path.isfile(transposedLoc) :\n",
      "            print \"using transposed\", transposedLoc\n",
      "            compatibilityMats[np.string_(i)+\"-\"+np.string_(j)] = np.exp(-np.load(transposedLoc).T/50)*10.0\n",
      "            continue\n",
      "            \n",
      "        print \"OOOOPS\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/media/ilisescu/Data1/PhD/data/theme_park_sunny/\n",
        "\n",
        "0-0 roller_coaster1 roller_coaster1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-roller_coaster1--roller_coaster1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0-1 roller_coaster1 lift_cars1\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_cars1--roller_coaster1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0-2 roller_coaster1 lift_shadows1\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_shadows1--roller_coaster1.npy\n",
        "\n",
        "0-3 roller_coaster1 orange_flag1\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-orange_flag1--roller_coaster1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0-4 roller_coaster1 blue_flag1\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-blue_flag1--roller_coaster1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0-5 roller_coaster1 people1\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-people1--roller_coaster1.npy\n",
        "\n",
        "0-6 roller_coaster1 pendulum_ride1\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-pendulum_ride1--roller_coaster1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0-7 roller_coaster1 people2\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-people2--roller_coaster1.npy\n",
        "\n",
        "0-8 roller_coaster1 people3\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-people3--roller_coaster1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0-9 roller_coaster1 people4\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-people4--roller_coaster1.npy\n",
        "\n",
        "0-10 roller_coaster1 person1\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-person1--roller_coaster1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0-11 roller_coaster1 person2\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-person2--roller_coaster1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0-12 roller_coaster1 person3\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-person3--roller_coaster1.npy\n",
        "\n",
        "1-1 lift_cars1 lift_cars1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_cars1--lift_cars1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1-2 lift_cars1 lift_shadows1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_cars1--lift_shadows1.npy\n",
        "\n",
        "1-3 lift_cars1 orange_flag1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_cars1--orange_flag1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1-4 lift_cars1 blue_flag1\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-blue_flag1--lift_cars1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1-5 lift_cars1 people1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_cars1--people1.npy\n",
        "\n",
        "1-6 lift_cars1 pendulum_ride1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_cars1--pendulum_ride1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1-7 lift_cars1 people2\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_cars1--people2.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1-8 lift_cars1 people3\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_cars1--people3.npy\n",
        "\n",
        "1-9 lift_cars1 people4\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_cars1--people4.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1-10 lift_cars1 person1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_cars1--person1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1-11 lift_cars1 person2\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_cars1--person2.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1-12 lift_cars1 person3\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_cars1--person3.npy\n",
        "\n",
        "2-2 lift_shadows1 lift_shadows1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_shadows1--lift_shadows1.npy\n",
        "\n",
        "2-3 lift_shadows1 orange_flag1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_shadows1--orange_flag1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2-4 lift_shadows1 blue_flag1\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-blue_flag1--lift_shadows1.npy\n",
        "\n",
        "2-5 lift_shadows1 people1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_shadows1--people1.npy\n",
        "\n",
        "2-6 lift_shadows1 pendulum_ride1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_shadows1--pendulum_ride1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2-7 lift_shadows1 people2\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_shadows1--people2.npy\n",
        "\n",
        "2-8 lift_shadows1 people3\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_shadows1--people3.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2-9 lift_shadows1 people4\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_shadows1--people4.npy\n",
        "\n",
        "2-10 lift_shadows1 person1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_shadows1--person1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2-11 lift_shadows1 person2\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_shadows1--person2.npy\n",
        "\n",
        "2-12 lift_shadows1 person3\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-lift_shadows1--person3.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3-3 orange_flag1 orange_flag1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-orange_flag1--orange_flag1.npy\n",
        "\n",
        "3-4 orange_flag1 blue_flag1\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-blue_flag1--orange_flag1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3-5 orange_flag1 people1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-orange_flag1--people1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3-6 orange_flag1 pendulum_ride1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-orange_flag1--pendulum_ride1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3-7 orange_flag1 people2\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-orange_flag1--people2.npy\n",
        "\n",
        "3-8 orange_flag1 people3\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-orange_flag1--people3.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3-9 orange_flag1 people4\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-orange_flag1--people4.npy\n",
        "\n",
        "3-10 orange_flag1 person1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-orange_flag1--person1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3-11 orange_flag1 person2\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-orange_flag1--person2.npy\n",
        "\n",
        "3-12 orange_flag1 person3\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-orange_flag1--person3.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4-4 blue_flag1 blue_flag1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-blue_flag1--blue_flag1.npy\n",
        "\n",
        "4-5 blue_flag1 people1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-blue_flag1--people1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4-6 blue_flag1 pendulum_ride1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-blue_flag1--pendulum_ride1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4-7 blue_flag1 people2\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-blue_flag1--people2.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4-8 blue_flag1 people3\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-blue_flag1--people3.npy\n",
        "\n",
        "4-9 blue_flag1 people4\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-blue_flag1--people4.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4-10 blue_flag1 person1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-blue_flag1--person1.npy\n",
        "\n",
        "4-11 blue_flag1 person2\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-blue_flag1--person2.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4-12 blue_flag1 person3\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-blue_flag1--person3.npy\n",
        "\n",
        "5-5 people1 people1\n",
        "using correct /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-people1--people1.npy\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5-6 people1 pendulum_ride1\n",
        "skipping correct\n",
        "using transposed /media/ilisescu/Data1/PhD/data/theme_park_sunny/inter_sequence_compatibility-bbox_dist-pendulum_ride1--people1.npy\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-39-a732286df525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransposedLoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"using transposed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransposedLoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mcompatibilityMats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransposedLoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_memmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/numpy/lib/format.pyc\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the memory-intensive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "window = Window()\n",
      "window.show()\n",
      "app.exec_()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: STARTED CONSTRUCTOR\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE SETTING SEQUENCE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: STARTING SETTING UI\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: gne STARTING IMAGELABELDEF CONSTRUCTOR\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: IMAGELABELDEF 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: IMAGELABELDEF 2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE IMAGELABELDEF CONSTRUCTOR\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE 1a\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE 1b\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE 1c\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE 1d\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE 2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE DEFINITIONS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE SIGNALS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE SETTING UI\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE SETTING VARS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: starting loading\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: set sprite list\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: set slider\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE LOADING SPRITES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE DEFINITION TAB\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: STARTED CONSTRUCTOR\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: STARTED SETTING UI\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: DONE DEFINITIONS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: DONE SIGNALS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: DONE 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: DONE 2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: DONE 3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: DONE 4\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: DONE 5\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: DONE SETTING UI\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: DONE SETTING VARS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "STARTING LOADING\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#####################\n",
        "\n",
        "LOADED SEQUENCE /home/ilisescu/PhD/data/synthesisedSequences/havana_new_semantics/synthesised_sequence.npy\n",
        "\n",
        "#####################\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#####################\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "#####################\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "window = Window()\n",
      "window.show()\n",
      "app.exec_()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: STARTED CONSTRUCTOR\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE SETTING SEQUENCE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: STARTING SETTING UI\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: gne STARTING IMAGELABELDEF CONSTRUCTOR\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: IMAGELABELDEF 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: IMAGELABELDEF 2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE IMAGELABELDEF CONSTRUCTOR\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE 1a\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE 1b\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE 1c\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE 1d\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE 2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE DEFINITIONS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE SIGNALS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE SETTING UI\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE SETTING VARS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: starting loading\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: set sprite list\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: set slider\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE LOADING SPRITES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def: DONE DEFINITION TAB\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: STARTED CONSTRUCTOR\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: STARTED SETTING UI\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: DONE DEFINITIONS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: DONE SIGNALS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: DONE 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "synth: DONE 2\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"/home/ilisescu/PhD/data/havana/preloaded_patches-blue_car2.npy\") as f :\n",
      "    tmp = np.load(f)\n",
      "#     print tmp.item().keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ufffdNUMPY\u0001\u0000F\u0000{'descr': '|O8', 'fortran_order': False, 'shape': (), }              \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "synthSeq = np.load(\"E:/PhD/data/synthesisedSequences/tetris/synthesised_sequence.npy\").item()\n",
      "usedSequences = synthSeq[DICT_USED_SEQUENCES]\n",
      "semanticSequences = []\n",
      "for sequence in usedSequences :\n",
      "    if ON_WINDOWS : \n",
      "        sequence = \"E:/\" + \"/\".join(sequence.split(\"/\")[4:])\n",
      "    semanticSequences.append(np.load(sequence).item())\n",
      "#     print semanticSequences[-1][DICT_SEQUENCE_NAME]\n",
      "\n",
      "overlayImg = QtGui.QImage(QtCore.QSize(1280, 720), QtGui.QImage.Format_ARGB32)\n",
      "overlayImg.fill(QtGui.QColor.fromRgb(255, 255, 255, 0))\n",
      "\n",
      "painter = QtGui.QPainter(overlayImg)\n",
      "painter.setRenderHints(QtGui.QPainter.HighQualityAntialiasing)\n",
      "\n",
      "for sequenceInstance in synthSeq[DICT_SEQUENCE_INSTANCES] :\n",
      "    seqIdx = sequenceInstance[DICT_SEQUENCE_IDX]\n",
      "    offset = sequenceInstance[DICT_OFFSET]\n",
      "    scale = sequenceInstance[DICT_SCALE]\n",
      "    sequence = semanticSequences[seqIdx]\n",
      "    frameKey = sequence[DICT_BBOXES].keys()[0]\n",
      "#     print sequence[DICT_BBOXES][frameKey], scale, offset    \n",
      "                \n",
      "    scaleTransf = np.array([[scale[0], 0.0], [0.0, scale[1]]])\n",
      "    offsetTransf = np.array([[offset[0]], [offset[1]]])\n",
      "    \n",
      "    if offset[0] == 0 and offset[1] == 0 :\n",
      "        painter.setPen(QtGui.QPen(QtGui.QColor.fromRgb(0, 255, 0, 255), 1, \n",
      "                                  QtCore.Qt.SolidLine, QtCore.Qt.RoundCap, QtCore.Qt.RoundJoin))\n",
      "    else :\n",
      "        painter.setPen(QtGui.QPen(QtGui.QColor.fromRgb(0, 0, 255, 255), 1, \n",
      "                                  QtCore.Qt.SolidLine, QtCore.Qt.RoundCap, QtCore.Qt.RoundJoin))\n",
      "        \n",
      "    bbox = sequence[DICT_BBOXES][frameKey]\n",
      "    transformedBBox = (np.dot(scaleTransf, bbox.T) + offsetTransf)\n",
      "    \n",
      "    x, y = transformedBBox[:, 0]\n",
      "    width, height = transformedBBox[:, 2] - transformedBBox[:, 0]\n",
      "    painter.drawRoundedRect(x, y, width, height, 3, 3)\n",
      "\n",
      "#     for p1, p2 in zip(np.mod(arange(4), 4), np.mod(arange(1, 5), 4)) :\n",
      "#         painter.drawLine(QtCore.QPointF(transformedBBox[0, p1], transformedBBox[1, p1]), QtCore.QPointF(transformedBBox[0, p2], transformedBBox[1, p2]))\n",
      "    \n",
      "    \n",
      "    painter.setPen(QtGui.QPen(QtGui.QColor.fromRgb(255, 255, 0, 255), 1, \n",
      "                              QtCore.Qt.SolidLine, QtCore.Qt.RoundCap, QtCore.Qt.RoundJoin))\n",
      "    painter.drawText(transformedBBox[0, 0]+5, transformedBBox[1, 0], \n",
      "                     transformedBBox[0, 2]-transformedBBox[0, 0]-5, 20, QtCore.Qt.AlignLeft, np.string_(seqIdx))\n",
      "\n",
      "print overlayImg.save(\"C:/Users/ilisescu/Desktop/bboxes.png\")\n",
      "painter.end()\n",
      "del painter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: 'E:/PhD/data/synthesisedSequences/tetris/synthesised_sequence.npy'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-54-001aa8757e26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msynthSeq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"E:/PhD/data/synthesisedSequences/tetris/synthesised_sequence.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0musedSequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynthSeq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDICT_USED_SEQUENCES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msemanticSequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musedSequences\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mON_WINDOWS\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'E:/PhD/data/synthesisedSequences/tetris/synthesised_sequence.npy'"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "paths = np.sort(glob.glob(\"E:/PhD/data/wave1/semantic_sequence-*.npy\"))\n",
      "semanticSequences = []\n",
      "for sequence in paths :\n",
      "    semanticSequences.append(np.load(sequence).item())\n",
      "    print semanticSequences[-1][DICT_SEQUENCE_NAME]\n",
      "\n",
      "overlayImg = QtGui.QImage(QtCore.QSize(1280, 720), QtGui.QImage.Format_ARGB32)\n",
      "overlayImg.fill(QtGui.QColor.fromRgb(255, 255, 255, 0))\n",
      "\n",
      "painter = QtGui.QPainter(overlayImg)\n",
      "painter.setRenderHints(QtGui.QPainter.HighQualityAntialiasing)\n",
      "\n",
      "for seqIdx in xrange(len(semanticSequences)) :\n",
      "    offset = np.array([0.0, 0.0])\n",
      "    scale = np.array([1.0, 1.0])\n",
      "    sequence = semanticSequences[seqIdx]\n",
      "    frameKey = np.sort(sequence[DICT_BBOXES].keys())[0]\n",
      "#     frameKey = np.sort(sequence[DICT_BBOXES].keys())[450]\n",
      "#     if seqIdx == 7 :\n",
      "#         frameKey = np.sort(sequence[DICT_BBOXES].keys())[-70]\n",
      "#         print sequence[DICT_BBOXES][frameKey], scale, offset    \n",
      "                \n",
      "    scaleTransf = np.array([[scale[0], 0.0], [0.0, scale[1]]])\n",
      "    offsetTransf = np.array([[offset[0]], [offset[1]]])\n",
      "    \n",
      "    if offset[0] == 0 and offset[1] == 0 :\n",
      "        painter.setPen(QtGui.QPen(QtGui.QColor.fromRgb(0, 255, 0, 255), 3, \n",
      "                                  QtCore.Qt.SolidLine, QtCore.Qt.RoundCap, QtCore.Qt.RoundJoin))\n",
      "    else :\n",
      "        painter.setPen(QtGui.QPen(QtGui.QColor.fromRgb(0, 0, 255, 255), 1, \n",
      "                                  QtCore.Qt.SolidLine, QtCore.Qt.RoundCap, QtCore.Qt.RoundJoin))\n",
      "        \n",
      "    bbox = sequence[DICT_BBOXES][frameKey]\n",
      "    transformedBBox = (np.dot(scaleTransf, bbox.T) + offsetTransf)\n",
      "    \n",
      "    x, y = transformedBBox[:, 0]\n",
      "    width, height = transformedBBox[:, 2] - transformedBBox[:, 0]\n",
      "    painter.drawRoundedRect(x, y, width, height, 3, 3)\n",
      "\n",
      "#     for p1, p2 in zip(np.mod(arange(4), 4), np.mod(arange(1, 5), 4)) :\n",
      "#         painter.drawLine(QtCore.QPointF(transformedBBox[0, p1], transformedBBox[1, p1]), QtCore.QPointF(transformedBBox[0, p2], transformedBBox[1, p2]))\n",
      "    \n",
      "    \n",
      "    painter.setPen(QtGui.QPen(QtGui.QColor.fromRgb(255, 255, 0, 255), 1, \n",
      "                              QtCore.Qt.SolidLine, QtCore.Qt.RoundCap, QtCore.Qt.RoundJoin))\n",
      "    painter.drawText(transformedBBox[0, 0]+5, transformedBBox[1, 0], \n",
      "                     transformedBBox[0, 2]-transformedBBox[0, 0]-5, 20, QtCore.Qt.AlignLeft, np.string_(seqIdx))\n",
      "\n",
      "print overlayImg.save(\"C:/Users/ilisescu/Desktop/bboxes.png\")\n",
      "painter.end()\n",
      "del painter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "aron1\n",
        "daniel1\n",
        "ferran1\n",
        "james1\n",
        "moos1\n",
        "peter1\n",
        "sara1\n",
        "tara1\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "synthSeq = np.load(dataPath+\"synthesisedSequences/digger/synthesised_sequence.npy\").item()\n",
      "usedSequences = synthSeq[DICT_USED_SEQUENCES]\n",
      "semanticSequences = []\n",
      "for sequence in usedSequences :\n",
      "    semanticSequences.append(np.load(sequence).item())\n",
      "    print semanticSequences[-1][DICT_SEQUENCE_NAME]\n",
      "    \n",
      "## 0 is compatible, 1 is incompatible\n",
      "## digger semantics (scooping, dropping)\n",
      "## truck semantics (moving, receiving dirt)\n",
      "## digger is rows, truck is columns\n",
      "## if digger is scooping, truck can move or receive\n",
      "## if digger is dropping, truck can't move, just receive\n",
      "hardcodedSemanticCompatibility = np.array([[0, 0], [1, 0]])\n",
      "print hardcodedSemanticCompatibility\n",
      "semanticCompatibilityCost = np.zeros((semanticSequences[0][DICT_FRAME_SEMANTICS].shape[0],\n",
      "                                      semanticSequences[1][DICT_FRAME_SEMANTICS].shape[0]), bool)\n",
      "thresh = 0.7\n",
      "for incompatibleCombination in np.argwhere(hardcodedSemanticCompatibility == 1) :\n",
      "    print incompatibleCombination\n",
      "    seq1Sems = (semanticSequences[0][DICT_FRAME_SEMANTICS][:, incompatibleCombination[0]] > thresh).reshape((len(semanticSequences[0][DICT_FRAME_SEMANTICS]), 1))\n",
      "    seq2Sems = (semanticSequences[1][DICT_FRAME_SEMANTICS][:, incompatibleCombination[1]] > thresh).reshape((1, len(semanticSequences[1][DICT_FRAME_SEMANTICS])))\n",
      "    \n",
      "    semanticCompatibilityCost = semanticCompatibilityCost | (seq1Sems & seq2Sems)\n",
      "    \n",
      "\n",
      "compatibilityMats = {}\n",
      "compatibilityMats[\"0-0\"] = np.zeros((len(semanticSequences[0][DICT_FRAME_SEMANTICS]), len(semanticSequences[0][DICT_FRAME_SEMANTICS])))\n",
      "compatibilityMats[\"0-1\"] = semanticCompatibilityCost*GRAPH_MAX_COST\n",
      "compatibilityMats[\"1-1\"] = np.zeros((len(semanticSequences[1][DICT_FRAME_SEMANTICS]), len(semanticSequences[1][DICT_FRAME_SEMANTICS])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "digger_right1\n",
        "truck_right1\n",
        "[[0 0]\n",
        " [1 0]]\n",
        "[1 0]\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(compatibilityMats[\"0-1\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "synthSeq = np.load(dataPath+\"synthesisedSequences/multipleCandles/synthesised_sequence.npy\").item()\n",
      "usedSequences = synthSeq[DICT_USED_SEQUENCES]\n",
      "semanticSequences = []\n",
      "for sequence in usedSequences :\n",
      "    semanticSequences.append(np.load(sequence).item())\n",
      "    print semanticSequences[-1][DICT_SEQUENCE_NAME]\n",
      "    \n",
      "## 0 is compatible, 1 is incompatible\n",
      "## candle has 3 labels, and two candles are compatible only if they show the same label\n",
      "hardcodedSemanticCompatibility = np.array([[0, 1, 1], [1, 0, 1], [1, 1, 0]])\n",
      "print hardcodedSemanticCompatibility\n",
      "semanticCompatibilityCost = np.zeros((semanticSequences[0][DICT_FRAME_SEMANTICS].shape[0],\n",
      "                                      semanticSequences[0][DICT_FRAME_SEMANTICS].shape[0]), bool)\n",
      "thresh = 0.9\n",
      "for incompatibleCombination in np.argwhere(hardcodedSemanticCompatibility == 1) :\n",
      "    print incompatibleCombination\n",
      "    seq1Sems = (semanticSequences[0][DICT_FRAME_SEMANTICS][:, incompatibleCombination[0]] > thresh).reshape((len(semanticSequences[0][DICT_FRAME_SEMANTICS]), 1))\n",
      "    seq2Sems = (semanticSequences[0][DICT_FRAME_SEMANTICS][:, incompatibleCombination[1]] > thresh).reshape((1, len(semanticSequences[0][DICT_FRAME_SEMANTICS])))\n",
      "    \n",
      "    semanticCompatibilityCost = semanticCompatibilityCost | (seq1Sems & seq2Sems)\n",
      "    \n",
      "\n",
      "compatibilityMats = {}\n",
      "compatibilityMats[\"0-0\"] = semanticCompatibilityCost*GRAPH_MAX_COST"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "candle_wind1\n",
        "[[0 1 1]\n",
        " [1 0 1]\n",
        " [1 1 0]]\n",
        "[0 1]\n",
        "[0 2]\n",
        "[1 0]\n",
        "[1 2]\n",
        "[2 0]\n",
        "[2 1]\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## newest compute transition costs\n",
      "filterSize = 4\n",
      "threshPercentile = 0.1 ## percentile of transitions to base threshold on\n",
      "minJumpLength = 20\n",
      "onlyBackwards = True ## indicates if only backward jumps need filtering out (i.e. the syntehsised sequence can be sped up but not slowed down)\n",
      "loopOnLast = True ## indicates if an empty frame has been added at the end of the sequence that the synthesis can keep showing without concenquences\n",
      "sigmaMultiplier = 0.002\n",
      "for seqLoc in np.sort(glob.glob(\"/home/ilisescu/PhD/data/street/semantic_sequence*.npy\"))[1:2] :\n",
      "    testSequence = np.load(seqLoc).item()\n",
      "    print testSequence[DICT_SEQUENCE_NAME]\n",
      "    distMat = np.load(testSequence['sequence_precomputed_distance_matrix_location'])\n",
      "#     gwv.showCustomGraph(distMat)\n",
      "    \n",
      "    ## filter to preserve dynamics\n",
      "    kernel = np.eye(filterSize*2+1)\n",
      "    \n",
      "    optimizedDistMat = cv2.filter2D(distMat, -1, kernel)\n",
      "    correction = 1\n",
      "    \n",
      "#     gwv.showCustomGraph(optimizedDistMat)\n",
      "    \n",
      "    ## init costs\n",
      "#     testCosts = np.zeros_like(optimizedDistMat)\n",
      "#     testCosts[0:-1, 0:-1] = np.copy(optimizedDistMat[1:, 0:-1])\n",
      "#     testCosts[-1, 1:] = optimizedDistMat\n",
      "    testCosts = np.copy(np.roll(optimizedDistMat, 1, axis=1))    \n",
      "    \n",
      "    # find threshold to use based on percentile\n",
      "    thresh = np.sort(testCosts.flatten())[int(len(testCosts.flatten())*threshPercentile)]\n",
      "    print \"THRESH\", thresh\n",
      "    \n",
      "    sigma = np.average(testCosts)*sigmaMultiplier\n",
      "    \n",
      "    ## don't want to jump too close so increase costs in a window\n",
      "    if onlyBackwards :\n",
      "        tmp = (np.triu(np.ones(optimizedDistMat.shape), k=2) +\n",
      "               np.tril(np.ones(optimizedDistMat.shape), k=-minJumpLength) +\n",
      "               np.eye(optimizedDistMat.shape[0], k=1))\n",
      "    else :\n",
      "        tmp = (np.triu(np.ones(optimizedDistMat.shape), k=minJumpLength) +\n",
      "               np.tril(np.ones(optimizedDistMat.shape), k=-minJumpLength) +\n",
      "               np.eye(optimizedDistMat.shape[0], k=1))\n",
      "    tmp[tmp == 0] = 10.0\n",
      "    testCosts *= tmp\n",
      "    \n",
      "    \n",
      "    ## actual filtering\n",
      "    invalidJumps = testCosts > thresh\n",
      "    testCosts[invalidJumps] = GRAPH_MAX_COST\n",
      "    testCosts[np.negative(invalidJumps)] = np.exp(testCosts[np.negative(invalidJumps)]/sigma)\n",
      "    \n",
      "    \n",
      "#     ## adding extra rows and columns to compensate for the index shift indicated by correction\n",
      "#     testCosts = np.concatenate((testCosts,\n",
      "#                                 np.ones((testCosts.shape[0], correction))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=1)\n",
      "#     testCosts = np.concatenate((testCosts,\n",
      "#                                 np.ones((correction, testCosts.shape[1]))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=0)\n",
      "    \n",
      "#     ## setting transition from N-1 to N to minCost\n",
      "#     testCosts[-2, -1] = np.min(testCosts)\n",
      "    \n",
      "    if loopOnLast :\n",
      "        ## setting the looping from the last frame\n",
      "        testCosts[-2, 0] = 0.0#np.min(testCosts)\n",
      "        ## setting the looping from the empty frame and in place looping\n",
      "        testCosts[-1, 0] = testCosts[-1, -1] = 0.0#np.min(testCosts)\n",
      "    else :\n",
      "        testCosts[-1, 0] = np.max(testCosts)\n",
      "    \n",
      "    gwv.showCustomGraph(testCosts)\n",
      "    \n",
      "    testSequence[DICT_TRANSITION_COSTS_LOCATION] = \"/\".join(seqLoc.split(\"/\")[:-1])+\"/\"+\"transition_costs_no_normalization-\"+testSequence[DICT_SEQUENCE_NAME]+\".npy\"\n",
      "    print \n",
      "    print testSequence[DICT_TRANSITION_COSTS_LOCATION], testCosts.shape\n",
      "    print \"------------------\"\n",
      "#     np.save(testSequence[DICT_TRANSITION_COSTS_LOCATION], testCosts)\n",
      "#     np.save(testSequence[DICT_SEQUENCE_LOCATION], testSequence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "blue_car1\n",
        "THRESH 667.487342435\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ilisescu/PhD/data/street/transition_costs_no_normalization-blue_car1.npy (115, 115)\n",
        "------------------\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(np.load(\"/home/ilisescu/PhD/data/street/transition_costs_no_normalization-blue_car1.npy\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(np.load(np.load(\"/home/ilisescu/PhD/data/street/semantic_sequence-blue_car1.npy\").item()[DICT_TRANSITION_COSTS_LOCATION]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## compute transition costs\n",
      "# synthSequence = np.load(dataPath+\"synthesisedSequences/wave-batch_ish_changed_slightly_where_asking_sems_too_long/synthesised_sequence.npy\").item()\n",
      "# synthSequence = np.load(dataPath+\"synthesisedSequences/lullaby/synthesised_sequence.npy\").item()\n",
      "# synthSequence = np.load(dataPath+\"synthesisedSequences/newHavana/synthesised_sequence.npy\").item()\n",
      "\n",
      "isLooping = True ## tells me that I'm using a sprite that loops back and I added an extra frame to it\n",
      "loopOnLast = True\n",
      "onlyBackwards = False\n",
      "# for seqLoc in synthSequence[DICT_USED_SEQUENCES] :\n",
      "# for seqLoc in np.sort(glob.glob(\"/home/ilisescu/PhD/data/havana/semantic_sequence*.npy\"))[[0]] :\n",
      "# for seqLoc in np.sort(glob.glob(\"/media/ilisescu/Data1/PhD/data/elevators/semantic_sequence*.npy\")) :\n",
      "# for seqLoc in np.sort(glob.glob(\"/media/ilisescu/Data1/PhD/data/wave1/semantic_sequence*.npy\"))[0:1] :\n",
      "# for seqLoc in np.sort(glob.glob(\"/media/ilisescu/Data1/PhD/data/toy/semantic_sequence*.npy\"))[0:1] :\n",
      "for seqLoc in np.sort(glob.glob(\"/home/ilisescu/PhD/data/street/semantic_sequence*.npy\"))[2:3] :\n",
      "    testSequence = np.load(seqLoc).item()\n",
      "    # print testSequence[DICT_TRANSITION_COSTS_LOCATION]\n",
      "#     distMat = np.load(\"/\".join(seqLoc.split(\"/\")[:-1])+\"/\"+testSequence[DICT_SEQUENCE_NAME]+\"-vanilla_distMat.npy\")\n",
      "#     distMat = np.load(\"/\".join(seqLoc.split(\"/\")[:-1])+\"/\"+testSequence[DICT_SEQUENCE_NAME]+\"-new_overlap_norm_distMat.npy\")\n",
      "    distMat = np.load(testSequence['sequence_precomputed_distance_matrix_location'])\n",
      "    ## filter ##\n",
      "    filterSize = 4\n",
      "#     optimizedDistMat = vtu.filterDistanceMatrix(distMat, filterSize, True)\n",
      "    gwv.showCustomGraph(distMat)\n",
      "    \n",
      "    if False :\n",
      "        coeff = special.binom(filterSize*2, range(0, filterSize*2 +1))\n",
      "        kernel = np.eye(len(coeff))\n",
      "        kernel = kernel*coeff/np.sum(coeff)\n",
      "    else :\n",
      "        kernel = np.eye(filterSize*2+1)\n",
      "        \n",
      "    optimizedDistMat = cv2.filter2D(distMat, -1, kernel)\n",
      "\n",
      "    ## if using vanilla\n",
      "    if True :\n",
      "        optimizedDistMat = optimizedDistMat[1:optimizedDistMat.shape[1], 0:-1]\n",
      "        correction = 1\n",
      "    else :\n",
      "        correction = 0\n",
      "    \n",
      "    ################# THIS ACCOUNTS FOR THE FACT THAT I DIDN'T NORMALIZE THE DISTMAT BY NUM OF PIXELS FOR THE WAVE SEQUENCES #################\n",
      "#     maxArea = 0.0\n",
      "#     for bboxKey in np.sort(testSequence[DICT_BBOXES].keys()) :\n",
      "#         maxArea = np.max((maxArea, np.prod(np.max(testSequence[DICT_BBOXES][bboxKey], axis=0) - np.min(testSequence[DICT_BBOXES][bboxKey], axis=0))))\n",
      "#     print maxArea\n",
      "#     optimizedDistMat /= (maxArea*2) # np.max(optimizedDistMat)\n",
      "    \n",
      "    ##########################################################################################################################################\n",
      "    \n",
      "    ## exponential\n",
      "#     testCosts = np.exp(np.copy(optimizedDistMat)/(np.average(optimizedDistMat)*0.1))\n",
      "#     testCosts = np.exp(np.copy(1.0+optimizedDistMat)/(np.average(1.0+optimizedDistMat)*0.002))\n",
      "\n",
      "    testCosts = np.copy(optimizedDistMat)\n",
      "    \n",
      "    threshPercentile = 0.1\n",
      "#     threshPercentile = 0.05\n",
      "        \n",
      "    print np.max(testCosts), np.min(testCosts), np.sort(testCosts.flatten())[int(len(testCosts.flatten())*threshPercentile)], int(len(testCosts.flatten())*threshPercentile)\n",
      "    thresh = np.sort(testCosts.flatten())[int(len(testCosts.flatten())*threshPercentile)]\n",
      "    print np.sort(testCosts.flatten())\n",
      "    print \"THRESH\", thresh\n",
      "    \n",
      "    ## don't want to jump too close so increase costs in a window\n",
      "    minJumpLength = 20\n",
      "    if onlyBackwards :\n",
      "        tmp = (np.triu(np.ones(optimizedDistMat.shape), k=2) +\n",
      "               np.tril(np.ones(optimizedDistMat.shape), k=-minJumpLength) +\n",
      "               np.eye(optimizedDistMat.shape[0], k=1))\n",
      "    else :\n",
      "        tmp = (np.triu(np.ones(optimizedDistMat.shape), k=minJumpLength) +\n",
      "               np.tril(np.ones(optimizedDistMat.shape), k=-minJumpLength) +\n",
      "               np.eye(optimizedDistMat.shape[0], k=1))\n",
      "    tmp[tmp == 0] = 100.0\n",
      "#     optimizedDistMat *= tmp\n",
      "    testCosts *= tmp\n",
      "    #########################################\n",
      "    \n",
      "    print np.max(testCosts), np.min(testCosts), np.sort(testCosts.flatten())[int(len(testCosts.flatten())*threshPercentile)], int(len(testCosts.flatten())*threshPercentile)\n",
      "\n",
      "    ## exponential\n",
      "    testCosts = np.exp(np.copy(testCosts)/(np.average(testCosts)*0.01)) ## this does the same as above and interestingly has the same semantic importance as above after binary search WTF???\n",
      "\n",
      "    ######## I'M FULL OF SHIT --> THEY SHOULD ALL WORK, PROBLEM WAS THAT TARA'S SPRITE I WAS LOOKING AT HAPPENED TO SWITCH LABEL AROUND THE 100 FRAME MARK \n",
      "    ######## (JUMPING OVER THE SMOOTHSTEP TRANSITION MOST LIKELY)\n",
      "    ######## SO WITHOUT A HIGH ENOUGH SEMANTIC IMPORTANCE, THE LAST FRAMES OF THE FIRST SEQUENCE WOULDN'T GET THE RIGHT SEMANTIC AND THEN FROM THERE ON\n",
      "    ######## IT'S PRETTY HARD TO SWITCH THE LABEL IMMEDITALEY WITHOUT THE SMOOTHSTEP TRANSITION\n",
      "\n",
      "    #########################################\n",
      "    ## do the thresholding based on how many jumps I want to keep per frame\n",
      "    desiredPercentage = 0.1 ## desired percentage of transitions to keep\n",
      "#     desiredPercentage = 0.05 ## desired percentage of transitions to keep\n",
      "    jumpsToKeep = int(testCosts.shape[0]*desiredPercentage)\n",
      "    testCosts[np.arange(testCosts.shape[0]).repeat(testCosts.shape[0]-jumpsToKeep),\n",
      "                           np.argsort(testCosts, axis=-1)[:, jumpsToKeep:].flatten()] = GRAPH_MAX_COST\n",
      "    invalidJumps = testCosts > thresh\n",
      "#     testCosts[testCosts > thresh] = GRAPH_MAX_COST\n",
      "    \n",
      "    ## exponential\n",
      "#     testCosts = np.exp(np.copy(optimizedDistMat)/(np.average(optimizedDistMat)*0.1))\n",
      "#     testCosts = np.exp(np.copy(1.0+testCosts)/(np.average(1.0+testCosts)*0.05))\n",
      "#     testCosts[testCosts > thresh] = GRAPH_MAX_COST\n",
      "\n",
      "\n",
      "    ## adding extra rows and columns so that the optimized matrix has the same dimensions as distMat\n",
      "    ## for the indices that were cut out I put zero cost for jumps to frames that can still be used after optimization\n",
      "    if isLooping :\n",
      "        ########## it means I deal with sprites like the havana cars ##########\n",
      "#         testCosts = np.concatenate((np.ones((testCosts.shape[0], filterSize))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts),\n",
      "#                                     testCosts,\n",
      "#                                     (1.0-np.eye(testCosts.shape[0], filterSize+correction+1, k=-testCosts.shape[0]+1))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=1)\n",
      "#         ## the +1 is because if a sprite is looping, the last frame is the empty frame\n",
      "#         testCosts = np.concatenate(((1.0-np.eye(filterSize, distMat.shape[0]+1, k=1))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts),\n",
      "#                                     testCosts,\n",
      "#                                     (1.0-np.eye(filterSize+correction+1, distMat.shape[0]+1, k=distMat.shape[0]+1-filterSize-correction))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=0)\n",
      "\n",
      "        testCosts = np.concatenate((testCosts,\n",
      "                                    (1.0-np.eye(testCosts.shape[0], correction+1, k=-testCosts.shape[0]+1))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=1)\n",
      "        ## the +1 is because if a sprite is looping, the last frame is the empty frame\n",
      "        testCosts = np.concatenate((testCosts,\n",
      "                                    (1.0-np.eye(correction+1, distMat.shape[0]+1, k=distMat.shape[0]+1-correction))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=0)\n",
      "\n",
      "        if loopOnLast :\n",
      "            ## setting the looping from the last frame\n",
      "            testCosts[-2, 0] = 0.0#np.min(testCosts)\n",
      "            ## setting the looping from the empty frame and in place looping\n",
      "            testCosts[-1, 0] = testCosts[-1, -1] = 0.0#np.min(testCosts)\n",
      "        else :\n",
      "            testCosts[-1, 0] = 0.0#np.min(testCosts)\n",
      "    else :\n",
      "#         testCosts = np.concatenate((np.ones((testCosts.shape[0], filterSize))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts),\n",
      "#                                     testCosts,\n",
      "#                                     np.ones((testCosts.shape[0], filterSize+correction))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=1)\n",
      "#         testCosts = np.concatenate((np.roll(np.concatenate((np.zeros((filterSize, 1)) + np.min(testCosts),\n",
      "#                                                             np.ones((filterSize, distMat.shape[0]-1))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=1), filterSize, axis=1),\n",
      "#                                     testCosts,\n",
      "#                                     np.roll(np.concatenate((np.zeros((filterSize+correction, 1)) + np.min(testCosts),\n",
      "#                                                             np.ones((filterSize+correction, distMat.shape[0]-1))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=1), filterSize, axis=1)), axis=0)\n",
      "        \n",
      "        testCosts = np.concatenate((testCosts,\n",
      "                                    np.ones((testCosts.shape[0], correction))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=1)\n",
      "        testCosts = np.concatenate((testCosts,\n",
      "                                    np.roll(np.concatenate((np.zeros((correction, 1)) + np.min(testCosts),\n",
      "                                                            np.ones((correction, distMat.shape[0]-1))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=1), 0, axis=1)), axis=0)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    gwv.showCustomGraph(testCosts)\n",
      "#     print testSequence[DICT_TRANSITION_COSTS_LOCATION]\n",
      "    testSequence[DICT_TRANSITION_COSTS_LOCATION] = \"/\".join(seqLoc.split(\"/\")[:-1])+\"/\"+\"transition_costs_no_normalization-\"+testSequence[DICT_SEQUENCE_NAME]+\".npy\"\n",
      "    print \n",
      "    print testSequence[DICT_TRANSITION_COSTS_LOCATION], testCosts.shape\n",
      "    print \"------------------\"\n",
      "#     np.save(testSequence[DICT_TRANSITION_COSTS_LOCATION], testCosts)\n",
      "#     np.save(testSequence[DICT_SEQUENCE_LOCATION], testSequence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "124374.045598 -2.1027517505e-09 642.115044415 7507\n",
        "[ -2.10275175e-09  -2.08092388e-09  -1.67347025e-09 ...,   1.24293284e+05\n",
        "   1.24374046e+05   1.24374046e+05]\n",
        "THRESH 642.115044415\n",
        "1682048.43599 -2.1027517505e-09 1199.43896906 7507\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ilisescu/PhD/data/street/transition_costs_no_normalization-grey_car1.npy (276, 276)\n",
        "------------------\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.load(\"/home/ilisescu/PhD/data/havana/transition_costs_no_normalization-black_car1.npy\")[21, 336]\n",
      "gwv.showCustomGraph(np.load(\"/home/ilisescu/PhD/data/havana/transition_costs_no_normalization-black_car1.npy\"))\n",
      "print testCosts[21, 336]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9272.12138603\n",
        "9272.12138603"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(np.load(\"/media/ilisescu/Data1/PhD/data/toy/transition_costs_no_normalization_-toy1.npy\"))\n",
      "tmp = np.argwhere(np.load(\"/media/ilisescu/Data1/PhD/data/toy/transition_costs_no_normalization_-toy1.npy\") != GRAPH_MAX_COST)\n",
      "print [len(np.argwhere(tmp[:, 0] == i)) for i in xrange(606)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1, 1, 1, 1, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 1, 1, 1, 1, 1]\n"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(np.argwhere(testCosts != GRAPH_MAX_COST))/float(896*896)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.199555066167\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(invalidJumps)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = np.load(\"/home/ilisescu/PhD/data/havana/transition_costs_no_normalization_-black_car1.npy\")\n",
      "np.min(tmp[tmp != GRAPH_MAX_COST]-testCosts[tmp != GRAPH_MAX_COST])\n",
      "# gwv.showCustomGraph(tmp-testCosts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "0.0"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## code to turn a sprite straight from the merging UI into a semantic sequence\n",
      "# seqLoc = \"/media/ilisescu/Data1/PhD/data/theme_park_sunny/\"\n",
      "# seqLoc = \"/media/ilisescu/Data1/PhD/data/windows/\"\n",
      "# seqLoc = \"/media/ilisescu/Data1/PhD/data/digger/\"\n",
      "seqLoc = \"/home/ilisescu/PhD/data/havana/\"\n",
      "\n",
      "loopingSequences = np.ones(4, bool) #np.array([False, False, True, True, True, True, True, True, True, True, True, True, True])\n",
      "\n",
      "for spriteLoc, loopingSequence in zip(np.sort(glob.glob(seqLoc+\"sprite-*.npy\"))[[1, 5, 6, 9]], loopingSequences) :\n",
      "    sequence = np.load(spriteLoc).item()\n",
      "    seqName = sequence[DICT_SEQUENCE_NAME]\n",
      "    print seqName, loopingSequence#, sequence.keys()\n",
      "    \n",
      "    if loopingSequence :\n",
      "        print \"adding extra frame for looping\"\n",
      "        sequence[DICT_BBOXES][np.max(sequence[DICT_FRAMES_LOCATIONS].keys())+1] = np.zeros((4, 2))\n",
      "        sequence[DICT_BBOX_CENTERS][np.max(sequence[DICT_FRAMES_LOCATIONS].keys())+1] = np.zeros(2)\n",
      "        sequence[DICT_BBOX_ROTATIONS][np.max(sequence[DICT_FRAMES_LOCATIONS].keys())+1] = 0.0\n",
      "        \n",
      "        if DICT_FOOTPRINTS in sequence.keys() :\n",
      "            sequence[DICT_FOOTPRINTS][np.max(sequence[DICT_FRAMES_LOCATIONS].keys())+1] = np.zeros((4, 2))\n",
      "\n",
      "    if DICT_MASK_LOCATION not in sequence.keys() :\n",
      "        print \"setting mask location\"\n",
      "        sequence[DICT_MASK_LOCATION] = seqLoc + sequence[DICT_SEQUENCE_NAME] + \"-maskedFlow-blended/\"\n",
      "\n",
      "    if DICT_FOOTPRINTS not in sequence.keys() :\n",
      "        print \"setting footprints\"\n",
      "        sequence[DICT_FOOTPRINTS] = sequence[DICT_BBOXES]\n",
      "\n",
      "    if DICT_SEQUENCE_LOCATION not in sequence.keys() :\n",
      "        print \"setting sequence location\"\n",
      "        sequence[DICT_SEQUENCE_LOCATION] = seqLoc + \"semantic_sequence-\" + sequence[DICT_SEQUENCE_NAME] + \".npy\"\n",
      "\n",
      "    if True and DICT_PATCHES_LOCATION not in sequence.keys() :\n",
      "        print \"setting preloaded patches\"\n",
      "#         currentSequencePatches = {}\n",
      "#         for frameKey in np.sort(sequence[DICT_FRAMES_LOCATIONS].keys()) :\n",
      "#             frameName = sequence[DICT_FRAMES_LOCATIONS][frameKey].split(os.sep)[-1]\n",
      "#             maskDir = sequence[DICT_MASK_LOCATION]\n",
      "\n",
      "#             if os.path.isdir(maskDir) and os.path.exists(maskDir+\"/\"+frameName) :\n",
      "#                 im = np.array(cv2.imread(maskDir+\"/\"+frameName, cv2.CV_LOAD_IMAGE_UNCHANGED), dtype=np.uint8)\n",
      "\n",
      "#                 visiblePixels = np.argwhere(im[:, :, -1] != 0)\n",
      "#                 topLeft = np.min(visiblePixels, axis=0)\n",
      "#                 patchSize = np.max(visiblePixels, axis=0) - topLeft + 1\n",
      "\n",
      "#                 currentSequencePatches[frameKey] = {'top_left_pos':topLeft, 'sprite_colors':im[visiblePixels[:, 0], visiblePixels[:, 1], :], \n",
      "#                                                    'visible_indices': visiblePixels-topLeft, 'patch_size': patchSize}\n",
      "\n",
      "#             sys.stdout.write('\\r' + \"Loaded image \" + np.string_(len(currentSequencePatches)) + \" (\" + np.string_(len(sequence[DICT_FRAMES_LOCATIONS])) + \")\")\n",
      "#             sys.stdout.flush()\n",
      "#         print \n",
      "        sequence[DICT_PATCHES_LOCATION] = seqLoc+\"preloaded_patches-\"+seqName+\".npy\"\n",
      "#         np.save(sequence[DICT_PATCHES_LOCATION], currentSequencePatches)\n",
      "\n",
      "    if DICT_FRAME_SEMANTICS not in sequence.keys() :\n",
      "        print \"setting frame semantics\",\n",
      "        if loopingSequence :\n",
      "            print \"LOOPING\"\n",
      "            sequence[DICT_FRAME_SEMANTICS] = np.concatenate((np.concatenate((np.zeros((len(sequence[DICT_FRAMES_LOCATIONS]), 1)),\n",
      "                                                                             np.ones((len(sequence[DICT_FRAMES_LOCATIONS]), 1))), axis=1),\n",
      "                                                             np.array([[1.0, 0.0]])), axis=0)\n",
      "        else :\n",
      "            print\n",
      "            sequence[DICT_FRAME_SEMANTICS] = np.ones((len(sequence[DICT_FRAMES_LOCATIONS]), 1))\n",
      "    else :\n",
      "        if loopingSequence :\n",
      "            print \"adding [1, 0] semantics at the end\"\n",
      "            sequence[DICT_FRAME_SEMANTICS] = np.concatenate((np.concatenate((np.zeros((len(sequence[DICT_FRAME_SEMANTICS]), 1)), sequence[DICT_FRAME_SEMANTICS]), axis=1),\n",
      "                                                             np.array([[1.0, 0.0, 0.0, 0.0]])), axis=0)\n",
      "    print sequence[DICT_FRAME_SEMANTICS].shape\n",
      "    if True and DICT_TRANSITION_COSTS_LOCATION not in sequence.keys() :\n",
      "        print \"setting transition costs location\"\n",
      "        sequence[DICT_TRANSITION_COSTS_LOCATION] = seqLoc + seqName + \"-vanilla_distMat.npy\"\n",
      "\n",
      "    np.save(sequence[DICT_SEQUENCE_LOCATION], sequence)\n",
      "#     print sequence.keys()\n",
      "    print \"saved\", sequence[DICT_SEQUENCE_LOCATION]\n",
      "    \n",
      "#     print np.max(sequence[DICT_BBOXES].keys()), np.max(sequence[DICT_BBOX_CENTERS].keys()), np.max(sequence[DICT_BBOX_ROTATIONS].keys()), \n",
      "#     print np.max(sequence[DICT_FOOTPRINTS].keys()), np.max(sequence[DICT_FRAMES_LOCATIONS].keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "blue_car2 True\n",
        "adding extra frame for looping\n",
        "setting mask location\n",
        "setting sequence location\n",
        "setting preloaded patches\n",
        "adding [1, 0] semantics at the end\n",
        "(632, 4)\n",
        "setting transition costs location\n",
        "saved /home/ilisescu/PhD/data/havana/semantic_sequence-blue_car2.npy\n",
        "pink_car1 True\n",
        "adding extra frame for looping\n",
        "setting mask location\n",
        "setting sequence location\n",
        "setting preloaded patches\n",
        "adding [1, 0] semantics at the end\n",
        "(370, 4)\n",
        "setting transition costs location\n",
        "saved /home/ilisescu/PhD/data/havana/semantic_sequence-pink_car1.npy\n",
        "red_car1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True\n",
        "adding extra frame for looping\n",
        "setting mask location\n",
        "setting sequence location\n",
        "setting preloaded patches\n",
        "adding [1, 0] semantics at the end\n",
        "(551, 4)\n",
        "setting transition costs location\n",
        "saved /home/ilisescu/PhD/data/havana/semantic_sequence-red_car1.npy\n",
        "white_car1 True\n",
        "adding extra frame for looping\n",
        "setting mask location\n",
        "setting sequence location\n",
        "setting preloaded patches\n",
        "adding [1, 0] semantics at the end\n",
        "(845, 4)\n",
        "setting transition costs location\n",
        "saved"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " /home/ilisescu/PhD/data/havana/semantic_sequence-white_car1.npy\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sequence[DICT_FRAME_SEMANTICS]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  0.00000000e+00   9.90866863e-01   9.08532879e-03   4.78082217e-05]\n",
        " [  0.00000000e+00   9.90871506e-01   9.08095735e-03   4.75370997e-05]\n",
        " [  0.00000000e+00   9.90880654e-01   9.07204279e-03   4.73032725e-05]\n",
        " ..., \n",
        " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]\n",
        " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]\n",
        " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for seqLoc in np.sort(glob.glob(\"/media/ilisescu/Data1/PhD/data/windows/semantic_sequence-window_*.npy\")) :\n",
      "#     seq = np.load(seqLoc).item()\n",
      "#     if seq[DICT_ICON_FRAME_KEY] < np.min(seq[DICT_BBOXES].keys()) or seq[DICT_ICON_FRAME_KEY] > np.max(seq[DICT_BBOXES].keys()) :\n",
      "#         print seqLoc\n",
      "#         print np.sort(seq[DICT_BBOXES].keys())\n",
      "#         print np.sort(seq[DICT_FRAMES_LOCATIONS].keys())\n",
      "#         print seq[DICT_ICON_FRAME_KEY]\n",
      "#         seq[DICT_ICON_FRAME_KEY] = np.min(seq[DICT_BBOXES].keys())\n",
      "#         np.save(seqLoc, seq)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## takes a non looping sprite and extends it with all frames mirrored time-wise\n",
      "for spriteLoc in np.sort(glob.glob(\"/media/ilisescu/Data1/PhD/data/windows/sprite*.npy\"))[0:1] :\n",
      "    baseLoc = \"/\".join(spriteLoc.split(\"/\")[:-1]) + \"/\"\n",
      "    print spriteLoc\n",
      "    sprite = np.load(spriteLoc).item()\n",
      "    print sprite.keys()\n",
      "    print len(sprite[DICT_FRAMES_LOCATIONS].keys()), np.sort(sprite[DICT_FRAMES_LOCATIONS].keys())\n",
      "    sortedKeys = np.sort(sprite[DICT_FRAMES_LOCATIONS].keys())[:-1][::-1]\n",
      "    maxKey = np.max(sprite[DICT_FRAMES_LOCATIONS].keys())\n",
      "    for i, key in enumerate(sortedKeys) :\n",
      "        newKey = maxKey + i + 1\n",
      "#         print key, newKey\n",
      "        sprite[DICT_BBOX_CENTERS][newKey] = sprite[DICT_BBOX_CENTERS][key]\n",
      "        sprite[DICT_BBOX_ROTATIONS][newKey] = sprite[DICT_BBOX_ROTATIONS][key]\n",
      "        sprite[DICT_BBOXES][newKey] = sprite[DICT_BBOXES][key]\n",
      "        sprite[DICT_FRAMES_LOCATIONS][newKey] = baseLoc+\"frame-{0:05d}.png\".format(newKey+1)\n",
      "        shutil.copyfile(baseLoc+sprite[DICT_SEQUENCE_NAME]+\"-maskedFlow/frame-{0:05d}.png\".format(key+1),\n",
      "                        baseLoc+sprite[DICT_SEQUENCE_NAME]+\"-maskedFlow/frame-{0:05d}.png\".format(newKey+1))\n",
      "    sprite[DICT_FRAME_SEMANTICS] = np.concatenate((sprite[DICT_FRAME_SEMANTICS], sprite[DICT_FRAME_SEMANTICS][:-1, :][::-1, :]))\n",
      "    \n",
      "    np.save(spriteLoc, sprite)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/media/ilisescu/Data1/PhD/data/windows/sprite-0000-window_row2a.npy\n",
        "['bbox_centers', 'icon_frame_key', 'icon_top_left', 'bbox_rotations', 'semantic_sequence_name', 'bboxes', 'icon_size', 'frame_locs', 'representative_color', 'semantics_per_frame']\n",
        "99 [ 61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
        "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
        "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
        " 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132\n",
        " 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150\n",
        " 151 152 153 154 155 156 157 158 159]\n"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# labelProbs = sprite[DICT_FRAME_SEMANTICS]\n",
      "# fig1 = figure()\n",
      "# clrs = np.arange(0.0, 1.0+1.0/(2-1), 1.0/(2-1)).astype(np.string_) #['r', 'g', 'b', 'm', 'c', 'y', 'k', 'w']\n",
      "# stackplot(np.arange(len(labelProbs)), np.row_stack(tuple([i for i in labelProbs.T])), colors=clrs)\n",
      "# print np.sort(sprite[DICT_BBOX_CENTERS].keys())\n",
      "# print np.sort(sprite[DICT_BBOX_ROTATIONS].keys())\n",
      "# print np.sort(sprite[DICT_BBOXES].keys())\n",
      "# print np.sort(sprite[DICT_FRAMES_LOCATIONS].keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "synthSeqLocation = dataPath+\"synthesisedSequences/tetris/synthesised_sequence.npy\"\n",
      "synthSeq = np.load(synthSeqLocation).item()\n",
      "# usedSequences = synthSeq[DICT_USED_SEQUENCES]\n",
      "# semanticSequences = []\n",
      "# for sequence in usedSequences :\n",
      "#     semanticSequences.append(np.load(sequence).item())\n",
      "\n",
      "TOGGLE_DELAY = 4\n",
      "# EXTEND_LENGTH = TOGGLE_DELAY*6 +1\n",
      "EXTEND_LENGTH = TOGGLE_DELAY*3 +1\n",
      "with open(\"/media/ilisescu/Data1/PhD/data/windows/tetris/6x9_sess2.txt\") as f:\n",
      "    lines = f.readlines()\n",
      "    gridSize = np.array(lines[0].split(\",\")[1:3], int)[::-1] ## (rows, cols)\n",
      "    lines = np.concatenate(([\"D,121231231233,\"+\"\".join(np.zeros(np.prod(gridSize), int).astype(np.string_))+\"\\n\"], lines[1:]))\n",
      "    for line in lines[0:] :\n",
      "#         print np.array(list(line.split(\",\")[-1])[:-1], int).reshape(gridSize, order='C')\n",
      "#         sys.stdout.flush()\n",
      "        instructions = np.array(list(line.split(\",\")[-1])[:-1], int)\n",
      "        print instructions\n",
      "        \n",
      "        \n",
      "        for instance, instruction in enumerate(instructions[0:]) :\n",
      "            numSemantics = synthSeq[DICT_SEQUENCE_INSTANCES][instance][DICT_DESIRED_SEMANTICS].shape[1]\n",
      "            \n",
      "\n",
      "            ## take current semantics\n",
      "            desiredSemantics = synthSeq[DICT_SEQUENCE_INSTANCES][instance][DICT_DESIRED_SEMANTICS][-1, :].reshape((1, numSemantics))\n",
      "#             print desiredSemantics\n",
      "\n",
      "            if synthSeq[DICT_SEQUENCE_INSTANCES][instance][DICT_DESIRED_SEMANTICS][-1, instruction] != 1.0 :\n",
      "                toggledlabels = toggleAllLabelsSmoothly(desiredSemantics[-1, :], instruction, TOGGLE_DELAY) #toggleLabelsSmoothly(np.array([[1.0, 0.0]]), self.TOGGLE_DELAY)\n",
      "                desiredSemantics = np.concatenate((desiredSemantics, toggledlabels)) #np.zeros((self.TOGGLE_DELAY, numSemantics))))\n",
      "#                 print desiredSemantics\n",
      "\n",
      "#                 ## do impulse\n",
      "#                 ## pad the tip with new semantics\n",
      "#                 tmp = np.zeros((1, numSemantics))\n",
      "#                 tmp[0, instruction] = 1.0\n",
      "#                 desiredSemantics = np.concatenate((desiredSemantics, tmp.repeat(TOGGLE_DELAY*2, axis=0)))\n",
      "#                 ## toggle back to default\n",
      "#                 toggledlabels = toggleAllLabelsSmoothly(desiredSemantics[-1, :], 0, TOGGLE_DELAY)\n",
      "#                 desiredSemantics = np.concatenate((desiredSemantics, toggledlabels))\n",
      "\n",
      "#                 ## pad remaining with default semantics\n",
      "#                 tmp = np.zeros((1, numSemantics))\n",
      "#                 tmp[0, instruction] = 1.0\n",
      "#                 desiredSemantics = np.concatenate((desiredSemantics, tmp.repeat(EXTEND_LENGTH-4*TOGGLE_DELAY-1, axis=0)))\n",
      "\n",
      "                \n",
      "                ## pad remaining with default semantics\n",
      "                tmp = np.zeros((1, numSemantics))\n",
      "                tmp[0, instruction] = 1.0\n",
      "                desiredSemantics = np.concatenate((desiredSemantics, tmp.repeat(EXTEND_LENGTH-TOGGLE_DELAY-1, axis=0)))\n",
      "\n",
      "            else :\n",
      "                desiredSemantics = desiredSemantics.repeat(EXTEND_LENGTH, axis=0)\n",
      "                \n",
      "            synthSeq[DICT_SEQUENCE_INSTANCES][instance][DICT_DESIRED_SEMANTICS] = np.concatenate((synthSeq[DICT_SEQUENCE_INSTANCES][instance][DICT_DESIRED_SEMANTICS][:-1, :],\n",
      "                                                                                                  desiredSemantics))\n",
      "        \n",
      "#         print desiredSemantics\n",
      "#         print desiredSemantics.shape\n",
      "#         print EXTEND_LENGTH\n",
      "#         print synthSeq[DICT_SEQUENCE_INSTANCES][instance][DICT_DESIRED_SEMANTICS].shape\n",
      "#         time.sleep(0.2)\n",
      "#         clear_output()\n",
      "\n",
      "\n",
      "# print synthSeq[DICT_SEQUENCE_INSTANCES][instance][DICT_DESIRED_SEMANTICS]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0\n",
        " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
        " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
        " 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1]\n",
        "[0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1]\n",
        "[0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1]\n",
        "[0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1]\n",
        "[0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1\n",
        " 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1\n",
        " 0 0 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
        " 0 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
        " 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
        " 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
        " 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
        " 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
        " 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1\n",
        " 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1\n",
        " 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
        " 1 1 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
        " 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
        " 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0]\n",
        "[0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
        " 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
        " 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
        " 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
        " 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
        " 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
        " 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
        " 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
        " 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1\n",
        " 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
        " 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1\n",
        " 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1\n",
        " 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
        " 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
        " 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0\n",
        " 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0\n",
        " 1 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
        " 1 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
        " 1 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
        " 1 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1\n",
        " 1 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1\n",
        " 1 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1\n",
        " 1 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1\n",
        " 1 0 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1\n",
        " 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1\n",
        " 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1]\n",
        "[0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
        " 0 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
        " 0 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
        " 0 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1\n",
        " 0 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1\n",
        " 0 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1\n",
        " 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1\n",
        " 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1\n",
        " 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1\n",
        " 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1\n",
        " 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1\n",
        " 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1\n",
        " 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1\n",
        " 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 1\n",
        " 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1\n",
        " 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1\n",
        " 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1\n",
        " 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1\n",
        " 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1\n",
        " 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0\n",
        " 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0\n",
        " 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
        " 0 0 0 1 0 0 1 1 0 0 0 1 1 0 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
        " 0 0 0 1 0 0 1 1 0 0 0 1 1 0 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
        " 0 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
        " 0 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 0]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0\n",
        " 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
        " 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
        " 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
        " 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
        " 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
        " 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
        " 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0\n",
        " 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
        " 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0\n",
        " 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0\n",
        " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0\n",
        " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0\n",
        " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0\n",
        " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0\n",
        " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0\n",
        " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0\n",
        " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0\n",
        " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
        "[0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0\n",
        " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.save(synthSeqLocation, synthSeq)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#  synthSeq[DICT_SEQUENCE_INSTANCES][1][DICT_DESIRED_SEMANTICS]\n",
      "# print instance\n",
      "labelProbs = synthSeq[DICT_SEQUENCE_INSTANCES][8][DICT_DESIRED_SEMANTICS]\n",
      "fig1 = figure()\n",
      "clrs = np.arange(0.0, 1.0+1.0/(2-1), 1.0/(2-1)).astype(np.string_) #['r', 'g', 'b', 'm', 'c', 'y', 'k', 'w']\n",
      "stackplot(np.arange(len(labelProbs)), np.row_stack(tuple([i for i in labelProbs.T])), colors=clrs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "[<matplotlib.collections.PolyCollection at 0x7f14af44c610>,\n",
        " <matplotlib.collections.PolyCollection at 0x7f14af44cb50>]"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gwv.showCustomGraph(compatibilityMats[\"2-7\"])\n",
      "# print window.semanticLoopingTab.semanticSequences[1][DICT_SEQUENCE_NAME]\n",
      "# print window.semanticLoopingTab.semanticSequences[0][DICT_SEQUENCE_NAME]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "lift_cars1\n",
        "roller_coaster1\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blueCarFrames = (\"389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406\"+\n",
      " \" 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424\"+\n",
      " \" 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442\"+\n",
      " \" 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460\"+\n",
      " \" 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478\"+\n",
      " \" 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496\"+\n",
      " \" 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514\"+\n",
      " \" 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532\"+\n",
      " \" 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550\"+\n",
      " \" 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568\"+\n",
      " \" 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586\"+\n",
      " \" 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604\"+\n",
      " \" 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622\"+\n",
      " \" 623 624 625 626 627 628 629 630   0   1   2   3   4   5   6   7   8   9\"+\n",
      " \" 10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27\"+\n",
      " \" 28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\"+\n",
      " \" 46  47  48  49  50  51  52  53  54  55  56  57  58\").split(\" \")\n",
      "blueCarFrames = np.array(blueCarFrames)[np.array(blueCarFrames) != '']\n",
      "# print \",\".join(blueCarFrames)\n",
      "blueCarFrames = np.array([389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,\n",
      "                          412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,\n",
      "                          435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,\n",
      "                          458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,\n",
      "                          481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,\n",
      "                          504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,\n",
      "                          527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,\n",
      "                          550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,\n",
      "                          573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,\n",
      "                          596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,\n",
      "                          619,620,621,622,623,624,625,626,627,628,629,630,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,\n",
      "                          18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,\n",
      "                          49,50,51,52,53,54,55,56,57,58])\n",
      "\n",
      "redCarFrames = (\"335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352\"+\n",
      "\" 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370\"+\n",
      "\" 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388\"+\n",
      "\" 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406\"+\n",
      "\" 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424\"+\n",
      "\" 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442\"+\n",
      "\" 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460\"+\n",
      "\" 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478\"+\n",
      "\" 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496\"+\n",
      "\" 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514\"+\n",
      "\" 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532\"+\n",
      "\" 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549   0\"+\n",
      "\" 1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\"+\n",
      "\" 19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\"+\n",
      "\" 37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\"+\n",
      "\" 55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\"+\n",
      "\" 73  74  75  76  77  78  79  80  81  82  83  84  85\").split(\" \")\n",
      "redCarFrames = np.array(redCarFrames)[np.array(redCarFrames) != \"\"]\n",
      "# print \",\".join(redCarFrames)\n",
      "redCarFrames = np.array([335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,\n",
      "                         359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,\n",
      "                         383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,\n",
      "                         407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,\n",
      "                         431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,\n",
      "                         455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,\n",
      "                         479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,\n",
      "                         503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,\n",
      "                         527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,0,1,\n",
      "                         2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,\n",
      "                         37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,\n",
      "                         69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85])\n",
      "\n",
      "print compatibilityMats[\"2-7\"][blueCarFrames, redCarFrames]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  5.22654523e-05   5.47464692e-05   5.60682139e-05   6.04117258e-05\n",
        "   6.36020300e-05   6.65232584e-05   8.78459469e-05   8.59109282e-05\n",
        "   8.76427132e-05   9.31759068e-05   9.85019096e-05   1.01273781e-04\n",
        "   1.09576687e-04   1.14124197e-04   1.54039831e-04   1.62111783e-04\n",
        "   1.68921986e-04   1.88304228e-04   2.02603584e-04   2.14475510e-04\n",
        "   2.31332760e-04   2.46832816e-04   2.66258138e-04   2.92916514e-04\n",
        "   3.13416109e-04   3.26665817e-04   3.50493896e-04   3.73002993e-04\n",
        "   4.12129427e-04   4.34863183e-04   4.66167207e-04   4.94417013e-04\n",
        "   5.40423394e-04   5.74714727e-04   6.29650150e-04   6.75204277e-04\n",
        "   7.34190343e-04   7.78070381e-04   9.27753569e-04   9.60636193e-04\n",
        "   1.00792533e-03   1.11071658e-03   1.20091968e-03   1.31884309e-03\n",
        "   1.45751167e-03   1.60950561e-03   1.73980309e-03   1.90906012e-03\n",
        "   2.07473725e-03   2.36262084e-03   2.44704469e-03   2.61336156e-03\n",
        "   2.80566662e-03   3.03906302e-03   3.25558344e-03   4.06711390e-03\n",
        "   4.21820758e-03   4.34859563e-03   4.78619305e-03   5.32767692e-03\n",
        "   5.59916444e-03   6.28626074e-03   6.68181516e-03   7.68427392e-03\n",
        "   9.50294046e-03   9.96795840e-03   1.03759612e-02   1.14560319e-02\n",
        "   1.29289088e-02   1.42860414e-02   1.57862441e-02   1.72560343e-02\n",
        "   1.89078841e-02   2.21367624e-02   2.32351544e-02   2.65268377e-02\n",
        "   2.93438974e-02   3.37049023e-02   3.98744753e-02   4.20468634e-02\n",
        "   5.04109988e-02   5.54188235e-02   6.27182436e-02   7.43032144e-02\n",
        "   8.13185495e-02   9.38311302e-02   1.04487623e-01   1.19245171e-01\n",
        "   1.41576172e-01   1.52809524e-01   1.79172820e-01   2.02732535e-01\n",
        "   2.33341232e-01   2.70672143e-01   2.90389395e-01   3.46168349e-01\n",
        "   3.85349805e-01   4.82348978e-01   5.66632010e-01   5.99795299e-01\n",
        "   7.07714024e-01   8.11873688e-01   9.01160105e-01   1.03805764e+00\n",
        "   1.13979232e+00   1.35443616e+00   1.50929387e+00   2.05247166e+00\n",
        "   2.48899799e+00   2.63099187e+00   2.96292993e+00   3.24358918e+00\n",
        "   4.15038304e+00   4.79678370e+00   4.89508251e+00   5.95799361e+00\n",
        "   6.29165001e+00   5.95938683e+00   7.60749437e+00   7.93099814e+00\n",
        "   9.94628062e+00   1.00000000e+01   1.00000000e+01   1.00000000e+01\n",
        "   1.00000000e+01   1.00000000e+01   1.00000000e+01   1.00000000e+01\n",
        "   1.00000000e+01   1.00000000e+01   1.00000000e+01   1.00000000e+01\n",
        "   1.00000000e+01   1.00000000e+01   1.00000000e+01   1.00000000e+01\n",
        "   1.00000000e+01   1.00000000e+01   1.00000000e+01   1.00000000e+01\n",
        "   1.00000000e+01   1.00000000e+01   1.00000000e+01   1.00000000e+01\n",
        "   1.00000000e+01   1.00000000e+01   1.00000000e+01   1.00000000e+01\n",
        "   1.00000000e+01   1.00000000e+01   1.00000000e+01   9.87206712e+00\n",
        "   8.50733022e+00   7.08952517e+00   6.16963985e+00   4.95134648e+00\n",
        "   4.24514194e+00   3.43220120e+00   2.82314562e+00   2.42601243e+00\n",
        "   1.87542281e+00   1.51041109e+00   1.25173585e+00   1.04843352e+00\n",
        "   8.26293506e-01   6.46684203e-01   5.28082297e-01   4.34368698e-01\n",
        "   3.28486238e-01   2.74608044e-01   2.03904438e-01   1.60015385e-01\n",
        "   1.23889104e-01   1.01009189e-01   7.82215385e-02   5.61226427e-02\n",
        "   4.49549436e-02   3.52059144e-02   3.10250429e-02   2.44697461e-02\n",
        "   1.76861165e-02   1.42621573e-02   1.09608497e-02   9.11725658e-03\n",
        "   6.43261577e-03   5.49356432e-03   4.81760921e-03   3.77926034e-03\n",
        "   3.00735735e-03   2.34183842e-03   1.49882745e-03   1.04428696e-03\n",
        "   7.91293322e-04   6.07829012e-04   4.36079160e-04   3.30098770e-04\n",
        "   2.77111892e-04   2.23069658e-04   1.87190580e-04   1.45379637e-04\n",
        "   8.54157972e-05   7.20264224e-05   4.89904421e-05   3.92050919e-05\n",
        "   2.71350131e-05   2.06206743e-05   1.86738561e-05   9.94397343e-06\n",
        "   8.62928218e-06   5.67611115e-06   3.95961471e-06   3.59369650e-06\n",
        "   2.72543721e-06   2.06153560e-06   1.38765607e-06   1.68994298e+00\n",
        "   1.67563480e+00   1.66165636e+00   1.70108012e+00   1.65088647e+00\n",
        "   1.60307120e+00   1.64729381e+00   1.49814355e+00   1.68135362e+00\n",
        "   1.52888488e+00   1.41045247e+00   1.43241924e+00   1.51176771e+00\n",
        "   1.53261921e+00   1.66266405e+00   1.82550769e+00   1.65064603e+00\n",
        "   1.66282488e+00   1.64729658e+00   1.64310091e+00   1.80618758e+00\n",
        "   1.77999890e+00   1.78379070e+00   1.81196205e+00   1.85415852e+00\n",
        "   1.72357928e+00   1.70039660e+00   1.49286675e-09   1.61483748e-09\n",
        "   1.66209606e-09   1.83062086e-09   1.94169013e-09   2.06735270e-09\n",
        "   2.15014984e-09   2.33469711e-09   2.48578974e-09   2.57550610e-09\n",
        "   2.75506352e-09   2.79996282e-09   3.04041621e-09   3.28947577e-09\n",
        "   3.44392331e-09   3.69612852e-09   3.85051327e-09   4.15234283e-09\n",
        "   4.56067501e-09   4.89370036e-09   5.21168620e-09   5.41887353e-09\n",
        "   5.88457737e-09   6.15019032e-09   6.35815506e-09   6.67879813e-09\n",
        "   6.94392818e-09   7.30328914e-09   8.10383571e-09   8.35854845e-09\n",
        "   8.88989198e-09   9.17077156e-09   9.74471432e-09   1.01550571e-08\n",
        "   1.04827141e-08   1.10277133e-08   1.14059914e-08   1.19141751e-08\n",
        "   1.29622066e-08   1.33345951e-08   1.44597800e-08   1.47651555e-08\n",
        "   1.53508447e-08   1.60342661e-08   1.66954295e-08   1.71698265e-08\n",
        "   1.73897315e-08   1.81093629e-08   2.00453015e-08   2.02113393e-08\n",
        "   2.17917432e-08   2.22220979e-08   2.34147022e-08   2.43999321e-08\n",
        "   2.49403910e-08   2.59321356e-08   2.64966954e-08   2.76169845e-08\n",
        "   2.87151628e-08]\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ## this repeats the first bbox to the rest of the frames\n",
      "# dataset = \"theme_park_sunny\"\n",
      "# startFrame = 1442\n",
      "# frameLocs = np.sort(glob.glob(\"/media/ilisescu/Data1/PhD/data/\"+dataset+\"/frame-0*.png\"))\n",
      "# print frameLocs.shape\n",
      "# for s in np.sort(glob.glob(\"/media/ilisescu/Data1/PhD/data/\"+dataset+\"/sprite*.npy\"))[-1:] :\n",
      "#     print s\n",
      "#     sprite = np.load(s).item()\n",
      "# #     sprite[DICT_ICON_FRAME_KEY] = np.min(sprite[DICT_BBOXES].keys())\n",
      "#     startFrame = np.min(sprite[DICT_BBOXES].keys())\n",
      "#     print startFrame\n",
      "#     for i in xrange(startFrame+1, startFrame+1016) :\n",
      "#         sprite[DICT_BBOXES][i] = sprite[DICT_BBOXES][startFrame]\n",
      "#         sprite[DICT_BBOX_ROTATIONS][i] = sprite[DICT_BBOX_ROTATIONS][startFrame]\n",
      "#         sprite[DICT_BBOX_CENTERS][i] = sprite[DICT_BBOX_CENTERS][startFrame]\n",
      "#         sprite[DICT_FRAMES_LOCATIONS][i] = \"/media/ilisescu/Data1/PhD/data/\"+dataset+\"/frame-{0:05d}.png\".format(i+1)\n",
      "        \n",
      "#     print len(sprite[DICT_BBOXES])\n",
      "# #     np.save(s, sprite)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(8597,)\n",
        "/media/ilisescu/Data1/PhD/data/theme_park_sunny/sprite-0010-lift_cars1.npy\n",
        "2451\n",
        "1016\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class TempWindow() :\n",
      "    def __init__(self, synthesisedSequence):\n",
      "        self.EXTEND_LENGTH = 301\n",
      "        self.semanticSequences = []\n",
      "        self.preloadedTransitionCosts = {}\n",
      "        for index, seq in enumerate(synthesisedSequence[DICT_USED_SEQUENCES]) :\n",
      "            self.semanticSequences.append(np.load(seq).item())\n",
      "            if DICT_TRANSITION_COSTS_LOCATION in self.semanticSequences[-1].keys() :\n",
      "                self.preloadedTransitionCosts[index] = np.load(self.semanticSequences[-1][DICT_TRANSITION_COSTS_LOCATION])#/GRAPH_MAX_COST*100.0\n",
      "                print \"loaded\", self.semanticSequences[-1][DICT_TRANSITION_COSTS_LOCATION]\n",
      "\n",
      "def getNewFramesForSequenceFull(self, synthesisedSequence, instancesToUse, instancesLengths, startingFrame, resolveCompatibility = True, numSteps=10, costsAlpha=0.1, compatibilityAlpha=0.65) :\n",
      "\n",
      "    gm = opengm.gm(instancesLengths.repeat(self.EXTEND_LENGTH))\n",
      "\n",
      "    self.allUnaries = []\n",
      "\n",
      "    for i, instanceIdx in enumerate(instancesToUse) : # xrange(len(synthesisedSequence[DICT_SEQUENCE_INSTANCES])) :\n",
      "        seqIdx = synthesisedSequence[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_IDX]\n",
      "        desiredSemantics = synthesisedSequence[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_DESIRED_SEMANTICS][startingFrame:startingFrame+self.EXTEND_LENGTH, :]\n",
      "\n",
      "        if len(desiredSemantics) != self.EXTEND_LENGTH :\n",
      "            raise Exception(\"desiredSemantics length is not the same as EXTEND_LENGTH\")\n",
      "\n",
      "        ################ FIND DESIRED START FRAME ################ \n",
      "        if len(synthesisedSequence[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_FRAMES]) == 0 :\n",
      "            desiredStartFrame = 0\n",
      "        else :\n",
      "            desiredStartFrame = synthesisedSequence[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_FRAMES][startingFrame]\n",
      "\n",
      "        distVariance = 1.0/50.0 ##self.semanticsImportanceSpinBox.value() ##0.0005\n",
      "\n",
      "        ################ GET UNARIES ################\n",
      "        self.unaries = vectorisedMultiNormalMultipleMeans(self.semanticSequences[seqIdx][DICT_FRAME_SEMANTICS], desiredSemantics, np.eye(desiredSemantics.shape[1])*distVariance, False).T\n",
      "\n",
      "        ## normalizing to turn into probabilities\n",
      "        self.unaries = self.unaries / np.sum(self.unaries, axis=0).reshape((1, self.unaries.shape[1]))\n",
      "        impossibleLabels = self.unaries <= 0.0\n",
      "        ## cost is -log(prob)\n",
      "        self.unaries[np.negative(impossibleLabels)] = -np.log(self.unaries[np.negative(impossibleLabels)])\n",
      "        ## if prob == 0.0 then set maxCost\n",
      "        self.unaries[impossibleLabels] = GRAPH_MAX_COST\n",
      "\n",
      "\n",
      "        ## force desiredStartFrame to be the first frame of the new sequence\n",
      "        self.unaries[:, 0] = GRAPH_MAX_COST\n",
      "        self.unaries[desiredStartFrame, 0] = 0.0\n",
      "        \n",
      "        self.unaries = costsAlpha*self.unaries\n",
      "\n",
      "        self.allUnaries.append(np.copy(self.unaries.T))\n",
      "\n",
      "        ## add unaries to the graph\n",
      "        fids = gm.addFunctions(self.unaries.T)\n",
      "        # add first order factors\n",
      "        gm.addFactors(fids, arange(self.EXTEND_LENGTH*i, self.EXTEND_LENGTH*i+self.EXTEND_LENGTH))\n",
      "\n",
      "\n",
      "        ################ GET PAIRWISE ################\n",
      "        pairIndices = np.array([np.arange(self.EXTEND_LENGTH-1), np.arange(1, self.EXTEND_LENGTH)]).T + self.EXTEND_LENGTH*i\n",
      "\n",
      "        ## add function for row-nodes pairwise cost\n",
      "        fid = gm.addFunction((1.0-costsAlpha)*(1.0-compatibilityAlpha)*(self.preloadedTransitionCosts[seqIdx]+0.1))##self.toggleSpeedDeltaSpinBox.value())\n",
      "        ## add second order factors\n",
      "        gm.addFactors(fid, pairIndices)\n",
      "\n",
      "    ################ ADD THE PAIRWISE BETWEEN ROWS ################\n",
      "    if resolveCompatibility :\n",
      "        for i, j in np.argwhere(np.triu(np.ones((len(instancesToUse), len(instancesToUse))), 1)) :\n",
      "            seq1Idx = synthesisedSequence[DICT_SEQUENCE_INSTANCES][instancesToUse[i]][DICT_SEQUENCE_IDX]\n",
      "            seq2Idx = synthesisedSequence[DICT_SEQUENCE_INSTANCES][instancesToUse[j]][DICT_SEQUENCE_IDX]\n",
      "            pairIndices = np.array([np.arange(self.EXTEND_LENGTH*i, self.EXTEND_LENGTH*i+self.EXTEND_LENGTH), \n",
      "                                    np.arange(self.EXTEND_LENGTH*j, self.EXTEND_LENGTH*j+self.EXTEND_LENGTH)]).T\n",
      "#             print pairIndices\n",
      "\n",
      "            ## add function for column-nodes pairwise cost\n",
      "            if seq1Idx <= seq2Idx :\n",
      "                fid = gm.addFunction((1.0-costsAlpha)*compatibilityAlpha*np.copy(compatibilityMats[np.string_(np.min([seq1Idx, seq2Idx])) + np.string_(np.max([seq1Idx, seq2Idx]))]))\n",
      "                print \"added vertical pairwise between\", seq1Idx, \"and\", seq2Idx, \"   used comptabilityMat\", np.string_(np.min([seq1Idx, seq2Idx])) + np.string_(np.max([seq1Idx, seq2Idx])),\n",
      "                print compatibilityMats[np.string_(np.min([seq1Idx, seq2Idx])) + np.string_(np.max([seq1Idx, seq2Idx]))].shape\n",
      "            else :\n",
      "                fid = gm.addFunction((1.0-costsAlpha)*compatibilityAlpha*np.copy(compatibilityMats[np.string_(np.min([seq1Idx, seq2Idx])) + np.string_(np.max([seq1Idx, seq2Idx]))].T))\n",
      "                print \"added vertical pairwise between\", seq1Idx, \"and\", seq2Idx, \"   used Transposed comptabilityMat\", np.string_(np.min([seq1Idx, seq2Idx])) + np.string_(np.max([seq1Idx, seq2Idx]))\n",
      "            ## add second order factors\n",
      "            gm.addFactors(fid, pairIndices)\n",
      "            \n",
      "    print gm; sys.stdout.flush()\n",
      "\n",
      "    t = time.time()\n",
      "    inferer = opengm.inference.TrwsExternal(gm=gm)#, parameter=opengm.InfParam(steps=numSteps, useRandomStart=True))\n",
      "    inferer.infer()\n",
      "    print \"solved in\", time.time() - t\n",
      "\n",
      "    return np.array(inferer.arg(), dtype=int), gm\n",
      "\n",
      "\n",
      "def getNewFramesForSequenceIterative(self, synthesisedSequence, instancesToUse, instancesLengths, lockedInstances, startingFrame, resolveCompatibility = False, costsAlpha=0.5, compatibilityAlpha=0.5) :\n",
      "\n",
      "    self.allUnaries = []\n",
      "    \n",
      "    self.synthesisedFrames = {}\n",
      "    totalCost = 0.0\n",
      "    for instanceIdx, instanceLength, lockedInstance in zip(instancesToUse, instancesLengths, lockedInstances) : # xrange(len(synthesisedSequence[DICT_SEQUENCE_INSTANCES])) :\n",
      "        \n",
      "        gm = opengm.gm(np.array([instanceLength]).repeat(self.EXTEND_LENGTH))\n",
      "        \n",
      "        seqIdx = synthesisedSequence[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_IDX]\n",
      "        desiredSemantics = synthesisedSequence[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_DESIRED_SEMANTICS][startingFrame:startingFrame+self.EXTEND_LENGTH, :]\n",
      "        \n",
      "        if lockedInstance : \n",
      "            if len(synthesisedSequence[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_FRAMES][startingFrame:startingFrame+self.EXTEND_LENGTH]) != self.EXTEND_LENGTH :\n",
      "                raise Exception(\"not enough synthesised frames\")\n",
      "            else :\n",
      "                self.synthesisedFrames[instanceIdx] = synthesisedSequence[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_FRAMES][startingFrame:startingFrame+self.EXTEND_LENGTH]\n",
      "                print \"locked instance\", instanceIdx\n",
      "                print self.synthesisedFrames[instanceIdx]\n",
      "                continue\n",
      "\n",
      "        if len(desiredSemantics) != self.EXTEND_LENGTH :\n",
      "            raise Exception(\"desiredSemantics length is not the same as EXTEND_LENGTH\")\n",
      "\n",
      "        ################ FIND DESIRED START FRAME ################ \n",
      "        if len(synthesisedSequence[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_FRAMES]) == 0 :\n",
      "            desiredStartFrame = 0\n",
      "        else :\n",
      "            desiredStartFrame = synthesisedSequence[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_FRAMES][startingFrame]\n",
      "\n",
      "        distVariance = 1.0/2.0 ##self.semanticsImportanceSpinBox.value() ##0.0005\n",
      "\n",
      "        ################ GET UNARIES ################\n",
      "        self.unaries = vectorisedMultiNormalMultipleMeans(self.semanticSequences[seqIdx][DICT_FRAME_SEMANTICS], desiredSemantics, np.eye(desiredSemantics.shape[1])*distVariance, False).T\n",
      "\n",
      "        ## normalizing to turn into probabilities\n",
      "        self.unaries = self.unaries / np.sum(self.unaries, axis=0).reshape((1, self.unaries.shape[1]))\n",
      "        impossibleLabels = self.unaries <= 0.0\n",
      "        ## cost is -log(prob)\n",
      "        self.unaries[np.negative(impossibleLabels)] = -np.log(self.unaries[np.negative(impossibleLabels)])\n",
      "        ## if prob == 0.0 then set maxCost\n",
      "        self.unaries[impossibleLabels] = GRAPH_MAX_COST\n",
      "\n",
      "\n",
      "        ## force desiredStartFrame to be the first frame of the new sequence\n",
      "        self.unaries[:, 0] = GRAPH_MAX_COST\n",
      "        self.unaries[desiredStartFrame, 0] = 0.0\n",
      "        \n",
      "        #### minimizing totalCost = a * unary + (1 - a) * (b * vert_link + (1-b)*horiz_link) = a*unary + (1-a)*b*sum(vert_link) + (1-a)*(1-b)*horiz_link\n",
      "        #### where a = costsAlpha, b = compatibilityAlpha, \n",
      "        \n",
      "        compatibilityCosts = np.zeros_like(self.unaries)\n",
      "        if resolveCompatibility :\n",
      "            seq1Idx = synthesisedSequence[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_IDX]\n",
      "            for instance2Idx in np.sort(self.synthesisedFrames.keys()) :\n",
      "                seq2Idx = synthesisedSequence[DICT_SEQUENCE_INSTANCES][instance2Idx][DICT_SEQUENCE_IDX]\n",
      "                print \"considering sequences\", seq1Idx, seq2Idx, self.synthesisedFrames.keys()\n",
      "                \n",
      "#                 if instance2Idx != 1 :\n",
      "#                     continue\n",
      "                \n",
      "                if seq1Idx <= seq2Idx :\n",
      "#                     self.unaries = (1.0-compatibilityAlpha)*self.unaries + compatibilityAlpha*compatibilityMats[np.string_(np.min([seq1Idx, seq2Idx])) + np.string_(np.max([seq1Idx, seq2Idx]))].T[self.synthesisedFrames[instance2Idx], :].T\n",
      "                    compatibilityCosts += (1.0-costsAlpha)*compatibilityAlpha*compatibilityMats[np.string_(np.min([seq1Idx, seq2Idx])) + np.string_(np.max([seq1Idx, seq2Idx]))].T[self.synthesisedFrames[instance2Idx], :].T\n",
      "                    \n",
      "                    print \"added vertical pairwise between\", seq1Idx, \"and\", seq2Idx, \"   used comptabilityMat\", np.string_(np.min([seq1Idx, seq2Idx])) + np.string_(np.max([seq1Idx, seq2Idx])),\n",
      "                    print compatibilityMats[np.string_(np.min([seq1Idx, seq2Idx])) + np.string_(np.max([seq1Idx, seq2Idx]))].shape\n",
      "                else :\n",
      "#                     self.unaries = (1.0-compatibilityAlpha)*self.unaries + compatibilityAlpha*compatibilityMats[np.string_(np.min([seq1Idx, seq2Idx])) + np.string_(np.max([seq1Idx, seq2Idx]))][self.synthesisedFrames[instance2Idx], :].T\n",
      "                    compatibilityCosts += (1.0-costsAlpha)*compatibilityAlpha*compatibilityMats[np.string_(np.min([seq1Idx, seq2Idx])) + np.string_(np.max([seq1Idx, seq2Idx]))][self.synthesisedFrames[instance2Idx], :].T\n",
      "                    \n",
      "                    print \"added vertical pairwise between\", seq1Idx, \"and\", seq2Idx, \"   used Transposed comptabilityMat\", np.string_(np.min([seq1Idx, seq2Idx])) + np.string_(np.max([seq1Idx, seq2Idx]))        \n",
      "#         ## doing the alpha*unaries + (1-alpha)*pairwise thingy\n",
      "#         self.unaries *= costsAlpha\n",
      "        self.unaries = costsAlpha*self.unaries + compatibilityCosts\n",
      "        \n",
      "\n",
      "        self.allUnaries.append(np.copy(self.unaries.T))\n",
      "        \n",
      "\n",
      "        ## add unaries to the graph\n",
      "        fids = gm.addFunctions(self.unaries.T)\n",
      "        # add first order factors\n",
      "        gm.addFactors(fids, arange(self.EXTEND_LENGTH))\n",
      "\n",
      "\n",
      "        ################ GET PAIRWISE ################\n",
      "        pairIndices = np.array([np.arange(self.EXTEND_LENGTH-1), np.arange(1, self.EXTEND_LENGTH)]).T\n",
      "\n",
      "#         ## add function for row-nodes pairwise cost doing the alpha*unaries + (1-alpha)*pairwise thingy at the same time\n",
      "#         fid = gm.addFunction((1.0-costsAlpha)*(self.preloadedTransitionCosts[seqIdx]+0.1))##self.toggleSpeedDeltaSpinBox.value())\n",
      "        if resolveCompatibility :\n",
      "            fid = gm.addFunction((1.0-costsAlpha)*(1.0-compatibilityAlpha)*(self.preloadedTransitionCosts[seqIdx]+0.1))##self.toggleSpeedDeltaSpinBox.value())\n",
      "        else :\n",
      "            fid = gm.addFunction((1.0-costsAlpha)*(self.preloadedTransitionCosts[seqIdx]+0.1))##self.toggleSpeedDeltaSpinBox.value())\n",
      "        ## add second order factors\n",
      "        gm.addFactors(fid, pairIndices)        \n",
      "            \n",
      "        print gm; sys.stdout.flush()\n",
      "\n",
      "        t = time.time()\n",
      "        inferer = opengm.inference.DynamicProgramming(gm=gm)\n",
      "        inferer.infer()\n",
      "        print \"solved in\", time.time() - t, \"cost\", gm.evaluate(inferer.arg())\n",
      "        print np.array(inferer.arg(), dtype=int)\n",
      "        totalCost += gm.evaluate(inferer.arg())\n",
      "        self.synthesisedFrames[instanceIdx] = np.array(inferer.arg(), dtype=int)\n",
      "        \n",
      "    return self.synthesisedFrames, totalCost\n",
      "#     return np.array(inferer.arg(), dtype=int), gm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "print len([c for c in itertools.permutations(tmp, 4)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'tmp' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-27-dc5514c489b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'tmp' is not defined"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compatibilityMats = {}\n",
      "compatibilityMats[\"00\"] = np.exp(-np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-black_car1--black_car1.npy\")/50)*10.0\n",
      "compatibilityMats[\"01\"] = np.exp(-np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-black_car1--blue_car1.npy\")/50)*10.0\n",
      "compatibilityMats[\"11\"] = np.exp(-np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-blue_car1--blue_car1.npy\")/50)*10.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(compatibilityMats[\"01\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compatibilityMats = {}\n",
      "compatibilityMats[\"00\"] = np.exp(-np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-black_car1--black_car1.npy\"))*10.0\n",
      "compatibilityMats[\"01\"] = np.exp(-np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-black_car1--blue_car1.npy\"))*10.0\n",
      "compatibilityMats[\"11\"] = np.exp(-np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-blue_car1--blue_car1.npy\"))*10.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compatibilityMats = {}\n",
      "compatibilityMats[\"00\"] = cv2.GaussianBlur(np.exp(-np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-black_car1--black_car1.npy\"))*10.0, (51, 51), 20.0)\n",
      "compatibilityMats[\"01\"] = cv2.GaussianBlur(np.exp(-np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-black_car1--blue_car1.npy\"))*10.0, (51, 51), 20.0)\n",
      "compatibilityMats[\"11\"] = cv2.GaussianBlur(np.exp(-np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-blue_car1--blue_car1.npy\"))*10.0, (51, 51), 20.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compatibilityMats = {}\n",
      "compatibilityMats[\"00\"] = np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-black_car1--black_car1.npy\")\n",
      "compatibilityMats[\"01\"] = np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-black_car1--blue_car1.npy\")\n",
      "compatibilityMats[\"11\"] = np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-blue_car1--blue_car1.npy\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compatibilityMats = {}\n",
      "compatibilityMats[\"00\"] = np.zeros_like(np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-black_car1--black_car1.npy\"))\n",
      "compatibilityMats[\"01\"] = np.zeros_like(np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-black_car1--blue_car1.npy\"))\n",
      "compatibilityMats[\"11\"] = np.zeros_like(np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/inter_sequence_compatibility-bbox_dist-blue_car1--blue_car1.npy\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "synthSeq = np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/newHavana/synthesised_sequence.npy\").item()\n",
      "\n",
      "frameIdx = 0\n",
      "\n",
      "tempWindow = TempWindow(synthSeq)\n",
      "\n",
      "#### NEW WAY ####\n",
      "\n",
      "instancesToUse = []\n",
      "instancesLengths = []\n",
      "maxFrames = 0\n",
      "t = time.time()\n",
      "for i in xrange(len(synthSeq[DICT_SEQUENCE_INSTANCES])) :\n",
      "\n",
      "#     availableDesiredSemantics = len(self.synthesisedSequence[DICT_SEQUENCE_INSTANCES][i][DICT_DESIRED_SEMANTICS]) - self.frameIdx\n",
      "#     if availableDesiredSemantics < self.EXTEND_LENGTH :\n",
      "#         ## the required desired semantics by copying the last one\n",
      "#         print \"extended desired semantics for\", i,\n",
      "#         lastSemantics = self.synthesisedSequence[DICT_SEQUENCE_INSTANCES][i][DICT_DESIRED_SEMANTICS][-1, :]\n",
      "#         self.synthesisedSequence[DICT_SEQUENCE_INSTANCES][i][DICT_DESIRED_SEMANTICS] = np.concatenate((self.synthesisedSequence[DICT_SEQUENCE_INSTANCES][i][DICT_DESIRED_SEMANTICS],\n",
      "#                                                                                                        lastSemantics.reshape((1, len(lastSemantics))).repeat(self.EXTEND_LENGTH-availableDesiredSemantics, axis=0)))\n",
      "#     else :\n",
      "#         print \"didn't extend semantics for\", i\n",
      "    desiredSemantics = synthSeq[DICT_SEQUENCE_INSTANCES][i][DICT_DESIRED_SEMANTICS][frameIdx:frameIdx+tempWindow.EXTEND_LENGTH, :]\n",
      "    print \"num of desired semantics =\", desiredSemantics.shape[0], \"(\", len(synthSeq[DICT_SEQUENCE_INSTANCES][i][DICT_DESIRED_SEMANTICS]), \")\",\n",
      "    print \n",
      "\n",
      "    seqIdx = synthSeq[DICT_SEQUENCE_INSTANCES][i][DICT_SEQUENCE_IDX]\n",
      "\n",
      "    if seqIdx in tempWindow.preloadedTransitionCosts.keys() :\n",
      "        instancesToUse.append(i)\n",
      "        instancesLengths.append(len(tempWindow.semanticSequences[seqIdx][DICT_FRAME_SEMANTICS]))\n",
      "#                 newFrames = self.getNewFramesForSequenceInstanceQuick(i, self.semanticSequences[seqIdx],\n",
      "#                                                                       self.preloadedTransitionCosts[seqIdx]+self.toggleSpeedDeltaSpinBox.value(),\n",
      "#                                                                       desiredSemantics, self.frameIdx, framesToNotUse)\n",
      "    else :\n",
      "        print \"ERROR: cannot extend instance\", i, \"because the semantic sequence\", seqIdx, \"does not have preloadedTransitionCosts\"\n",
      "        break\n",
      "        \n",
      "instancesToUse = np.array(instancesToUse)\n",
      "instancesLengths = np.array(instancesLengths)\n",
      "print instancesToUse, instancesLengths\n",
      "newFramesNewWay, gm = getNewFramesForSequenceFull(tempWindow, synthSeq, np.array(instancesToUse), np.array(instancesLengths), frameIdx)\n",
      "# getNewFramesForSequenceIterative(tempWindow, synthSeq, np.array(instancesToUse), np.array(instancesLengths), np.ones(len(instancesToUse), bool), frameIdx, True)\n",
      "# gm = window.semanticLoopingTab.getNewFramesForSequenceFull(synthSeq, np.array(instancesToUse), np.array(instancesLengths), frameIdx, True)\n",
      "\n",
      "# selectedSequences = np.array([1, 2])\n",
      "# ## using Peter's idea\n",
      "# if True :\n",
      "# #     print selectedSequences, instancesToUse, np.array([instancesToUse != selectedSequence for selectedSequence in selectedSequences]).all(axis=0)\n",
      "#     notSelected = np.array([instancesToUse != selectedSequence for selectedSequence in selectedSequences]).all(axis=0)\n",
      "#     notSelectedInstances = instancesToUse[notSelected]\n",
      "#     selectedSequences = instancesToUse[np.negative(notSelected)]\n",
      "#     for s in xrange(len(selectedSequences)) : #permutation in itertools.permutations(selectedSequences, len(selectedSequences)) :\n",
      "# #         print np.concatenate((notSelectedInstances, permutation)), np.concatenate((np.ones(len(notSelectedInstances), bool), np.zeros(len(permutation), bool)))\n",
      "#         reorderedInstances = np.concatenate((notSelectedInstances, np.roll(selectedSequences, s)))\n",
      "#         reorderedLengths = np.concatenate((instancesLengths[notSelected], np.roll(instancesLengths[np.negative(notSelected)], s)))\n",
      "#         lockedInstances = np.concatenate((np.ones(len(instancesToUse)-1, bool), [False]))\n",
      "#         print reorderedInstances, reorderedLengths, lockedInstances\n",
      "#         print \n",
      "# #         getNewFramesForSequenceIterative(tempWindow, synthSeq, reorderedInstances, reorderedLengths, lockedInstances, frameIdx-50, True, 0.3, 0.7)\n",
      "#         print \n",
      "\n",
      "\n",
      "print \"new way done in\", time.time() - t\n",
      "\n",
      "\n",
      "\n",
      "# print gm.evaluate(newFramesNewWay)\n",
      "# print gm\n",
      "# # print 757.411073682 + 827.424882297 + 805.571144802 + 717.196980651 + 739.054008251 + 765.178588429\n",
      "# print newFramesNewWay.reshape((2, tempWindow.EXTEND_LENGTH))\n",
      "# newFrames1 = newFramesNewWay.reshape((2, tempWindow.EXTEND_LENGTH))[0, :]\n",
      "# newFrames2 = newFramesNewWay.reshape((2, tempWindow.EXTEND_LENGTH))[1, :]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loaded /home/ilisescu/PhD/data/havana/transition_costs_no_normalization_-black_car1.npy\n",
        "loaded /home/ilisescu/PhD/data/havana/transition_costs_no_normalization_-blue_car1.npy\n",
        "num of desired semantics = 301 ( 605 )\n",
        "num of desired semantics = 301 ( 338 )\n",
        "num of desired semantics = 301 ( 361 )\n",
        "num of desired semantics = 301 ( 605 )\n",
        "[0 1 2 3] [274 362 274 362]\n",
        "added vertical pairwise between"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1 and 0    used Transposed comptabilityMat 01\n",
        "added vertical pairwise between 1 and 1    used comptabilityMat 11 (274, 274)\n",
        "added vertical pairwise between 1 and 0    used Transposed comptabilityMat 01\n",
        "added vertical pairwise between 0 and 1    used comptabilityMat 01 (362, 274)\n",
        "added vertical pairwise between 0 and 0    used comptabilityMat 00 (362, 362)\n",
        "added vertical pairwise between 1 and 0    used Transposed comptabilityMat 01\n",
        "-number of variables :1204\n",
        "-number of function(type-0)1214\n",
        "-number of function(type-1)0\n",
        "-number of function(type-2)0\n",
        "-number of function(type-3)0\n",
        "-number of function(type-4)0\n",
        "-number of function(type-5)0\n",
        "-number of function(type-6)0\n",
        "-number of function(type-7)0\n",
        "-number of factors :4210\n",
        "-max. factor order :2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "solved in 6475.9673481\n",
        "new way done in 6476.05949807\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "instancesToUse = np.array([0, 1, 2, 3])\n",
      "instancesLengths = np.array([10, 31, 51,12])\n",
      "print instancesToUse, instancesLengths\n",
      "# newFramesNewWay, gm = getNewFramesForSequenceFull(tempWindow, synthSeq, np.array(instancesToUse), np.array(instancesLengths), frameIdx, True)\n",
      "# getNewFramesForSequenceIterative(tempWindow, synthSeq, np.array(instancesToUse), np.array(instancesLengths), np.ones(len(instancesToUse), bool), frameIdx, True)\n",
      "# gm = window.semanticLoopingTab.getNewFramesForSequenceFull(synthSeq, np.array(instancesToUse), np.array(instancesLengths), frameIdx, True)\n",
      "\n",
      "selectedSequences = np.array([-1])\n",
      "## using Peter's idea\n",
      "if True :\n",
      "#     print selectedSequences, instancesToUse, np.array([instancesToUse != selectedSequence for selectedSequence in selectedSequences]).all(axis=0)\n",
      "    notSelected = np.array([instancesToUse != selectedSequence for selectedSequence in selectedSequences]).all(axis=0)\n",
      "    notSelectedInstances = instancesToUse[notSelected]\n",
      "    selectedSequences = instancesToUse[np.negative(notSelected)]\n",
      "    print notSelectedInstances\n",
      "    if len(selectedSequences) > 1 :\n",
      "        for s in xrange(len(selectedSequences)) : #permutation in itertools.permutations(selectedSequences, len(selectedSequences)) :\n",
      "    #         print np.concatenate((notSelectedInstances, permutation)), np.concatenate((np.ones(len(notSelectedInstances), bool), np.zeros(len(permutation), bool)))\n",
      "            reorderedInstances = np.concatenate((notSelectedInstances, np.roll(selectedSequences, s)))\n",
      "            reorderedLengths = np.concatenate((instancesLengths[notSelected], np.roll(instancesLengths[np.negative(notSelected)], s)))\n",
      "            lockedInstances = np.concatenate((np.ones(len(instancesToUse)-1, bool), [False]))\n",
      "    else :\n",
      "        print notSelectedInstances, instancesLengths[notSelected], np.zeros(len(notSelectedInstances), bool)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 1 2 3] [10 31 51 12]\n",
        "[0 1 2 3]\n",
        "[0 1 2 3] [10 31 51 12] [False False False False]\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "synthSeq = np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/wave-tagging_bad_jumps/synthesised_sequence.npy\").item()\n",
      "# print synthSeq[DICT_SEQUENCE_INSTANCES][1][DICT_DESIRED_SEMANTICS][68:169]\n",
      "usedSeq = np.load(synthSeq[DICT_USED_SEQUENCES][1]).item()\n",
      "unaries = np.zeros((usedSeq[DICT_FRAME_SEMANTICS].shape[0], 101))\n",
      "desiredSems = np.argmax(synthSeq[DICT_SEQUENCE_INSTANCES][1][DICT_DESIRED_SEMANTICS][68:169, :], axis=1)\n",
      "thresholdedSems = synthSeq[DICT_SEQUENCE_INSTANCES][1][DICT_DESIRED_SEMANTICS][np.arange(68, 169), desiredSems] > 0.75\n",
      "print desiredSems * thresholdedSems\n",
      "print (1-desiredSems) * thresholdedSems\n",
      "\n",
      "for i, des in enumerate(desiredSems * thresholdedSems) :\n",
      "    if des == 1 :\n",
      "        unaries[:, i] = usedSeq[DICT_FRAME_SEMANTICS][:, 1] <= 0.75\n",
      "        \n",
      "for i, des in enumerate((1-desiredSems) * thresholdedSems) :\n",
      "    if des == 1 :\n",
      "        unaries[:, i] = usedSeq[DICT_FRAME_SEMANTICS][:, 0] <= 0.75\n",
      "\n",
      "# for i, sem in enumerate(usedSeq[DICT_FRAME_SEMANTICS]) :\n",
      "#     print sem[np.argmax(sem)] > 0.75\n",
      "#     if np.argmax(sem) == 0 and sem[np.argmax(sem)] <= 0.75 :\n",
      "#         unaries[i, ((1-desiredSems) * thresholdedSems).astype(bool)] = 1\n",
      "#     elif \n",
      "gwv.showCustomGraph(unaries)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
        " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
        "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
        " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# usedSeq[DICT_TRANSITION_COSTS_LOCATION] = \"/media/ilisescu/Data1/PhD/data/wave2/transition_costs_no_normalization_-tara2.npy\"\n",
      "# np.save(usedSeq[DICT_SEQUENCE_LOCATION], usedSeq)\n",
      "print usedSeq[DICT_TRANSITION_COSTS_LOCATION]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/media/ilisescu/Data1/PhD/data/wave2/transition_costs_no_normalization_-tara2.npy\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(np.load(\"/media/ilisescu/Data1/PhD/data/wave2/transition_costs-learned_thresholded_filtered-tara2.npy\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print window.semanticLoopingTab.synthesisedSequence[DICT_USED_SEQUENCES][1]\n",
      "testSequence = np.load(\"/home/ilisescu/PhD/data/havana/semantic_sequence-blue_car1.npy\").item()\n",
      "# print testSequence[DICT_TRANSITION_COSTS_LOCATION]\n",
      "distMat = np.load(\"/home/ilisescu/PhD/data/havana/\"+testSequence[DICT_SEQUENCE_NAME]+\"-vanilla_distMat.npy\")\n",
      "## filter ##\n",
      "filterSize = 4\n",
      "optimizedDistMat = vtu.filterDistanceMatrix(distMat, filterSize, True)\n",
      "\n",
      "isLooping = True\n",
      "\n",
      "## if using vanilla\n",
      "if True :\n",
      "    optimizedDistMat = optimizedDistMat[1:optimizedDistMat.shape[1], 0:-1]\n",
      "    correction = 1\n",
      "else :\n",
      "    correction = 0\n",
      "\n",
      "## don't want to jump too close so increase costs in a window\n",
      "minJumpLength = 1\n",
      "tmp = (np.triu(np.ones(optimizedDistMat.shape), k=minJumpLength) +\n",
      "       np.tril(np.ones(optimizedDistMat.shape), k=-minJumpLength) +\n",
      "       np.eye(optimizedDistMat.shape[0], k=1))\n",
      "tmp[tmp == 0] = 10.0\n",
      "optimizedDistMat *= tmp\n",
      "#########################################\n",
      "\n",
      "\n",
      "# thresholdedCosts = np.copy(sequenceTransitionCost) #np.load(\"/media/ilisescu/Data1/PhD/data/wave2/transition_costs-tara2.npy\")\n",
      "\n",
      "## thresholded distMat\n",
      "# testCosts = np.copy(optimizedDistMat) ## turns into a hunt for best semantic importance parameter and it ends with wither not switching label or switching to it immediately\n",
      "## without threshold it does pretty much the same but the fact that it has more jumps means it can use slightly worse frames in terms of semantics but better in terms of jumps\n",
      "\n",
      "## constant multiplier\n",
      "# testCosts = np.copy(optimizedDistMat)*100.0 ## does the same as thresholded\n",
      "\n",
      "## squared\n",
      "# testCosts = np.copy(optimizedDistMat)**2 ## this does the same as above and interestingly has the same semantic importance as above after binary search\n",
      "\n",
      "## exponential\n",
      "testCosts = np.exp(np.copy(optimizedDistMat)/(np.average(optimizedDistMat)*0.2)) ## this does the same as above and interestingly has the same semantic importance as above after binary search WTF???\n",
      "\n",
      "######## I'M FULL OF SHIT --> THEY SHOULD ALL WORK, PROBLEM WAS THAT THE TARA SPRITE I WAS LOOKING AT HAPPENED TO SWITCH LABEL AROUND THE 100 FRAME MARK \n",
      "######## (JUMPING OVER THE SMOOTHSTEP TRANSITION MOST LIKELY)\n",
      "######## SO WITHOUT A HIGH ENOUGH SEMANTIC IMPORTANCE, THE LAST FRAMES OF THE FIRST SEQUENCE WOULDN'T GET THE RIGHT SEMANTIC AND THEN FROM THERE ON\n",
      "######## IT'S PRETTY HARD TO SWITCH THE LABEL IMMEDITALEY WITHOUT THE SMOOTHSTEP TRANSITION\n",
      "\n",
      "\n",
      "## constant addition\n",
      "# testCosts = np.copy(optimizedDistMat)+2.0 ## does the same as above and all use the same semantic importance value!!!!!\n",
      "\n",
      "\n",
      "\n",
      "#########################################\n",
      "## do the thresholding based on how many jumps I want to keep per frame\n",
      "desiredPercentage = 0.1 ## desired percentage of transitions to keep\n",
      "jumpsToKeep = int(testCosts.shape[0]*desiredPercentage)\n",
      "testCosts[np.arange(testCosts.shape[0]).repeat(testCosts.shape[0]-jumpsToKeep),\n",
      "                       np.argsort(testCosts, axis=-1)[:, jumpsToKeep:].flatten()] = GRAPH_MAX_COST\n",
      "\n",
      "\n",
      "## adding extra rows and columns so that the optimized matrix has the same dimensions as distMat\n",
      "## for the indices that were cut out I put zero cost for jumps to frames that can still be used after optimization\n",
      "if isLooping :\n",
      "    ## it means I deal with sprites like the havana cars\n",
      "    testCosts = np.concatenate((np.ones((testCosts.shape[0], filterSize))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts),\n",
      "                                testCosts,\n",
      "                                (1.0-np.eye(testCosts.shape[0], filterSize+correction+1, k=-testCosts.shape[0]+1))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=1)\n",
      "    ## the +1 is because if a sprite is looping, the last frame is the empty frame\n",
      "    testCosts = np.concatenate(((1.0-np.eye(filterSize, distMat.shape[0]+1, k=1))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts),\n",
      "                                testCosts,\n",
      "                                (1.0-np.eye(filterSize+correction+1, distMat.shape[0]+1, k=distMat.shape[0]+1-filterSize-correction))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=0)\n",
      "    ## setting the looping from the last frame\n",
      "    testCosts[-2, 0] = np.min(testCosts)\n",
      "    ## setting the looping from the empty frame and in place looping\n",
      "    testCosts[-1, 0] = testCosts[-1, -1] = np.min(testCosts)\n",
      "else :\n",
      "    testCosts = np.concatenate((np.ones((testCosts.shape[0], filterSize))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts),\n",
      "                                testCosts,\n",
      "                                np.ones((testCosts.shape[0], filterSize+correction))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=1)\n",
      "    testCosts = np.concatenate((np.roll(np.concatenate((np.zeros((filterSize, 1)) + np.min(testCosts),\n",
      "                                                        np.ones((filterSize, distMat.shape[0]-1))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=1), filterSize, axis=1),\n",
      "                                testCosts,\n",
      "                                np.roll(np.concatenate((np.zeros((filterSize+correction, 1)) + np.min(testCosts),\n",
      "                                                        np.ones((filterSize+correction, distMat.shape[0]-1))*(np.max(testCosts)-np.min(testCosts)) + np.min(testCosts)), axis=1), filterSize, axis=1)), axis=0)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gwv.showCustomGraph(testCosts)\n",
      "print testSequence[DICT_TRANSITION_COSTS_LOCATION]\n",
      "# testSequence[DICT_TRANSITION_COSTS_LOCATION] = \"/media/ilisescu/Data1/PhD/data/wave2/transition_costs_TEST_-tara2.npy\"\n",
      "# np.save(testSequence[DICT_TRANSITION_COSTS_LOCATION], testCosts)\n",
      "# np.save(testSequence[DICT_SEQUENCE_LOCATION], testSequence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ilisescu/PhD/data/havana/transition_costs_no_normalization_-blue_car1.npy\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import special"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(tmp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(np.load(\"/home/ilisescu/PhD/data/havana/transition_costs_no_normalization_-blue_car1.npy\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(np.load(\"/media/ilisescu/Data1/PhD/data/toy/transition_costs-precomputed_loops-toy1.npy\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# np.save(\"waveSeqBadJames.npy\", window.semanticLoopingTab.synthesisedSequence)\n",
      "synthSequence = np.load(\"waveSeqBadJames.npy\").item()\n",
      "usedSequence = np.load(synthSequence[DICT_USED_SEQUENCES][synthSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_IDX]]).item()\n",
      "print synthSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES]\n",
      "# print synthSequence[DICT_SEQUENCE_INSTANCES][0][DICT_DESIRED_SEMANTICS]\n",
      "# print usedSequence[DICT_FRAME_SEMANTICS][synthSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES], :]\n",
      "usedDistMat = np.load(usedSequence[DICT_TRANSITION_COSTS_LOCATION])\n",
      "print usedDistMat[368, 510]\n",
      "visCosts = np.copy(usedDistMat)\n",
      "visCosts[visCosts == GRAPH_MAX_COST] = 50.0\n",
      "# visCosts[visCosts != 0] = np.log(visCosts[visCosts != 0])\n",
      "gwv.showCustomGraph(visCosts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  0   2 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
        " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
        " 360 361 362 363 364 365 366 367 368 510 511 512 513 514 515 516 517 518\n",
        " 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536\n",
        " 537 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526\n",
        " 527 528 529 530 531 532 533 534 535 536 537]\n",
        "24.1895028357\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def saveSequenceImages(outputDir, bgImage, synthesisedSequence, semanticSequences, preloadedPatches) :\n",
      "    for frameIdx in arange(len(synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES]))[0:] :\n",
      "        ## go through all the semantic sequence instances\n",
      "#         frame = np.zeros((bgImage.shape[0], bgImage.shape[1], 4), dtype=uint8)\n",
      "#         frame[:, :, 0:3] = bgImage[:, :, 0:3]\n",
      "        frame = np.copy(bgImage[:, :, 0:3])\n",
      "        for s in xrange(len(synthesisedSequence[DICT_SEQUENCE_INSTANCES])) :\n",
      "            ## index in semanticSequences of current instance\n",
      "            seqIdx = int(synthesisedSequence[DICT_SEQUENCE_INSTANCES][s][DICT_SEQUENCE_IDX])\n",
      "            ## if there's a frame to show and the requested frameIdx exists for current instance draw, else draw just first frame\n",
      "            if frameIdx < len(synthesisedSequence[DICT_SEQUENCE_INSTANCES][s][DICT_SEQUENCE_FRAMES]) :\n",
      "                sequenceFrameIdx = int(synthesisedSequence[DICT_SEQUENCE_INSTANCES][s][DICT_SEQUENCE_FRAMES][frameIdx])\n",
      "                if sequenceFrameIdx >= 0 and sequenceFrameIdx < len(semanticSequences[seqIdx][DICT_FRAMES_LOCATIONS].keys()) :\n",
      "                    frameToShowKey = np.sort(semanticSequences[seqIdx][DICT_FRAMES_LOCATIONS].keys())[sequenceFrameIdx]\n",
      "                else :\n",
      "                    frameToShowKey = -1\n",
      "                    print \"NOT OVERLAYING 1\"\n",
      "            else :\n",
      "                frameToShowKey = -1 #np.sort(semanticSequences[seqIdx][DICT_FRAMES_LOCATIONS].keys())[0]\n",
      "                print \"NOT OVERLAYING 2\"\n",
      "\n",
      "            if frameToShowKey >= 0 and seqIdx >= 0 and seqIdx < len(semanticSequences) :\n",
      "                if seqIdx in preloadedPatches.keys() :\n",
      "                    frame = drawFrame(np.copy(frame), semanticSequences[seqIdx], frameToShowKey,\n",
      "                                      synthesisedSequence[DICT_SEQUENCE_INSTANCES][s][DICT_OFFSET],\n",
      "                                      synthesisedSequence[DICT_SEQUENCE_INSTANCES][s][DICT_SCALE],\n",
      "                                      preloadedPatches[seqIdx][frameToShowKey])\n",
      "                else :\n",
      "                    frame = drawFrame(np.copy(frame), semanticSequences[seqIdx], frameToShowKey,\n",
      "                                      synthesisedSequence[DICT_SEQUENCE_INSTANCES][s][DICT_OFFSET],\n",
      "                                      synthesisedSequence[DICT_SEQUENCE_INSTANCES][s][DICT_SCALE])\n",
      "        \n",
      "#                 drawOverlay.save(outputDir+\"frame-{0:05d}.png\".format(frameIdx+1))\n",
      "#                 figure(); imshow(frame)%%!\n",
      "        Image.fromarray(frame.astype(np.uint8)).save(outputDir+\"frame-{0:05d}.png\".format(frameIdx+1))\n",
      "\n",
      "        \n",
      "def drawFrame(currentFrame, sequence, frameKey, offset, scale, spritePatch = None) :\n",
      "    \n",
      "#     frame = np.zeros((imgSize[0], imgSize[1], 3), dtype=np.uint8)\n",
      "\n",
      "    scaleTransf = np.array([[scale[0], 0.0], [0.0, scale[1]]])\n",
      "    offsetTransf = np.array([[offset[0]], [offset[1]]])\n",
      "\n",
      "    ## draw sprite\n",
      "    tl = np.min(sequence[DICT_BBOXES][frameKey], axis=0)\n",
      "    br = np.max(sequence[DICT_BBOXES][frameKey], axis=0)\n",
      "    w, h = br-tl\n",
      "    aabb = np.array([tl, tl + [w, 0], br, tl + [0, h]])\n",
      "\n",
      "    transformedAABB = (np.dot(scaleTransf, aabb.T) + offsetTransf)\n",
      "\n",
      "    if spritePatch != None :\n",
      "        transformedPatchTopLeftDelta = np.dot(scaleTransf, spritePatch['top_left_pos'][::-1].reshape((2, 1))-tl.reshape((2, 1)))\n",
      "\n",
      "        image = np.ascontiguousarray(np.zeros((spritePatch['patch_size'][0], spritePatch['patch_size'][1], 4)), dtype=np.uint8)\n",
      "        image[spritePatch['visible_indices'][:, 0], spritePatch['visible_indices'][:, 1], :] = spritePatch['sprite_colors']\n",
      "\n",
      "    else :\n",
      "        transformedPatchTopLeftDelta = np.zeros((2, 1))\n",
      "\n",
      "        frameName = sequence[DICT_FRAMES_LOCATIONS][frameKey].split(os.sep)[-1]\n",
      "        if DICT_MASK_LOCATION in sequence.keys() :\n",
      "            image = np.array(Image.open(sequence[DICT_MASK_LOCATION]+frameName))[:, :, [2, 1, 0, 3]]\n",
      "        else :\n",
      "            image = np.array(Image.open(sequence[DICT_FRAMES_LOCATIONS][frameKey]))\n",
      "        image = np.ascontiguousarray(image[aabb[0, 1]:aabb[2, 1], aabb[0, 0]:aabb[2, 0], :])\n",
      "\n",
      "    if image.shape[-1] == 3 :\n",
      "        img = cv2.cvtColor(cv2.resize(image, dsize=(0, 0), fx = scale[0], fy=scale[1], interpolation=cv2.INTER_AREA), cv2.COLOR_BGR2RGB)\n",
      "    else :\n",
      "        img = cv2.cvtColor(cv2.resize(image, dsize=(0, 0), fx = scale[0], fy=scale[1], interpolation=cv2.INTER_AREA), cv2.COLOR_BGRA2RGBA)\n",
      "    topLeftPos = transformedAABB[:, :1] + transformedPatchTopLeftDelta\n",
      "    \n",
      "#     currentFrame[topLeftPos[1]:topLeftPos[1]+img.shape[0], \n",
      "#                  topLeftPos[0]:topLeftPos[0]+img.shape[1], :] = img\n",
      "    \n",
      "    if img.shape[-1] == 3 :\n",
      "        currentFrame[topLeftPos[1]:topLeftPos[1]+img.shape[0], \n",
      "                     topLeftPos[0]:topLeftPos[0]+img.shape[1], :] = img\n",
      "    else :\n",
      "        currentFrame[topLeftPos[1]:topLeftPos[1]+img.shape[0], \n",
      "                     topLeftPos[0]:topLeftPos[0]+img.shape[1]] = (img[:, :, 0:3]*(img[:, :, 3].reshape((img.shape[0], img.shape[1], 1))/255.0)+\n",
      "                                                             currentFrame[topLeftPos[1]:topLeftPos[1]+img.shape[0], \n",
      "                                                                          topLeftPos[0]:topLeftPos[0]+img.shape[1], 0:3]*(1.0-img[:, :, 3].reshape((img.shape[0], img.shape[1], 1))/255.0))\n",
      "\n",
      "\n",
      "    return currentFrame\n",
      "        \n",
      "        \n",
      "# location = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/wave-batch_ish_changed_slightly_where_asking_sems_too_long/\"\n",
      "# location = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/wave-same_as_batch_ish_but_costs_from_dists_no_normalization/\"\n",
      "location = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/wave-test_sequence/\"\n",
      "synthesisedSequence = np.load(location+\"synthesised_sequence.npy\").item()\n",
      "## update background\n",
      "bgImage = np.ascontiguousarray(np.array(Image.open(synthesisedSequence[DICT_SEQUENCE_BG]))[:, :, 0:3])\n",
      "# bgImage = QtGui.QImage(im.data, im.shape[1], im.shape[0], im.strides[0], QtGui.QImage.Format_RGB888);\n",
      "\n",
      "## load used semantic sequences\n",
      "semanticSequences = []\n",
      "preloadedPatches = {}\n",
      "for index, seq in enumerate(synthesisedSequence[DICT_USED_SEQUENCES]) :\n",
      "    semanticSequences.append(np.load(seq).item())\n",
      "    if DICT_PATCHES_LOCATION in semanticSequences[-1].keys() :\n",
      "        preloadedPatches[index] = np.load(semanticSequences[-1][DICT_PATCHES_LOCATION]).item()\n",
      "        \n",
      "saveSequenceImages(location, bgImage, synthesisedSequence, semanticSequences, preloadedPatches)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### resample sprites to a subset of the initial frames\n",
      "subsetExtremes = np.array([[1122, 2674], [1252, 2588], [1394, 2610], [1346, 2522], [1216, 2496], [1806, 2702], [1624, 2880], [1478, 2614]]) ## wave1\n",
      "# subsetExtremes = np.array([[682, 2002], [1194, 1938], [470, 1990], [896, 2088], [899, 2019], [1320, 2256], [546, 2050], [886, 2006]]) ## wave2\n",
      "# subsetExtremes = np.array([[868, 1844], [1060, 1708], [372, 1804], [832, 1984], [1173, 1893], [1020, 2100], [806, 1902], [906, 1906]]) ## wave3\n",
      "baseLoc = \"/media/ilisescu/Data1/PhD/data/wave1/\"\n",
      "# for i, sprite in enumerate(np.sort(glob.glob(baseLoc+\"sprite*.npy\"))) :\n",
      "#     print sprite, subsetExtremes[i, :], np.diff(subsetExtremes[i, :])\n",
      "#     s = np.load(sprite).item()\n",
      "    \n",
      "#     allKeys = s[DICT_FRAMES_LOCATIONS].keys()\n",
      "#     for key in allKeys :\n",
      "#         if key < subsetExtremes[i, 0] or key >= subsetExtremes[i, 1] :\n",
      "#             del s[DICT_BBOX_CENTERS][key]\n",
      "#             del s[DICT_BBOX_ROTATIONS][key]\n",
      "#             del s[DICT_BBOXES][key]\n",
      "#             del s[DICT_FRAMES_LOCATIONS][key]\n",
      "#     s[DICT_FRAME_SEMANTICS] = s[DICT_FRAME_SEMANTICS][subsetExtremes[i, 0]:subsetExtremes[i, 1], :]\n",
      "#     s[DICT_ICON_FRAME_KEY] = subsetExtremes[i, 0]\n",
      "    \n",
      "# #     print s.keys()\n",
      "# #     print s[DICT_ICON_FRAME_KEY]\n",
      "# #     print len(s[DICT_BBOX_CENTERS].keys())\n",
      "# #     print len(s[DICT_BBOX_ROTATIONS].keys())\n",
      "# #     print len(s[DICT_BBOXES].keys())\n",
      "# #     print len(s[DICT_FRAMES_LOCATIONS].keys())\n",
      "# #     print s[DICT_FRAME_SEMANTICS].shape\n",
      "\n",
      "\n",
      "#     np.save(sprite, s)\n",
      "# #     print np.load(baseLoc+s[DICT_SEQUENCE_NAME]+\"-vanilla_distMat.npy\").shape\n",
      "#     np.save(baseLoc+s[DICT_SEQUENCE_NAME]+\"-vanilla_distMat.npy\", \n",
      "#             np.load(baseLoc+s[DICT_SEQUENCE_NAME]+\"-vanilla_distMat.npy\")[subsetExtremes[i, 0]:subsetExtremes[i, 1], subsetExtremes[i, 0]:subsetExtremes[i, 1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## puts together sound based on semantics of synthesised sequence\n",
      "soundTracks = []\n",
      "samplerate = 0\n",
      "for track in np.sort(glob.glob(\"/media/ilisescu/Data1/PhD/data/toy/toy[1-8].wav\")) :\n",
      "    print track,\n",
      "    sig, samplerate = sf.read(track)\n",
      "    print sig.shape\n",
      "    soundTracks.append(sig)\n",
      "\n",
      "synthSequence = np.load(dataPath+\"synthesisedSequences/lullaby/synthesised_sequence.npy\").item()#window.semanticLoopingTab.synthesisedSequence\n",
      "usedSequence = np.load(synthSequence[DICT_USED_SEQUENCES][0]).item()\n",
      "frameSemantics = usedSequence[DICT_FRAME_SEMANTICS][:, 1:]\n",
      "numSemantics = frameSemantics.shape[1]\n",
      "usedFrames = synthSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES]\n",
      "videoFPS = 50.0\n",
      "audioSamplesPerFrame = int(np.round(samplerate/videoFPS))\n",
      "audioTrack = np.zeros((audioSamplesPerFrame*len(usedFrames), 2))\n",
      "\n",
      "for sem in arange(numSemantics)[0:] :\n",
      "#     figure(); plot(frameSemantics[usedFrames, sem])\n",
      "    semLocs = np.argwhere(frameSemantics[usedFrames, sem] > 0.9).flatten()\n",
      "    print semLocs\n",
      "    if len(semLocs) > 0 :\n",
      "        clusters = np.concatenate(([0], np.cumsum((np.abs(semLocs[:-1]-semLocs[1:]) != 1).astype(int))))\n",
      "        for cluster in xrange(np.max(clusters)+1) :\n",
      "            centerLoc = int(np.round(np.median(semLocs[np.argwhere(clusters == cluster).flatten()])))\n",
      "            print centerLoc, centerLoc*audioSamplesPerFrame, sem, len(soundTracks[sem])\n",
      "            audioTrack[centerLoc*audioSamplesPerFrame:centerLoc*audioSamplesPerFrame+len(soundTracks[sem]), :] += soundTracks[sem]\n",
      "    #         scatter(centerLoc, 1)\n",
      "sf.write(dataPath+\"synthesisedSequences/lullaby/lullaby.wav\", audioTrack, samplerate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[]\n",
        "[331 332 333 334 335 390 391 392 393 394 418 419 420 421 422 487 488 489\n",
        " 490 491]\n",
        "333 319680 1 33256\n",
        "392 376320 1 33256\n",
        "420 403200 1 33256\n",
        "489 469440 1 33256\n",
        "[  9  10  11  12  13  24  25  26  27  28  72  73  74  75  76  87  88  89\n",
        "  90  91 149 150 151 152 153 347 348 349 350 351 434 435 436 437 438]\n",
        "11 10560 2 34998\n",
        "26 24960 2 34998\n",
        "74 71040 2 34998\n",
        "89 85440 2 34998\n",
        "151 144960 2 34998\n",
        "349 335040 2 34998\n",
        "436 418560 2 34998\n",
        "[362 363 364 365 366 449 450 451 452 453 504 505 506 507 508]\n",
        "364 349440 3 39591\n",
        "451 432960 3 39591\n",
        "506 485760 3 39591\n",
        "[ 36  37  38  39  40 102 103 104 105 106 164 165 166 167 168 299 300 301\n",
        " 302 303 562 563 564 565 566]\n",
        "38 36480 4 37374\n",
        "104 99840 4 37374\n",
        "166 159360 4 37374\n",
        "301 288960 4 37374\n",
        "564 541440 4 37374\n",
        "[237 238 239 240 241 270 271 272 273 274 542 543 544 545 546]\n",
        "239 229440 5 37216\n",
        "272 261120 5 37216\n",
        "544 522240 5 37216\n",
        "[208 209 210 211 212 525 526 527 528 529 592 593 594 595 596]\n",
        "210 201600 6 35315\n",
        "527 505920 6 35315\n",
        "594 570240 6 35315\n",
        "[182 183 184 185 186 187 188 622 623 624 625 626 627 628 629]\n",
        "185 177600 7 36423\n",
        "626 600960 7 36423\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def intervalOverlap(intervals) :\n",
      "    ############# this doesn't really work with more than 2 intervals #############\n",
      "    \n",
      "    \n",
      "    ## this returns a sorted array such that the numbers in the first column are the sorted interval start and end points\n",
      "    ## and the second column are the their indices where even numbers denote starting points and odd ones denote end points\n",
      "    ## the key makes sure that I put start points before end points if they have the same value\n",
      "    sortedPoints = np.array(sorted(np.array([(x, y) for x, y in zip(intervals.flatten(), arange(len(intervals)*2))]), key=lambda t: (t[0], np.mod(t[1], 2))))\n",
      "#     print sortedPoints\n",
      "    startInterval = -1\n",
      "    numEnteredIntervals = 0\n",
      "    for i in sortedPoints[:, 1] :\n",
      "        ## if even then I'm entering an interval\n",
      "        if np.mod(i, 2) == 0 :\n",
      "            startInterval = i\n",
      "            numEnteredIntervals += 1\n",
      "        else :\n",
      "            if numEnteredIntervals > 1 :\n",
      "                startIntervalIdx = startInterval/len(intervals.T)\n",
      "                endIntervalIdx = i/len(intervals.T)\n",
      "                overlapAmount = intervals[endIntervalIdx, 1]-intervals[startIntervalIdx, 0]+1\n",
      "#                 print \"overlap =\", startIntervalIdx, endIntervalIdx, np.sum(np.abs(np.diff(intervals, axis=-1)))+1-overlapAmount, \n",
      "                return float(overlapAmount)/(np.sum(np.abs(np.diff(intervals, axis=-1))+1)-overlapAmount), overlapAmount\n",
      "#                 return float(overlapAmount)/np.min(np.abs(np.diff(intervals, axis=-1))+1), overlapAmount\n",
      "            else :\n",
      "                return 0.0, 0\n",
      "            numEnteredIntervals -= 1\n",
      "    \n",
      "    \n",
      "# print intervalOverlap(np.array([[200, 250], [220, 270]]))\n",
      "# print intervalOverlap(np.array([[220, 270], [200, 250]]))\n",
      "# print intervalOverlap(np.array([[190, 270], [200, 250]]))\n",
      "# print intervalOverlap(np.array([[200, 250], [190, 270]]))\n",
      "# print intervalOverlap(np.array([[150, 195], [200, 250]]))\n",
      "# print intervalOverlap(np.array([[200, 250], [150, 195]]))\n",
      "# print intervalOverlap(np.array([[200, 250], [250, 320]]))\n",
      "# print intervalOverlap(np.array([[447, 467], [446, 467]]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###### load synthesised sequence ######\n",
      "# synthSequence = np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/wave/synthesised_sequence.npy\").item()\n",
      "###### get used semantic sequence ######\n",
      "# usedSequence = np.load(synthSequence[DICT_USED_SEQUENCES][0]).item()\n",
      "def getPrecomputedLoops(semanticSequence) :\n",
      "    print semanticSequence[DICT_SEQUENCE_NAME]\n",
      "    # semanticSequence = np.load(\"/media/ilisescu/Data1/PhD/data/wave3/semantic_sequence-peter3.npy\").item()\n",
      "\n",
      "    numSemantics = semanticSequence[DICT_FRAME_SEMANTICS].shape[1]\n",
      "\n",
      "    ###### get distance matrix and process for video textures ######\n",
      "    distMat = np.load(\"/\".join(semanticSequence[DICT_SEQUENCE_LOCATION].split(\"/\")[:-1])+\"/\"+semanticSequence[DICT_SEQUENCE_NAME]+\"-vanilla_distMat.npy\")\n",
      "\n",
      "    filterSize = correction = 4\n",
      "    distMat = vtu.filterDistanceMatrix(distMat, filterSize, False)[1:, :-1]\n",
      "\n",
      "    probs, cumProbs = vtu.getProbabilities(distMat, 0.05, np.zeros_like(distMat), True)\n",
      "#     gwv.showCustomGraph(probs)\n",
      "\n",
      "    precomputedLoops = []\n",
      "    ###### for each possible semantics get the best loops ######\n",
      "    for currentSemantics in arange(numSemantics)[0:] :\n",
      "        ###### set desired semantics and get cost of each frame based on how far their label is to the desired one and how far in the timeline they are ######\n",
      "        desiredSemantics = np.zeros((1, numSemantics))\n",
      "        desiredSemantics[0, currentSemantics] = 1.0\n",
      "        distVariance = 0.05\n",
      "        distToSemantics = vectorisedMinusLogMultiNormal(semanticSequence[DICT_FRAME_SEMANTICS], desiredSemantics, np.eye(desiredSemantics.shape[1])*distVariance, False).T\n",
      "\n",
      "        frameSemanticCost = distToSemantics[filterSize:-filterSize-1]\n",
      "        ## the further away from a frame showing the desired semantics, the higher the cost\n",
      "        frameSemanticCost[np.argwhere(frameSemanticCost >= 0.01*np.max(frameSemanticCost))] = np.max(frameSemanticCost)\n",
      "        frameSemanticCost = frameSemanticCost+np.min(np.abs(arange(len(frameSemanticCost)).reshape((1, len(frameSemanticCost))) - np.argwhere(frameSemanticCost < 0.01*np.max(frameSemanticCost))), axis=0)\n",
      "\n",
      "        ###### run stochastic video textures and store the jump locations ######\n",
      "        totalJumps = 10000\n",
      "        currentFrame = np.random.choice(np.argsort(frameSemanticCost)[:10])\n",
      "\n",
      "        ## jumps in jumpLocations are already at the correct position (i.e. they account for the filtering of distMat)\n",
      "        jumpLocations = np.zeros(np.array(distMat.shape)+filterSize*2, dtype=int)\n",
      "        jumpCounter = 0\n",
      "        prevFrame = vtu.getNewFrame(currentFrame, cumProbs)\n",
      "        while jumpCounter < totalJumps :\n",
      "            currentFrame = vtu.getNewFrame(prevFrame, cumProbs, 100)\n",
      "            ## if there is a jump, record it\n",
      "            if currentFrame != prevFrame + 1 :\n",
      "                jumpCounter += 1\n",
      "                jumpLocations[prevFrame+correction, currentFrame+correction] += 1\n",
      "\n",
      "                ## randomly reinitialize the start frame to one of the best frames showing desiredSemantics\n",
      "                if np.random.rand() < 0.5 :\n",
      "                    currentFrame = vtu.getNewFrame(np.random.choice(np.argsort(frameSemanticCost)[:10]), cumProbs, 10)\n",
      "            prevFrame = currentFrame\n",
      "\n",
      "            if np.mod(jumpCounter, 1000) == 0 :\n",
      "                sys.stdout.write('\\r' + \"Jumped \" + np.string_(jumpCounter) + \" times\")\n",
      "                sys.stdout.flush()\n",
      "\n",
      "        print\n",
      "#         gwv.showCustomGraph(jumpLocations)\n",
      "\n",
      "        ###### sort jumps based on how often they've been used ######\n",
      "        sortedJumps = np.argsort(np.ndarray.flatten(jumpLocations))[::-1]\n",
      "        sortedJumps = np.array([np.array(sortedJumps/jumpLocations.shape[0], dtype=int), \n",
      "                                np.array(np.mod(sortedJumps, jumpLocations.shape[0]), dtype=int)]).T\n",
      "\n",
      "        ###### find backward jumps among the top used jumps ######\n",
      "        numJumpsToConsider = 5000\n",
      "        jump = sortedJumps[2, :]\n",
      "        backwardsJumps = [] ## (jump_from, jump_to, semantics_cost, jump_cost)\n",
      "        for jump in sortedJumps[:numJumpsToConsider, :] :\n",
      "            if jump[0] > jump[1] :\n",
      "                backwardsJumps.append(np.array([jump[0], jump[1], \n",
      "                                                np.sum(frameSemanticCost[arange(jump[1], jump[0]+1)-correction]),\n",
      "                                                distMat[jump[0]-correction, jump[1]-correction]]))\n",
      "\n",
      "        ###### only keep loops that show the desired semantic ######\n",
      "        validLoops = []\n",
      "        for i, jump in enumerate(backwardsJumps) :\n",
      "            newJump = np.sort(jump[:2])\n",
      "\n",
      "            loopDistToSemantics = frameSemanticCost[arange(newJump[0]-correction, newJump[1]-correction, dtype=int)]\n",
      "            thresh = np.max(distToSemantics)+1 ## it means I'm within 1 frames of the desired semantics\n",
      "            complyingFrames = loopDistToSemantics < thresh\n",
      "\n",
      "            if np.any(complyingFrames) :\n",
      "                validLoops.append(i)    \n",
      "\n",
      "        backwardsJumps = np.array(backwardsJumps)[validLoops, :]\n",
      "\n",
      "        ###### only keep loops that do not overlap too much and that are not too costly ######\n",
      "        maxLoopOverlap = 0.5\n",
      "        maxDivergenceToThresholdCost = 3.0\n",
      "        thresholdSemanticCost = backwardsJumps[np.argsort(np.sum(backwardsJumps[:, 2:], axis=1)).flatten(), :][int(np.round(backwardsJumps.shape[0]*0.05)), 2] ## takingthe value of the fifth percentile as threshold\n",
      "        print \"using threshold\", thresholdSemanticCost\n",
      "\n",
      "\n",
      "        keptLoops = []\n",
      "        for jump in backwardsJumps[np.argsort(np.sum(backwardsJumps[:, 2:], axis=1)).flatten(), :] :\n",
      "\n",
      "            newJump = np.sort(jump[:2])\n",
      "            if len(keptLoops) == 0 :\n",
      "                print newJump, \"\\t\", jump[2:]\n",
      "                keptLoops.append(newJump)\n",
      "            else :\n",
      "                doKeep = True\n",
      "                for loop in keptLoops :\n",
      "                    ## only keep loop if it is not overlapping with already kept loops too much\n",
      "                    if intervalOverlap(np.array([loop, newJump]))[0] > maxLoopOverlap :\n",
      "                        doKeep = False\n",
      "                        break\n",
      "\n",
      "        #         if doKeep and np.sum(jump[2:]) < np.min(np.sum(backwardsJumps[:, 2:4], axis=-1))*1.5 :# len(np.argwhere(complyingFrames))/float(len(complyingFrames)) > 0.8 :\n",
      "    #             if doKeep :\n",
      "    #                 print newJump, \"\\t\", jump[2:]\n",
      "                if doKeep and jump[2] < thresholdSemanticCost*maxDivergenceToThresholdCost :\n",
      "                    print newJump, \"\\t\", jump[2:]\n",
      "                    keptLoops.append(newJump)\n",
      "\n",
      "        precomputedLoops.append(keptLoops)\n",
      "        print \"done semantics\", currentSemantics; sys.stdout.flush()\n",
      "        \n",
      "    return precomputedLoops\n",
      "\n",
      "# print getPrecomputedLoops(usedSequence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def printPrecomputedLoops(precomputedLoops, semanticSequence) :\n",
      "    for loops in precomputedLoops :\n",
      "        for loop in loops :\n",
      "            print loop\n",
      "            print semanticSequence[DICT_FRAMES_LOCATIONS][np.sort(semanticSequence[DICT_FRAMES_LOCATIONS].keys())[loop[0]]]\n",
      "            print semanticSequence[DICT_FRAMES_LOCATIONS][np.sort(semanticSequence[DICT_FRAMES_LOCATIONS].keys())[loop[1]]]\n",
      "            print\n",
      "        print \"--------------------\"\n",
      "        print\n",
      "# printPrecomputedLoops(getPrecomputedLoops(usedSequence), usedSequence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getPrecomputedLoopsTransitionCosts(semanticSequence, precomputedLoops) :\n",
      "    print\n",
      "    print\n",
      "    print precomputedLoops\n",
      "    ## modifies the transitionCosts matrix to give low cost to the precomputed loops\n",
      "    costLoc = \"/\".join(semanticSequence[DICT_SEQUENCE_LOCATION].split(\"/\")[:-1]) + \"/transition_costs-\" + semanticSequence[DICT_SEQUENCE_NAME] + \".npy\"\n",
      "    transitionCosts = np.load(costLoc)\n",
      "#     precomputedLoopPrior = np.ones_like(transitionCosts)*0.0\n",
      "    transitionsToChange = np.zeros_like(transitionCosts)\n",
      "#     gwv.showCustomGraph(np.copy(transitionCosts))\n",
      "    for loops in precomputedLoops :\n",
      "        for loop in loops :\n",
      "    #         print loop\n",
      "    #         print arange(loop[0], loop[1]+1)\n",
      "            idxes = meshgrid(arange(loop[0], loop[1]+1, dtype=int), arange(loop[0], loop[1]+1, dtype=int))\n",
      "    #         transitionCosts[idxes] = np.max(transitionCosts)#/2\n",
      "            transitionsToChange[idxes[0].flatten()[transitionCosts[idxes[0].flatten(), idxes[1].flatten()] != np.max(transitionCosts)],\n",
      "                                idxes[1].flatten()[transitionCosts[idxes[0].flatten(), idxes[1].flatten()] != np.max(transitionCosts)]] = 1\n",
      "    #         precomputedLoopPrior[meshgrid(arange(loop[0], loop[1]+1, dtype=int), arange(loop[0], loop[1]+1, dtype=int))]  = 0.0\n",
      "    transitionCosts[transitionsToChange == 1] = transitionCosts[transitionsToChange == 1]**2\n",
      "\n",
      "    for loops in precomputedLoops :\n",
      "        for loop in loops :\n",
      "    #         print loop\n",
      "    #         print arange(loop[0], loop[1]+1)\n",
      "            transitionCosts[arange(loop[0], loop[1]+1, dtype=int), np.roll(arange(loop[0], loop[1]+1, dtype=int), -1)] = 0\n",
      "    #         transitionCosts[loop[1], loop[0]] = 0\n",
      "#             precomputedLoopPrior[arange(loop[0], loop[1]+1, dtype=int), np.roll(arange(loop[0], loop[1]+1, dtype=int), -1)] = 1.0\n",
      "#     gwv.showCustomGraph(transitionCosts)\n",
      "    return transitionCosts\n",
      "# loopsToUse = getPrecomputedLoops(usedSequence)\n",
      "# gwv.showCustomGraph(getPrecomputedLoopsTransitionCosts(usedSequence, loopsToUse))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seqLoc = \"/media/ilisescu/Data1/PhD/data/wave1/\"\n",
      "for semLoc in np.sort(glob.glob(seqLoc+\"semantic_sequence-*.npy\")) :\n",
      "    currentSequence = np.load(semLoc).item()\n",
      "    precomputedLoops = getPrecomputedLoops(currentSequence)\n",
      "    \n",
      "    transitionCosts = getPrecomputedLoopsTransitionCosts(currentSequence, precomputedLoops)\n",
      "    \n",
      "    currentSequence[DICT_TRANSITION_COSTS_LOCATION] = \"/\".join(currentSequence[DICT_SEQUENCE_LOCATION].split(\"/\")[:-1]) + \"/transition_costs-precomputed_loops-\" + currentSequence[DICT_SEQUENCE_NAME] + \".npy\"\n",
      "    gwv.showCustomGraph(transitionCosts)\n",
      "    np.save(currentSequence[DICT_TRANSITION_COSTS_LOCATION], transitionCosts)\n",
      "    print \"saved\", currentSequence[DICT_TRANSITION_COSTS_LOCATION]\n",
      "#     np.save(currentSequence[DICT_SEQUENCE_LOCATION], currentSequence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(np.load(\"/media/ilisescu/Data1/PhD/data/wave1/transition_costs-precomputed_loops-aron1.npy\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print transitionCosts[idxes][transitionCosts[idxes] != np.max(transitionCosts)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  5.40505323   5.40796698   5.41105617 ...,  10.32799665   9.66916633\n",
        "   1.05740465]\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(precomputedLoopPrior)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "usedSequence = np.load(\"/media/ilisescu/Data1/PhD/data/wave3/semantic_sequence-james3.npy\").item()\n",
      "print usedSequence[DICT_TRANSITION_COSTS_LOCATION]\n",
      "gwv.showCustomGraph(np.load(usedSequence[DICT_TRANSITION_COSTS_LOCATION]))\n",
      "# gwv.showCustomGraph(np.load(\"/media/ilisescu/Data1/PhD/data/wave2/james2-vanilla_distMat.npy\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/media/ilisescu/Data1/PhD/data/wave3/transition_costs-precomputed_loops-james3.npy\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## renormalize the prior\n",
      "# precomputedLoopPrior = precomputedLoopPrior / np.sum(precomputedLoopPrior, axis=1).reshape((len(precomputedLoopPrior), 1))\n",
      "## get rid of first filterSize frames and the last ones as they get lost in the filtering and will be added back later in the sequenceTransitionCosts\n",
      "precomputedLoopPrior = precomputedLoopPrior[filterSize:-filterSize-1, filterSize:-filterSize-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(-np.log(precomputedLoopPrior))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:1: RuntimeWarning: divide by zero encountered in log\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distMat = np.load(\"/media/ilisescu/Data1/PhD/data/wave1/james1-vanilla_distMat.npy\")\n",
      "    \n",
      "## filter ##\n",
      "filterSize = 4\n",
      "optimizedDistMat = vtu.filterDistanceMatrix(distMat, filterSize, True)\n",
      "## if using vanilla\n",
      "if True :\n",
      "    optimizedDistMat = optimizedDistMat[1:optimizedDistMat.shape[1], 0:-1]\n",
      "    correction = 1\n",
      "else :\n",
      "    correction = 0\n",
      "    \n",
      "# #### this is just normalizing to [0, 1] A ####\n",
      "# optimizedDistMat = optimizedDistMat/np.max(optimizedDistMat)\n",
      "# ########\n",
      "\n",
      "## don't want to jump too close so increase costs in a window\n",
      "minJumpLength = 20\n",
      "tmp = (np.triu(np.ones(optimizedDistMat.shape), k=minJumpLength) +\n",
      "       np.tril(np.ones(optimizedDistMat.shape), k=-minJumpLength) +\n",
      "       np.eye(optimizedDistMat.shape[0], k=1))\n",
      "tmp[tmp == 0] = 10.0\n",
      "optimizedDistMat *= tmp\n",
      "\n",
      "\n",
      "#### this is just normalizing to [0, 1] B ####\n",
      "sequenceTransitionCost = optimizedDistMat\n",
      "########\n",
      "\n",
      "#### this turns to a probability and then does the same as the unaries ####\n",
      "# sequenceTransitionCost = vtu.dist2prob(optimizedDistMat, 0.1, True)\n",
      "# # sequenceTransitionCost = sequenceTransitionCost*precomputedLoopPrior\n",
      "\n",
      "# gwv.showCustomGraph(np.copy(sequenceTransitionCost))\n",
      "\n",
      "# impossibleTransitions = sequenceTransitionCost <= 0.0\n",
      "# ## cost is -log(prob)\n",
      "# sequenceTransitionCost[np.negative(impossibleTransitions)] = -np.log(sequenceTransitionCost[np.negative(impossibleTransitions)])\n",
      "# ## if prob == 0.0 then set maxCost\n",
      "# sequenceTransitionCost[impossibleTransitions] = GRAPH_MAX_COST\n",
      "########\n",
      "\n",
      "## do the thresholding based on how many jumps I want to keep per frame\n",
      "desiredPercentage = 0.1 ## desired percentage of transitions to keep\n",
      "jumpsToKeep = int(sequenceTransitionCost.shape[0]*desiredPercentage)\n",
      "sequenceTransitionCost[np.arange(sequenceTransitionCost.shape[0]).repeat(sequenceTransitionCost.shape[0]-jumpsToKeep),\n",
      "                       np.argsort(sequenceTransitionCost, axis=-1)[:, jumpsToKeep:].flatten()] = GRAPH_MAX_COST\n",
      "\n",
      "\n",
      "## adding extra rows and columns so that the optimized matrix has the same dimensions as distMat\n",
      "## for the indices that were cut out I put zero cost for jumps to frames that can still be used after optimization\n",
      "sequenceTransitionCost = np.concatenate((np.ones((sequenceTransitionCost.shape[0], filterSize))*np.max(sequenceTransitionCost),\n",
      "                                         sequenceTransitionCost,\n",
      "                                         np.ones((sequenceTransitionCost.shape[0], filterSize+correction))*np.max(sequenceTransitionCost)), axis=1)\n",
      "sequenceTransitionCost = np.concatenate((np.roll(np.concatenate((np.zeros((filterSize, 1)),\n",
      "                                                                 np.ones((filterSize, distMat.shape[0]-1))*np.max(sequenceTransitionCost)), axis=1), filterSize, axis=1),\n",
      "                                         sequenceTransitionCost,\n",
      "                                         np.roll(np.concatenate((np.zeros((filterSize+correction, 1)),\n",
      "                                                                 np.ones((filterSize+correction, distMat.shape[0]-1))*np.max(sequenceTransitionCost)), axis=1), filterSize, axis=1)), axis=0)\n",
      "\n",
      "# sequenceTransitionCost += (1.0 - precomputedLoopPrior)*10000.0\n",
      "\n",
      "gwv.showCustomGraph(np.copy(sequenceTransitionCost))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gwv.showCustomGraph(-np.log(precomputedLoopPrior))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "visCosts = np.copy(sequenceTransitionCost)#np.load(usedSequence[DICT_TRANSITION_COSTS_LOCATION]))\n",
      "visCosts[visCosts == GRAPH_MAX_COST] = 50.0\n",
      "# visCosts[visCosts != 0] = np.log(visCosts[visCosts != 0])\n",
      "gwv.showCustomGraph(visCosts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "usedSequence[DICT_TRANSITION_COSTS_LOCATION] = \"/\".join(usedSequence[DICT_SEQUENCE_LOCATION].split(\"/\")[:-1]) + \"/transition_costs-\" + usedSequence[DICT_SEQUENCE_NAME] + \".npy\"\n",
      "np.save(usedSequence[DICT_TRANSITION_COSTS_LOCATION], sequenceTransitionCost)\n",
      "np.save(usedSequence[DICT_SEQUENCE_LOCATION], usedSequence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(precomputedLoopPrior)\n",
      "print precomputedLoopPrior.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(715, 715)\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sequenceTransitionCost[111, 10]\n",
      "print sequenceTransitionCost[111, 9]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6.55746963447\n",
        "10000000.0\n"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "currentSemantics = 0\n",
      "desiredSemantics = np.zeros((1, numSemantics))\n",
      "desiredSemantics[0, currentSemantics] = 1.0\n",
      "distVariance = 0.05\n",
      "distToSemantics = vectorisedMinusLogMultiNormal(usedSequence[DICT_FRAME_SEMANTICS], desiredSemantics, np.eye(desiredSemantics.shape[1])*distVariance, False).T\n",
      "\n",
      "frameSemanticCost = distToSemantics[filterSize:-filterSize-1]\n",
      "## the further away from a frame showing the desired semantics, the higher the cost\n",
      "frameSemanticCost[np.argwhere(frameSemanticCost >= 0.01*np.max(frameSemanticCost))] = np.max(frameSemanticCost)\n",
      "frameSemanticCost = frameSemanticCost+np.min(np.abs(arange(len(frameSemanticCost)).reshape((1, len(frameSemanticCost))) - np.argwhere(frameSemanticCost < 0.01*np.max(frameSemanticCost))), axis=0)\n",
      "\n",
      "newJump = precomputedLoops[currentSemantics][2]\n",
      "print newJump\n",
      "loopDistToSemantics = frameSemanticCost[arange(newJump[0]-correction, newJump[1]-correction, dtype=int)]\n",
      "thresh = np.max(distToSemantics) + 1 ## it means I'm within 6 frames of the desired semantics\n",
      "complyingFrames = loopDistToSemantics < thresh\n",
      "print complyingFrames"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  6.  16.]\n",
        "[ True  True  True  True  True  True  True  True  True  True]\n"
       ]
      }
     ],
     "prompt_number": 675
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pie = np.exp(-frameSemanticCost).reshape((len(frameSemanticCost), 1))\n",
      "pie /= np.sum(pie)\n",
      "\n",
      "oldPie = np.copy(pie)\n",
      "for i in xrange(1000) :\n",
      "    pie = np.dot(probs, oldPie)\n",
      "    pie /= np.sum(pie)\n",
      "    print np.sum((pie-oldPie)**2)\n",
      "    oldPie = np.copy(pie)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0238474452418\n",
        "0.0238547223301\n",
        "0.0238672752354\n",
        "0.0234048538885\n",
        "0.0183607943583\n",
        "0.0151966021848\n",
        "0.0142520216876\n",
        "0.0144247759509\n",
        "0.0148718685382\n",
        "0.011199235825\n",
        "0.00881838916245\n",
        "0.00577251057578\n",
        "0.00300702946347\n",
        "0.00125343604677\n",
        "0.000423574001868\n",
        "0.000130643707076\n",
        "4.69875884901e-05\n",
        "2.52152914546e-05\n",
        "1.84037287416e-05\n",
        "1.47703951463e-05\n",
        "1.18480036773e-05\n",
        "9.38508996131e-06\n",
        "7.41098010552e-06\n",
        "5.89695746788e-06\n",
        "4.80454866639e-06\n",
        "4.08259197478e-06\n",
        "3.60021698935e-06\n",
        "3.21143642015e-06\n",
        "2.84227573069e-06\n",
        "2.49017742924e-06\n",
        "2.18037341269e-06\n",
        "1.92289597642e-06\n",
        "1.69984538881e-06\n",
        "1.47791317535e-06\n",
        "1.23302326196e-06\n",
        "9.68011722027e-07\n",
        "7.13049944751e-07\n",
        "5.07836936663e-07\n",
        "3.70903328886e-07\n",
        "2.90746960833e-07\n",
        "2.44319390958e-07\n",
        "2.13117710658e-07\n",
        "1.87169040286e-07\n",
        "1.63016840961e-07\n",
        "1.40423034847e-07\n",
        "1.19814961984e-07\n",
        "1.01461462176e-07\n",
        "8.55055123374e-08\n",
        "7.2137885175e-08\n",
        "6.15895082945e-08\n",
        "5.3971139162e-08\n",
        "4.88387907396e-08\n",
        "4.51178802821e-08\n",
        "4.17901821239e-08\n",
        "3.84138156063e-08\n",
        "3.50617159279e-08\n",
        "3.19848379453e-08\n",
        "2.93310301744e-08\n",
        "2.70873741036e-08\n",
        "2.51599296988e-08\n",
        "2.34507652386e-08\n",
        "2.18921866039e-08\n",
        "2.04492084546e-08\n",
        "1.91045768755e-08\n",
        "1.78429851358e-08\n",
        "1.66502788039e-08\n",
        "1.55248131187e-08\n",
        "1.44793976247e-08\n",
        "1.35310905369e-08\n",
        "1.26871235588e-08\n",
        "1.19349242363e-08\n",
        "1.12471858731e-08\n",
        "1.05972181632e-08\n",
        "9.96918049192e-09\n",
        "9.35893768578e-09\n",
        "8.76997597083e-09\n",
        "8.20860975408e-09\n",
        "7.6803564463e-09\n",
        "7.18800898231e-09\n",
        "6.73181358791e-09\n",
        "6.31071019198e-09\n",
        "5.92297845141e-09\n",
        "5.56623297783e-09\n",
        "5.23716909739e-09\n",
        "4.93169449759e-09\n",
        "4.6457822185e-09\n",
        "4.37624903789e-09\n",
        "4.12091253364e-09\n",
        "3.87840859802e-09\n",
        "3.64799505744e-09\n",
        "3.42936383051e-09\n",
        "3.22243064137e-09\n",
        "3.02715603046e-09\n",
        "2.8434394853e-09\n",
        "2.6710552383e-09\n",
        "2.50962117264e-09\n",
        "2.35860723079e-09\n",
        "2.21736415769e-09\n",
        "2.08517046296e-09\n",
        "1.96128962493e-09\n",
        "1.8450167021e-09\n",
        "1.73570580975e-09\n",
        "1.63279228868e-09\n",
        "1.53580686324e-09\n",
        "1.4443709377e-09\n",
        "1.35817716008e-09\n",
        "1.27696744268e-09\n",
        "1.20051247198e-09\n",
        "1.12859374192e-09\n",
        "1.06099187161e-09\n",
        "9.97481905845e-10\n",
        "9.37833989291e-10\n",
        "8.81817051432e-10\n",
        "8.2920349152e-10\n",
        "7.79773484578e-10\n",
        "7.33318327747e-10\n",
        "6.89642759337e-10\n",
        "6.4856629196e-10\n",
        "6.0992363291e-10\n",
        "5.73564254153e-10\n",
        "5.39351196069e-10\n",
        "5.07159318464e-10\n",
        "4.76873323295e-10\n",
        "4.48385848378e-10\n",
        "4.21595826149e-10\n",
        "3.96407208488e-10\n",
        "3.72728100597e-10\n",
        "3.50470298976e-10\n",
        "3.29549178353e-10\n",
        "3.09883829009e-10\n",
        "2.91397326401e-10\n",
        "2.74017016481e-10\n",
        "2.57674717141e-10\n",
        "2.42306770773e-10\n",
        "2.27853929949e-10\n",
        "2.14261102653e-10\n",
        "2.01477009037e-10\n",
        "1.89453803355e-10\n",
        "1.7814670268e-10\n",
        "1.67513650522e-10\n",
        "1.57515032616e-10\n",
        "1.4811345255e-10\n",
        "1.39273565377e-10\n",
        "1.30961959203e-10\n",
        "1.23147070533e-10\n",
        "1.1579911885e-10\n",
        "1.08890047959e-10\n",
        "1.02393465207e-10\n",
        "9.62845740333e-11\n",
        "9.0540099149e-11\n",
        "8.51382056779e-11\n",
        "8.00584139877e-11\n",
        "7.52815120401e-11\n",
        "7.07894676286e-11\n",
        "6.65653434368e-11\n",
        "6.25932176708e-11\n",
        "5.88581120706e-11\n",
        "5.53459279568e-11\n",
        "5.20433900805e-11\n",
        "4.89379974475e-11\n",
        "4.60179798837e-11\n",
        "4.32722589233e-11\n",
        "4.06904116655e-11\n",
        "3.82626364951e-11\n",
        "3.59797198498e-11\n",
        "3.38330035337e-11\n",
        "3.1814352453e-11\n",
        "2.99161229949e-11\n",
        "2.8131132437e-11\n",
        "2.6452629774e-11\n",
        "2.48742682457e-11\n",
        "2.33900797293e-11\n",
        "2.19944510488e-11\n",
        "2.06821021623e-11\n",
        "1.94480660953e-11\n",
        "1.82876704276e-11\n",
        "1.71965201191e-11\n",
        "1.61704814694e-11\n",
        "1.52056670393e-11\n",
        "1.42984213967e-11\n",
        "1.34453075948e-11\n",
        "1.26430943231e-11\n",
        "1.18887436998e-11\n",
        "1.11793996882e-11\n",
        "1.05123771288e-11\n",
        "9.88515138734e-12\n",
        "9.29534861223e-12\n",
        "8.74073659379e-12\n",
        "8.21921620451e-12\n",
        "7.72881339324e-12\n",
        "7.2676716995e-12\n",
        "6.83404525027e-12\n",
        "6.42629219997e-12\n",
        "6.0428685752e-12\n",
        "5.68232248866e-12\n",
        "5.343288691e-12\n",
        "5.02448343473e-12\n",
        "4.72469962964e-12\n",
        "4.44280227303e-12\n",
        "4.17772414172e-12\n",
        "3.92846173384e-12\n",
        "3.69407144981e-12\n",
        "3.4736660015e-12\n",
        "3.2664110384e-12\n",
        "3.0715219795e-12\n",
        "2.88826103873e-12\n",
        "2.71593443216e-12\n",
        "2.55388975494e-12\n",
        "2.40151351672e-12\n",
        "2.2582288249e-12\n",
        "2.12349320583e-12\n",
        "1.99679655512e-12\n",
        "1.87765920894e-12\n",
        "1.76563012913e-12\n",
        "1.66028519526e-12\n",
        "1.56122559768e-12\n",
        "1.46807632592e-12\n",
        "1.38048474693e-12\n",
        "1.29811926838e-12\n",
        "1.22066808187e-12\n",
        "1.14783798166e-12\n",
        "1.07935325431e-12\n",
        "1.01495463496e-12\n",
        "9.54398326211e-13\n",
        "8.97455075742e-13\n",
        "8.4390930902e-13\n",
        "7.93558313714e-13\n",
        "7.46211472682e-13\n",
        "7.01689542554e-13\n",
        "6.59823975227e-13\n",
        "6.20456279687e-13\n",
        "5.83437421842e-13\n",
        "5.48627260093e-13\n",
        "5.15894014569e-13\n",
        "4.85113768062e-13\n",
        "4.56169996762e-13\n",
        "4.28953129051e-13\n",
        "4.03360130662e-13\n",
        "3.7929411464e-13\n",
        "3.56663974593e-13\n",
        "3.35384039849e-13\n",
        "3.1537375119e-13\n",
        "2.96557355925e-13\n",
        "2.78863621148e-13\n",
        "2.62225564088e-13\n",
        "2.46580198538e-13\n",
        "2.31868296387e-13\n",
        "2.18034163391e-13\n",
        "2.05025428306e-13\n",
        "1.92792844602e-13\n",
        "1.81290104013e-13\n",
        "1.70473661214e-13\n",
        "1.60302568963e-13\n",
        "1.50738323086e-13\n",
        "1.41744716711e-13\n",
        "1.33287703205e-13\n",
        "1.25335267295e-13\n",
        "1.17857303862e-13\n",
        "1.1082550399e-13\n",
        "1.04213247793e-13\n",
        "9.79955036414e-14\n",
        "9.21487334048e-14\n",
        "8.66508033384e-14\n",
        "8.1480900293e-14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7.66194529173e-14\n",
        "7.20480575672e-14\n",
        "6.77494086363e-14\n",
        "6.37072330348e-14\n",
        "5.99062285901e-14\n",
        "5.63320061166e-14\n",
        "5.29710349412e-14\n",
        "4.98105916821e-14\n",
        "4.68387120856e-14\n",
        "4.404414573e-14\n",
        "4.14163134394e-14\n",
        "3.8945267232e-14\n",
        "3.6621652662e-14\n",
        "3.44366734074e-14\n",
        "3.23820579687e-14\n",
        "3.04500283567e-14\n",
        "2.86332706465e-14\n",
        "2.69249072901e-14\n",
        "2.53184710806e-14\n",
        "2.38078806694e-14\n",
        "2.23874175426e-14\n",
        "2.10517043757e-14\n",
        "1.97956846745e-14\n",
        "1.86146036345e-14\n",
        "1.7503990141e-14\n",
        "1.64596398419e-14\n",
        "1.54775992332e-14\n",
        "1.45541506911e-14\n",
        "1.36857983998e-14\n",
        "1.28692551165e-14\n",
        "1.2101429728e-14\n",
        "1.13794155478e-14\n",
        "1.07004793134e-14\n",
        "1.0062050839e-14\n",
        "9.46171328496e-15\n",
        "8.89719400996e-15\n",
        "8.36635596606e-15\n",
        "7.8671896101e-15\n",
        "7.39780529476e-15\n",
        "6.9564261168e-15\n",
        "6.54138118883e-15\n",
        "6.1510993153e-15\n",
        "5.78410304342e-15\n",
        "5.43900307067e-15\n",
        "5.11449298578e-15\n",
        "4.80934432214e-15\n",
        "4.5224019085e-15\n",
        "4.25257949462e-15\n",
        "3.9988556405e-15\n",
        "3.76026984864e-15\n",
        "3.53591892837e-15\n",
        "3.32495357651e-15\n",
        "3.12657516256e-15\n",
        "2.94003270489e-15\n",
        "2.76462002851e-15\n",
        "2.5996730909e-15\n",
        "2.44456746912e-15\n",
        "2.29871599526e-15\n",
        "2.16156653416e-15\n",
        "2.03259989283e-15\n",
        "1.91132785532e-15\n",
        "1.79729133436e-15\n",
        "1.69005863341e-15\n",
        "1.58922381245e-15\n",
        "1.49440515145e-15\n",
        "1.40524370496e-15\n",
        "1.32140194372e-15\n",
        "1.24256247643e-15\n",
        "1.16842684859e-15\n",
        "1.09871441261e-15\n",
        "1.03316126522e-15\n",
        "9.71519248634e-16\n",
        "9.13555011033e-16\n",
        "8.59049123112e-16\n",
        "8.07795247629e-16\n",
        "7.59599358046e-16\n",
        "7.14279004152e-16\n",
        "6.71662621318e-16\n",
        "6.31588881297e-16\n",
        "5.93906080932e-16\n",
        "5.58471568384e-16\n",
        "5.25151202998e-16\n",
        "4.93818847223e-16\n",
        "4.64355889491e-16\n",
        "4.36650794912e-16\n",
        "4.10598683239e-16\n",
        "3.86100931676e-16\n",
        "3.63064801693e-16\n",
        "3.41403087793e-16\n",
        "3.21033787505e-16\n",
        "3.01879790888e-16\n",
        "2.83868588684e-16\n",
        "2.66931997751e-16\n",
        "2.51005903065e-16\n",
        "2.3603001481e-16\n",
        "2.2194764039e-16\n",
        "2.0870546964e-16\n",
        "1.9625337306e-16\n",
        "1.84544212075e-16\n",
        "1.73533660527e-16\n",
        "1.63180036924e-16\n",
        "1.53444146676e-16\n",
        "1.44289133643e-16\n",
        "1.35680340631e-16\n",
        "1.2758517829e-16\n",
        "1.19973001572e-16\n",
        "1.12814993913e-16\n",
        "1.06084057954e-16\n",
        "9.97547131284e-17\n",
        "9.38029991055e-17\n",
        "8.82063851205e-17\n",
        "8.29436846458e-17\n",
        "7.79949752528e-17\n",
        "7.33415231257e-17\n",
        "6.8965712175e-17\n",
        "6.48509773661e-17\n",
        "6.09817420142e-17\n",
        "5.73433587139e-17\n",
        "5.39220540651e-17\n",
        "5.07048763798e-17\n",
        "4.76796467404e-17\n",
        "4.48349128407e-17\n",
        "4.21599056923e-17\n",
        "3.96444988015e-17\n",
        "3.72791698517e-17\n",
        "3.50549646672e-17\n",
        "3.29634633278e-17\n",
        "3.09967482442e-17\n",
        "2.91473742358e-17\n",
        "2.74083403327e-17\n",
        "2.57730632579e-17\n",
        "2.42353525e-17\n",
        "2.27893869381e-17\n",
        "2.14296927119e-17\n",
        "2.01511225932e-17\n",
        "1.89488364133e-17\n",
        "1.78182828215e-17\n",
        "1.67551819932e-17\n",
        "1.57555094715e-17\n",
        "1.48154808917e-17\n",
        "1.39315376958e-17\n",
        "1.31003336265e-17\n",
        "1.23187220953e-17\n",
        "1.15837442235e-17\n",
        "1.08926176917e-17\n",
        "1.0242726183e-17\n",
        "9.63160946281e-18\n",
        "9.05695409495e-18\n",
        "8.51658466882e-18\n",
        "8.00845556498e-18\n",
        "7.53064321635e-18\n",
        "7.08133881276e-18\n",
        "6.65884147303e-18\n",
        "6.26155180109e-18\n",
        "5.88796581391e-18\n",
        "5.53666926672e-18\n",
        "5.20633230035e-18\n",
        "4.89570438405e-18\n",
        "4.60360961479e-18\n",
        "4.32894222803e-18\n",
        "4.07066246277e-18\n",
        "3.82779256379e-18\n",
        "3.5994131266e-18\n",
        "3.38465961036e-18\n",
        "3.18271902525e-18\n",
        "2.99282692852e-18\n",
        "2.81426445201e-18\n",
        "2.64635563549e-18\n",
        "2.48846484438e-18\n",
        "2.33999436663e-18\n",
        "2.20038215702e-18\n",
        "2.06909969169e-18\n",
        "1.94565000109e-18\n",
        "1.82956574658e-18\n",
        "1.72040748299e-18\n",
        "1.61776198213e-18\n",
        "1.52124066911e-18\n",
        "1.43047815544e-18\n",
        "1.34513084632e-18\n",
        "1.26487565789e-18\n",
        "1.1894087722e-18\n",
        "1.11844450128e-18\n",
        "1.05171420851e-18\n",
        "9.88965277409e-19\n",
        "9.29960165245e-19\n",
        "8.744755035e-19\n",
        "8.22301250104e-19\n",
        "7.73239894569e-19\n",
        "7.2710570952e-19\n",
        "6.83724053155e-19\n",
        "6.42930695723e-19\n",
        "6.04571211399e-19\n",
        "5.6850038832e-19\n",
        "5.34581675968e-19\n",
        "5.02686672114e-19\n",
        "4.72694635081e-19\n",
        "4.44492027185e-19\n",
        "4.17972086004e-19\n",
        "3.93034415802e-19\n",
        "3.69584613534e-19\n",
        "3.47533909631e-19\n",
        "3.26798824969e-19\n",
        "3.07300869266e-19\n",
        "2.8896623143e-19\n",
        "2.71725499925e-19\n",
        "2.55513409413e-19\n",
        "2.40268588529e-19\n",
        "2.25933328344e-19\n",
        "2.12453359256e-19\n",
        "1.99777653877e-19\n",
        "1.87858222548e-19\n",
        "1.76649948122e-19\n",
        "1.66110396175e-19\n",
        "1.56199671315e-19\n",
        "1.46880256905e-19\n",
        "1.38116867796e-19\n",
        "1.29876335036e-19\n",
        "1.22127460396e-19\n",
        "1.14840911246e-19\n",
        "1.07989102393e-19\n",
        "1.01546096997e-19\n",
        "9.54875029662e-20\n",
        "8.97903871468e-20\n",
        "8.44331793224e-20\n",
        "7.93956016906e-20\n",
        "7.46585852132e-20\n",
        "7.02041927198e-20\n",
        "6.60155674627e-20\n",
        "6.20768478865e-20\n",
        "5.83731266947e-20\n",
        "5.48903829846e-20\n",
        "5.16154314166e-20\n",
        "4.85358761037e-20\n",
        "4.5640055997e-20\n",
        "4.29170113371e-20\n",
        "4.03564328704e-20\n",
        "3.79486278883e-20\n",
        "3.56844807357e-20\n",
        "3.3555420075e-20\n",
        "3.15533877892e-20\n",
        "2.9670802122e-20\n",
        "2.79005388193e-20\n",
        "2.62358960728e-20\n",
        "2.4670571218e-20\n",
        "2.3198638307e-20\n",
        "2.18145268393e-20\n",
        "2.05129963248e-20\n",
        "1.92891194834e-20\n",
        "1.8138263409e-20\n",
        "1.70560714547e-20\n",
        "1.60384469383e-20\n",
        "1.50815373849e-20\n",
        "1.41817201928e-20\n",
        "1.33355894382e-20\n",
        "1.2539941766e-20\n",
        "1.17917652112e-20\n",
        "1.10882274796e-20\n",
        "1.04266652809e-20\n",
        "9.8045740528e-21\n",
        "9.21959911542e-21\n",
        "8.66952556048e-21\n",
        "8.15227156736e-21\n",
        "7.66587867043e-21\n",
        "7.20850567116e-21\n",
        "6.77842117718e-21\n",
        "6.37399696228e-21\n",
        "5.99370209228e-21\n",
        "5.63609692732e-21\n",
        "5.29982778396e-21\n",
        "4.983621591e-21\n",
        "4.68628137082e-21\n",
        "4.40668153329e-21\n",
        "4.14376348719e-21\n",
        "3.89653218229e-21\n",
        "3.66405146868e-21\n",
        "3.44544143101e-21\n",
        "3.23987434493e-21\n",
        "3.04657239227e-21\n",
        "2.86480317592e-21\n",
        "2.69387900663e-21\n",
        "2.5331528079e-21\n",
        "2.38201611655e-21\n",
        "2.23989677223e-21\n",
        "2.10625669108e-21\n",
        "1.98059008336e-21\n",
        "1.86242120836e-21\n",
        "1.75130266353e-21\n",
        "1.64681386548e-21\n",
        "1.54855920628e-21\n",
        "1.45616680358e-21\n",
        "1.36928678295e-21\n",
        "1.28759038445e-21\n",
        "1.21076824492e-21\n",
        "1.13852963813e-21\n",
        "1.07060096665e-21\n",
        "1.00672518527e-21\n",
        "9.4666048161e-22\n",
        "8.90179385812e-22\n",
        "8.3706815905e-22\n",
        "7.87125803843e-22\n",
        "7.40163141872e-22\n",
        "6.96002529988e-22\n",
        "6.54476471671e-22\n",
        "6.15428139337e-22\n",
        "5.78709557187e-22\n",
        "5.44181746893e-22\n",
        "5.11713937981e-22\n",
        "4.81183300224e-22\n",
        "4.52474247564e-22\n",
        "4.25478044774e-22\n",
        "4.00092560502e-22\n",
        "3.7622162719e-22\n",
        "3.53774936616e-22\n",
        "3.32667495767e-22\n",
        "3.12819386752e-22\n",
        "2.94155511128e-22\n",
        "2.76605161233e-22\n",
        "2.60101943778e-22\n",
        "2.44583343125e-22\n",
        "2.29990642977e-22\n",
        "2.16268624293e-22\n",
        "2.03365268403e-22\n",
        "1.91231788191e-22\n",
        "1.79822236544e-22\n",
        "1.69093417051e-22\n",
        "1.59004721405e-22\n",
        "1.49517937909e-22\n",
        "1.40597169174e-22\n",
        "1.32208665096e-22\n",
        "1.2432064078e-22\n",
        "1.16903237583e-22\n",
        "1.09928383752e-22\n",
        "1.03369658802e-22\n",
        "9.72022751598e-23\n",
        "9.14028444649e-23\n",
        "8.59494395882e-23\n",
        "8.08213865129e-23\n",
        "7.59993105733e-23\n",
        "7.14649337987e-23\n",
        "6.72010845084e-23\n",
        "6.31916200326e-23\n",
        "5.94213939294e-23\n",
        "5.58761067562e-23\n",
        "5.25423488552e-23\n",
        "4.94074827623e-23\n",
        "4.6459660261e-23\n",
        "4.36877143224e-23\n",
        "4.10811650729e-23\n",
        "3.86301146555e-23\n",
        "3.63253063108e-23\n",
        "3.41580115712e-23\n",
        "3.21200297946e-23\n",
        "3.02036323441e-23\n",
        "2.8401582534e-23\n",
        "2.67070388769e-23\n",
        "2.51136092046e-23\n",
        "2.36152427936e-23\n",
        "2.22062748324e-23\n",
        "2.08813675581e-23\n",
        "1.96355140743e-23\n",
        "1.84639916469e-23\n",
        "1.7362366188e-23\n",
        "1.6326467103e-23\n",
        "1.53523721148e-23\n",
        "1.4436396518e-23\n",
        "1.35750695626e-23\n",
        "1.27651347391e-23\n",
        "1.20035209199e-23\n",
        "1.12873529273e-23\n",
        "1.06139134709e-23\n",
        "9.98064822306e-24\n",
        "9.3851660927e-24\n",
        "8.82521200653e-24\n",
        "8.29866857363e-24\n",
        "7.80354450569e-24\n",
        "7.33795697549e-24\n",
        "6.900148402e-24\n",
        "6.4884634183e-24\n",
        "6.10133883553e-24\n",
        "5.73731020267e-24\n",
        "5.39500206817e-24\n",
        "5.07311699483e-24\n",
        "4.77043741544e-24\n",
        "4.48581710264e-24\n",
        "4.21817637076e-24\n",
        "3.96650329633e-24\n",
        "3.72985122823e-24\n",
        "3.50731536809e-24\n",
        "3.29805661319e-24\n",
        "3.10128253577e-24\n",
        "2.91625026774e-24\n",
        "2.74225562792e-24\n",
        "2.57864327375e-24\n",
        "2.42479122428e-24\n",
        "2.28012032489e-24\n",
        "2.14407989952e-24\n",
        "2.01615691646e-24\n",
        "1.89586531763e-24\n",
        "1.78275114147e-24\n",
        "1.67638685835e-24\n",
        "1.57636765444e-24\n",
        "1.48231598632e-24\n",
        "1.39387581219e-24\n",
        "1.31071356158e-24\n",
        "1.23250998273e-24\n",
        "1.15897462125e-24\n",
        "1.08982611835e-24\n",
        "1.02480389659e-24\n",
        "9.63659800056e-25\n",
        "9.06165038215e-25\n",
        "8.52100744047e-25\n",
        "8.01261823787e-25\n",
        "7.53455343939e-25\n",
        "7.08500550374e-25\n",
        "6.66229151554e-25\n",
        "6.26479679757e-25\n",
        "5.89101255852e-25\n",
        "5.53953998086e-25\n",
        "5.20903536706e-25\n",
        "4.89824760207e-25\n",
        "4.60599479444e-25\n",
        "4.33119079714e-25\n",
        "4.07277244138e-25\n",
        "3.82978166563e-25\n",
        "3.60128287736e-25\n",
        "3.38641900885e-25\n",
        "3.1843709555e-25\n",
        "2.99438057961e-25\n",
        "2.81572522487e-25\n",
        "2.64772914392e-25\n",
        "2.48975616366e-25\n",
        "2.34120917938e-25\n",
        "2.20152128054e-25\n",
        "2.07017336382e-25\n",
        "1.94666138931e-25\n",
        "1.83051477217e-25\n",
        "1.72130224266e-25\n",
        "1.61860460578e-25\n",
        "1.52203036863e-25\n",
        "1.43122064884e-25\n",
        "1.34582952378e-25\n",
        "1.26553372207e-25\n",
        "1.19002748294e-25\n",
        "1.11902533869e-25\n",
        "1.05225921157e-25\n",
        "9.89478829925e-26\n",
        "9.30442798671e-26\n",
        "8.74927499126e-26\n",
        "8.22727440536e-26\n",
        "7.73642585118e-26\n",
        "7.27480659305e-26\n",
        "6.84079600556e-26\n",
        "6.43264898539e-26\n",
        "6.04886078661e-26\n",
        "5.68796635639e-26\n",
        "5.34857907821e-26\n",
        "5.02946859561e-26\n",
        "4.72939077552e-26\n",
        "4.44723817373e-26\n",
        "4.18188851971e-26\n",
        "3.93238830986e-26\n",
        "3.69776493233e-26\n",
        "3.47714504744e-26\n",
        "3.26967718442e-26\n",
        "3.07461779277e-26\n",
        "2.89115963514e-26\n",
        "2.71865767354e-26\n",
        "2.55647664691e-26\n",
        "2.40392915618e-26\n",
        "2.26050153634e-26\n",
        "2.1256279943e-26\n",
        "1.9988247334e-26\n",
        "1.8795609017e-26\n",
        "1.76741144429e-26\n",
        "1.66195846819e-26\n",
        "1.56280161762e-26\n",
        "1.46956761566e-26\n",
        "1.38188846356e-26\n",
        "1.29943361813e-26\n",
        "1.22191318204e-26\n",
        "1.14900336504e-26\n",
        "1.08045132231e-26\n",
        "1.01598329448e-26\n",
        "9.55369210508e-27\n",
        "8.98377427546e-27\n",
        "8.44770803931e-27\n",
        "7.94369711036e-27\n",
        "7.46969210478e-27\n",
        "7.02403453112e-27\n",
        "6.60493609563e-27\n",
        "6.21078780855e-27\n",
        "5.84029406034e-27\n",
        "5.4918946438e-27\n",
        "5.16414959813e-27\n",
        "4.85606490259e-27\n",
        "4.56636198906e-27\n",
        "4.2938285412e-27\n",
        "4.0377459249e-27\n",
        "3.79682701769e-27\n",
        "3.57033161165e-27\n",
        "3.35728345882e-27\n",
        "3.15695051408e-27\n",
        "2.96854094836e-27\n",
        "2.79146115717e-27\n",
        "2.62491917621e-27\n",
        "2.46831026691e-27\n",
        "2.32103621762e-27\n",
        "2.18257732675e-27\n",
        "2.05235932302e-27\n",
        "1.92997288925e-27\n",
        "1.81477890853e-27\n",
        "1.70648768811e-27\n",
        "1.60468205789e-27\n",
        "1.50893314455e-27\n",
        "1.41890623541e-27\n",
        "1.33425228074e-27\n",
        "1.2546270579e-27\n",
        "1.17978428435e-27\n",
        "1.10940406423e-27\n",
        "1.04319838481e-27\n",
        "9.80961917376e-28"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9.22444481318e-28\n",
        "8.67401291271e-28\n",
        "8.15656921208e-28\n",
        "7.66997578704e-28\n",
        "7.21214387818e-28\n",
        "6.78196570055e-28\n",
        "6.37742551175e-28\n",
        "5.99684636423e-28\n",
        "5.63906231005e-28\n",
        "5.30269272783e-28\n",
        "4.98627947934e-28\n",
        "4.68868494514e-28\n",
        "4.40913800141e-28\n",
        "4.14601273491e-28\n",
        "3.89843642715e-28\n",
        "3.66595743814e-28\n",
        "3.44729330542e-28\n",
        "3.24159409863e-28\n",
        "3.04815104498e-28\n",
        "2.86634804297e-28\n",
        "2.69531256779e-28\n",
        "2.5345184964e-28\n",
        "2.38335123286e-28\n",
        "2.24100079807e-28\n",
        "2.1073553701e-28\n",
        "1.98163287937e-28\n",
        "1.86334958363e-28\n",
        "1.7522012894e-28\n",
        "1.64749045786e-28\n",
        "1.54937043976e-28\n",
        "1.4569248122e-28\n",
        "1.36997544074e-28\n",
        "1.28838017429e-28\n",
        "1.2113704022e-28\n",
        "1.13910564143e-28\n",
        "1.07127121919e-28\n",
        "1.00724627932e-28\n",
        "9.47187370878e-29\n",
        "8.9070191542e-29\n",
        "8.3748515052e-29\n",
        "7.87564524912e-29\n",
        "7.40591070058e-29\n",
        "6.9645937656e-29\n",
        "6.54868005346e-29\n",
        "6.15784281907e-29\n",
        "5.790183766e-29\n",
        "5.44502453056e-29\n",
        "5.12040180209e-29\n",
        "4.81409037918e-29\n",
        "4.52721551557e-29\n",
        "4.25717566358e-29\n",
        "4.00367839312e-29\n",
        "3.76493662834e-29\n",
        "3.5398419251e-29\n",
        "3.32852227592e-29\n",
        "3.13011347146e-29\n",
        "2.94303437308e-29\n",
        "2.76705093514e-29\n",
        "2.60217125446e-29\n",
        "2.44720080307e-29\n",
        "2.30128723003e-29\n",
        "2.16385544588e-29\n",
        "2.03456254012e-29\n",
        "1.91365780687e-29\n",
        "1.79992558751e-29\n",
        "1.69161449889e-29\n",
        "1.59050588045e-29\n",
        "1.49577713064e-29\n",
        "1.40654154587e-29\n",
        "1.32261132915e-29\n",
        "1.24385987035e-29\n",
        "1.16957151439e-29\n",
        "1.09970406573e-29\n",
        "1.03444792625e-29\n",
        "9.72824943577e-30\n",
        "9.14497788457e-30\n",
        "8.59965265458e-30\n",
        "8.08556073268e-30\n",
        "7.60532530503e-30\n",
        "7.14974102835e-30\n",
        "6.72173568292e-30\n",
        "6.32433818853e-30\n",
        "5.9461919532e-30\n",
        "5.59199397024e-30\n",
        "5.25794085715e-30\n",
        "4.94354163344e-30\n",
        "4.65122026252e-30\n",
        "4.37149525396e-30\n",
        "4.11061802778e-30\n",
        "3.87251299538e-30\n",
        "3.63730701417e-30\n",
        "3.42176329187e-30\n",
        "3.21783632196e-30\n",
        "3.02238922724e-30\n",
        "2.84564777412e-30\n",
        "2.67807348422e-30\n",
        "2.51371694555e-30\n",
        "2.36496137981e-30\n",
        "2.22976490632e-30\n",
        "2.08796991284e-30\n",
        "1.9681723213e-30\n",
        "1.8470846012e-30\n",
        "1.74804844983e-30\n",
        "1.63496871447e-30\n",
        "1.53661256306e-30\n",
        "1.44554663955e-30\n",
        "1.36646304717e-30\n",
        "1.27789584848e-30\n",
        "1.20308898667e-30\n",
        "1.13129990097e-30\n",
        "1.06278433194e-30\n",
        "9.99448085063e-31\n",
        "9.3910695077e-31\n",
        "8.85451511127e-31\n",
        "8.30574309675e-31\n",
        "7.82272541503e-31\n",
        "7.39550280777e-31\n",
        "6.90887165642e-31\n",
        "6.49721353476e-31\n",
        "6.10800124264e-31\n",
        "5.78674286834e-31\n",
        "5.406563545e-31\n",
        "5.11146556238e-31\n",
        "4.87488933091e-31\n",
        "4.53466317977e-31\n",
        "4.22665779897e-31\n",
        "3.99526878898e-31\n",
        "3.73674043561e-31\n",
        "3.52415604385e-31\n",
        "3.32135928825e-31\n",
        "3.1697811725e-31\n",
        "2.94672641745e-31\n",
        "2.74442666086e-31\n",
        "2.58302893551e-31\n",
        "2.43339179603e-31\n",
        "2.28788487351e-31\n",
        "2.14935051328e-31\n",
        "2.02480688681e-31\n",
        "1.91411058379e-31\n",
        "1.78837312526e-31\n",
        "1.6802017841e-31\n",
        "1.61739512094e-31\n",
        "1.50030600945e-31\n",
        "1.39956332239e-31\n",
        "1.31550701275e-31\n",
        "1.25723023462e-31\n",
        "1.16340415633e-31\n",
        "1.09799635926e-31\n",
        "1.02803563748e-31\n",
        "9.66635335755e-32\n",
        "9.54058486596e-32\n",
        "8.60147302514e-32\n",
        "8.05261120285e-32\n",
        "7.55193054302e-32\n",
        "7.2472800231e-32\n",
        "6.70141336042e-32\n",
        "6.74428599039e-32\n",
        "5.91364876825e-32\n",
        "6.92699542832e-32\n",
        "5.51701816638e-32\n",
        "4.99732270992e-32\n",
        "4.72717530019e-32\n",
        "4.56207006565e-32\n",
        "4.17820533243e-32\n",
        "3.84321295233e-32\n",
        "3.7111908308e-32\n",
        "3.4834646612e-32\n",
        "3.18812405655e-32\n",
        "3.0369836949e-32\n",
        "2.86326913973e-32\n",
        "2.65896351958e-32\n",
        "2.50100999267e-32\n",
        "2.34788069458e-32\n",
        "2.23800018464e-32\n",
        "2.09111041056e-32\n",
        "2.13217748121e-32\n",
        "2.0580602114e-32\n",
        "1.73535880023e-32\n",
        "1.6265597451e-32\n",
        "1.56265046823e-32\n",
        "1.46976290463e-32\n",
        "1.35754551192e-32\n",
        "1.27590978025e-32\n",
        "1.20432217428e-32\n",
        "1.1302002025e-32\n",
        "1.06390702309e-32\n",
        "1.00680150752e-32\n",
        "9.49084734899e-33\n",
        "8.85593934022e-33\n",
        "8.30886426935e-33\n",
        "8.24802068175e-33\n",
        "7.41158592148e-33\n",
        "7.28557292707e-33\n",
        "1.19946503162e-32\n",
        "1.08850306688e-32\n",
        "1.4950313312e-32\n",
        "5.51410294039e-33\n",
        "6.47476394365e-33\n",
        "4.87703202201e-33\n",
        "4.61386234675e-33\n",
        "4.29267027033e-33\n",
        "4.04525221937e-33\n",
        "3.82858510063e-33\n",
        "3.62390802426e-33\n",
        "3.41894882925e-33\n",
        "3.39703761455e-33\n",
        "3.68752577853e-33\n",
        "3.22659093369e-33\n",
        "3.27431600433e-33\n",
        "2.9136743375e-33\n",
        "2.77068720466e-33\n",
        "2.27679149822e-33\n",
        "2.16624800947e-33\n",
        "2.05034426648e-33\n",
        "2.05673895575e-33\n"
       ]
      }
     ],
     "prompt_number": 569
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# figure(); plot(pie)\n",
      "print np.sum(pie)\n",
      "print np.min(pie), np.max(pie)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n",
        "0.00166389351082 0.00166389351082\n"
       ]
      }
     ],
     "prompt_number": 572
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## plots desired semantics\n",
      "sequence = window.semanticLoopingTab.synthesisedSequence\n",
      "# sequence = np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/lullaby/synthesised_sequence.npy\").item()\n",
      "# sequence = np.load(\"tmpSeq.npy\").item()\n",
      "desiredSemantics = sequence[DICT_SEQUENCE_INSTANCES][0][DICT_DESIRED_SEMANTICS]#[:366, :]\n",
      "figure()\n",
      "clrs = np.arange(0.0, 1.0+1.0/(len(desiredSemantics.T)-1), 1.0/(len(desiredSemantics.T)-1)).astype(np.string_)\n",
      "stack_coll = stackplot(np.arange(len(desiredSemantics)), np.row_stack(tuple([i for i in desiredSemantics.T])), colors=clrs)\n",
      "proxy_rects = [Rectangle((0, 0), 1, 1, fc=pc.get_facecolor()[0]) for pc in stack_coll]\n",
      "legend(proxy_rects, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"])\n",
      "## plots frames semantics\n",
      "usedSequence = np.load(sequence[DICT_USED_SEQUENCES][sequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_IDX]]).item()\n",
      "actualSemantics = usedSequence[DICT_FRAME_SEMANTICS][sequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES], :]\n",
      "figure()\n",
      "clrs = np.arange(0.0, 1.0+1.0/(len(actualSemantics.T)-1), 1.0/(len(actualSemantics.T)-1)).astype(np.string_)\n",
      "stack_coll = stackplot(np.arange(len(actualSemantics)), np.row_stack(tuple([i for i in actualSemantics.T])), colors=clrs)\n",
      "proxy_rects = [Rectangle((0, 0), 1, 1, fc=pc.get_facecolor()[0]) for pc in stack_coll]\n",
      "legend(proxy_rects, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "<matplotlib.legend.Legend at 0x7f9c90018890>"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "actualSemantics = np.load(\"/media/ilisescu/Data1/PhD/data/wave2/semantic_sequence-tara2.npy\").item()[DICT_FRAME_SEMANTICS]\n",
      "figure()\n",
      "clrs = np.arange(0.0, 1.0+1.0/(len(actualSemantics.T)-1), 1.0/(len(actualSemantics.T)-1)).astype(np.string_)\n",
      "stack_coll = stackplot(np.arange(len(actualSemantics)), np.row_stack(tuple([i for i in actualSemantics.T])), colors=clrs)\n",
      "proxy_rects = [Rectangle((0, 0), 1, 1, fc=pc.get_facecolor()[0]) for pc in stack_coll]\n",
      "legend(proxy_rects, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "<matplotlib.legend.Legend at 0x7f8de77af910>"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print actualSemantics[800:850, :]\n",
      "np.sort(np.load(\"/media/ilisescu/Data1/PhD/data/wave2/semantic_sequence-tara2.npy\").item()[DICT_FRAMES_LOCATIONS].keys())[805]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "1487"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "startSwitchValue = smoothstep(8)[0]\n",
      "currentSemantics = -1\n",
      "\n",
      "for i, sem in enumerate(desiredSemantics[:-1, :]) :\n",
      "    print i, \"\\t\", \"{0:04.3f}\".format(np.sum(sem)), \"\\t\",\n",
      "    for n in sem :\n",
      "        print \"{0:04.3f}\".format(n), \"\\t\",\n",
      "        \n",
      "    if len(np.argwhere(desiredSemantics[i+1, :] == startSwitchValue)) > 1 :\n",
      "        print\n",
      "        print \"oh, oh\"\n",
      "        break\n",
      "        \n",
      "    if len(np.argwhere(desiredSemantics[i+1, :] == startSwitchValue)) == 1 :\n",
      "        newSem = int(np.argwhere(desiredSemantics[i+1, :] == startSwitchValue).flatten())\n",
      "        if currentSemantics != newSem :\n",
      "            currentSemantics = newSem\n",
      "            print \"switched to\", currentSemantics\n",
      "        else :\n",
      "            print\n",
      "    else :\n",
      "        print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 \t1.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \tswitched to 3\n",
        "1 \t1.000 \t0.988 \t0.000 \t0.000 \t0.012 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "2 \t1.000 \t0.924 \t0.000 \t0.000 \t0.076 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "3 \t1.000 \t0.790 \t0.000 \t0.000 \t0.210 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "4 \t1.000 \t0.603 \t0.000 \t0.000 \t0.397 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "5 \t1.000 \t0.397 \t0.000 \t0.000 \t0.603 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "6 \t1.000 \t0.210 \t0.000 \t0.000 \t0.790 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "7 \t1.000 \t0.076 \t0.000 \t0.000 \t0.924 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "8 \t1.000 \t0.012 \t0.000 \t0.000 \t0.988 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "9 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "10 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "11 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "12 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "13 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "14 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "15 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "16 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "17 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "18 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "19 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "20 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "21 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "22 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "23 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "24 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "25 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "26 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "27 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \tswitched to 0\n",
        "28 \t1.000 \t0.012 \t0.000 \t0.000 \t0.988 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "29 \t1.000 \t0.076 \t0.000 \t0.000 \t0.924 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \tswitched to 5\n",
        "30 \t1.000 \t0.076 \t0.000 \t0.000 \t0.913 \t0.000 \t0.012 \t0.000 \t0.000 \t0.000 \t\n",
        "31 \t1.000 \t0.071 \t0.000 \t0.000 \t0.853 \t0.000 \t0.076 \t0.000 \t0.000 \t0.000 \t\n",
        "32 \t1.000 \t0.060 \t0.000 \t0.000 \t0.730 \t0.000 \t0.210 \t0.000 \t0.000 \t0.000 \t\n",
        "33 \t1.000 \t0.046 \t0.000 \t0.000 \t0.557 \t0.000 \t0.397 \t0.000 \t0.000 \t0.000 \t\n",
        "34 \t1.000 \t0.030 \t0.000 \t0.000 \t0.366 \t0.000 \t0.603 \t0.000 \t0.000 \t0.000 \t\n",
        "35 \t1.000 \t0.016 \t0.000 \t0.000 \t0.194 \t0.000 \t0.790 \t0.000 \t0.000 \t0.000 \t\n",
        "36 \t1.000 \t0.006 \t0.000 \t0.000 \t0.071 \t0.000 \t0.924 \t0.000 \t0.000 \t0.000 \t\n",
        "37 \t1.000 \t0.001 \t0.000 \t0.000 \t0.011 \t0.000 \t0.988 \t0.000 \t0.000 \t0.000 \t\n",
        "38 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t\n",
        "39 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t\n",
        "40 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t\n",
        "41 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t\n",
        "42 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \tswitched to 0\n",
        "43 \t1.000 \t0.012 \t0.000 \t0.000 \t0.000 \t0.000 \t0.988 \t0.000 \t0.000 \t0.000 \t\n",
        "44 \t1.000 \t0.076 \t0.000 \t0.000 \t0.000 \t0.000 \t0.924 \t0.000 \t0.000 \t0.000 \t\n",
        "45 \t1.000 \t0.210 \t0.000 \t0.000 \t0.000 \t0.000 \t0.790 \t0.000 \t0.000 \t0.000 \t\n",
        "46 \t1.000 \t0.397 \t0.000 \t0.000 \t0.000 \t0.000 \t0.603 \t0.000 \t0.000 \t0.000 \t\n",
        "47 \t1.000 \t0.603 \t0.000 \t0.000 \t0.000 \t0.000 \t0.397 \t0.000 \t0.000 \t0.000 \t\n",
        "48 \t1.000 \t0.790 \t0.000 \t0.000 \t0.000 \t0.000 \t0.210 \t0.000 \t0.000 \t0.000 \t\n",
        "49 \t1.000 \t0.924 \t0.000 \t0.000 \t0.000 \t0.000 \t0.076 \t0.000 \t0.000 \t0.000 \t\n",
        "50 \t1.000 \t0.988 \t0.000 \t0.000 \t0.000 \t0.000 \t0.012 \t0.000 \t0.000 \t0.000 \tswitched to 3\n",
        "51 \t1.000 \t0.977 \t0.000 \t0.000 \t0.012 \t0.000 \t0.011 \t0.000 \t0.000 \t0.000 \t\n",
        "52 \t1.000 \t0.913 \t0.000 \t0.000 \t0.076 \t0.000 \t0.011 \t0.000 \t0.000 \t0.000 \t\n",
        "53 \t1.000 \t0.781 \t0.000 \t0.000 \t0.210 \t0.000 \t0.009 \t0.000 \t0.000 \t0.000 \t\n",
        "54 \t1.000 \t0.596 \t0.000 \t0.000 \t0.397 \t0.000 \t0.007 \t0.000 \t0.000 \t0.000 \t\n",
        "55 \t1.000 \t0.392 \t0.000 \t0.000 \t0.603 \t0.000 \t0.005 \t0.000 \t0.000 \t0.000 \t\n",
        "56 \t1.000 \t0.207 \t0.000 \t0.000 \t0.790 \t0.000 \t0.002 \t0.000 \t0.000 \t0.000 \t\n",
        "57 \t1.000 \t0.076 \t0.000 \t0.000 \t0.924 \t0.000 \t0.001 \t0.000 \t0.000 \t0.000 \t\n",
        "58 \t1.000 \t0.011 \t0.000 \t0.000 \t0.988 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "59 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "60 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "61 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "62 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "63 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "64 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "65 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "66 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "67 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "68 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "69 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "70 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "71 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "72 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "73 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "74 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "75 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "76 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "77 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "78 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "79 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "80 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \tswitched to 0\n",
        "81 \t1.000 \t0.012 \t0.000 \t0.000 \t0.988 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "82 \t1.000 \t0.076 \t0.000 \t0.000 \t0.924 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "83 \t1.000 \t0.210 \t0.000 \t0.000 \t0.790 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "84 \t1.000 \t0.397 \t0.000 \t0.000 \t0.603 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \tswitched to 5\n",
        "85 \t1.000 \t0.392 \t0.000 \t0.000 \t0.596 \t0.000 \t0.012 \t0.000 \t0.000 \t0.000 \t\n",
        "86 \t1.000 \t0.366 \t0.000 \t0.000 \t0.557 \t0.000 \t0.076 \t0.000 \t0.000 \t0.000 \t\n",
        "87 \t1.000 \t0.313 \t0.000 \t0.000 \t0.477 \t0.000 \t0.210 \t0.000 \t0.000 \t0.000 \t\n",
        "88 \t1.000 \t0.239 \t0.000 \t0.000 \t0.364 \t0.000 \t0.397 \t0.000 \t0.000 \t0.000 \t\n",
        "89 \t1.000 \t0.157 \t0.000 \t0.000 \t0.239 \t0.000 \t0.603 \t0.000 \t0.000 \t0.000 \t\n",
        "90 \t1.000 \t0.083 \t0.000 \t0.000 \t0.127 \t0.000 \t0.790 \t0.000 \t0.000 \t0.000 \t\n",
        "91 \t1.000 \t0.030 \t0.000 \t0.000 \t0.046 \t0.000 \t0.924 \t0.000 \t0.000 \t0.000 \t\n",
        "92 \t1.000 \t0.005 \t0.000 \t0.000 \t0.007 \t0.000 \t0.988 \t0.000 \t0.000 \t0.000 \t\n",
        "93 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t\n",
        "94 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t\n",
        "95 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t\n",
        "96 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \tswitched to 0\n",
        "97 \t1.000 \t0.012 \t0.000 \t0.000 \t0.000 \t0.000 \t0.988 \t0.000 \t0.000 \t0.000 \t\n",
        "98 \t1.000 \t0.076 \t0.000 \t0.000 \t0.000 \t0.000 \t0.924 \t0.000 \t0.000 \t0.000 \t\n",
        "99 \t1.000 \t0.210 \t0.000 \t0.000 \t0.000 \t0.000 \t0.790 \t0.000 \t0.000 \t0.000 \t\n",
        "100 \t1.000 \t0.397 \t0.000 \t0.000 \t0.000 \t0.000 \t0.603 \t0.000 \t0.000 \t0.000 \t\n",
        "101 \t1.000 \t0.603 \t0.000 \t0.000 \t0.000 \t0.000 \t0.397 \t0.000 \t0.000 \t0.000 \t\n",
        "102 \t1.000 \t0.790 \t0.000 \t0.000 \t0.000 \t0.000 \t0.210 \t0.000 \t0.000 \t0.000 \t\n",
        "103 \t1.000 \t0.924 \t0.000 \t0.000 \t0.000 \t0.000 \t0.076 \t0.000 \t0.000 \t0.000 \t\n",
        "104 \t1.000 \t0.988 \t0.000 \t0.000 \t0.000 \t0.000 \t0.012 \t0.000 \t0.000 \t0.000 \t\n",
        "105 \t1.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \tswitched to 3\n",
        "106 \t1.000 \t0.988 \t0.000 \t0.000 \t0.012 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "107 \t1.000 \t0.924 \t0.000 \t0.000 \t0.076 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "108 \t1.000 \t0.790 \t0.000 \t0.000 \t0.210 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "109 \t1.000 \t0.603 \t0.000 \t0.000 \t0.397 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "110 \t1.000 \t0.397 \t0.000 \t0.000 \t0.603 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "111 \t1.000 \t0.210 \t0.000 \t0.000 \t0.790 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "112 \t1.000 \t0.076 \t0.000 \t0.000 \t0.924 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "113 \t1.000 \t0.012 \t0.000 \t0.000 \t0.988 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "114 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "115 \t1.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \tswitched to 0\n",
        "116 \t1.000 \t0.012 \t0.000 \t0.000 \t0.988 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "117 \t1.000 \t0.076 \t0.000 \t0.000 \t0.924 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "118 \t1.000 \t0.210 \t0.000 \t0.000 \t0.790 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "119 \t1.000 \t0.397 \t0.000 \t0.000 \t0.603 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "120 \t1.000 \t0.603 \t0.000 \t0.000 \t0.397 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \tswitched to 5\n",
        "121 \t1.000 \t0.596 \t0.000 \t0.000 \t0.392 \t0.000 \t0.012 \t0.000 \t0.000 \t0.000 \t\n",
        "122 \t1.000 \t0.557 \t0.000 \t0.000 \t0.366 \t0.000 \t0.076 \t0.000 \t0.000 \t0.000 \t\n",
        "123 \t1.000 \t0.477 \t0.000 \t0.000 \t0.313 \t0.000 \t0.210 \t0.000 \t0.000 \t0.000 \t\n",
        "124 \t1.000 \t0.364 \t0.000 \t0.000 \t0.239 \t0.000 \t0.397 \t0.000 \t0.000 \t0.000 \t\n",
        "125 \t1.000 \t0.239 \t0.000 \t0.000 \t0.157 \t0.000 \t0.603 \t0.000 \t0.000 \t0.000 \t\n",
        "126 \t1.000 \t0.127 \t0.000 \t0.000 \t0.083 \t0.000 \t0.790 \t0.000 \t0.000 \t0.000 \t\n",
        "127 \t1.000 \t0.046 \t0.000 \t0.000 \t0.030 \t0.000 \t0.924 \t0.000 \t0.000 \t0.000 \t\n",
        "128 \t1.000 \t0.007 \t0.000 \t0.000 \t0.005 \t0.000 \t0.988 \t0.000 \t0.000 \t0.000 \t\n",
        "129 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t\n",
        "130 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t\n",
        "131 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t\n",
        "132 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \tswitched to 0\n",
        "133 \t1.000 \t0.012 \t0.000 \t0.000 \t0.000 \t0.000 \t0.988 \t0.000 \t0.000 \t0.000 \t\n",
        "134 \t1.000 \t0.076 \t0.000 \t0.000 \t0.000 \t0.000 \t0.924 \t0.000 \t0.000 \t0.000 \t\n",
        "135 \t1.000 \t0.210 \t0.000 \t0.000 \t0.000 \t0.000 \t0.790 \t0.000 \t0.000 \t0.000 \t\n",
        "136 \t1.000 \t0.397 \t0.000 \t0.000 \t0.000 \t0.000 \t0.603 \t0.000 \t0.000 \t0.000 \t\n",
        "137 \t1.000 \t0.603 \t0.000 \t0.000 \t0.000 \t0.000 \t0.397 \t0.000 \t0.000 \t0.000 \t\n",
        "138 \t1.000 \t0.790 \t0.000 \t0.000 \t0.000 \t0.000 \t0.210 \t0.000 \t0.000 \t0.000 \tswitched to 8\n",
        "139 \t1.000 \t0.781 \t0.000 \t0.000 \t0.000 \t0.000 \t0.207 \t0.000 \t0.000 \t0.012 \t\n",
        "140 \t1.000 \t0.730 \t0.000 \t0.000 \t0.000 \t0.000 \t0.194 \t0.000 \t0.000 \t0.076 \t\n",
        "141 \t1.000 \t0.624 \t0.000 \t0.000 \t0.000 \t0.000 \t0.166 \t0.000 \t0.000 \t0.210 \t\n",
        "142 \t1.000 \t0.477 \t0.000 \t0.000 \t0.000 \t0.000 \t0.127 \t0.000 \t0.000 \t0.397 \t\n",
        "143 \t1.000 \t0.313 \t0.000 \t0.000 \t0.000 \t0.000 \t0.083 \t0.000 \t0.000 \t0.603 \t\n",
        "144 \t1.000 \t0.166 \t0.000 \t0.000 \t0.000 \t0.000 \t0.044 \t0.000 \t0.000 \t0.790 \t\n",
        "145 \t1.000 \t0.060 \t0.000 \t0.000 \t0.000 \t0.000 \t0.016 \t0.000 \t0.000 \t0.924 \t\n",
        "146 \t1.000 \t0.009 \t0.000 \t0.000 \t0.000 \t0.000 \t0.002 \t0.000 \t0.000 \t0.988 \t\n",
        "147 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t\n",
        "148 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \tswitched to 0\n",
        "149 \t1.000 \t0.012 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.988 \t\n",
        "150 \t1.000 \t0.076 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.924 \t\n",
        "151 \t1.000 \t0.210 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.790 \t\n",
        "152 \t1.000 \t0.397 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.603 \t\n",
        "153 \t1.000 \t0.603 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.397 \t\n",
        "154 \t1.000 \t0.790 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.210 \t\n",
        "155 \t1.000 \t0.924 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.076 \tswitched to 7\n",
        "156 \t1.000 \t0.913 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.012 \t0.076 \t\n",
        "157 \t1.000 \t0.853 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.076 \t0.071 \t\n",
        "158 \t1.000 \t0.730 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.210 \t0.060 \t\n",
        "159 \t1.000 \t0.557 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.397 \t0.046 \t\n",
        "160 \t1.000 \t0.366 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.603 \t0.030 \t\n",
        "161 \t1.000 \t0.194 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.790 \t0.016 \t\n",
        "162 \t1.000 \t0.071 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.924 \t0.006 \t\n",
        "163 \t1.000 \t0.081 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.913 \t0.006 \t\n",
        "164 \t1.000 \t0.142 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.853 \t0.005 \t\n",
        "165 \t1.000 \t0.266 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.730 \t0.005 \tswitched to 6\n",
        "166 \t1.000 \t0.263 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.012 \t0.721 \t0.005 \t\n",
        "167 \t1.000 \t0.245 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.076 \t0.674 \t0.004 \t\n",
        "168 \t1.000 \t0.210 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.210 \t0.577 \t0.004 \t\n",
        "169 \t1.000 \t0.160 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.397 \t0.440 \t0.003 \t\n",
        "170 \t1.000 \t0.105 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.603 \t0.289 \t0.002 \t\n",
        "171 \t1.000 \t0.056 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.790 \t0.153 \t0.001 \t\n",
        "172 \t1.000 \t0.020 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.924 \t0.056 \t0.000 \t\n",
        "173 \t1.000 \t0.003 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.988 \t0.008 \t0.000 \t\n",
        "174 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \tswitched to 0\n",
        "175 \t1.000 \t0.012 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.988 \t0.000 \t0.000 \t\n",
        "176 \t1.000 \t0.076 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.924 \t0.000 \t0.000 \t\n",
        "177 \t1.000 \t0.210 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.790 \t0.000 \t0.000 \t\n",
        "178 \t1.000 \t0.397 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.603 \t0.000 \t0.000 \t\n",
        "179 \t1.000 \t0.603 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.397 \t0.000 \t0.000 \t\n",
        "180 \t1.000 \t0.596 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.404 \t0.000 \t0.000 \t\n",
        "181 \t1.000 \t0.557 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.443 \t0.000 \t0.000 \t\n",
        "182 \t1.000 \t0.477 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.523 \t0.000 \t0.000 \t\n",
        "183 \t1.000 \t0.364 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.636 \t0.000 \t0.000 \t\n",
        "184 \t1.000 \t0.239 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.761 \t0.000 \t0.000 \t\n",
        "185 \t1.000 \t0.127 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.873 \t0.000 \t0.000 \t\n",
        "186 \t1.000 \t0.046 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.954 \t0.000 \t0.000 \t\n",
        "187 \t1.000 \t0.007 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.993 \t0.000 \t0.000 \t\n",
        "188 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t\n",
        "189 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t\n",
        "190 \t1.000 \t0.012 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.988 \t0.000 \t0.000 \t\n",
        "191 \t1.000 \t0.076 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.924 \t0.000 \t0.000 \t\n",
        "192 \t1.000 \t0.210 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.790 \t0.000 \t0.000 \t\n",
        "193 \t1.000 \t0.397 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.603 \t0.000 \t0.000 \t\n",
        "194 \t1.000 \t0.603 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.397 \t0.000 \t0.000 \tswitched to 5\n",
        "195 \t1.000 \t0.596 \t0.000 \t0.000 \t0.000 \t0.000 \t0.012 \t0.392 \t0.000 \t0.000 \t\n",
        "196 \t1.000 \t0.557 \t0.000 \t0.000 \t0.000 \t0.000 \t0.076 \t0.366 \t0.000 \t0.000 \t\n",
        "197 \t1.000 \t0.477 \t0.000 \t0.000 \t0.000 \t0.000 \t0.210 \t0.313 \t0.000 \t0.000 \t\n",
        "198 \t1.000 \t0.364 \t0.000 \t0.000 \t0.000 \t0.000 \t0.397 \t0.239 \t0.000 \t0.000 \t\n",
        "199 \t1.000 \t0.239 \t0.000 \t0.000 \t0.000 \t0.000 \t0.603 \t0.157 \t0.000 \t0.000 \t\n",
        "200 \t1.000 \t0.127 \t0.000 \t0.000 \t0.000 \t0.000 \t0.790 \t0.083 \t0.000 \t0.000 \t\n",
        "201 \t1.000 \t0.046 \t0.000 \t0.000 \t0.000 \t0.000 \t0.924 \t0.030 \t0.000 \t0.000 \t\n",
        "202 \t1.000 \t0.007 \t0.000 \t0.000 \t0.000 \t0.000 \t0.988 \t0.005 \t0.000 \t0.000 \t\n",
        "203 \t1.000 \t0.018 \t0.000 \t0.000 \t0.000 \t0.000 \t0.977 \t0.005 \t0.000 \t0.000 \t\n",
        "204 \t1.000 \t0.083 \t0.000 \t0.000 \t0.000 \t0.000 \t0.913 \t0.004 \t0.000 \t0.000 \t\n",
        "205 \t1.000 \t0.215 \t0.000 \t0.000 \t0.000 \t0.000 \t0.781 \t0.004 \t0.000 \t0.000 \t\n",
        "206 \t1.000 \t0.401 \t0.000 \t0.000 \t0.000 \t0.000 \t0.596 \t0.003 \t0.000 \t0.000 \tswitched to 2\n",
        "207 \t1.000 \t0.396 \t0.000 \t0.012 \t0.000 \t0.000 \t0.589 \t0.003 \t0.000 \t0.000 \t\n",
        "208 \t1.000 \t0.370 \t0.000 \t0.076 \t0.000 \t0.000 \t0.551 \t0.003 \t0.000 \t0.000 \t\n",
        "209 \t1.000 \t0.317 \t0.000 \t0.210 \t0.000 \t0.000 \t0.471 \t0.002 \t0.000 \t0.000 \t\n",
        "210 \t1.000 \t0.242 \t0.000 \t0.397 \t0.000 \t0.000 \t0.360 \t0.002 \t0.000 \t0.000 \t\n",
        "211 \t1.000 \t0.159 \t0.000 \t0.603 \t0.000 \t0.000 \t0.237 \t0.001 \t0.000 \t0.000 \t\n",
        "212 \t1.000 \t0.084 \t0.000 \t0.790 \t0.000 \t0.000 \t0.125 \t0.001 \t0.000 \t0.000 \t\n",
        "213 \t1.000 \t0.031 \t0.000 \t0.924 \t0.000 \t0.000 \t0.046 \t0.000 \t0.000 \t0.000 \t\n",
        "214 \t1.000 \t0.042 \t0.000 \t0.913 \t0.000 \t0.000 \t0.045 \t0.000 \t0.000 \t0.000 \t\n",
        "215 \t1.000 \t0.105 \t0.000 \t0.853 \t0.000 \t0.000 \t0.042 \t0.000 \t0.000 \t0.000 \t\n",
        "216 \t1.000 \t0.234 \t0.000 \t0.730 \t0.000 \t0.000 \t0.036 \t0.000 \t0.000 \t0.000 \tswitched to 3\n",
        "217 \t1.000 \t0.231 \t0.000 \t0.721 \t0.012 \t0.000 \t0.036 \t0.000 \t0.000 \t0.000 \t\n",
        "218 \t1.000 \t0.216 \t0.000 \t0.674 \t0.076 \t0.000 \t0.033 \t0.000 \t0.000 \t0.000 \t\n",
        "219 \t1.000 \t0.185 \t0.000 \t0.577 \t0.210 \t0.000 \t0.028 \t0.000 \t0.000 \t0.000 \t\n",
        "220 \t1.000 \t0.141 \t0.000 \t0.440 \t0.397 \t0.000 \t0.022 \t0.000 \t0.000 \t0.000 \t\n",
        "221 \t1.000 \t0.093 \t0.000 \t0.289 \t0.603 \t0.000 \t0.014 \t0.000 \t0.000 \t0.000 \t\n",
        "222 \t1.000 \t0.049 \t0.000 \t0.153 \t0.790 \t0.000 \t0.008 \t0.000 \t0.000 \t0.000 \t\n",
        "223 \t1.000 \t0.060 \t0.000 \t0.151 \t0.781 \t0.000 \t0.007 \t0.000 \t0.000 \t0.000 \t\n",
        "224 \t1.000 \t0.122 \t0.000 \t0.141 \t0.730 \t0.000 \t0.007 \t0.000 \t0.000 \t0.000 \t\n",
        "225 \t1.000 \t0.249 \t0.000 \t0.121 \t0.624 \t0.000 \t0.006 \t0.000 \t0.000 \t0.000 \t\n",
        "226 \t1.000 \t0.426 \t0.000 \t0.092 \t0.477 \t0.000 \t0.005 \t0.000 \t0.000 \t0.000 \t\n",
        "227 \t1.000 \t0.623 \t0.000 \t0.061 \t0.313 \t0.000 \t0.003 \t0.000 \t0.000 \t0.000 \tswitched to 4\n",
        "228 \t1.000 \t0.616 \t0.000 \t0.060 \t0.310 \t0.012 \t0.003 \t0.000 \t0.000 \t0.000 \t\n",
        "229 \t1.000 \t0.575 \t0.000 \t0.056 \t0.289 \t0.076 \t0.003 \t0.000 \t0.000 \t0.000 \t\n",
        "230 \t1.000 \t0.492 \t0.000 \t0.048 \t0.248 \t0.210 \t0.002 \t0.000 \t0.000 \t0.000 \t\n",
        "231 \t1.000 \t0.376 \t0.000 \t0.037 \t0.189 \t0.397 \t0.002 \t0.000 \t0.000 \t0.000 \t\n",
        "232 \t1.000 \t0.247 \t0.000 \t0.024 \t0.124 \t0.603 \t0.001 \t0.000 \t0.000 \t0.000 \t\n",
        "233 \t1.000 \t0.131 \t0.000 \t0.013 \t0.066 \t0.790 \t0.001 \t0.000 \t0.000 \t0.000 \t\n",
        "234 \t1.000 \t0.048 \t0.000 \t0.005 \t0.024 \t0.924 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "235 \t1.000 \t0.059 \t0.000 \t0.005 \t0.024 \t0.913 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "236 \t1.000 \t0.120 \t0.000 \t0.004 \t0.022 \t0.853 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "237 \t1.000 \t0.247 \t0.000 \t0.004 \t0.019 \t0.730 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "238 \t1.000 \t0.425 \t0.000 \t0.003 \t0.014 \t0.557 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "239 \t1.000 \t0.420 \t0.000 \t0.014 \t0.014 \t0.551 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "240 \t1.000 \t0.393 \t0.000 \t0.079 \t0.013 \t0.515 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "241 \t1.000 \t0.336 \t0.000 \t0.212 \t0.011 \t0.440 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "242 \t1.000 \t0.257 \t0.000 \t0.398 \t0.009 \t0.336 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "243 \t1.000 \t0.169 \t0.000 \t0.604 \t0.006 \t0.221 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "244 \t1.000 \t0.089 \t0.000 \t0.791 \t0.003 \t0.117 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "245 \t1.000 \t0.033 \t0.000 \t0.924 \t0.001 \t0.043 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "246 \t1.000 \t0.005 \t0.000 \t0.988 \t0.000 \t0.006 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "247 \t1.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "248 \t1.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "249 \t1.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "250 \t1.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "251 \t1.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "252 \t1.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "253 \t1.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "254 \t1.000 \t0.000 \t0.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \tswitched to 0\n",
        "255 \t1.000 \t0.012 \t0.000 \t0.988 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "256 \t1.000 \t0.076 \t0.000 \t0.924 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \tswitched to 3\n",
        "257 \t1.000 \t0.076 \t0.000 \t0.913 \t0.012 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "258 \t1.000 \t0.071 \t0.000 \t0.853 \t0.076 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "259 \t1.000 \t0.060 \t0.000 \t0.730 \t0.210 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "260 \t1.000 \t0.046 \t0.000 \t0.557 \t0.397 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "261 \t1.000 \t0.030 \t0.000 \t0.366 \t0.603 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "262 \t1.000 \t0.016 \t0.000 \t0.194 \t0.790 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "263 \t1.000 \t0.027 \t0.000 \t0.192 \t0.781 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "264 \t1.000 \t0.091 \t0.000 \t0.179 \t0.730 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "265 \t1.000 \t0.223 \t0.000 \t0.153 \t0.624 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "266 \t1.000 \t0.406 \t0.000 \t0.117 \t0.477 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "267 \t1.000 \t0.610 \t0.000 \t0.077 \t0.313 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \tswitched to 4\n",
        "268 \t1.000 \t0.603 \t0.000 \t0.076 \t0.310 \t0.012 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "269 \t1.000 \t0.563 \t0.000 \t0.071 \t0.289 \t0.076 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "270 \t1.000 \t0.482 \t0.000 \t0.061 \t0.248 \t0.210 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "271 \t1.000 \t0.368 \t0.000 \t0.046 \t0.189 \t0.397 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "272 \t1.000 \t0.242 \t0.000 \t0.031 \t0.124 \t0.603 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "273 \t1.000 \t0.128 \t0.000 \t0.016 \t0.066 \t0.790 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "274 \t1.000 \t0.138 \t0.000 \t0.016 \t0.065 \t0.781 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "275 \t1.000 \t0.195 \t0.000 \t0.015 \t0.061 \t0.730 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "276 \t1.000 \t0.311 \t0.000 \t0.013 \t0.052 \t0.624 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "277 \t1.000 \t0.474 \t0.000 \t0.010 \t0.040 \t0.477 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "278 \t1.000 \t0.468 \t0.000 \t0.021 \t0.039 \t0.471 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "279 \t1.000 \t0.438 \t0.000 \t0.085 \t0.037 \t0.440 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "280 \t1.000 \t0.374 \t0.000 \t0.218 \t0.031 \t0.377 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "281 \t1.000 \t0.286 \t0.000 \t0.403 \t0.024 \t0.288 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "282 \t1.000 \t0.188 \t0.000 \t0.607 \t0.016 \t0.189 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "283 \t1.000 \t0.099 \t0.000 \t0.792 \t0.008 \t0.100 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "284 \t1.000 \t0.036 \t0.000 \t0.924 \t0.003 \t0.036 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "285 \t1.000 \t0.005 \t0.000 \t0.989 \t0.000 \t0.005 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "286 \t1.000 \t0.017 \t0.000 \t0.977 \t0.000 \t0.005 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "287 \t1.000 \t0.081 \t0.000 \t0.913 \t0.000 \t0.005 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "288 \t1.000 \t0.214 \t0.000 \t0.781 \t0.000 \t0.004 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "289 \t1.000 \t0.212 \t0.000 \t0.772 \t0.000 \t0.016 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "290 \t1.000 \t0.198 \t0.000 \t0.721 \t0.000 \t0.080 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "291 \t1.000 \t0.169 \t0.000 \t0.617 \t0.000 \t0.213 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "292 \t1.000 \t0.129 \t0.000 \t0.471 \t0.000 \t0.399 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "293 \t1.000 \t0.085 \t0.000 \t0.310 \t0.000 \t0.605 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "294 \t1.000 \t0.045 \t0.000 \t0.164 \t0.000 \t0.791 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "295 \t1.000 \t0.016 \t0.000 \t0.060 \t0.000 \t0.924 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "296 \t1.000 \t0.028 \t0.000 \t0.059 \t0.000 \t0.913 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "297 \t1.000 \t0.092 \t0.000 \t0.055 \t0.000 \t0.853 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "298 \t1.000 \t0.223 \t0.000 \t0.047 \t0.000 \t0.730 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "299 \t1.000 \t0.407 \t0.000 \t0.036 \t0.000 \t0.557 \t0.000 \t0.000 \t0.000 \t0.000 \tswitched to 7\n",
        "300 \t1.000 \t0.402 \t0.000 \t0.036 \t0.000 \t0.551 \t0.000 \t0.000 \t0.012 \t0.000 \t\n",
        "301 \t1.000 \t0.375 \t0.000 \t0.033 \t0.000 \t0.515 \t0.000 \t0.000 \t0.076 \t0.000 \t\n",
        "302 \t1.000 \t0.321 \t0.000 \t0.028 \t0.000 \t0.440 \t0.000 \t0.000 \t0.210 \t0.000 \t\n",
        "303 \t1.000 \t0.245 \t0.000 \t0.022 \t0.000 \t0.336 \t0.000 \t0.000 \t0.397 \t0.000 \t\n",
        "304 \t1.000 \t0.161 \t0.000 \t0.014 \t0.000 \t0.221 \t0.000 \t0.000 \t0.603 \t0.000 \t\n",
        "305 \t1.000 \t0.085 \t0.000 \t0.008 \t0.000 \t0.117 \t0.000 \t0.000 \t0.790 \t0.000 \t\n",
        "306 \t1.000 \t0.031 \t0.000 \t0.003 \t0.000 \t0.043 \t0.000 \t0.000 \t0.924 \t0.000 \t\n",
        "307 \t1.000 \t0.005 \t0.000 \t0.000 \t0.000 \t0.006 \t0.000 \t0.000 \t0.988 \t0.000 \t\n",
        "308 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \tswitched to 0\n",
        "309 \t1.000 \t0.012 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.988 \t0.000 \t\n",
        "310 \t1.000 \t0.076 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.924 \t0.000 \t\n",
        "311 \t1.000 \t0.210 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.790 \t0.000 \t\n",
        "312 \t1.000 \t0.397 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.603 \t0.000 \tswitched to 6\n",
        "313 \t1.000 \t0.392 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.012 \t0.596 \t0.000 \t\n",
        "314 \t1.000 \t0.366 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.076 \t0.557 \t0.000 \t\n",
        "315 \t1.000 \t0.313 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.210 \t0.477 \t0.000 \t\n",
        "316 \t1.000 \t0.239 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.397 \t0.364 \t0.000 \t\n",
        "317 \t1.000 \t0.157 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.603 \t0.239 \t0.000 \t\n",
        "318 \t1.000 \t0.083 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.790 \t0.127 \t0.000 \t\n",
        "319 \t1.000 \t0.030 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.924 \t0.046 \t0.000 \t\n",
        "320 \t1.000 \t0.005 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.988 \t0.007 \t0.000 \t\n",
        "321 \t1.000 \t0.016 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.977 \t0.007 \t0.000 \t\n",
        "322 \t1.000 \t0.081 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.913 \t0.006 \t0.000 \t\n",
        "323 \t1.000 \t0.213 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.781 \t0.005 \t0.000 \t\n",
        "324 \t1.000 \t0.399 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.596 \t0.004 \t0.000 \tswitched to 5\n",
        "325 \t1.000 \t0.395 \t0.000 \t0.000 \t0.000 \t0.000 \t0.012 \t0.589 \t0.004 \t0.000 \t\n",
        "326 \t1.000 \t0.369 \t0.000 \t0.000 \t0.000 \t0.000 \t0.076 \t0.551 \t0.004 \t0.000 \t\n",
        "327 \t1.000 \t0.316 \t0.000 \t0.000 \t0.000 \t0.000 \t0.210 \t0.471 \t0.003 \t0.000 \t\n",
        "328 \t1.000 \t0.241 \t0.000 \t0.000 \t0.000 \t0.000 \t0.397 \t0.360 \t0.003 \t0.000 \t\n",
        "329 \t1.000 \t0.158 \t0.000 \t0.000 \t0.000 \t0.000 \t0.603 \t0.237 \t0.002 \t0.000 \t\n",
        "330 \t1.000 \t0.084 \t0.000 \t0.000 \t0.000 \t0.000 \t0.790 \t0.125 \t0.001 \t0.000 \t\n",
        "331 \t1.000 \t0.031 \t0.000 \t0.000 \t0.000 \t0.000 \t0.924 \t0.046 \t0.000 \t0.000 \t\n",
        "332 \t1.000 \t0.005 \t0.000 \t0.000 \t0.000 \t0.000 \t0.988 \t0.007 \t0.000 \t0.000 \t\n",
        "333 \t1.000 \t0.016 \t0.000 \t0.000 \t0.000 \t0.000 \t0.977 \t0.007 \t0.000 \t0.000 \t\n",
        "334 \t1.000 \t0.081 \t0.000 \t0.000 \t0.000 \t0.000 \t0.913 \t0.006 \t0.000 \t0.000 \t\n",
        "335 \t1.000 \t0.214 \t0.000 \t0.000 \t0.000 \t0.000 \t0.781 \t0.005 \t0.000 \t0.000 \t\n",
        "336 \t1.000 \t0.399 \t0.000 \t0.000 \t0.000 \t0.000 \t0.596 \t0.004 \t0.000 \t0.000 \t\n",
        "337 \t1.000 \t0.395 \t0.000 \t0.000 \t0.000 \t0.000 \t0.589 \t0.004 \t0.012 \t0.000 \t\n",
        "338 \t1.000 \t0.369 \t0.000 \t0.000 \t0.000 \t0.000 \t0.551 \t0.004 \t0.076 \t0.000 \t\n",
        "339 \t1.000 \t0.316 \t0.000 \t0.000 \t0.000 \t0.000 \t0.471 \t0.003 \t0.210 \t0.000 \t\n",
        "340 \t1.000 \t0.241 \t0.000 \t0.000 \t0.000 \t0.000 \t0.360 \t0.003 \t0.397 \t0.000 \t\n",
        "341 \t1.000 \t0.158 \t0.000 \t0.000 \t0.000 \t0.000 \t0.237 \t0.002 \t0.603 \t0.000 \t\n",
        "342 \t1.000 \t0.084 \t0.000 \t0.000 \t0.000 \t0.000 \t0.125 \t0.001 \t0.790 \t0.000 \t\n",
        "343 \t1.000 \t0.031 \t0.000 \t0.000 \t0.000 \t0.000 \t0.046 \t0.000 \t0.924 \t0.000 \t\n",
        "344 \t1.000 \t0.005 \t0.000 \t0.000 \t0.000 \t0.000 \t0.007 \t0.000 \t0.988 \t0.000 \t\n",
        "345 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t1.000 \t0.000 \tswitched to 0\n",
        "346 \t1.000 \t0.012 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.988 \t0.000 \t\n",
        "347 \t1.000 \t0.076 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.924 \t0.000 \t\n",
        "348 \t1.000 \t0.210 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.790 \t0.000 \t\n",
        "349 \t1.000 \t0.397 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.603 \t0.000 \t\n",
        "350 \t1.000 \t0.603 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.397 \t0.000 \tswitched to 8\n",
        "351 \t1.000 \t0.596 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.392 \t0.012 \t\n",
        "352 \t1.000 \t0.557 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.366 \t0.076 \t\n",
        "353 \t1.000 \t0.477 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.313 \t0.210 \t\n",
        "354 \t1.000 \t0.364 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.239 \t0.397 \t\n",
        "355 \t1.000 \t0.239 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.157 \t0.603 \t\n",
        "356 \t1.000 \t0.127 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.083 \t0.790 \t\n",
        "357 \t1.000 \t0.046 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.030 \t0.924 \t\n",
        "358 \t1.000 \t0.057 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.030 \t0.913 \t\n",
        "359 \t1.000 \t0.119 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.028 \t0.853 \t\n",
        "360 \t1.000 \t0.246 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.024 \t0.730 \t\n",
        "361 \t1.000 \t0.425 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.018 \t0.557 \t\n",
        "362 \t1.000 \t0.622 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.012 \t0.366 \t\n",
        "363 \t1.000 \t0.800 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.006 \t0.194 \t\n",
        "364 \t1.000 \t0.927 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.002 \t0.071 \t\n",
        "365 \t1.000 \t0.989 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.011 \t\n",
        "366 \t1.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "367 \t1.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n",
        "368 \t1.000 \t1.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t0.000 \t\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# dirLoc = \"/media/ilisescu/Data1/PhD/toyLullaby/\"\n",
      "# os.mkdir(dirLoc)\n",
      "# for i, f in enumerate(window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES]) :\n",
      "#     print window.semanticLoopingTab.semanticSequences[0][DICT_FRAMES_LOCATIONS][f]\n",
      "#     copyanything(window.semanticLoopingTab.semanticSequences[0][DICT_FRAMES_LOCATIONS][f], dirLoc + \"frame-{0:05d}.png\".format(i+1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# synthSeq = window.semanticLoopingTab.synthesisedSequence\n",
      "# synthSeq[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES] = synthSeq[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES][:370]\n",
      "# synthSeq[DICT_SEQUENCE_INSTANCES][0][DICT_DESIRED_SEMANTICS] = synthSeq[DICT_SEQUENCE_INSTANCES][0][DICT_DESIRED_SEMANTICS][:370, :]\n",
      "# # np.save(window.semanticLoopingTab.loadedSynthesisedSequence, synthSeq)\n",
      "# print window.semanticLoopingTab.loadedSynthesisedSequence"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ilisescu/PhD/data/synthesisedSequences/lullaby-no_learning-L2_cost_to_probability_and_back_thresholded/synthesised_sequence.npy\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gwv.showCustomGraph(window.semanticLoopingTab.unaries[:, 1:])\n",
      "print np.min(window.semanticLoopingTab.unaries[:, 1:]), np.max(window.semanticLoopingTab.unaries[:, 1:])\n",
      "print window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_DESIRED_SEMANTICS]\n",
      "print window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES]\n",
      "print (window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES][:-1]-\n",
      "       window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES][1:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7.95064472653 8.32453715728\n",
        "[[ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 0.98846721  0.01153279]\n",
        " [ 0.92358888  0.07641112]\n",
        " [ 0.79012346  0.20987654]\n",
        " [ 0.6033125   0.3966875 ]\n",
        " [ 0.3966875   0.6033125 ]\n",
        " [ 0.20987654  0.79012346]\n",
        " [ 0.07641112  0.92358888]\n",
        " [ 0.01153279  0.98846721]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.01153279  0.98846721]\n",
        " [ 0.07641112  0.92358888]\n",
        " [ 0.20987654  0.79012346]\n",
        " [ 0.3966875   0.6033125 ]\n",
        " [ 0.6033125   0.3966875 ]\n",
        " [ 0.79012346  0.20987654]\n",
        " [ 0.92358888  0.07641112]\n",
        " [ 0.98846721  0.01153279]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 0.98846721  0.01153279]\n",
        " [ 0.92358888  0.07641112]\n",
        " [ 0.79012346  0.20987654]\n",
        " [ 0.6033125   0.3966875 ]\n",
        " [ 0.3966875   0.6033125 ]\n",
        " [ 0.20987654  0.79012346]\n",
        " [ 0.07641112  0.92358888]\n",
        " [ 0.01153279  0.98846721]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.01153279  0.98846721]\n",
        " [ 0.07641112  0.92358888]\n",
        " [ 0.20987654  0.79012346]\n",
        " [ 0.3966875   0.6033125 ]\n",
        " [ 0.6033125   0.3966875 ]\n",
        " [ 0.79012346  0.20987654]\n",
        " [ 0.92358888  0.07641112]\n",
        " [ 0.98846721  0.01153279]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]]\n",
        "[   0    2    3    4    5    6    7    8    9   10   11   12   13   14   15\n",
        "   16   17   18   19  262  263  264  265  266  267  268  269  270  271  272\n",
        "  273  274  275  276  277  278  279  280  281  282 2046 2047 2048 2049 2050\n",
        " 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065\n",
        " 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080\n",
        " 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095\n",
        " 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110\n",
        " 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125\n",
        " 2126 2127 2006 2007 2008 2009 2043 2044 2045 2046 2047 2048 2049 2050 2051\n",
        " 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066\n",
        " 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081\n",
        " 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096\n",
        " 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111\n",
        " 2112 2113 2114 2115 2116 2117]\n",
        "[   -2    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1  -243    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1 -1764    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1   121    -1    -1    -1   -34    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gwv.showCustomGraph(window.semanticLoopingTab.unaries[:, 1:])\n",
      "print np.min(window.semanticLoopingTab.unaries[:, 1:]), np.max(window.semanticLoopingTab.unaries[:, 1:])\n",
      "print window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_DESIRED_SEMANTICS]\n",
      "print window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES]\n",
      "print (window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES][:-1]-\n",
      "       window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES][1:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7.95087140588 8.15087140588\n",
        "[[ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 0.98846721  0.01153279]\n",
        " [ 0.92358888  0.07641112]\n",
        " [ 0.79012346  0.20987654]\n",
        " [ 0.6033125   0.3966875 ]\n",
        " [ 0.3966875   0.6033125 ]\n",
        " [ 0.20987654  0.79012346]\n",
        " [ 0.07641112  0.92358888]\n",
        " [ 0.01153279  0.98846721]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.01153279  0.98846721]\n",
        " [ 0.07641112  0.92358888]\n",
        " [ 0.20987654  0.79012346]\n",
        " [ 0.3966875   0.6033125 ]\n",
        " [ 0.6033125   0.3966875 ]\n",
        " [ 0.79012346  0.20987654]\n",
        " [ 0.92358888  0.07641112]\n",
        " [ 0.98846721  0.01153279]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 0.98846721  0.01153279]\n",
        " [ 0.92358888  0.07641112]\n",
        " [ 0.79012346  0.20987654]\n",
        " [ 0.6033125   0.3966875 ]\n",
        " [ 0.3966875   0.6033125 ]\n",
        " [ 0.20987654  0.79012346]\n",
        " [ 0.07641112  0.92358888]\n",
        " [ 0.01153279  0.98846721]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.01153279  0.98846721]\n",
        " [ 0.07641112  0.92358888]\n",
        " [ 0.20987654  0.79012346]\n",
        " [ 0.3966875   0.6033125 ]\n",
        " [ 0.6033125   0.3966875 ]\n",
        " [ 0.79012346  0.20987654]\n",
        " [ 0.92358888  0.07641112]\n",
        " [ 0.98846721  0.01153279]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]]\n",
        "[   0    2    3    4    5    6    7    8    9   10   11   12   13   14   15\n",
        "   16   17  262  263  264  265  266  267  268  269  270  271  272  273  274\n",
        "  275  276  277  278  279  280  281  282  283 3254 3255 3256 3257 3258 3259\n",
        " 3260 3261 3262 3263 3264 3265 3266 3267 3268 3269 3270 3271 3272 3273 3274\n",
        " 3275 3276 3277 3278 3279 3280 3281 3282 3283 3284 3285 3286 3287 3288 3289\n",
        " 3290 3291 3292 3293 3294 3295 3296 3297 3298 3299 3300 3301 3302 3303 3304\n",
        " 3305 3306 3307 3308 3309 3310 3311 3312 3313 3314 3315 3316 3317 3318 3319\n",
        " 3320 3321 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036\n",
        " 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051\n",
        " 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066\n",
        " 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081\n",
        " 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096\n",
        " 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111\n",
        " 2112 2113 2114 2115 2116 2117]\n",
        "[   -2    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1  -245    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1 -2971    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1  1297    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1]\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(window.semanticLoopingTab.unaries[:, 1:])\n",
      "print np.min(window.semanticLoopingTab.unaries[:, 1:]), np.max(window.semanticLoopingTab.unaries[:, 1:])\n",
      "print window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_DESIRED_SEMANTICS]\n",
      "print window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES]\n",
      "print (window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES][:-1]-\n",
      "       window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES][1:])\n",
      "print\n",
      "print window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_DESIRED_SEMANTICS]\n",
      "print window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_SEQUENCE_FRAMES]\n",
      "print (window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_SEQUENCE_FRAMES][:-1]-\n",
      "       window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_SEQUENCE_FRAMES][1:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6.44433097168 8.44433097168\n",
        "[[ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 0.98846721  0.01153279]\n",
        " [ 0.92358888  0.07641112]\n",
        " [ 0.79012346  0.20987654]\n",
        " [ 0.6033125   0.3966875 ]\n",
        " [ 0.3966875   0.6033125 ]\n",
        " [ 0.20987654  0.79012346]\n",
        " [ 0.07641112  0.92358888]\n",
        " [ 0.01153279  0.98846721]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.01153279  0.98846721]\n",
        " [ 0.07641112  0.92358888]\n",
        " [ 0.20987654  0.79012346]\n",
        " [ 0.3966875   0.6033125 ]\n",
        " [ 0.6033125   0.3966875 ]\n",
        " [ 0.79012346  0.20987654]\n",
        " [ 0.92358888  0.07641112]\n",
        " [ 0.98846721  0.01153279]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 0.98846721  0.01153279]\n",
        " [ 0.92358888  0.07641112]\n",
        " [ 0.79012346  0.20987654]\n",
        " [ 0.6033125   0.3966875 ]\n",
        " [ 0.3966875   0.6033125 ]\n",
        " [ 0.20987654  0.79012346]\n",
        " [ 0.07641112  0.92358888]\n",
        " [ 0.01153279  0.98846721]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.01153279  0.98846721]\n",
        " [ 0.07641112  0.92358888]\n",
        " [ 0.20987654  0.79012346]\n",
        " [ 0.3966875   0.6033125 ]\n",
        " [ 0.6033125   0.3966875 ]\n",
        " [ 0.79012346  0.20987654]\n",
        " [ 0.92358888  0.07641112]\n",
        " [ 0.98846721  0.01153279]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 1.          0.        ]]\n",
        "[   0    2    3    4    5    6    7    8    9   10   11   12   13   14   15\n",
        "   16   17  262  263  264  265  266  267  268  269  270  271  272  273  274\n",
        "  275  276  277  278  279  280  281  282  283 3254 3255 3256 3257 3258 3259\n",
        " 3260 3261 3262 3263 3264 3265 3266 3267 3268 3269 3270 3271 3272 3273 3274\n",
        " 3275 3276 3277 3278 3279 3280 3281 3282 3283 3284 3285 3286 3287 3288 3289\n",
        " 3290 3291 3292 3293 3294 3295 3296 3297 3298 3299 3300 3301 3302 3303 3304\n",
        " 3305 3306 3307 3308 3309 3310 3311 3312 3313 3314 3315 3316 3317 3318 3319\n",
        " 3320 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970\n",
        " 1971 1972 1973 1974 1975 1976 1977 2043 2044 2045 2046 2047 2048 2049 2050\n",
        " 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065\n",
        " 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080\n",
        " 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095\n",
        " 2096 2097 2098 2099 2100 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376\n",
        " 2377 2378 2379 2380 2381 2382]\n",
        "[   -2    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1  -245    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1 -2971    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1  1363    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1   -66    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1  -267    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1]\n",
        "\n",
        "[[ 1.          0.        ]\n",
        " [ 0.98846721  0.01153279]\n",
        " [ 0.92358888  0.07641112]\n",
        " [ 0.79012346  0.20987654]\n",
        " [ 0.6033125   0.3966875 ]\n",
        " [ 0.3966875   0.6033125 ]\n",
        " [ 0.20987654  0.79012346]\n",
        " [ 0.07641112  0.92358888]\n",
        " [ 0.01153279  0.98846721]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]]\n",
        "[   0    2    3    4    5    6    7    8    9   10   11   12   13   14   15\n",
        "   16   17   18   19   20   21   22   23   24   25   26   27   28   29   50\n",
        "  316 2445 2446 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517\n",
        " 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532\n",
        " 1533 1534 1535 1536 1537 1538 1539 2485 2486 1543 2491 2492 2493 2494 2495\n",
        " 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510\n",
        " 2511 2512 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523 2524 2525\n",
        " 2526 2527 2528 2529 2530 2531 2532 2533 2534 2535 2536 2537 2538 2539 2540\n",
        " 2541 2542 2543 2544 2545 2546 2547 2548 2549 2550 2551 2552 2553 2554 2555\n",
        " 2556 2557 2558 2559 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570\n",
        " 2571 2572 2573 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585\n",
        " 2586 2587 2588 2589 2590 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638\n",
        " 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653\n",
        " 1654 1655 1656 1657 1658 1659]\n",
        "[   -2    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1   -21  -266 -2129    -1   940    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1  -946    -1   943  -948    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1   961    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1]\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(window.semanticLoopingTab.unaries[:, 1:])\n",
      "print np.min(window.semanticLoopingTab.unaries[:, 1:]), np.max(window.semanticLoopingTab.unaries[:, 1:])\n",
      "print window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_DESIRED_SEMANTICS].T\n",
      "print window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES]\n",
      "print (window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES][:-1]-\n",
      "       window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES][1:])\n",
      "print\n",
      "print window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_DESIRED_SEMANTICS].T\n",
      "print window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_SEQUENCE_FRAMES]\n",
      "print (window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_SEQUENCE_FRAMES][:-1]-\n",
      "       window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_SEQUENCE_FRAMES][1:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7.95087140588 8.15087140588\n",
        "[[ 1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          0.98846721  0.92358888  0.79012346  0.6033125   0.3966875\n",
        "   0.20987654  0.07641112  0.01153279  0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.01153279\n",
        "   0.07641112  0.20987654  0.3966875   0.6033125   0.79012346  0.92358888\n",
        "   0.98846721  1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          0.98846721\n",
        "   0.92358888  0.79012346  0.6033125   0.3966875   0.20987654  0.07641112\n",
        "   0.01153279  0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.01153279  0.07641112  0.20987654  0.3966875   0.6033125\n",
        "   0.79012346  0.92358888  0.98846721  1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.        ]\n",
        " [ 0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.01153279  0.07641112  0.20987654  0.3966875   0.6033125\n",
        "   0.79012346  0.92358888  0.98846721  1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          0.98846721\n",
        "   0.92358888  0.79012346  0.6033125   0.3966875   0.20987654  0.07641112\n",
        "   0.01153279  0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.01153279\n",
        "   0.07641112  0.20987654  0.3966875   0.6033125   0.79012346  0.92358888\n",
        "   0.98846721  1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          0.98846721  0.92358888  0.79012346  0.6033125   0.3966875\n",
        "   0.20987654  0.07641112  0.01153279  0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.        ]]\n",
        "[   0    2    3    4    5    6    7    8    9   10   11   12   13   14   15\n",
        "   16   17  262  263  264  265  266  267  268  269  270  271  272  273  274\n",
        "  275  276  277  278  279  280  281  282  283 3254 3255 3256 3257 3258 3259\n",
        " 3260 3261 3262 3263 3264 3265 3266 3267 3268 3269 3270 3271 3272 3273 3274\n",
        " 3275 3276 3277 3278 3279 3280 3281 3282 3283 3284 3285 3286 3287 3288 3289\n",
        " 3290 3291 3292 3293 3294 3295 3296 3297 3298 3299 3300 3301 3302 3303 3304\n",
        " 3305 3306 3307 3308 3309 3310 3311 3312 3313 3314 3315 3316 3317 3318 3319\n",
        " 3320 3321 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036\n",
        " 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051\n",
        " 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066\n",
        " 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081\n",
        " 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096\n",
        " 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111\n",
        " 2112 2113 2114 2115 2116 2117]\n",
        "[   -2    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1  -245    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1 -2971    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1  1297    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1]\n",
        "\n",
        "[[ 1.          0.98846721  0.92358888  0.79012346  0.6033125   0.3966875\n",
        "   0.20987654  0.07641112  0.01153279  0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.        ]\n",
        " [ 0.          0.01153279  0.07641112  0.20987654  0.3966875   0.6033125\n",
        "   0.79012346  0.92358888  0.98846721  1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.          1.\n",
        "   1.          1.          1.          1.          1.          1.        ]]\n",
        "[   0    2    3    4    5    6    7    8    9   10   11   12   13   14   15\n",
        "   16   17   18   19   20   21   22   23   24   25   26   27   28   29   50\n",
        "  316 2445 2446 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517\n",
        " 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532\n",
        " 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547\n",
        " 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562\n",
        " 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577\n",
        " 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592\n",
        " 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607\n",
        " 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622\n",
        " 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637\n",
        " 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652\n",
        " 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667\n",
        " 1668 1669 1670 1671 1672 1673]\n",
        "[   -2    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1   -21  -266 -2129    -1   940    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1]\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print window.semanticLoopingTab.unaries[arange(3315, 3408), arange(3408-3315)]\n",
      "# otherFrames = arange(3315, 3408)\n",
      "gwv.showCustomGraph(np.load(window.semanticLoopingTab.semanticSequences[instanceIdx][DICT_TRANSITION_COSTS_LOCATION]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  1.00000000e+07   9.67145646e+00   9.58432871e+00   9.49300952e+00\n",
        "   9.38348337e+00   9.27821310e+00   9.16279270e+00   9.11100376e+00\n",
        "   9.07478076e+00   9.04722304e+00   8.63795695e+00   8.31535285e+00\n",
        "   8.14170394e+00   8.08468759e+00   8.07913883e+00   8.07911979e+00\n",
        "   8.07911355e+00   8.07911121e+00   8.07911012e+00   8.07910950e+00\n",
        "   8.07910915e+00   8.07910899e+00   8.07910892e+00   8.07910889e+00\n",
        "   8.07910889e+00   8.07910888e+00   8.07910888e+00   8.07910888e+00\n",
        "   8.07910888e+00   8.07910889e+00   8.07910889e+00   8.07910889e+00\n",
        "   8.07910888e+00   8.07910887e+00   8.07910884e+00   8.07910877e+00\n",
        "   8.07910864e+00   8.07910841e+00   8.07910807e+00   8.07910774e+00\n",
        "   8.07910745e+00   8.07910729e+00   8.07910719e+00   8.07910717e+00\n",
        "   8.07910722e+00   8.07910735e+00   8.07910754e+00   8.07910779e+00\n",
        "   8.07910811e+00   8.07910865e+00   8.07910958e+00   8.07911127e+00\n",
        "   8.07911478e+00   8.07912010e+00   8.07912426e+00   8.07912786e+00\n",
        "   8.07912949e+00   8.07912988e+00   8.07912993e+00   8.07912971e+00\n",
        "   8.07912950e+00   8.07912928e+00   8.07912867e+00   8.07912783e+00\n",
        "   8.07996132e+00   8.08524926e+00   8.10019191e+00   8.13350056e+00\n",
        "   8.19778404e+00   8.29743250e+00   8.40485133e+00   8.47097931e+00\n",
        "   8.48382737e+00   8.48433487e+00   8.48467114e+00   8.48486970e+00\n",
        "   8.48698487e+00   8.48874915e+00   8.48883082e+00   8.48887894e+00\n",
        "   8.48890467e+00   8.48890509e+00   8.48890527e+00   8.48890533e+00\n",
        "   8.48890537e+00   8.48890539e+00   8.48890591e+00   8.48890663e+00\n",
        "   8.48890732e+00   8.48890781e+00   8.48890806e+00   8.48890806e+00\n",
        "   8.48890806e+00]\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gwv.showCustomGraph(window.semanticLoopingTab.unaries)\n",
      "print np.min(window.semanticLoopingTab.unaries[:, 1:]), np.max(window.semanticLoopingTab.unaries[:, 1:])\n",
      "instanceIdx = 0\n",
      "chosenFrames = window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_FRAMES][0:]\n",
      "otherFrames = arange(3315)\n",
      "print \"chosen frames\", chosenFrames\n",
      "print \"chosen frames unary\", np.sum(window.semanticLoopingTab.unaries[chosenFrames, arange(101)])\n",
      "print \"chosen frames cost\", np.sum(np.load(window.semanticLoopingTab.semanticSequences[instanceIdx][DICT_TRANSITION_COSTS_LOCATION])[chosenFrames[1:-1],\n",
      "                                                                                                                                     chosenFrames[2:]])\n",
      "print \"other cost\", np.sum(np.load(window.semanticLoopingTab.semanticSequences[instanceIdx][DICT_TRANSITION_COSTS_LOCATION])[arange(2, 101), arange(3, 102)])\n",
      "# print np.load(window.semanticLoopingTab.semanticSequences[instanceIdx][DICT_TRANSITION_COSTS_LOCATION])[3321, 2024]\n",
      "print \"chosen frames all costs\", np.load(window.semanticLoopingTab.semanticSequences[instanceIdx][DICT_TRANSITION_COSTS_LOCATION])[chosenFrames[1:-1],\n",
      "                                                                                                        chosenFrames[2:]]\n",
      "print \"other all costs\", np.load(window.semanticLoopingTab.semanticSequences[instanceIdx][DICT_TRANSITION_COSTS_LOCATION])[arange(2, 101), arange(3, 102)]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6.49355278934 10.0791016794\n",
        "chosen frames [   0 3391 3390 3389 3388 3387 3386 3385 3384 3383 3382 3381 3380 3379 3378\n",
        " 3377 3376 3375 3374 3373 3372 3371 3370 3369 3368 3367 3366 3365 3364 3363\n",
        " 3362 3361 3360 3359 3358 3357 3356 3355 3354 3353 3352 3351 3350 3349 3348\n",
        " 3347 3346 3345 3344 3343 3342 3341 3340 3339 3338 3337 3336 3335 3334 3333\n",
        " 3332 3331 3330 3329 3328 3327 3326 3325 3324 3323 3322 3321 3320 3319 3318\n",
        " 3317 3316 3315 3314 3313 3312 3311 3310 3309 3308 3307 3306 3305 3304 3303\n",
        " 3302 3301 3300 3299 3298 3297 3296 3295 3294 3293 3292]\n",
        "chosen frames unary 757.788556446\n",
        "chosen frames cost 990000000.0\n",
        "other cost 4.69064833152e-08\n",
        "chosen frames all costs [ 10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.  10000000.  10000000.  10000000.\n",
        "  10000000.  10000000.  10000000.]\n",
        "other all costs "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  4.69064833e-08   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(window.semanticLoopingTab.unaries)\n",
      "print window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_SEQUENCE_FRAMES]\n",
      "print np.sum(np.load(window.semanticLoopingTab.semanticSequences[1][DICT_TRANSITION_COSTS_LOCATION])[window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_SEQUENCE_FRAMES][1:-1],\n",
      "                                                                                                     window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_SEQUENCE_FRAMES][2:]])\n",
      "print np.sum(np.load(window.semanticLoopingTab.semanticSequences[1][DICT_TRANSITION_COSTS_LOCATION])[arange(2, 101), arange(3, 102)])\n",
      "\n",
      "print np.load(window.semanticLoopingTab.semanticSequences[1][DICT_TRANSITION_COSTS_LOCATION])[window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_SEQUENCE_FRAMES][1:-1],\n",
      "                                                                                              window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_SEQUENCE_FRAMES][2:]]\n",
      "print np.load(window.semanticLoopingTab.semanticSequences[1][DICT_TRANSITION_COSTS_LOCATION])[arange(2, 101), arange(3, 102)]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  0   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
        "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
        "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
        "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
        "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
        "  91  92  93  94  95  96  97  98  99 100 101]\n",
        "0.00022055909279\n",
        "0.00022055909279\n",
        "[  6.39652072e-07   9.60025511e-07   1.30973951e-06   1.57946213e-06\n",
        "   1.74252314e-06   1.87529758e-06   1.99637240e-06   2.10125297e-06\n",
        "   2.18850150e-06   2.23567305e-06   2.26554763e-06   2.27001676e-06\n",
        "   2.27060781e-06   2.27610618e-06   2.27335279e-06   2.27745045e-06\n",
        "   2.29162067e-06   2.29165759e-06   2.28484377e-06   2.28564009e-06\n",
        "   2.27895583e-06   2.27827965e-06   2.27809504e-06   2.28576718e-06\n",
        "   2.28268526e-06   2.28780759e-06   2.27735560e-06   2.27314468e-06\n",
        "   2.27569196e-06   2.28212899e-06   2.27849436e-06   2.29445480e-06\n",
        "   2.29653732e-06   2.29133686e-06   2.29737649e-06   2.29980884e-06\n",
        "   2.29597989e-06   2.29879095e-06   2.29890104e-06   2.28976526e-06\n",
        "   2.28934555e-06   2.28513525e-06   2.28236129e-06   2.27667529e-06\n",
        "   2.27359513e-06   2.27163750e-06   2.27272122e-06   2.26899596e-06\n",
        "   2.27286206e-06   2.27317846e-06   2.28059894e-06   2.28285003e-06\n",
        "   2.29197812e-06   2.29221752e-06   2.30684630e-06   2.30871896e-06\n",
        "   2.31340533e-06   2.31149492e-06   2.31861921e-06   2.30725320e-06\n",
        "   2.29592036e-06   2.29490719e-06   2.30291790e-06   2.29431843e-06\n",
        "   2.29634582e-06   2.29610634e-06   2.29688451e-06   2.30075777e-06\n",
        "   2.30374009e-06   2.30346415e-06   2.30728086e-06   2.29874008e-06\n",
        "   2.28876651e-06   2.29245821e-06   2.29024471e-06   2.28780789e-06\n",
        "   2.28817615e-06   2.29122728e-06   2.28817736e-06   2.29522318e-06\n",
        "   2.29908312e-06   2.30071829e-06   2.29560946e-06   2.29783953e-06\n",
        "   2.29442191e-06   2.29756276e-06   2.30054246e-06   2.30371699e-06\n",
        "   2.29861945e-06   2.30561030e-06   2.30108287e-06   2.30252011e-06\n",
        "   2.30498219e-06   2.30536925e-06   2.30119476e-06   2.30176084e-06\n",
        "   2.30435115e-06   2.29592554e-06   2.29752557e-06]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[  6.39652072e-07   9.60025511e-07   1.30973951e-06   1.57946213e-06\n",
        "   1.74252314e-06   1.87529758e-06   1.99637240e-06   2.10125297e-06\n",
        "   2.18850150e-06   2.23567305e-06   2.26554763e-06   2.27001676e-06\n",
        "   2.27060781e-06   2.27610618e-06   2.27335279e-06   2.27745045e-06\n",
        "   2.29162067e-06   2.29165759e-06   2.28484377e-06   2.28564009e-06\n",
        "   2.27895583e-06   2.27827965e-06   2.27809504e-06   2.28576718e-06\n",
        "   2.28268526e-06   2.28780759e-06   2.27735560e-06   2.27314468e-06\n",
        "   2.27569196e-06   2.28212899e-06   2.27849436e-06   2.29445480e-06\n",
        "   2.29653732e-06   2.29133686e-06   2.29737649e-06   2.29980884e-06\n",
        "   2.29597989e-06   2.29879095e-06   2.29890104e-06   2.28976526e-06\n",
        "   2.28934555e-06   2.28513525e-06   2.28236129e-06   2.27667529e-06\n",
        "   2.27359513e-06   2.27163750e-06   2.27272122e-06   2.26899596e-06\n",
        "   2.27286206e-06   2.27317846e-06   2.28059894e-06   2.28285003e-06\n",
        "   2.29197812e-06   2.29221752e-06   2.30684630e-06   2.30871896e-06\n",
        "   2.31340533e-06   2.31149492e-06   2.31861921e-06   2.30725320e-06\n",
        "   2.29592036e-06   2.29490719e-06   2.30291790e-06   2.29431843e-06\n",
        "   2.29634582e-06   2.29610634e-06   2.29688451e-06   2.30075777e-06\n",
        "   2.30374009e-06   2.30346415e-06   2.30728086e-06   2.29874008e-06\n",
        "   2.28876651e-06   2.29245821e-06   2.29024471e-06   2.28780789e-06\n",
        "   2.28817615e-06   2.29122728e-06   2.28817736e-06   2.29522318e-06\n",
        "   2.29908312e-06   2.30071829e-06   2.29560946e-06   2.29783953e-06\n",
        "   2.29442191e-06   2.29756276e-06   2.30054246e-06   2.30371699e-06\n",
        "   2.29861945e-06   2.30561030e-06   2.30108287e-06   2.30252011e-06\n",
        "   2.30498219e-06   2.30536925e-06   2.30119476e-06   2.30176084e-06\n",
        "   2.30435115e-06   2.29592554e-06   2.29752557e-06]\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_SEQUENCE_FRAMES]\n",
      "print window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_DESIRED_SEMANTICS]\n",
      "chosenFrames = window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][1][DICT_SEQUENCE_FRAMES]\n",
      "print window.semanticLoopingTab.semanticSequences[1][DICT_FRAME_SEMANTICS][chosenFrames, :]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[   0    2    3    4    5    6    7    8    9   10   11   12   13   14   15\n",
        "   16   17   18   19   20   21   22   23   24   25   26   27   28   29   50\n",
        "  316 2445 2446 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517\n",
        " 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532\n",
        " 1533 1534 1535 1536 1537 1538 1539 2485 1542 2488 1545 2493 2494 2495 2496\n",
        " 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 2511\n",
        " 2512 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523]\n",
        "[[ 1.          0.        ]\n",
        " [ 1.          0.        ]\n",
        " [ 0.98846721  0.01153279]\n",
        " [ 0.92358888  0.07641112]\n",
        " [ 0.79012346  0.20987654]\n",
        " [ 0.6033125   0.3966875 ]\n",
        " [ 0.3966875   0.6033125 ]\n",
        " [ 0.20987654  0.79012346]\n",
        " [ 0.07641112  0.92358888]\n",
        " [ 0.01153279  0.98846721]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]]\n",
        "[[ 0.99814627  0.00185373]\n",
        " [ 0.99814627  0.00185373]\n",
        " [ 0.9981463   0.0018537 ]\n",
        " [ 0.99814639  0.00185361]\n",
        " [ 0.99814663  0.00185337]\n",
        " [ 0.99814707  0.00185293]\n",
        " [ 0.99814784  0.00185216]\n",
        " [ 0.99814892  0.00185108]\n",
        " [ 0.99815025  0.00184975]\n",
        " [ 0.99815173  0.00184827]\n",
        " [ 0.99815334  0.00184666]\n",
        " [ 0.99815485  0.00184515]\n",
        " [ 0.99815634  0.00184366]\n",
        " [ 0.99815783  0.00184217]\n",
        " [ 0.99815919  0.00184081]\n",
        " [ 0.99816038  0.00183962]\n",
        " [ 0.99816157  0.00183843]\n",
        " [ 0.99816294  0.00183706]\n",
        " [ 0.99816491  0.00183509]\n",
        " [ 0.99816789  0.00183211]\n",
        " [ 0.99817221  0.00182779]\n",
        " [ 0.99817706  0.00182294]\n",
        " [ 0.99818194  0.00181806]\n",
        " [ 0.99818686  0.00181314]\n",
        " [ 0.99819094  0.00180906]\n",
        " [ 0.99819378  0.00180622]\n",
        " [ 0.99819609  0.00180391]\n",
        " [ 0.99819879  0.00180121]\n",
        " [ 0.99820231  0.00179769]\n",
        " [ 0.99822437  0.00177563]\n",
        " [ 0.99814272  0.00185728]\n",
        " [ 0.99800201  0.00199799]\n",
        " [ 0.99795671  0.00204329]\n",
        " [ 0.99769762  0.00230238]\n",
        " [ 0.99763161  0.00236839]\n",
        " [ 0.9975445   0.0024555 ]\n",
        " [ 0.99743422  0.00256578]\n",
        " [ 0.99728842  0.00271158]\n",
        " [ 0.99711307  0.00288693]\n",
        " [ 0.99688327  0.00311673]\n",
        " [ 0.99660659  0.00339341]\n",
        " [ 0.99624244  0.00375756]\n",
        " [ 0.99573788  0.00426212]\n",
        " [ 0.99510957  0.00489043]\n",
        " [ 0.99433522  0.00566478]\n",
        " [ 0.99339488  0.00660512]\n",
        " [ 0.99227447  0.00772553]\n",
        " [ 0.99094477  0.00905523]\n",
        " [ 0.98930157  0.01069843]\n",
        " [ 0.9872708   0.0127292 ]\n",
        " [ 0.98477845  0.01522155]\n",
        " [ 0.98144627  0.01855373]\n",
        " [ 0.97678732  0.02321268]\n",
        " [ 0.97014232  0.02985768]\n",
        " [ 0.96113311  0.03886689]\n",
        " [ 0.94657838  0.05342162]\n",
        " [ 0.92574561  0.07425439]\n",
        " [ 0.89813119  0.10186881]\n",
        " [ 0.86463886  0.13536114]\n",
        " [ 0.82760244  0.17239756]\n",
        " [ 0.79344368  0.20655632]\n",
        " [ 0.76319273  0.23680727]\n",
        " [ 0.73829699  0.26170301]\n",
        " [ 0.71638621  0.28361379]\n",
        " [ 0.69854872  0.30145128]\n",
        " [ 0.68482535  0.31517465]\n",
        " [ 0.67160581  0.32839419]\n",
        " [ 0.63411323  0.36588677]\n",
        " [ 0.62280686  0.37719314]\n",
        " [ 0.59180692  0.40819308]\n",
        " [ 0.56853992  0.43146008]\n",
        " [ 0.52356224  0.47643776]\n",
        " [ 0.50994163  0.49005837]\n",
        " [ 0.49300282  0.50699718]\n",
        " [ 0.47143859  0.52856141]\n",
        " [ 0.4402849   0.5597151 ]\n",
        " [ 0.40218017  0.59781983]\n",
        " [ 0.36204628  0.63795372]\n",
        " [ 0.32362202  0.67637798]\n",
        " [ 0.28801847  0.71198153]\n",
        " [ 0.25796851  0.74203149]\n",
        " [ 0.22569012  0.77430988]\n",
        " [ 0.19395838  0.80604162]\n",
        " [ 0.16330228  0.83669772]\n",
        " [ 0.13629081  0.86370919]\n",
        " [ 0.10993936  0.89006064]\n",
        " [ 0.08429307  0.91570693]\n",
        " [ 0.05823998  0.94176002]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.          1.        ]\n",
        " [ 0.13410542  0.86589458]\n",
        " [ 0.17815503  0.82184497]\n",
        " [ 0.20274964  0.79725036]\n",
        " [ 0.21889727  0.78110273]\n",
        " [ 0.23409738  0.76590262]\n",
        " [ 0.25094775  0.74905225]\n",
        " [ 0.26586607  0.73413393]]\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "window.semanticLoopingTab.loadSynthesisedSequenceAtLocation(window.semanticLoopingTab.loadedSynthesisedSequence)\n",
      "basePath = \"/\".join(window.semanticLoopingTab.loadedSynthesisedSequence.split('/')[:-1])+\"/\"\n",
      "img = QtGui.QImage(QtCore.QSize(1280, 720), QtGui.QImage.Format_ARGB32)\n",
      "img.fill(QtGui.QColor.fromRgb(255, 255, 255, 0))\n",
      "painter = QtGui.QPainter(img)\n",
      "\n",
      "# for i in xrange(len(window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][0][DICT_SEQUENCE_FRAMES])) :\n",
      "#     window.semanticLoopingTab.showFrame(i)\n",
      "    \n",
      "#     painter.drawImage(QtCore.QPoint(0, 0), window.semanticLoopingTab.frameLabel.qImage)\n",
      "#     painter.drawImage(QtCore.QPoint(0, 0), window.semanticLoopingTab.overlayImg)\n",
      "#     img.save(basePath+\"frame-{0:05d}.png\".format(i+1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "selected sequence 0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "selected instance 0\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(np.load(\"/media/ilisescu/Data1/PhD/data/wave3/transition_costs-tara3.npy\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print np.sort(np.load(\"/home/ilisescu/PhD/data/havana/semantic_sequence-blue_car1.npy\").item()[DICT_BBOXES].keys())\n",
      "# print np.sort(np.load(\"/home/ilisescu/PhD/data/havana/semantic_sequence-blue_car1.npy\").item()[DICT_FRAMES_LOCATIONS].keys())\n",
      "# print np.load(\"/home/ilisescu/PhD/data/havana/semantic_sequence-blue_car1.npy\").item()[DICT_BBOX_CENTERS][2590]\n",
      "for seqLoc in np.sort(glob.glob(\"/home/ilisescu/PhD/data/havana/semantic_sequence-*.npy\")) :\n",
      "    tmp = np.load(seqLoc).item()\n",
      "    print np.max(tmp[DICT_BBOXES].keys()), np.max(tmp[DICT_BBOX_CENTERS].keys()), np.max(tmp[DICT_BBOX_ROTATIONS].keys()), \n",
      "    print np.max(tmp[DICT_FOOTPRINTS].keys()), np.max(tmp[DICT_FRAMES_LOCATIONS].keys())\n",
      "    \n",
      "#     tmp[DICT_BBOX_CENTERS][np.max(tmp[DICT_BBOXES].keys())] = tmp[DICT_BBOX_CENTERS][np.max(tmp[DICT_BBOX_CENTERS].keys())]\n",
      "#     del tmp[DICT_BBOX_CENTERS][np.max(tmp[DICT_BBOX_CENTERS].keys())]\n",
      "    \n",
      "#     tmp[DICT_BBOX_ROTATIONS][np.max(tmp[DICT_BBOXES].keys())] = tmp[DICT_BBOX_ROTATIONS][np.max(tmp[DICT_BBOX_ROTATIONS].keys())]\n",
      "#     del tmp[DICT_BBOX_ROTATIONS][np.max(tmp[DICT_BBOX_ROTATIONS].keys())]\n",
      "    \n",
      "#     tmp[DICT_FOOTPRINTS][np.max(tmp[DICT_BBOXES].keys())] = tmp[DICT_BBOXES][np.max(tmp[DICT_BBOXES].keys())]\n",
      "    \n",
      "#     np.save(seqLoc, tmp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4237 4237 4237 4237 4236\n",
        "2589 2589 2589 2589 2588\n",
        "4696 4696 4696 4696 4695\n",
        "3182 3182 3182 3182 3181\n",
        "3389 3389 3389 3389 3388\n",
        "5105 5105 5105 5105 5104\n",
        "4650"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4650 4650 4650 4649\n",
        "2472 2472 2472 2472 2471\n",
        "2667 2667 2667 2667 2666\n",
        "1305 1305 1305 1305 1304\n",
        "3584 3584 3584 3584 3583\n",
        "988 988 988 988 987\n",
        "1008 1008 1008 1008 1007\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## code to copy semantic labels from sprite\n",
      "# seqLoc = \"/media/ilisescu/Data1/PhD/data/wave3/\"\n",
      "seqLoc = \"/media/ilisescu/Data1/PhD/data/digger/\"\n",
      "for spriteLoc in np.sort(glob.glob(seqLoc+\"sprite-*.npy\"))[0:1] :\n",
      "    sprite = np.load(spriteLoc).item()\n",
      "    seqName = sprite[DICT_SEQUENCE_NAME]\n",
      "    sequence = np.load(seqLoc+\"semantic_sequence-\"+seqName+\".npy\").item()\n",
      "#     print np.max(np.abs(sprite[DICT_FRAME_SEMANTICS]-sequence[DICT_FRAME_SEMANTICS]))\n",
      "    \n",
      "    fig1 = figure()\n",
      "    clrs = np.arange(0.0, 1.0+1.0/(len(sequence[DICT_FRAME_SEMANTICS].T)-1), 1.0/(len(sequence[DICT_FRAME_SEMANTICS].T)-1)).astype(np.string_) #['r', 'g', 'b', 'm', 'c', 'y', 'k', 'w']\n",
      "    stackplot(np.arange(len(sequence[DICT_FRAME_SEMANTICS])), np.row_stack(tuple([i for i in sequence[DICT_FRAME_SEMANTICS].T])), colors=clrs)\n",
      "    \n",
      "    fig1 = figure()\n",
      "    clrs = np.arange(0.0, 1.0+1.0/(len(sprite[DICT_FRAME_SEMANTICS].T)-1), 1.0/(len(sprite[DICT_FRAME_SEMANTICS].T)-1)).astype(np.string_) #['r', 'g', 'b', 'm', 'c', 'y', 'k', 'w']\n",
      "    stackplot(np.arange(len(sprite[DICT_FRAME_SEMANTICS])), np.row_stack(tuple([i for i in sprite[DICT_FRAME_SEMANTICS].T])), colors=clrs)\n",
      "        \n",
      "    sequence[DICT_FRAME_SEMANTICS][:len(sprite[DICT_FRAME_SEMANTICS]), :] = sprite[DICT_FRAME_SEMANTICS]\n",
      "    \n",
      "    fig1 = figure()\n",
      "    clrs = np.arange(0.0, 1.0+1.0/(len(sequence[DICT_FRAME_SEMANTICS].T)-1), 1.0/(len(sequence[DICT_FRAME_SEMANTICS].T)-1)).astype(np.string_) #['r', 'g', 'b', 'm', 'c', 'y', 'k', 'w']\n",
      "    stackplot(np.arange(len(sequence[DICT_FRAME_SEMANTICS])), np.row_stack(tuple([i for i in sequence[DICT_FRAME_SEMANTICS].T])), colors=clrs)\n",
      "#     np.save(sequence[DICT_SEQUENCE_LOCATION], sequence)\n",
      "    print \"saved\", sequence[DICT_SEQUENCE_LOCATION]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saved /media/ilisescu/Data1/PhD/data/digger/semantic_sequence-truck_right1.npy\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = np.load(\"/media/ilisescu/Data1/PhD/data/wave3/fullLength-sprites/semantic_sequence-daniel3.npy\").item()[DICT_FRAME_SEMANTICS]\n",
      "fig1 = figure()\n",
      "clrs = np.arange(0.0, 1.0+1.0/(len(tmp.T)-1), 1.0/(len(tmp.T)-1)).astype(np.string_) #['r', 'g', 'b', 'm', 'c', 'y', 'k', 'w']\n",
      "stackplot(np.arange(len(tmp)), np.row_stack(tuple([i for i in tmp.T])), colors=clrs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "[<matplotlib.collections.PolyCollection at 0x7f9325643790>,\n",
        " <matplotlib.collections.PolyCollection at 0x7f93256433d0>]"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "synthSeq = np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/wave-no_learning-L2_cost_normalized_thresholded/synthesised_sequence.npy\").item()\n",
      "instanceIdx = 1\n",
      "print synthSeq[DICT_USED_SEQUENCES][synthSeq[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_IDX]]\n",
      "semSeq = np.load(synthSeq[DICT_USED_SEQUENCES][synthSeq[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_IDX]]).item()\n",
      "transitionCosts = np.load(semSeq[DICT_TRANSITION_COSTS_LOCATION])\n",
      "chosenFrames = synthSeq[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_FRAMES][0:]\n",
      "otherFrames = arange(3315)\n",
      "print \"chosen frames\", chosenFrames\n",
      "print \"jumps\", chosenFrames[:-1] - chosenFrames[1:]\n",
      "# print \"chosen frames unary\", np.sum(window.semanticLoopingTab.unaries[chosenFrames, arange(101)])\n",
      "print \"chosen frames cost\", np.sum(transitionCosts[chosenFrames[0:-1], chosenFrames[1:]])\n",
      "# print \"other cost\", np.sum(transitionCosts[arange(2, 101), arange(3, 102)])\n",
      "# print np.load(window.semanticLoopingTab.semanticSequences[instanceIdx][DICT_TRANSITION_COSTS_LOCATION])[3321, 2024]\n",
      "print \"chosen frames all costs\", transitionCosts[chosenFrames[0:-1], chosenFrames[1:]]\n",
      "# print \"other all costs\", transitionCosts[arange(2, 101), arange(3, 102)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/media/ilisescu/Data1/PhD/data/wave3/semantic_sequence-james3.npy\n",
        "chosen frames [   0    2 2774 2871 2345 2346 2423 2387 1990 1991 1992 1993 1994 1995 1996\n",
        " 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011\n",
        " 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026\n",
        " 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041\n",
        " 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056\n",
        " 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071\n",
        " 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086\n",
        " 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101\n",
        " 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116\n",
        " 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131\n",
        " 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146\n",
        " 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161\n",
        " 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176\n",
        " 2177]\n",
        "jumps [   -2 -2772   -97   526    -1   -77    36   397    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1]\n",
        "chosen frames cost 2.56740184562\n",
        "chosen frames all costs [  0.00000000e+00   7.38258391e-01   2.88717087e-01   2.97864441e-01\n",
        "   2.00893249e-06   3.35133047e-01   4.05730538e-01   5.01323619e-01\n",
        "   1.76270934e-06   1.75649260e-06   1.75488365e-06   1.73622058e-06\n",
        "   1.74899945e-06   1.75470650e-06   1.75567537e-06   1.75191563e-06\n",
        "   1.76605705e-06   1.76492376e-06   1.76692015e-06   1.76657443e-06\n",
        "   1.76514977e-06   1.75635285e-06   1.75728036e-06   1.75806893e-06\n",
        "   1.77094291e-06   1.77143003e-06   1.79445420e-06   1.80423433e-06\n",
        "   1.81469728e-06   1.81676036e-06   1.83818469e-06   1.84941348e-06\n",
        "   1.86628508e-06   1.88868890e-06   1.90364801e-06   1.91738592e-06\n",
        "   1.92306749e-06   1.92936618e-06   1.93127396e-06   1.93368947e-06\n",
        "   1.92898396e-06   1.91566830e-06   1.90150185e-06   1.88897758e-06\n",
        "   1.87605555e-06   1.87261706e-06   1.88278319e-06   1.89141608e-06\n",
        "   1.89796693e-06   1.91193309e-06   1.93392218e-06   1.94534706e-06\n",
        "   1.96113682e-06   1.96956722e-06   1.97095501e-06   1.97119897e-06\n",
        "   1.98202934e-06   1.99002403e-06   2.00259647e-06   2.01700009e-06\n",
        "   2.01952249e-06   2.02252969e-06   2.02306906e-06   2.02216677e-06\n",
        "   2.03362895e-06   2.03853711e-06   2.04024130e-06   2.04381901e-06\n",
        "   2.04586132e-06   2.04426459e-06   2.03926554e-06   2.04788659e-06\n",
        "   2.04454837e-06   2.05420035e-06   2.06154148e-06   2.06788516e-06\n",
        "   2.06583478e-06   2.07495048e-06   2.07568145e-06   2.07687314e-06\n",
        "   2.07999352e-06   2.08096138e-06   2.07949518e-06   2.07623985e-06\n",
        "   2.06684695e-06   2.06802946e-06   2.06841012e-06   2.06102989e-06\n",
        "   2.06428522e-06   2.06641727e-06   2.06815531e-06   2.06885716e-06\n",
        "   2.07290454e-06   2.06914838e-06   2.06829096e-06   2.06474822e-06\n",
        "   2.05746758e-06   2.06238371e-06   2.06247214e-06   2.05752941e-06\n",
        "   2.05610374e-06   2.05758796e-06   2.04526087e-06   2.04325190e-06\n",
        "   2.04528385e-06   2.04406215e-06   2.04219115e-06   2.04880175e-06\n",
        "   2.04728855e-06   2.04645309e-06   2.04767480e-06   2.04803184e-06\n",
        "   2.04541239e-06   2.03788221e-06   2.03095363e-06   2.02183692e-06\n",
        "   2.02085432e-06   2.01267986e-06   2.02127876e-06   2.03056017e-06\n",
        "   2.04172473e-06   2.04392488e-06   2.05534141e-06   2.05436186e-06\n",
        "   2.04913151e-06   2.04517500e-06   2.04246773e-06   2.03895681e-06\n",
        "   2.03336123e-06   2.04072423e-06   2.04376196e-06   2.04199706e-06\n",
        "   2.03854608e-06   2.03869670e-06   2.02985705e-06   2.02783441e-06\n",
        "   2.03511394e-06   2.03871431e-06   2.04496089e-06   2.04799872e-06\n",
        "   2.04764074e-06   2.04096034e-06   2.04066152e-06   2.04083945e-06\n",
        "   2.03978931e-06   2.03916210e-06   2.04710696e-06   2.05627067e-06\n",
        "   2.05469632e-06   2.06057218e-06   2.06500178e-06   2.05965292e-06\n",
        "   2.05263583e-06   2.05633932e-06   2.05693117e-06   2.05999497e-06\n",
        "   2.06546126e-06   2.06842415e-06   2.06483969e-06   2.06778628e-06\n",
        "   2.04926359e-06   2.03798562e-06   2.03230777e-06   2.02869166e-06\n",
        "   2.02143470e-06   2.02562144e-06   2.02225828e-06   2.02324491e-06\n",
        "   2.02465333e-06   2.02312640e-06   2.02016661e-06   2.02428339e-06\n",
        "   2.01802411e-06   2.01523249e-06   2.00863985e-06   2.02531874e-06\n",
        "   2.03298603e-06   2.03972282e-06   2.04272378e-06   2.04880617e-06\n",
        "   2.03760242e-06   2.03092776e-06   2.03095759e-06   2.02647800e-06\n",
        "   2.03303250e-06   2.04181885e-06   2.05430473e-06   2.05774989e-06\n",
        "   2.05940920e-06   2.05159130e-06   2.04229104e-06   2.03214177e-06\n",
        "   2.01925229e-06   2.01632125e-06   2.01138026e-06]\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "synthSeq = np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/wave-no_learning-L2_cost_normalized_thresholded/synthesised_sequence.npy\").item()\n",
      "instanceIdx = 1\n",
      "print synthSeq[DICT_USED_SEQUENCES][synthSeq[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_IDX]]\n",
      "semSeq = np.load(synthSeq[DICT_USED_SEQUENCES][synthSeq[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_IDX]]).item()\n",
      "transitionCosts = sequenceTransitionCost#np.load(semSeq[DICT_TRANSITION_COSTS_LOCATION])\n",
      "chosenFrames = synthSeq[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_FRAMES][0:]\n",
      "otherFrames = arange(3315)\n",
      "print \"chosen frames\", chosenFrames\n",
      "print \"jumps\", chosenFrames[:-1] - chosenFrames[1:]\n",
      "# print \"chosen frames unary\", np.sum(window.semanticLoopingTab.unaries[chosenFrames, arange(101)])\n",
      "print \"chosen frames cost\", np.sum(transitionCosts[chosenFrames[0:-1], chosenFrames[1:]])\n",
      "# print \"other cost\", np.sum(transitionCosts[arange(2, 101), arange(3, 102)])\n",
      "# print np.load(window.semanticLoopingTab.semanticSequences[instanceIdx][DICT_TRANSITION_COSTS_LOCATION])[3321, 2024]\n",
      "print \"chosen frames all costs\", transitionCosts[chosenFrames[0:-1], chosenFrames[1:]]\n",
      "# print \"other all costs\", transitionCosts[arange(2, 101), arange(3, 102)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/media/ilisescu/Data1/PhD/data/wave3/semantic_sequence-james3.npy\n",
        "chosen frames [   0    2 2774 2871 2345 2346 2423 2387 1990 1991 1992 1993 1994 1995 1996\n",
        " 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011\n",
        " 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026\n",
        " 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041\n",
        " 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056\n",
        " 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071\n",
        " 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086\n",
        " 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101\n",
        " 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116\n",
        " 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131\n",
        " 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146\n",
        " 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161\n",
        " 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176\n",
        " 2177]\n",
        "jumps [   -2 -2772   -97   526    -1   -77    36   397    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1]\n",
        "chosen frames cost 954.543189109\n",
        "chosen frames all costs [ 0.          7.99489724  7.71369078  7.7400698   5.01664794  7.71822295\n",
        "  7.82291955  7.79190661  2.92287204  2.89884476  2.89090193  2.85118977\n",
        "  2.78130429  2.70357243  2.66676017  2.62280245  2.61338147  2.6240679\n",
        "  2.65124793  2.66178606  2.69421178  2.72470585  2.76590687  2.83584602\n",
        "  2.92391687  3.02626795  3.13099168  3.24959014  3.37124558  3.48722383\n",
        "  3.59852646  3.70421961  3.80213498  3.88052913  3.95167315  3.97617676\n",
        "  4.01031976  4.03757309  4.05794821  4.06061064  4.07053667  4.08781221\n",
        "  4.10006885  4.12725433  4.16666116  4.21616143  4.25543645  4.27304623\n",
        "  4.29150914  4.30685795  4.33378797  4.35931358  4.43142265  4.48106283\n",
        "  4.54432786  4.60860315  4.6652396   4.70664072  4.76255186  4.81527043\n",
        "  4.87340234  4.93993149  4.98819575  5.05011173  5.10070186  5.12658939\n",
        "  5.15037914  5.19623515  5.20631637  5.21307585  5.23651487  5.26755439\n",
        "  5.27577194  5.28634419  5.29082791  5.2832491   5.26803883  5.2358543\n",
        "  5.22167142  5.22533065  5.23479798  5.24499151  5.26558188  5.27300669\n",
        "  5.28338272  5.28121025  5.28863467  5.31667383  5.33939855  5.34203413\n",
        "  5.34365107  5.32680607  5.28217432  5.26249907  5.2635872   5.28040112\n",
        "  5.30271621  5.32659254  5.32957838  5.32763     5.3132948   5.30064178\n",
        "  5.30726064  5.31531645  5.30871919  5.30769902  5.30351992  5.29017149\n",
        "  5.27663222  5.29592083  5.29144256  5.27456869  5.26062984  5.25074705\n",
        "  5.22732917  5.21992597  5.23962233  5.25404466  5.27152969  5.27727239\n",
        "  5.29254942  5.28199698  5.2916903   5.29228399  5.29814889  5.30689802\n",
        "  5.3306923   5.32441798  5.33137728  5.33208554  5.33024916  5.3304614\n",
        "  5.31551269  5.29823627  5.30131276  5.3028712   5.2985734   5.32009187\n",
        "  5.33739069  5.35262577  5.36550037  5.37237551  5.39817279  5.41768153\n",
        "  5.4150665   5.40562171  5.40472173  5.38355153  5.36117988  5.34310942\n",
        "  5.33797132  5.33663632  5.34402232  5.35066641  5.3605267   5.35660847\n",
        "  5.34440417  5.34109217  5.34486242  5.34885127  5.37497924  5.39047799\n",
        "  5.38612201  5.36625766  5.35107271  5.33009314  5.3280012   5.32788669\n",
        "  5.33798985  5.33909171  5.32525497  5.30209888  5.30231875  5.27510511\n",
        "  5.26462519  5.28568037  5.30011257  5.30476275  5.32639578  5.34878831\n",
        "  5.33895     5.3242885   5.31312052  5.31484636  5.29934726  5.28681381\n",
        "  5.27511098  5.2441106   5.21016349  5.16134634  5.11767453  5.07311992\n",
        "  5.01703724  4.95912269  4.92093045]\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "synthSeq = np.load(\"/home/ilisescu/PhD/data/synthesisedSequences/wave-no_learning-L2_cost_normalized_thresholded/synthesised_sequence.npy\").item()\n",
      "instanceIdx = 1\n",
      "print synthSeq[DICT_USED_SEQUENCES][synthSeq[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_IDX]]\n",
      "semSeq = np.load(synthSeq[DICT_USED_SEQUENCES][synthSeq[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_IDX]]).item()\n",
      "transitionCosts = sequenceTransitionCost#np.load(semSeq[DICT_TRANSITION_COSTS_LOCATION])\n",
      "chosenFrames = window.semanticLoopingTab.synthesisedSequence[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_FRAMES]#synthSeq[DICT_SEQUENCE_INSTANCES][instanceIdx][DICT_SEQUENCE_FRAMES][0:]\n",
      "otherFrames = arange(3315)\n",
      "print \"chosen frames\", chosenFrames\n",
      "print \"jumps\", chosenFrames[:-1] - chosenFrames[1:]\n",
      "# print \"chosen frames unary\", np.sum(window.semanticLoopingTab.unaries[chosenFrames, arange(101)])\n",
      "print \"chosen frames cost\", np.sum(transitionCosts[chosenFrames[0:-1], chosenFrames[1:]])\n",
      "# print \"other cost\", np.sum(transitionCosts[arange(2, 101), arange(3, 102)])\n",
      "# print np.load(window.semanticLoopingTab.semanticSequences[instanceIdx][DICT_TRANSITION_COSTS_LOCATION])[3321, 2024]\n",
      "print \"chosen frames all costs\", transitionCosts[chosenFrames[0:-1], chosenFrames[1:]]\n",
      "# print \"other all costs\", transitionCosts[arange(2, 101), arange(3, 102)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " /media/ilisescu/Data1/PhD/data/wave3/semantic_sequence-james3.npy\n",
        "chosen frames [   0    2 2774 2871 2345 2433 2365 2010 1990 1991 1992 1993 1994 1995 1996\n",
        " 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2395 2396 2397 2398\n",
        " 2399 2400 2401 2402 2403 2404 2405 2406 2407 2408 2369 2370 2371 2372 2373\n",
        " 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388\n",
        " 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403\n",
        " 2404 2405 2406 2407 1662 1663 1664 1665 1666 1667 1668 1669 1670 2396 2397\n",
        " 2398 2399 2400 2401 2402 2403 2404 2405 2406 2407 2408]\n",
        "jumps [   -2 -2772   -97   526   -88    68   355    20    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1  -388    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    39    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1    -1    -1   745    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1  -726    -1    -1    -1    -1    -1    -1    -1    -1\n",
        "    -1    -1    -1    -1]\n",
        "chosen frames cost 362.973124446\n",
        "chosen frames all costs [ 0.          7.99489724  7.71369078  7.7400698   7.69909913  7.77152527\n",
        "  7.8255858   7.12369469  2.92287204  2.89884476  2.89090193  2.85118977\n",
        "  2.78130429  2.70357243  2.66676017  2.62280245  2.61338147  2.6240679\n",
        "  2.65124793  2.66178606  2.69421178  2.72470585  2.76590687  2.83584602\n",
        "  2.92391687  7.18693517  3.41074926  3.31326143  3.23722637  3.18372761\n",
        "  3.14567926  3.12103638  3.10585205  3.09517389  3.08891196  3.11498828\n",
        "  3.165894    3.27529265  3.39729255  7.36313924  3.51766306  3.41765123\n",
        "  3.32570147  3.29183805  3.27462984  3.24302748  3.22529605  3.25485358\n",
        "  3.24780099  3.2908367   3.35013122  3.427863    3.47868711  3.55791838\n",
        "  3.58689313  3.61911185  3.64893674  3.68402034  3.67797604  3.69998629\n",
        "  3.70674034  3.70486543  3.68408141  3.66552727  3.60320664  3.51535426\n",
        "  3.41074926  3.31326143  3.23722637  3.18372761  3.14567926  3.12103638\n",
        "  3.10585205  3.09517389  3.08891196  3.11498828  3.165894    3.27529265\n",
        "  6.57931129  3.3537282   3.25906083  3.17472724  3.12974529  3.10404166\n",
        "  3.11940368  3.17983077  3.26593387  6.69757276  3.31326143  3.23722637\n",
        "  3.18372761  3.14567926  3.12103638  3.10585205  3.09517389  3.08891196\n",
        "  3.11498828  3.165894    3.27529265  3.39729255]\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## this turns distance matrix into transition costs and updates the sequence dict\n",
      "distMatName = \"vanilla_distMat\"\n",
      "# distMatName = \"learned_distMat\"\n",
      "transCostName = \"transition_costs\"\n",
      "# transCostName = \"learned_transition_costs\"\n",
      "dataset = \"wave3\"#\"toy\"\n",
      "for s in np.sort(glob.glob(\"/media/ilisescu/Data1/PhD/data/\"+dataset+\"/semantic_sequence*.npy\"))[0:1]:\n",
      "    sequence = np.load(s).item()\n",
      "    seqLoc = \"/media/ilisescu/Data1/PhD/data/\"+dataset+\"/\"\n",
      "    seqName = sequence[DICT_SEQUENCE_NAME]\n",
      "    print sequence[DICT_TRANSITION_COSTS_LOCATION]\n",
      "    distMat = np.load(seqLoc+seqName+\"-\"+distMatName+\".npy\")\n",
      "    \n",
      "    ## filter ##\n",
      "    filterSize = 4\n",
      "    optimizedDistMat = vtu.filterDistanceMatrix(distMat/np.max(distMat), filterSize, True)\n",
      "    ## if using vanilla\n",
      "    if True :\n",
      "        optimizedDistMat = optimizedDistMat[1:optimizedDistMat.shape[1], 0:-1]\n",
      "        correction = 1\n",
      "    else :\n",
      "        correction = 0\n",
      "\n",
      "#     #### this is just normalizing to [0, 1] A ####\n",
      "#     optimizedDistMat = optimizedDistMat/np.max(optimizedDistMat)\n",
      "#     ########\n",
      "\n",
      "    ## don't want to jump too close so increase costs in a window\n",
      "    minJumpLength = 20\n",
      "    tmp = (np.triu(np.ones(optimizedDistMat.shape), k=minJumpLength) +\n",
      "           np.tril(np.ones(optimizedDistMat.shape), k=-minJumpLength) +\n",
      "           np.eye(optimizedDistMat.shape[0], k=1))\n",
      "    tmp[tmp == 0] = 10.0\n",
      "    optimizedDistMat *= tmp\n",
      "    \n",
      "    \n",
      "#     #### this is just normalizing to [0, 1] B ####\n",
      "#     sequenceTransitionCost = optimizedDistMat\n",
      "#     ########\n",
      "    \n",
      "    #### this turns to a probability and then does the same as the unaries ####\n",
      "    sequenceTransitionCost = vtu.dist2prob(optimizedDistMat, 0.1, True)\n",
      "    \n",
      "    impossibleTransitions = sequenceTransitionCost <= 0.0\n",
      "    ## cost is -log(prob)\n",
      "    sequenceTransitionCost[np.negative(impossibleTransitions)] = -np.log(sequenceTransitionCost[np.negative(impossibleTransitions)])\n",
      "    ## if prob == 0.0 then set maxCost\n",
      "    sequenceTransitionCost[impossibleTransitions] = GRAPH_MAX_COST\n",
      "    ########\n",
      "    \n",
      "    ## do the thresholding based on how many jumps I want to keep per frame\n",
      "    desiredPercentage = 0.1 ## desired percentage of transitions to keep\n",
      "    jumpsToKeep = int(sequenceTransitionCost.shape[0]*desiredPercentage)\n",
      "    sequenceTransitionCost[np.arange(sequenceTransitionCost.shape[0]).repeat(sequenceTransitionCost.shape[0]-jumpsToKeep),\n",
      "                           np.argsort(sequenceTransitionCost, axis=-1)[:, jumpsToKeep:].flatten()] = GRAPH_MAX_COST\n",
      "\n",
      "\n",
      "    ## adding extra rows and columns so that the optimized matrix has the same dimensions as distMat\n",
      "    ## for the indices that were cut out I put zero cost for jumps to frames that can still be used after optimization\n",
      "    sequenceTransitionCost = np.concatenate((np.ones((sequenceTransitionCost.shape[0], filterSize))*np.max(sequenceTransitionCost),\n",
      "                                             sequenceTransitionCost,\n",
      "                                             np.ones((sequenceTransitionCost.shape[0], filterSize+correction))*np.max(sequenceTransitionCost)), axis=1)\n",
      "    sequenceTransitionCost = np.concatenate((np.roll(np.concatenate((np.zeros((filterSize, 1)),\n",
      "                                                                     np.ones((filterSize, distMat.shape[0]-1))*np.max(sequenceTransitionCost)), axis=1), filterSize, axis=1),\n",
      "                                             sequenceTransitionCost,\n",
      "                                             np.roll(np.concatenate((np.zeros((filterSize+correction, 1)),\n",
      "                                                                     np.ones((filterSize+correction, distMat.shape[0]-1))*np.max(sequenceTransitionCost)), axis=1), filterSize, axis=1)), axis=0)\n",
      "\n",
      "    #### this finds a threshold based on how many transitions are kept ####\n",
      "#     maxCost = GRAPH_MAX_COST\n",
      "#     desiredPercentage = 0.1 ## desired percentage of transitions to keep\n",
      "#     ## finding best threshold\n",
      "# #     step = 0.025\n",
      "# #     steps = arange(step, 1.0+step, step)\n",
      "# #     percentages = np.array([np.argwhere(sequenceTransitionCost <= t).shape[0]/float(np.prod(sequenceTransitionCost.shape)) for t in steps])\n",
      "# #     diffs = np.abs(percentages-desiredPercentage)\n",
      "# #     thresh = steps[np.max(np.argwhere(diffs == np.min(diffs)))]\n",
      "#     bestT = 0.0\n",
      "#     bestDiff = 1.0\n",
      "#     t = 0.5\n",
      "#     for i in xrange(50) :\n",
      "#         p = np.argwhere(sequenceTransitionCost <= t).shape[0]/float(np.prod(sequenceTransitionCost.shape))\n",
      "#         if np.abs(p - desiredPercentage) < desiredPercentage*0.1 :\n",
      "#             bestT = t\n",
      "#             break\n",
      "\n",
      "#         if bestDiff > np.abs(p - desiredPercentage) :\n",
      "#             bestDiff = np.abs(p - desiredPercentage)\n",
      "#             bestT = t\n",
      "\n",
      "#         if p > desiredPercentage :\n",
      "#             t *= 0.5\n",
      "#         else :\n",
      "#             t *= 1.5\n",
      "#     thresh = bestT\n",
      "#     sequenceTransitionCost[sequenceTransitionCost > thresh] = maxCost\n",
      "    ########\n",
      "\n",
      "\n",
      "#     ## add some number to the costs to give some cost to following the timeline, which should not influence following the timeline loop-wise but should reduce the length of\n",
      "#     ## transition animations\n",
      "# #     sequenceTransitionCost += 0.1\n",
      "\n",
      "    gwv.showCustomGraph(sequenceTransitionCost)\n",
      "#     gwv.showCustomGraph(np.load(seqLoc+transCostName+\"-\"+seqName+\".npy\"))\n",
      "\n",
      "#     sequence[DICT_TRANSITION_COSTS_LOCATION] = seqLoc+transCostName+\"-\"+seqName+\".npy\"\n",
      "#     np.save(sequence[DICT_TRANSITION_COSTS_LOCATION], sequenceTransitionCost)\n",
      "#     np.save(sequence[DICT_SEQUENCE_LOCATION], sequence)\n",
      "    print sequence[DICT_TRANSITION_COSTS_LOCATION]\n",
      "# #     print sequence.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'np' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-d450e383a27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# transCostName = \"learned_transition_costs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"wave3\"\u001b[0m\u001b[0;31m#\"toy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/media/ilisescu/Data1/PhD/data/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/semantic_sequence*.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mseqLoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/media/ilisescu/Data1/PhD/data/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(np.load(\"/media/ilisescu/Data1/PhD/data/wave3/transition_costs-aron3.npy\"))\n",
      "# jumpsToKeep = int(sequenceTransitionCost.shape[0]*desiredPercentage)\n",
      "# print np.argsort(sequenceTransitionCost, axis=-1)[:, jumpsToKeep:].flatten()\n",
      "# print np.arange(sequenceTransitionCost.shape[0]).repeat(sequenceTransitionCost.shape[0]-jumpsToKeep)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for s in np.sort(glob.glob(\"/media/ilisescu/Data1/PhD/data/\"+dataset+\"/semantic_sequence*.npy\"))[0:]:\n",
      "    sequence = np.load(s).item()\n",
      "    print sequence[DICT_SEQUENCE_NAME]\n",
      "    print np.argwhere(np.load(sequence[DICT_TRANSITION_COSTS_LOCATION]) == maxCost+0.1).shape[0]/float(np.prod(sequenceTransitionCost.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "aron1\n",
        "0.902861303213"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "daniel1\n",
        "0.909265401412"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "ferran1\n",
        "0.900128189398"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "james1\n",
        "0.897215162005"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "moos1\n",
        "0.92032537655"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "peter1\n",
        "0.901268472477"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sara1\n",
        "0.909309387207"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "tara1\n",
        "0.896789005824"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## this removes frames from each sprite (so that the number of frames is divisible by 8 or 16 for computing blocked distance matrix)\n",
      "dataset = \"wave3\"\n",
      "frameLocs = np.sort(glob.glob(\"/media/ilisescu/Data1/PhD/data/\"+dataset+\"/frame-0*.png\"))\n",
      "desiredNumFrames = 3040\n",
      "print frameLocs.shape\n",
      "for s in np.sort(glob.glob(\"/media/ilisescu/Data1/PhD/data/\"+dataset+\"/sprite*.npy\"))[0:] :\n",
      "    print s\n",
      "    sprite = np.load(s).item()\n",
      "    for i in xrange(desiredNumFrames, len(frameLocs)) :\n",
      "        del sprite[DICT_BBOXES][i]\n",
      "        del sprite[DICT_BBOX_ROTATIONS][i]\n",
      "        del sprite[DICT_BBOX_CENTERS][i]\n",
      "        del sprite[DICT_FRAMES_LOCATIONS][i]\n",
      "        print \"frame-{0:05d}.png\".format(i+1)\n",
      "#         os.remove(\"/media/ilisescu/Data1/PhD/data/\"+dataset+\"/\"+sprite[DICT_SEQUENCE_NAME]+\"-maskedFlow/frame-{0:05d}.png\".format(i+1))\n",
      "#     np.save(s, sprite)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3040,)\n",
        "/media/ilisescu/Data1/PhD/data/wave3/sprite-0000-peter3.npy\n",
        "/media/ilisescu/Data1/PhD/data/wave3/sprite-0001-tara3.npy\n",
        "/media/ilisescu/Data1/PhD/data/wave3/sprite-0002-aron3.npy\n",
        "/media/ilisescu/Data1/PhD/data/wave3/sprite-0003-moos3.npy\n",
        "/media/ilisescu/Data1/PhD/data/wave3/sprite-0004-james3.npy\n",
        "/media/ilisescu/Data1/PhD/data/wave3/sprite-0005-daniel3.npy\n",
        "/media/ilisescu/Data1/PhD/data/wave3/sprite-0006-sara3.npy\n",
        "/media/ilisescu/Data1/PhD/data/wave3/sprite-0007-ferran3.npy\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# def estimateFutureCost(alpha, p, distanceMatrixFilt, weights) :\n",
      "\n",
      "#     distMatFilt = distanceMatrixFilt[1:distanceMatrixFilt.shape[1], 0:-1]\n",
      "#     distMat = distMatFilt ** p\n",
      "    \n",
      "#     last = np.copy(distMat)\n",
      "#     current = np.zeros(distMat.shape)\n",
      "    \n",
      "#     ## while distance between last and current is larger than threshold\n",
      "#     iterations = 0 \n",
      "#     while np.linalg.norm(last - current) > 0.1 : \n",
      "#         for i in range(distMat.shape[0]-1, -1, -1) :\n",
      "#             m = np.min(distMat*weights[1:distanceMatrixFilt.shape[1], 0:-1], axis=1)\n",
      "#             distMat[i, :] = (distMatFilt[i, :] ** p) + alpha*m\n",
      "            \n",
      "#         last = np.copy(current)\n",
      "#         current = np.copy(distMat)\n",
      "        \n",
      "#         sys.stdout.write('\\r' + \"Iteration \" + np.string_(iterations) + \"; distance \" + np.string_(np.linalg.norm(last - current)))\n",
      "#         sys.stdout.flush()\n",
      "#         iterations += 1\n",
      "    \n",
      "#     print\n",
      "#     print 'finished in', iterations, 'iterations'\n",
      "    \n",
      "#     return distMat\n",
      "\n",
      "# distMat = np.load(\"/media/ilisescu/Data1/PhD/data/candle_wind/vanilla_distMat.npy\")\n",
      "# seqLoc = \"/media/ilisescu/Data1/PhD/data/candle_wind/\"\n",
      "# seqName = \"candle_wind1\"\n",
      "# filterSize = 2\n",
      "# if False :\n",
      "#     optimizedDistMat = estimateFutureCost(0.999, 2.0, vtu.filterDistanceMatrix(distMat/np.max(distMat), filterSize, True),\n",
      "#                                                 np.ones(np.array(distMat.shape)-(filterSize*2)))\n",
      "# else :\n",
      "#     optimizedDistMat = vtu.filterDistanceMatrix(distMat/np.max(distMat), filterSize, True)\n",
      "#     optimizedDistMat = optimizedDistMat[1:optimizedDistMat.shape[1], 0:-1]\n",
      "\n",
      "# sequenceTransitionCost = optimizedDistMat/np.max(optimizedDistMat)\n",
      "\n",
      "# ## don't want to jump too close so increase costs in a window\n",
      "# minJumpLength = 20\n",
      "# tmp = (np.triu(np.ones(sequenceTransitionCost.shape), k=minJumpLength) +\n",
      "#        np.tril(np.ones(sequenceTransitionCost.shape), k=-minJumpLength) +\n",
      "#        np.eye(sequenceTransitionCost.shape[0], k=1))\n",
      "# tmp[tmp == 0] = 10.0\n",
      "# sequenceTransitionCost *= tmp\n",
      "\n",
      "\n",
      "# ## adding extra rows and columns so that the optimized matrix has the same dimensions as distMat\n",
      "# ## for the indices that were cut out I put zero cost for jumps to frames that can still be used after optimization\n",
      "# sequenceTransitionCost = np.concatenate((np.ones((sequenceTransitionCost.shape[0], filterSize)),\n",
      "#                                          sequenceTransitionCost,\n",
      "#                                          np.concatenate((np.zeros((1, filterSize+1)),\n",
      "#                                                          np.ones((sequenceTransitionCost.shape[0]-1, filterSize+1))), axis=0)), axis=1)\n",
      "# sequenceTransitionCost = np.concatenate((np.roll(np.concatenate((np.zeros((filterSize, 1)),\n",
      "#                                                                  np.ones((filterSize, distMat.shape[0]-1))), axis=1), filterSize, axis=1),\n",
      "#                                          sequenceTransitionCost,\n",
      "#                                          np.ones((filterSize+1, distMat.shape[0]))), axis=0)\n",
      "\n",
      "# maxCost = GRAPH_MAX_COST\n",
      "# ## threshold\n",
      "# sequenceTransitionCost[sequenceTransitionCost > 0.25] = maxCost\n",
      "# ## add some number to the costs to give some cost to following the timeline, which should not influence following the timeline loop-wise but should reduce the length of\n",
      "# ## transition animations\n",
      "# sequenceTransitionCost += 0.1\n",
      "\n",
      "# # np.save(\"tmp.npy\", sequenceTransitionCost)\n",
      "\n",
      "# # sequenceTransitionCost = np.load(\"tmp.npy\")\n",
      "# # gwv.showCustomGraph(np.log(sequenceTransitionCost.T))\n",
      "\n",
      "# sequence = np.load(seqLoc+\"semantic_sequence-\"+seqName+\".npy\").item()\n",
      "# # sequence[DICT_TRANSITION_COSTS_LOCATION] = seqLoc+\"transition_costs-\"+seqName+\".npy\"\n",
      "# np.save(sequence[DICT_TRANSITION_COSTS_LOCATION], sequenceTransitionCost)\n",
      "# # np.save(seqLoc+\"semantic_sequence-\"+seqName+\".npy\", sequence)\n",
      "# print sequence.keys()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "semanticSequence = window.semanticLoopingTab.semanticSequences[0]\n",
      "desiredSemanticIdx = 1\n",
      "## set starting frame\n",
      "desiredStartFrame = frameIdx = int(np.argwhere(semanticSequence[DICT_FRAME_SEMANTICS][:, desiredSemanticIdx] >= 0.9)[0])\n",
      "print \"starting from\", desiredStartFrame\n",
      "\n",
      "distVariance = 0.0005\n",
      "\n",
      "desiredSemantics = np.zeros((301, 3))\n",
      "desiredSemantics[:, desiredSemanticIdx] = 1.0\n",
      "\n",
      "unaries = vectorisedMinusLogMultiNormalMultipleMeans(semanticSequence[DICT_FRAME_SEMANTICS], desiredSemantics, np.eye(desiredSemantics.shape[1])*distVariance, True).T\n",
      "unaries[:, 0] = GRAPH_MAX_COST\n",
      "unaries[desiredStartFrame, 0] = 0.0\n",
      "\n",
      "numNodes = len(desiredSemantics)\n",
      "numLabels = sequenceTransitionCost.shape[0]\n",
      "gm = opengm.gm(np.ones(numNodes,dtype=opengm.label_type)*numLabels)\n",
      "\n",
      "\n",
      "fids = gm.addFunctions(unaries.T)\n",
      "# add first order factors\n",
      "gm.addFactors(fids, arange(numNodes))\n",
      "\n",
      "pairIndices = np.array([np.arange(numNodes-1), np.arange(1, numNodes)]).T\n",
      "\n",
      "## add function for row-nodes pairwise cost\n",
      "#         fid = gm.addFunction(sequenceTransitionCost+np.random.rand(sequenceTransitionCost.shape[0], sequenceTransitionCost.shape[1])*0.01-0.005)\n",
      "\n",
      "## randomize\n",
      "bestTransitions = np.argsort(sequenceTransitionCost, axis=-1)\n",
      "jumpLength = np.abs(bestTransitions-arange(sequenceTransitionCost.shape[0]).reshape((sequenceTransitionCost.shape[0], 1)))\n",
      "minJumpLength = 10\n",
      "numTop = 15\n",
      "topBest = np.array([bestTransitions[i, jumpLength[i, :] >= minJumpLength][:numTop] for i in xrange(sequenceTransitionCost.shape[0])])\n",
      "cost = np.copy(sequenceTransitionCost)\n",
      "for i in xrange(sequenceTransitionCost.shape[0]) :\n",
      "    cost[i, topBest[i, :]] += (np.random.rand(numTop)*0.1-0.05)\n",
      "    \n",
      "\n",
      "fid = gm.addFunction(cost)\n",
      "## add second order factors\n",
      "gm.addFactors(fid, pairIndices)\n",
      "inferer = opengm.inference.DynamicProgramming(gm=gm)\n",
      "inferer.infer()\n",
      "\n",
      "minCostTraversal = np.array(inferer.arg(), dtype=int)\n",
      "print minCostTraversal, gm.evaluate(inferer.arg())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting from 51\n",
        "[ 51 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694\n",
        " 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712\n",
        " 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730\n",
        " 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748\n",
        " 749 750 751 752 753 754 712 713 714 715 716 717 718 719 720 721 722 723\n",
        " 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741\n",
        " 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759\n",
        " 760 761 762 763 764 765 685 686 687 688 689 690 691 692 693 694 695 696\n",
        " 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714\n",
        " 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732\n",
        " 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750\n",
        " 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 685 686 687\n",
        " 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705\n",
        " 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723\n",
        " 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741\n",
        " 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759\n",
        " 760 761 762 763 764 765 766 767 768 769 770 771 772]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2623.97051288\n"
       ]
      }
     ],
     "prompt_number": 48
    }
   ],
   "metadata": {}
  }
 ]
}