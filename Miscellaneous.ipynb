{
 "metadata": {
  "name": "",
  "signature": "sha256:4025ebd1a3f409506508c89852e6432c371e1bb8dc80c0296a6ecc5f0d796efa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab\n",
      "\n",
      "from PIL import Image\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import scipy as sp\n",
      "import scipy.io as sio\n",
      "import cv2\n",
      "import cv\n",
      "import glob\n",
      "import time\n",
      "import gc\n",
      "import re\n",
      "\n",
      "import sys\n",
      "import os\n",
      "\n",
      "import GraphWithValues as gwv\n",
      "\n",
      "# dataFolder = \"/home/ilisescu/PhD/data/\"\n",
      "dataFolder = \"/media/ilisescu/Data1/PhD/data/\"\n",
      "dataPath = \"/media/ilisescu/Data1/PhD/data/\"\n",
      "# dataSet = \"clouds_subsample10/\"\n",
      "# dataSet = \"theme_park_cloudy/\"\n",
      "# dataSet = \"theme_park_sunny/\"\n",
      "dataSet = \"wave1/\"\n",
      "dataSet = \"wave2/\"\n",
      "dataSet = \"wave3/\"\n",
      "dataSet = \"windows/\"\n",
      "dataSet = \"digger/\"\n",
      "\n",
      "DICT_SEQUENCE_NAME = 'semantic_sequence_name'\n",
      "DICT_BBOXES = 'bboxes'\n",
      "DICT_FOOTPRINTS = 'footprints' ## same as bboxes but it indicates the footprint of the sprite on the ground plane\n",
      "DICT_BBOX_ROTATIONS = 'bbox_rotations'\n",
      "DICT_BBOX_CENTERS = 'bbox_centers'\n",
      "DICT_FRAMES_LOCATIONS = 'frame_locs'\n",
      "DICT_MASK_LOCATION = 'frame_masks_location'\n",
      "DICT_SEQUENCE_FRAMES = 'sequence_frames'\n",
      "DICT_SEQUENCE_IDX = 'semantic_sequence_idx' # index of the instantiated sem sequence in the list of all used sem sequences for a synthesised sequence\n",
      "DICT_DESIRED_SEMANTICS = 'desired_semantics' # stores what the desired semantics are for a certain sprite \n",
      "#(I could index them by the frame when the toggle happened instead of using the below but maybe ordering is important and I would lose that using a dict)\n",
      "DICT_FRAME_SEMANTIC_TOGGLE = 'frame_semantic_toggle'# stores the frame index in the generated sequence when the desired semantics have changed\n",
      "DICT_ICON_TOP_LEFT = \"icon_top_left\"\n",
      "DICT_ICON_FRAME_KEY = \"icon_frame_key\"\n",
      "DICT_ICON_SIZE = \"icon_size\"\n",
      "DICT_REPRESENTATIVE_COLOR = 'representative_color'\n",
      "DICT_OFFSET = \"instance_offset\"\n",
      "DICT_SCALE = \"instance_scale\"\n",
      "DICT_FRAME_SEMANTICS = \"semantics_per_frame\"\n",
      "DICT_USED_SEQUENCES = \"used_semantic_sequences\"\n",
      "DICT_SEQUENCE_INSTANCES = \"sequence_instances\"\n",
      "DICT_SEQUENCE_BG = \"sequence_background_image\"\n",
      "DICT_SEQUENCE_LOCATION = \"sequence_location\"\n",
      "DICT_PATCHES_LOCATION = \"sequence_preloaded_patches_location\"\n",
      "DICT_TRANSITION_COSTS_LOCATION = \"sequence_precomputed_transition_costs_location\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: TkAgg\n",
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "RENDER BBOXES"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "paths = np.sort(glob.glob(\"E:/PhD/data/digger/semantic_sequence-*.npy\"))\n",
      "semanticSequences = []\n",
      "for sequence in paths :\n",
      "    semanticSequences.append(np.load(sequence).item())\n",
      "    print semanticSequences[-1][DICT_SEQUENCE_NAME]\n",
      "\n",
      "\n",
      "\n",
      "for frameKey in np.sort(semanticSequences[0][DICT_BBOXES].keys())[0:] :\n",
      "    \n",
      "    overlayImg = QtGui.QImage(QtCore.QSize(1280, 720), QtGui.QImage.Format_ARGB32)\n",
      "    overlayImg.fill(QtGui.QColor.fromRgb(255, 255, 255, 0))\n",
      "    \n",
      "    painter = QtGui.QPainter(overlayImg)\n",
      "    painter.setRenderHints(QtGui.QPainter.HighQualityAntialiasing)\n",
      "    \n",
      "    for seqIdx in xrange(len(semanticSequences)) :\n",
      "        offset = np.array([0.0, 0.0])\n",
      "        scale = np.array([1.0, 1.0])\n",
      "        sequence = semanticSequences[seqIdx]\n",
      "        if frameKey in sequence[DICT_BBOXES].keys() :\n",
      "#         frameKey = np.sort(sequence[DICT_BBOXES].keys())[0]\n",
      "    #     frameKey = np.sort(sequence[DICT_BBOXES].keys())[450]\n",
      "    #     if seqIdx == 7 :\n",
      "    #         frameKey = np.sort(sequence[DICT_BBOXES].keys())[-70]\n",
      "    #         print sequence[DICT_BBOXES][frameKey], scale, offset    \n",
      "\n",
      "            scaleTransf = np.array([[scale[0], 0.0], [0.0, scale[1]]])\n",
      "            offsetTransf = np.array([[offset[0]], [offset[1]]])\n",
      "\n",
      "            if offset[0] == 0 and offset[1] == 0 :\n",
      "                painter.setPen(QtGui.QPen(QtGui.QColor.fromRgb(0, 0, 255, 255), 3, \n",
      "                                          QtCore.Qt.SolidLine, QtCore.Qt.RoundCap, QtCore.Qt.RoundJoin))\n",
      "            else :\n",
      "                painter.setPen(QtGui.QPen(QtGui.QColor.fromRgb(0, 0, 255, 255), 1, \n",
      "                                          QtCore.Qt.SolidLine, QtCore.Qt.RoundCap, QtCore.Qt.RoundJoin))\n",
      "\n",
      "            bbox = sequence[DICT_BBOXES][frameKey]\n",
      "            transformedBBox = (np.dot(scaleTransf, bbox.T) + offsetTransf)\n",
      "\n",
      "            x, y = transformedBBox[:, 0]\n",
      "            width, height = transformedBBox[:, 2] - transformedBBox[:, 0]\n",
      "        #     painter.drawRoundedRect(x, y, width, height, 3, 3)\n",
      "\n",
      "            for p1, p2 in zip(np.mod(arange(4), 4), np.mod(arange(1, 5), 4)) :\n",
      "                painter.drawLine(QtCore.QPointF(transformedBBox[0, p1], transformedBBox[1, p1]), QtCore.QPointF(transformedBBox[0, p2], transformedBBox[1, p2]))\n",
      "\n",
      "\n",
      "            painter.setPen(QtGui.QPen(QtGui.QColor.fromRgb(255, 255, 0, 255), 1, \n",
      "                                      QtCore.Qt.SolidLine, QtCore.Qt.RoundCap, QtCore.Qt.RoundJoin))\n",
      "        #     painter.drawText(transformedBBox[0, 0]+5, transformedBBox[1, 0], \n",
      "        #                      transformedBBox[0, 2]-transformedBBox[0, 0]-5, 20, QtCore.Qt.AlignLeft, np.string_(seqIdx))\n",
      "\n",
      "    print overlayImg.save(\"E:/PhD/data/digger/bboxes-{0:05}.png\".format(frameKey+1)),\n",
      "    painter.end()\n",
      "    del painter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "digger_right1\n",
        "truck_right1\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True True\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = Image.fromarray(np.zeros((720, 1280, 4), np.uint8))\n",
      "for sIdx in xrange(len(semanticSequences)) :\n",
      "    for frameKey in np.sort(semanticSequences[0][DICT_BBOXES].keys())[0:] :\n",
      "        if not os.path.isfile(\"E:/PhD/data/digger/\"+semanticSequences[sIdx][DICT_SEQUENCE_NAME] + \"-maskedFlow/scribble-frame-{0:05}.png\".format(frameKey+1)) :\n",
      "            tmp.save(\"E:/PhD/data/digger/\"+semanticSequences[sIdx][DICT_SEQUENCE_NAME] + \"-maskedFlow/scribble-frame-{0:05}.png\".format(frameKey+1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "overlayImg.save(\"C:/Users/ilisescu/Desktop/bboxes.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "MAKE IMAGE FROM DESIRED SEMANTICS"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "synthSeq = np.load(dataPath+\"synthesisedSequences/waveFullBusier/synthesised_sequence.npy\").item()\n",
      "bgImage = np.array(Image.open(dataPath+\"synthesisedSequences/waveFullBusier/median.png\"))[:, :, 0:3]\n",
      "usedSequences = synthSeq[DICT_USED_SEQUENCES]\n",
      "semanticSequences = []\n",
      "bboxes = [] ## first row = top left (x, y), second row = (width, height)\n",
      "for sequence in usedSequences :\n",
      "    semanticSequences.append(np.load(sequence).item())\n",
      "    print semanticSequences[-1][DICT_SEQUENCE_NAME]\n",
      "    bboxes.append(np.concatenate((np.min(np.min(np.array(semanticSequences[-1][DICT_BBOXES].values()), axis=1), axis=0),\n",
      "                                  np.max(np.max(np.array(semanticSequences[-1][DICT_BBOXES].values()), axis=1), axis=0))).reshape((2, 2)))\n",
      "    bboxes[-1][1, :] = bboxes[-1][1, :]-bboxes[-1][0, :]\n",
      "#     print bboxes[-1]\n",
      "\n",
      "\n",
      "bboxToUse = np.zeros(len(synthSeq[DICT_SEQUENCE_INSTANCES]))\n",
      "maxFrames =  327\n",
      "for frame in arange(maxFrames)[0:] :\n",
      "#     for i, instance in enumerate(synthSeq[DICT_SEQUENCE_INSTANCES]) :\n",
      "    img = np.zeros((bgImage.shape[0], bgImage.shape[1], 4), np.uint8)\n",
      "    for i, sIdx in enumerate([0, 1, 2, 3, 14, 13, 4, 5, 6, 7, 8, 9, 10, 11, 12]) :\n",
      "        instance = synthSeq[DICT_SEQUENCE_INSTANCES][sIdx]\n",
      "#         print len(instance[DICT_DESIRED_SEMANTICS])\n",
      "#         print len(instance[DICT_SEQUENCE_FRAMES])\n",
      "\n",
      "        desiredSemantics = instance[DICT_DESIRED_SEMANTICS][frame, :]\n",
      "#         print desiredSemantics\n",
      "#         print instance[DICT_OFFSET]\n",
      "        offset = instance[DICT_OFFSET]\n",
      "        scale = instance[DICT_SCALE]\n",
      "        seqIdx = instance[DICT_SEQUENCE_IDX]\n",
      "        bbox = bboxes[seqIdx]\n",
      "        x, y = bbox[0, :].astype(int)\n",
      "        w, h = bbox[1, :].astype(int)\n",
      "        \n",
      "#         if desiredSemantics[0] > 0.5 :            \n",
      "#             imgToUse = cv2.resize(sitImg, (w, h))\n",
      "#         else :\n",
      "#             imgToUse = cv2.resize(upImg, (w, h))\n",
      "        imgToUse = (cv2.resize(sitImg, (w, h))*desiredSemantics[0] + cv2.resize(upImg, (w, h))*(1.0-desiredSemantics[0])).astype(np.uint8)\n",
      "        \n",
      "        img[y:y+h, x:x+w, :] = (imgToUse[:, :, :]*(imgToUse[:, :, 3].reshape((h, w, 1))/255.0) +\n",
      "                                  img[y:y+h, x:x+w, :]*(1.0-(imgToUse[:, :, 3].reshape((h, w, 1))/255.0))).astype(np.uint8)\n",
      "    \n",
      "    img = (img[:, :, 0:3]*(img[:, :, 3].reshape((img.shape[0], img.shape[1], 1))/255.0)+\n",
      "           bgImage*(1.0-(img[:, :, 3].reshape((img.shape[0], img.shape[1], 1))/255.0))).astype(np.uint8)\n",
      "    cv2.imwrite(dataPath+\"synthesisedSequences/waveFullBusier/input-{0:05}.png\".format(frame+1), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
      "        \n",
      "#         fig1 = figure()\n",
      "#         clrs = np.arange(0.0, 1.0+1.0/(len(desiredSemantics.T)-1), 1.0/(len(desiredSemantics.T)-1)).astype(np.string_) #['r', 'g', 'b', 'm', 'c', 'y', 'k', 'w']\n",
      "#         stackplot(np.arange(len(desiredSemantics)), np.row_stack(tuple([i for i in desiredSemantics.T])), colors=clrs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sara3\n",
        "tara3\n",
        "peter1\n",
        "james2\n",
        "moos2\n",
        "james1\n",
        "sara1\n",
        "tara1\n",
        "daniel2\n",
        "moos3\n",
        "peter3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "aron1\n",
        "ferran1\n",
        "moos1\n",
        "aron2\n"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sitImg = np.array(Image.open(\"/home/ilisescu/PhD/person_sit.png\"))\n",
      "upImg = np.array(Image.open(\"/home/ilisescu/PhD/person_up.png\"))\n",
      "# sitImg = cv2.resize(sitImg, (100, 50))\n",
      "\n",
      "figure(); imshow(sitImg)\n",
      "figure(); imshow(upImg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 87,
       "text": [
        "<matplotlib.image.AxesImage at 0x7f78571e4f10>"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(); imshow(img[:, :, :3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "<matplotlib.image.AxesImage at 0x7f78570391d0>"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "MAKE IMAGES FROM TETRIS INPUT"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "synthSeq = np.load(synthSeqLocation).item()\n",
      "sessionName = \"6x9_sess2\"\n",
      "\n",
      "outputImgPath = \"/media/ilisescu/Data1/PhD/data/windows/tetris/\"+sessionName\n",
      "if not os.path.isdir(outputImgPath) :\n",
      "    os.mkdir(outputImgPath)\n",
      "    \n",
      "with open(\"/media/ilisescu/Data1/PhD/data/windows/tetris/\"+sessionName+\".txt\") as f:\n",
      "    lines = f.readlines()\n",
      "    gridSize = np.array(lines[0].split(\",\")[1:3], int)[::-1] ## (rows, cols)\n",
      "    lines = np.concatenate(([\"D,121231231233,\"+\"\".join(np.zeros(np.prod(gridSize), int).astype(np.string_))+\"\\n\"], lines[1:]))\n",
      "    \n",
      "    cellSize = 100\n",
      "    spacing = 10\n",
      "    \n",
      "    previousFrameInstructions = np.ones(gridSize)\n",
      "    previousFrame = np.ones(np.concatenate(((gridSize*cellSize) + ((gridSize+1)*spacing), [3])), np.uint8)*15\n",
      "    \n",
      "    PIECE_I = 0\n",
      "    PIECE_J = 1\n",
      "    PIECE_L = 2\n",
      "    PIECE_O = 3\n",
      "    PIECE_S = 4\n",
      "    PIECE_T = 5\n",
      "    PIECE_Z = 6\n",
      "    \n",
      "    \n",
      "    pieces = np.array([[0, 7, PIECE_Z],\n",
      "                       [8, 21, PIECE_T],\n",
      "                       [22, 31, PIECE_I],\n",
      "                       [32, 40, PIECE_Z],\n",
      "                       [41, 55, PIECE_T],\n",
      "                       [56, 65, PIECE_S],\n",
      "                       [66, 73, PIECE_I],\n",
      "                       [74, 79, PIECE_O],\n",
      "                       [80, 92, PIECE_J],\n",
      "                       [93, 105, PIECE_T],\n",
      "                       [106, 113, PIECE_O],\n",
      "                       [114, 122, PIECE_L],\n",
      "                       [123, 126, PIECE_O],\n",
      "                       [127, 130, PIECE_L]])\n",
      "    currentPiece = 0\n",
      "    \n",
      "    for frame, line in enumerate(lines[0:]) :\n",
      "        \n",
      "        if pieces[currentPiece, 1] < frame :\n",
      "            currentPiece += 1\n",
      "        \n",
      "#         print np.array(list(line.split(\",\")[-1])[:-1], int).reshape(gridSize, order='C')\n",
      "        sys.stdout.flush()\n",
      "        instructions = np.array(list(line.split(\",\")[-1])[:-1], int)\n",
      "#         print instructions\n",
      "        \n",
      "        outputImg = np.copy(previousFrame)\n",
      "        \n",
      "        for instance, instruction in enumerate(instructions[0:]) :\n",
      "            i, j = [int(instance/gridSize[1]), np.mod(instance, gridSize[1])]\n",
      "            \n",
      "#             if instruction == 0 :\n",
      "#                 color = np.array([255, 255, 255])\n",
      "#             else :\n",
      "#                 color = np.array([0, 84, 194])\n",
      "            if instruction != previousFrameInstructions[i, j] :\n",
      "                if instruction == 0 :\n",
      "                    color = np.array([245, 245, 245])\n",
      "                else :\n",
      "                    if pieces[currentPiece, 2] == PIECE_I :\n",
      "                        color = np.array([255, 0, 0], np.uint8)\n",
      "                    elif pieces[currentPiece, 2] == PIECE_J :\n",
      "                        color = np.array([146, 146, 146], np.uint8)\n",
      "                    elif pieces[currentPiece, 2] == PIECE_L :\n",
      "                        color = np.array([219, 20, 203], np.uint8)\n",
      "                    elif pieces[currentPiece, 2] == PIECE_O :\n",
      "                        color = np.array([10, 45, 201], np.uint8)\n",
      "                    elif pieces[currentPiece, 2] == PIECE_S :\n",
      "                        color = np.array([31, 181, 24], np.uint8)\n",
      "                    elif pieces[currentPiece, 2] == PIECE_T :\n",
      "                        color = np.array([107, 44, 12], np.uint8)\n",
      "                    else :\n",
      "                        color = np.array([42, 171, 250], np.uint8)\n",
      "\n",
      "                outputImg[i*cellSize + ((i+1)*spacing):(i+1)*cellSize + ((i+1)*spacing),\n",
      "                          j*cellSize + ((j+1)*spacing):(j+1)*cellSize + ((j+1)*spacing)] = color\n",
      "                \n",
      "#         contrastEnhancer = ImageEnhance.Brightness(Image.fromarray(outputImg))\n",
      "#         colorEnhancer = ImageEnhance.Contrast(contrastEnhancer.enhance(1.2))\n",
      "#         colorEnhancer.enhance(2.0).save(outputImgPath+\"/frame-{0:05}.png\".format(frame+1))\n",
      "        cv2.imwrite(outputImgPath+\"/frame-{0:05}.png\".format(frame+1), cv2.cvtColor(outputImg, cv2.COLOR_RGB2BGR))\n",
      "#         Image.fromarray(outputImg).save(outputImgPath+\"/frame-{0:05}.png\".format(frame+1))\n",
      "        previousFrameInstructions = instructions.reshape(gridSize, order='C')\n",
      "        previousFrame = np.copy(outputImg)\n",
      "\n",
      "# figure(); imshow(outputImg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(); imshow(outputImg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 154,
       "text": [
        "<matplotlib.image.AxesImage at 0x7f7692a98d50>"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pilImg = Image.fromarray(outputImg)\n",
      "pilImg.save()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from PIL import ImageEnhance"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "enhancer = ImageEnhance.Contrast(Image.fromarray(outputImg))\n",
      "enhancer.enhance(1.8).show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "RESIZE IMAGES AND CHANGE THE BACKGROUND"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# basePath = \"/media/ilisescu/Data1/PhD/demos/sprite_originalspeed/\"\n",
      "# basePath = \"/home/ilisescu/PhD/data/synthesisedSequences/waveFull/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/waveFullBusier/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/theme_park_mixedCompatibility/no_people/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/theme_park_mixedCompatibility/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/tetris/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/digger/with_sem_compat/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/multipleCandles/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/digger/\"\n",
      "# basePath = \"/home/ilisescu/PhD/data/synthesisedSequences/street/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/plane_departures/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/flowers/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/street_complex/\"\n",
      "basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/wave_by_numbers_fattestbar/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/super_mario_full/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/super_mario_planes_latest/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/USER STUDIES SEQUENCES/aron/wave_user_study_task/\"\n",
      "bgImage = np.array(Image.open(basePath+\"bgImage.png\"))\n",
      "frameLocs = np.sort(glob.glob(basePath + \"frame-*.png\"))\n",
      "\n",
      "if not os.path.isdir(basePath + \"on_bg/\") :\n",
      "    os.mkdir(basePath + \"on_bg/\")\n",
      "    \n",
      "for loc in frameLocs[195:] :\n",
      "    currentFrame = np.array(Image.open(loc))\n",
      "    \n",
      "#     if currentFrame.shape[0] >= bgImage.shape[0] :\n",
      "#         currentFrame = currentFrame[currentFrame.shape[0]-bgImage.shape[0]:, :, :]\n",
      "#     else :\n",
      "#         currentFrame = np.concatenate((np.zeros((bgImage.shape[0]-currentFrame.shape[0],\n",
      "#                                                  currentFrame.shape[1],\n",
      "#                                                  currentFrame.shape[2]), np.uint8),\n",
      "#                                        currentFrame), axis=0)\n",
      "        \n",
      "#     if currentFrame.shape[1] >= bgImage.shape[1] :\n",
      "#         delta = (currentFrame.shape[1]-bgImage.shape[1])/2\n",
      "#         currentFrame = currentFrame[:, delta:-delta, :]\n",
      "#     else :\n",
      "#         delta = (bgImage.shape[1]-currentFrame.shape[1])/2\n",
      "#         currentFrame = np.concatenate((np.zeros((currentFrame.shape[0], delta, currentFrame.shape[2]), np.uint8),\n",
      "#                                        currentFrame,\n",
      "#                                        np.zeros((currentFrame.shape[0], delta, currentFrame.shape[2]), np.uint8)), axis=1)\n",
      "    \n",
      "    alphas = currentFrame[:, :, -1].reshape((currentFrame.shape[0], currentFrame.shape[1], 1))\n",
      "    finalFrame = (currentFrame[:, :, 0:3]*(alphas/255.0) + bgImage[:, :, 0:3]*((255-alphas)/255.0)).astype(np.uint8)\n",
      "\n",
      "    \n",
      "    Image.fromarray(finalFrame).save(basePath + \"on_bg/\"+loc.split(\"/\")[-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# basePath = \"/media/ilisescu/Data1/PhD/demos/sprite_originalspeed/\"\n",
      "# basePath = \"/home/ilisescu/PhD/data/synthesisedSequences/waveFull/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/waveFullBusier/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/theme_park_mixedCompatibility/no_people/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/theme_park_mixedCompatibility/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/tetris/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/digger/with_sem_compat/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/multipleCandles/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/digger/\"\n",
      "# basePath = \"/home/ilisescu/PhD/data/synthesisedSequences/street/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/plane_departures/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/flowers/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/street_complex/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/wave_by_numbers_fattestbar/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/super_mario_full/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/super_mario_planes_latest/\"\n",
      "basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/USER STUDIES SEQUENCES/moos/wave_user_study_task/\"\n",
      "bgImage = np.array(Image.open(basePath+\"bgImage.png\"))\n",
      "frameLocs = np.sort(glob.glob(basePath + \"frame-*.png\"))\n",
      "\n",
      "if not os.path.isdir(basePath + \"on_bg/\") :\n",
      "    os.mkdir(basePath + \"on_bg/\")\n",
      "    \n",
      "for loc in frameLocs[0:] :\n",
      "    currentFrame = np.array(Image.open(loc))\n",
      "    \n",
      "#     if currentFrame.shape[0] >= bgImage.shape[0] :\n",
      "#         currentFrame = currentFrame[currentFrame.shape[0]-bgImage.shape[0]:, :, :]\n",
      "#     else :\n",
      "#         currentFrame = np.concatenate((np.zeros((bgImage.shape[0]-currentFrame.shape[0],\n",
      "#                                                  currentFrame.shape[1],\n",
      "#                                                  currentFrame.shape[2]), np.uint8),\n",
      "#                                        currentFrame), axis=0)\n",
      "        \n",
      "#     if currentFrame.shape[1] >= bgImage.shape[1] :\n",
      "#         delta = (currentFrame.shape[1]-bgImage.shape[1])/2\n",
      "#         currentFrame = currentFrame[:, delta:-delta, :]\n",
      "#     else :\n",
      "#         delta = (bgImage.shape[1]-currentFrame.shape[1])/2\n",
      "#         currentFrame = np.concatenate((np.zeros((currentFrame.shape[0], delta, currentFrame.shape[2]), np.uint8),\n",
      "#                                        currentFrame,\n",
      "#                                        np.zeros((currentFrame.shape[0], delta, currentFrame.shape[2]), np.uint8)), axis=1)\n",
      "    \n",
      "    alphas = currentFrame[:, :, -1].reshape((currentFrame.shape[0], currentFrame.shape[1], 1))\n",
      "    finalFrame = (currentFrame[:, :, 0:3]*(alphas/255.0) + bgImage[:, :, 0:3]*((255-alphas)/255.0)).astype(np.uint8)\n",
      "\n",
      "    \n",
      "    Image.fromarray(finalFrame).save(basePath + \"on_bg/\"+loc.split(\"/\")[-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# basePath = \"/media/ilisescu/Data1/PhD/demos/sprite_originalspeed/\"\n",
      "# basePath = \"/home/ilisescu/PhD/data/synthesisedSequences/waveFull/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/waveFullBusier/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/theme_park_mixedCompatibility/no_people/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/theme_park_mixedCompatibility/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/tetris/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/digger/with_sem_compat/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/multipleCandles/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/digger/\"\n",
      "# basePath = \"/home/ilisescu/PhD/data/synthesisedSequences/street/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/plane_departures/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/flowers/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/street_complex/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/wave_by_numbers_fattestbar/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/super_mario_full/\"\n",
      "# basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/super_mario_planes_latest/\"\n",
      "basePath = \"/media/ilisescu/Data1/PhD/data/synthesisedSequences/USER STUDIES SEQUENCES/clement/wave_user_study_task/\"\n",
      "bgImage = np.array(Image.open(basePath+\"bgImage.png\"))\n",
      "frameLocs = np.sort(glob.glob(basePath + \"frame-*.png\"))\n",
      "\n",
      "if not os.path.isdir(basePath + \"on_bg/\") :\n",
      "    os.mkdir(basePath + \"on_bg/\")\n",
      "    \n",
      "for loc in frameLocs[0:] :\n",
      "    currentFrame = np.array(Image.open(loc))\n",
      "    \n",
      "#     if currentFrame.shape[0] >= bgImage.shape[0] :\n",
      "#         currentFrame = currentFrame[currentFrame.shape[0]-bgImage.shape[0]:, :, :]\n",
      "#     else :\n",
      "#         currentFrame = np.concatenate((np.zeros((bgImage.shape[0]-currentFrame.shape[0],\n",
      "#                                                  currentFrame.shape[1],\n",
      "#                                                  currentFrame.shape[2]), np.uint8),\n",
      "#                                        currentFrame), axis=0)\n",
      "        \n",
      "#     if currentFrame.shape[1] >= bgImage.shape[1] :\n",
      "#         delta = (currentFrame.shape[1]-bgImage.shape[1])/2\n",
      "#         currentFrame = currentFrame[:, delta:-delta, :]\n",
      "#     else :\n",
      "#         delta = (bgImage.shape[1]-currentFrame.shape[1])/2\n",
      "#         currentFrame = np.concatenate((np.zeros((currentFrame.shape[0], delta, currentFrame.shape[2]), np.uint8),\n",
      "#                                        currentFrame,\n",
      "#                                        np.zeros((currentFrame.shape[0], delta, currentFrame.shape[2]), np.uint8)), axis=1)\n",
      "    \n",
      "    alphas = currentFrame[:, :, -1].reshape((currentFrame.shape[0], currentFrame.shape[1], 1))\n",
      "    finalFrame = (currentFrame[:, :, 0:3]*(alphas/255.0) + bgImage[:, :, 0:3]*((255-alphas)/255.0)).astype(np.uint8)\n",
      "\n",
      "    \n",
      "    Image.fromarray(finalFrame).save(basePath + \"on_bg/\"+loc.split(\"/\")[-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print loc.split(\"/\")[-1]\n",
      "print basePath + \"on_bg/\"+loc.split(\"/\")[-1]\n",
      "# if not os.path.isdir(basePath + \"on_bg/\") :\n",
      "#     os.mkdir(basePath + \"on_bg/\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "frame-00001.png\n",
        "/home/ilisescu/PhD/data/synthesisedSequences/waveFull/on_bg/frame-00001.png\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## resize frames and fill emptyness with zeros\n",
      "desiredSize = [720, 1280, 3]\n",
      "for frame in np.sort(glob.glob(\"/media/ilisescu/Data1/PhD/demos/ground_plane/frame-*.png\")) :\n",
      "    frameName = frame.split('/')[-1] \n",
      "    im = cv2.resize(np.array(Image.open(frame))[70:70+941, 61:61+1798, :], (1280, 670), interpolation=cv2.INTER_CUBIC)\n",
      "    imSize = im.shape\n",
      "    topLeft = ((desiredSize[0]-imSize[0])/2, (desiredSize[1]-imSize[1])/2)\n",
      "    resizedImage = np.zeros(desiredSize, dtype=uint8)\n",
      "    resizedImage[topLeft[0]:topLeft[0]+imSize[0], topLeft[1]:topLeft[1]+imSize[1]] = im\n",
      "    Image.fromarray(resizedImage).save(\"/media/ilisescu/Data1/PhD/demos/ground_plane/\"+frameName)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## change background of resampled sprite\n",
      "basePath = \"/media/ilisescu/Data1/PhD/demos/sprite_resampled/\"\n",
      "coords = np.loadtxt(glob.glob(basePath+\"/*.csv\")[0], delimiter=\",\")[:, 0:2].astype(np.int)\n",
      "bgImage = np.array(Image.open(basePath+\"median.png\"))\n",
      "frameLocs = np.sort(glob.glob(basePath + \"frame-*.png\"))\n",
      "for num, loc, i in zip(arange(len(frameLocs)/5), frameLocs[::5], arange(0, len(frameLocs), 5)) :\n",
      "    currentFrame = np.array(Image.open(loc))\n",
      "    alphas = currentFrame[:, :, -1].reshape((currentFrame.shape[0], currentFrame.shape[1], 1))\n",
      "    \n",
      "    finalFrame = np.copy(bgImage)\n",
      "    \n",
      "    finalFrame[coords[i, 1]:coords[i, 1]+currentFrame.shape[0], \n",
      "               coords[i, 0]:coords[i, 0]+currentFrame.shape[1], :] = (currentFrame[:, :, 0:3]*(alphas/255.0) + \n",
      "                                                                      finalFrame[coords[i, 1]:coords[i, 1]+currentFrame.shape[0], \n",
      "                                                                                 coords[i, 0]:coords[i, 0]+currentFrame.shape[1], :]*(1.0-alphas/255.0))\n",
      "    \n",
      "#     alphas = currentFrame[:, :, -1].reshape((currentFrame.shape[0], currentFrame.shape[1], 1))\n",
      "#     finalFrame = (currentFrame[:, :, 0:3]*(alphas/255.0) + bgImage[:, :, 0:3]*((255-alphas)/255.0)).astype(np.uint8)\n",
      "\n",
      "    \n",
      "    Image.fromarray(finalFrame).save(basePath+\"onBG/frame-{0:05d}.png\".format(num+1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "TRY EPIC FLOW"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## trying EpicFlow\n",
      "flow = sio.loadmat(\"/home/ilisescu/PhD/EpicFlowTry/flow.mat\")['flow']\n",
      "## flow goes from im1 to im2 so I should be able to make im2 by moving pixels from im1\n",
      "im1 = np.array(Image.open(\"/home/ilisescu/PhD/EpicFlowTry/frame-00522.png\"))\n",
      "im2 = np.array(Image.open(\"/home/ilisescu/PhD/EpicFlowTry/frame-01022.png\"))\n",
      "im1 = np.array(Image.open(\"/home/ilisescu/PhD/EpicFlowTry/frame-01022.png\"))\n",
      "im2 = np.array(Image.open(\"/home/ilisescu/PhD/EpicFlowTry/frame-01023.png\"))\n",
      "# im1 = np.array(Image.open(\"/home/ilisescu/PhD/EpicFlowTry/frame-01022.png\"))\n",
      "# im2 = np.array(Image.open(\"/home/ilisescu/PhD/EpicFlowTry/frame-00522.png\"))\n",
      "# im1 = np.array(Image.open(\"/home/ilisescu/PhD/EpicFlowTry/frame-01025.png\"))\n",
      "# im2 = np.array(Image.open(\"/home/ilisescu/PhD/EpicFlowTry/frame-01036.png\"))\n",
      "\n",
      "# im1 = np.array(Image.open(\"/home/ilisescu/PhD/data/havana/frame-01025.png\"))\n",
      "# im2 = np.array(Image.open(\"/home/ilisescu/PhD/data/havana/frame-01036.png\"))\n",
      "flow = cv2.calcOpticalFlowFarneback(cv2.cvtColor(im1, cv2.COLOR_RGB2GRAY), \n",
      "                                    cv2.cvtColor(im2, cv2.COLOR_RGB2GRAY), \n",
      "                                    0.5, 3, 15, 3, 5, 1.1, 0)\n",
      "\n",
      "print flow.shape\n",
      "\n",
      "rowIdxs = np.arange(im1.shape[0]).reshape((im1.shape[0], 1)).repeat(im1.shape[1], axis=-1)\n",
      "colIdxs = np.arange(im1.shape[1]).reshape((1, im1.shape[1])).repeat(im1.shape[0], axis=0)\n",
      "\n",
      "recon = np.zeros_like(im1)\n",
      "recon[np.clip(np.array(rowIdxs-flow[:, :, 1], dtype=int), 0, im1.shape[0]-1).flatten(),\n",
      "             np.clip(np.array(colIdxs-flow[:, :, 0], dtype=int), 0, im1.shape[1]-1).flatten(), :] = im1[rowIdxs.flatten(),\n",
      "                                                                                                        colIdxs.flatten(), :]\n",
      "\n",
      "# recon[rowIdxs.flatten(), \n",
      "#       colIdxs.flatten(), :] = im2[np.clip(np.array(rowIdxs-flow[:, :, 1], dtype=int), 0, im1.shape[0]-1).flatten(),\n",
      "#                                   np.clip(np.array(colIdxs-flow[:, :, 0], dtype=int), 0, im1.shape[1]-1).flatten(), :]\n",
      "\n",
      "remapped = cv2.remap(im2, np.array(flow[:, :, 0]+colIdxs, dtype=np.float32),\n",
      "                     np.array(flow[:, :, 1]+rowIdxs, dtype=np.float32), cv2.INTER_LINEAR)\n",
      "\n",
      "figure(); imshow(im1)\n",
      "figure(); imshow(im2)\n",
      "figure(); imshow(remapped)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(647, 1150, 2)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "<matplotlib.image.AxesImage at 0x7f15d32b97d0>"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.average(np.linalg.norm(flow.reshape((np.prod(flow.shape[0:2]), 2)), axis=1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.66991\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.average(np.linalg.norm(flow.reshape((np.prod(flow.shape[0:2]), 2)), axis=1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.488877\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sio.savemat(\"/home/ilisescu/PhD/EpicFlowTry/flowTest.mat\", {'flowTest':flow})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(flow[:, :, 1])\n",
      "# print (flow[:, :, 0]+colIdxs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(); imshow(np.load(dataFolder+\"Videos/6489810.avi_distanceMatrix.npy\"), interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "<matplotlib.image.AxesImage at 0x7f5bb73621d0>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "COMPUTE IMAGE MEDIAN"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "frameLocs = np.sort(glob.glob(dataFolder + dataSet + \"/frame-*.png\"))\n",
      "frameSize = np.array(Image.open(frameLocs[0])).shape[0:2]\n",
      "numOfFrames = len(frameLocs)\n",
      "print numOfFrames, frameSize\n",
      "medianImage = np.zeros((frameSize[0], frameSize[1], 3), dtype=np.uint8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "250 (720, 1280)\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allFrames = np.zeros((frameSize[0], frameSize[1], numOfFrames), dtype=np.uint8)\n",
      "channel = 2\n",
      "for i in xrange(len(frameLocs)) :\n",
      "#     allFrames[:, :, i] = cv2.cvtColor(np.array(Image.open(frameLocs[i])), cv2.COLOR_RGB2LAB)[:, :, channel]\n",
      "    allFrames[:, :, i] = np.array(Image.open(frameLocs[i]))[:, :, channel]\n",
      "    if np.mod(i, 100) == 0 :\n",
      "        sys.stdout.write('\\r' + \"Loaded image \" + np.string_(i) + \" (\" + np.string_(len(frameLocs)) + \")\")\n",
      "        sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Loaded image 0 (250)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Loaded image 100 (250)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Loaded image 200 (250)"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "medianImage[:, :, channel] = np.median(allFrames, axis=-1)\n",
      "# medianImage[:, :, channel] = np.mean(allFrames, axis=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# figure(); imshow(cv2.cvtColor(medianImage, cv2.COLOR_LAB2RGB))\n",
      "figure(); imshow(medianImage)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "<matplotlib.image.AxesImage at 0x7fd1a56bc750>"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataFolder + dataSet + \"median.png\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "'/media/ilisescu/Data1/PhD/data/digger/median.png'"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image.fromarray(np.array(medianImage, dtype=np.uint8)).save(dataFolder + dataSet + \"median.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## combine medians of different datasets (for now specifically for the wave sequence)\n",
      "allFrames = np.zeros((frameSize[0], frameSize[1], 3, 3), dtype=np.uint8)\n",
      "allFrames[:, :, :, 0] = np.array(Image.open(dataFolder+\"wave1/medianOne.png\"))\n",
      "allFrames[:, :, :, 1] = np.array(Image.open(dataFolder+\"wave2/medianOne.png\"))\n",
      "allFrames[:, :, :, 2] = np.array(Image.open(dataFolder+\"wave3/medianOne.png\"))\n",
      "allFrames = np.concatenate((allFrames, medianImage.reshape((frameSize[0], frameSize[1], 3, 1))), axis=-1)\n",
      "\n",
      "medianImage = np.zeros((frameSize[0], frameSize[1], 3), dtype=np.uint8)\n",
      "medianImage = np.median(allFrames, axis=-1).astype(uint8)\n",
      "figure(); imshow(medianImage)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 101,
       "text": [
        "<matplotlib.image.AxesImage at 0x7f623ccdaf50>"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(np.sum((allFrames[:, :, :, 0]/255.0-allFrames[:, :, :, 1]/255.0)**2, axis=-1)**.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image.fromarray(np.array(medianImage, dtype=np.uint8)).save(dataFolder + \"wave3/\" + \"median.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "RENDER SPRITE ON BACKGROUND"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "basePath = \"/media/ilisescu/Data1/PhD/data/havana/\"\n",
      "bgImage = np.array(Image.open(basePath+\"median.png\"))\n",
      "for i in np.arange(800, 800+476) :\n",
      "    currentFrame = np.array(Image.open(basePath+\"bus1/bus1-frame-{0:05d}.png\".format(i)))\n",
      "    spriteLoc = np.argwhere(currentFrame[:, :, -1] != 0)\n",
      "    alphas = currentFrame[spriteLoc[:, 0], spriteLoc[:, 1], -1].reshape((len(spriteLoc), 1)).repeat(3, axis=-1)\n",
      "    \n",
      "    finalFrame = np.copy(bgImage)\n",
      "    finalFrame[spriteLoc[:, 0], spriteLoc[:, 1], :] = (currentFrame[spriteLoc[:, 0], spriteLoc[:, 1], 0:-1]*(alphas/255.0) + \n",
      "                                                       bgImage[spriteLoc[:, 0], spriteLoc[:, 1], :]*((255-alphas)/255.0))\n",
      "\n",
      "    \n",
      "    Image.fromarray((finalFrame).astype(numpy.uint8)).save(basePath+\"bus1OnMedian/bus1-frame-{0:05d}.png\".format(i))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = np.array(Image.open(dataFolder+\"testImage.png\"))\n",
      "figure(); imshow(img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 204,
       "text": [
        "<matplotlib.image.AxesImage at 0x7fce4b249850>"
       ]
      }
     ],
     "prompt_number": 204
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "square = np.vstack((np.array([[-0.5, -0.5, 0.0], [-0.5, 0.5, 0.0], [0.5, 0.5, 0.0], [0.5, -0.5, 0.0], [-0.5, -0.5, 0.0]]).T, ones(5)))\n",
      "print square\n",
      "intrinsics = np.array([[640.0, 0.0, 320.0, 0.0], [0.0, 360.0, 180.0, 0.0], [0.0, 0.0, 1.0, 0.0]])\n",
      "extrinsics = np.array([[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 4.0], [0.0, 0.0, 0.0, 1.0]])\n",
      "\n",
      "\n",
      "theta = 10.0*(np.pi/180.0)\n",
      "R = np.array([[np.cos(theta), 0.0, np.sin(theta), 0.], [0.0, 1.0, 0.0, 0.0], [-np.sin(theta), 0.0, np.cos(theta), 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
      "\n",
      "squareImg = np.dot(np.dot(intrinsics, extrinsics), np.dot(R, square))\n",
      "squareImg = squareImg/squareImg[-1, :]\n",
      "print squareImg[0:2, :]\n",
      "\n",
      "figure(); \n",
      "xlim(0, 640); ylim(0, 360)\n",
      "plot(squareImg[0, :], squareImg[1, :])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[-0.5 -0.5  0.5  0.5 -0.5]\n",
        " [-0.5  0.5  0.5 -0.5 -0.5]\n",
        " [ 0.   0.   0.   0.   0. ]\n",
        " [ 1.   1.   1.   1.   1. ]]\n",
        "[[ 242.88914959  242.88914959  400.53266404  400.53266404  242.88914959]\n",
        " [ 135.95601962  224.04398038  225.99844323  134.00155677  135.95601962]]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 356,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7fce452f0410>]"
       ]
      }
     ],
     "prompt_number": 356
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "origSquare = np.copy(squareImg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 344
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "H = cv2.findHomography(squareImg[0:2, 0:-1].T, origSquare[0:2, 0:-1].T)[0]\n",
      "xs = np.ndarray.flatten(np.arange(img.shape[1], dtype=float).reshape((img.shape[1], 1)).repeat(img.shape[0], axis=-1))\n",
      "ys = np.ndarray.flatten(np.arange(img.shape[0], dtype=float).reshape((1, img.shape[0])).repeat(img.shape[1], axis=0))\n",
      "data = np.array(np.vstack((xs.reshape((1, len(xs))), ys.reshape((1, len(ys))), np.ones(len(ys)))), dtype=int)\n",
      "imgWarped = np.zeros(img.shape, dtype=np.uint8)\n",
      "\n",
      "warpedCoords = np.dot(H, data)\n",
      "warpedCoords /= warpedCoords[-1, :]\n",
      "\n",
      "for warpedCoord, coord in zip(np.array(warpedCoords.T, dtype=int), data.T) :\n",
      "    if warpedCoord[0] < img.shape[1] and warpedCoord[0] > 0 and warpedCoord[1] < img.shape[0] and warpedCoord[1] > 0 :\n",
      "        imgWarped[coord[1], coord[0], :] = img[warpedCoord[1], warpedCoord[0], :]\n",
      "        \n",
      "figure(); imshow(imgWarped)\n",
      "figure(); imshow(img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 358,
       "text": [
        "<matplotlib.image.AxesImage at 0x7fce45fab290>"
       ]
      }
     ],
     "prompt_number": 358
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "square = np.vstack((np.array([[-0.5, -0.5, 0.0], [-0.5, 0.5, 0.0], [0.5, 0.5, 0.0], [0.5, -0.5, 0.0], [-0.5, -0.5, 0.0]]).T, ones(5)))\n",
      "print square\n",
      "intrinsics = np.eye(3, 4)#np.array([[640.0, 0.0, 320.0, 0.0], [0.0, 360.0, 180.0, 0.0], [0.0, 0.0, 1.0, 0.0]])\n",
      "extrinsics = np.array([[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 2.0], [0.0, 0.0, 0.0, 1.0]])\n",
      "print intrinsics\n",
      "print extrinsics\n",
      "print np.dot(intrinsics, extrinsics)\n",
      "\n",
      "# square = np.dot(np.dot(intrinsics, extrinsics), square)\n",
      "# square = square/square[-1, :]\n",
      "print square\n",
      "\n",
      "theta = 10.0*(np.pi/180.0)\n",
      "R = np.array([[np.cos(theta), 0.0, np.sin(theta)], [0.0, 1.0, 0.0], [-np.sin(theta), 0.0, np.cos(theta)]])\n",
      "t = np.array([0.0, 0.0, 0.0])\n",
      "n = np.array([0.0, 0.0, 1.0])\n",
      "d = 2.0\n",
      "\n",
      "# H = R-np.dot(t, n.T)/d\n",
      "# H = np.dot(np.dot(R, np.eye(3)-np.dot(extrinsics[0:3, -1]-t, n.T)/d), extrinsics[0:3, 0:3].T)\n",
      "print H\n",
      "# print np.dot(t, n.T)/d\n",
      "\n",
      "H = np.hstack((np.vstack((R, np.zeros((1, 3)))), np.array([[0.0], [0], [0], [1]])))\n",
      "extrinsicsCam2 = np.dot(H, extrinsics)\n",
      "print H\n",
      "print extrinsicsCam2\n",
      "\n",
      "# square = np.dot(np.dot(np.dot(intrinsics[:, 0:-1], H), np.linalg.inv(intrinsics[:, 0:-1])), square)\n",
      "# square = np.dot(np.linalg.inv(intrinsics[:, 0:-1]), square)\n",
      "# square =  np.dot(np.dot(intrinsics, np.dot(extrinsics, H)), square)\n",
      "\n",
      "# cam2 = np.dot(np.dot(np.dot(intrinsics, extrinsicsCam2), \n",
      "#                      np.hstack((np.linalg.inv(intrinsics[:, 0:-1]), np.zeros((3, 1))))), \n",
      "#               np.linalg.inv(extrinsicsCam2))\n",
      "print cam2.shape\n",
      "# square = np.dot(np.dot(intrinsics[:, 0:3], np.dot(np.linalg.inv(extrinsics), extrinsicsCam2)[0:3, :]), square)\n",
      "# square = np.dot(np.dot(intrinsics, extrinsicsCam2), square)\n",
      "\n",
      "square = square/square[-1, :]\n",
      "print square[0:2, :]\n",
      "\n",
      "figure(); \n",
      "xlim(0, 640); ylim(0, 360)\n",
      "plot(square[0, :], square[1, :], )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[-0.5 -0.5  0.5  0.5 -0.5]\n",
        " [-0.5  0.5  0.5 -0.5 -0.5]\n",
        " [ 0.   0.   0.   0.   0. ]\n",
        " [ 1.   1.   1.   1.   1. ]]\n",
        "[[ 1.  0.  0.  0.]\n",
        " [ 0.  1.  0.  0.]\n",
        " [ 0.  0.  1.  0.]]\n",
        "[[ 1.  0.  0.  0.]\n",
        " [ 0.  1.  0.  0.]\n",
        " [ 0.  0.  1.  2.]\n",
        " [ 0.  0.  0.  1.]]\n",
        "[[ 1.  0.  0.  0.]\n",
        " [ 0.  1.  0.  0.]\n",
        " [ 0.  0.  1.  2.]]\n",
        "[[-0.5 -0.5  0.5  0.5 -0.5]\n",
        " [-0.5  0.5  0.5 -0.5 -0.5]\n",
        " [ 0.   0.   0.   0.   0. ]\n",
        " [ 1.   1.   1.   1.   1. ]]\n",
        "[[ 0.98480775  0.          0.17364818  0.        ]\n",
        " [ 0.          1.          0.          0.        ]\n",
        " [-0.17364818  0.          0.98480775  0.        ]\n",
        " [ 0.          0.          0.          1.        ]]\n",
        "[[ 0.98480775  0.          0.17364818  0.        ]\n",
        " [ 0.          1.          0.          0.        ]\n",
        " [-0.17364818  0.          0.98480775  0.        ]\n",
        " [ 0.          0.          0.          1.        ]]\n",
        "[[ 0.98480775  0.          0.17364818  0.34729636]\n",
        " [ 0.          1.          0.          0.        ]\n",
        " [-0.17364818  0.          0.98480775  1.96961551]\n",
        " [ 0.          0.          0.          1.        ]]\n",
        "(3, 4)\n",
        "[[-0.5 -0.5  0.5  0.5 -0.5]\n",
        " [-0.5  0.5  0.5 -0.5 -0.5]]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 254,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7fce4a73f150>]"
       ]
      }
     ],
     "prompt_number": 254
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs = np.ndarray.flatten(np.arange(img.shape[1], dtype=float).reshape((img.shape[1], 1)).repeat(img.shape[0], axis=-1))\n",
      "ys = np.ndarray.flatten(np.arange(img.shape[0], dtype=float).reshape((1, img.shape[0])).repeat(img.shape[1], axis=0))\n",
      "data = np.array(np.vstack((xs.reshape((1, len(xs))), ys.reshape((1, len(ys))), np.ones(len(ys)))), dtype=int)\n",
      "imgWarped = np.zeros(img.shape, dtype=np.uint8)\n",
      "\n",
      "\n",
      "theta = 45.0*(np.pi/180.0)\n",
      "R = np.array([[np.cos(theta), 0.0, np.sin(theta)], [0.0, 1.0, 0.0], [-np.sin(theta), 0.0, np.cos(theta)]])\n",
      "originT = (np.array([[img.shape[1]], [img.shape[0]], [0]])/2).repeat(data.shape[-1], axis=-1)\n",
      "\n",
      "warpedCoords = np.dot(R, data-originT)+originT\n",
      "warpedCoords /= warpedCoords[-1, :]\n",
      "\n",
      "for warpedCoord, coord in zip(np.array(warpedCoords.T, dtype=int), data.T) :\n",
      "    if warpedCoord[0] < img.shape[1] and warpedCoord[0] > 0 and warpedCoord[1] < img.shape[0] and warpedCoord[1] > 0 :\n",
      "        imgWarped[coord[1], coord[0], :] = img[warpedCoord[1], warpedCoord[0], :]\n",
      "        \n",
      "figure(); imshow(imgWarped)\n",
      "figure(); imshow(img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 251,
       "text": [
        "<matplotlib.image.AxesImage at 0x7fce49364410>"
       ]
      }
     ],
     "prompt_number": 251
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print warpedCoords\n",
      "print data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.00626959  1.00626959  1.00626959 ...,  0.99375     0.99375     0.99375   ]\n",
        " [ 0.79798884  0.79355557  0.7891223  ...,  0.78223688  0.78665629\n",
        "   0.79107571]\n",
        " [ 1.          1.          1.         ...,  1.          1.          1.        ]]\n",
        "[[  0   0   0 ..., 639 639 639]\n",
        " [  0   1   2 ..., 357 358 359]\n",
        " [  1   1   1 ...,   1   1   1]]\n"
       ]
      }
     ],
     "prompt_number": 247
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.max(warpedCoords[0, :]), np.min(warpedCoords[0, :]), np.max(warpedCoords[1, :]), np.min(warpedCoords[1, :])\n",
      "print R\n",
      "print np.linalg.inv(R)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "629 0 359 0\n",
        "[[ 0.98480775  0.          0.17364818]\n",
        " [ 0.          1.          0.        ]\n",
        " [-0.17364818  0.          0.98480775]]\n",
        "[[ 0.98480775  0.         -0.17364818]\n",
        " [ 0.          1.          0.        ]\n",
        " [ 0.17364818  0.          0.98480775]]\n"
       ]
      }
     ],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.dot(intrinsics, extrinsicsCam2)\n",
      "print np.hstack((np.linalg.inv(intrinsics[:, 0:-1]), np.zeros((3, 1))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  3.94256258e+02   0.00000000e+00   5.97128129e+02   1.28000000e+03]\n",
        " [ -9.00000000e+01   3.60000000e+02   1.55884573e+02   7.20000000e+02]\n",
        " [ -5.00000000e-01   0.00000000e+00   8.66025404e-01   4.00000000e+00]]\n",
        "[[ 0.0015625   0.         -0.5         0.        ]\n",
        " [ 0.          0.00277778 -0.5         0.        ]\n",
        " [ 0.          0.          1.          0.        ]]\n"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.dot(extrinsicsCam2, np.linalg.inv(extrinsics))\n",
      "print extrinsics\n",
      "print extrinsicsCam2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.8660254   0.          0.5        -2.        ]\n",
        " [ 0.          1.          0.          0.        ]\n",
        " [-0.5         0.          0.8660254   0.53589838]\n",
        " [ 0.          0.          0.          1.        ]]\n",
        "[[ 1.  0.  0.  0.]\n",
        " [ 0.  1.  0.  0.]\n",
        " [ 0.  0.  1.  4.]\n",
        " [ 0.  0.  0.  1.]]\n",
        "[[ 0.8660254  0.         0.5        0.       ]\n",
        " [ 0.         1.         0.         0.       ]\n",
        " [-0.5        0.         0.8660254  4.       ]\n",
        " [ 0.         0.         0.         1.       ]]\n"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.dot(extrinsics[0:3, -1]-t, n.T)/d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.dot(extrinsics, H).shape\n",
      "print extrinsics.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(4, 4)\n",
        "(4, 4)\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.dot(t, n.T)/d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sift"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sift.process_image(dataFolder + '/mopeds/frame-00001.png', 'tmp.key')\n",
      "l1,d1 = sift.read_features_from_file('tmp.key')\n",
      "im = array(Image.open(dataFolder + '/mopeds/frame-00001.png'))\n",
      "sift.plot_features(im,l1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processed tmp.pgm\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = loadtxt('tmp2.key')\n",
      "l = f[:,:4]\n",
      "d = f[:,4:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def draw_circle(c,r):\n",
      "    t = arange(0,1.01,.01)*2*pi\n",
      "    x = r*cos(t) + c[0]\n",
      "    y = r*sin(t) + c[1]\n",
      "    plot(x,y,'b',linewidth=2)\n",
      "\n",
      "figure(); imshow(im)\n",
      "if False:\n",
      "    [draw_circle([p[0],p[1]],p[2]) for p in l]\n",
      "else:\n",
      "    plot(l[:,0],l[:,1],'ob')\n",
      "axis('off')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "(-100.0, 500.0, 400.0, -50.0)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
      "gray = np.float32(gray)\n",
      "\n",
      "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
      "# dst = cv2.dilate(dst,None)\n",
      "# Threshold for an optimal value, it may vary depending on the image.\n",
      "corners  = np.zeros(gray.shape)\n",
      "corners[dst>0.01*dst.max()]=255"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(); imshow(im)\n",
      "scatter(np.argwhere(corners == 255)[:, 1], np.argwhere(corners == 255)[:, 0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "<matplotlib.collections.PathCollection at 0x7fa5f83eb550>"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## read frames from sequence of images\n",
      "# sampleData = \"pendulum/\"\n",
      "sampleData = \"ribbon2/\"\n",
      "# sampleData = \"ribbon1_matted/\"\n",
      "# sampleData = \"little_palm1_cropped/\"\n",
      "# sampleData = \"ballAnimation/\"\n",
      "outputData = dataFolder+sampleData\n",
      "\n",
      "## Find pngs in sample data\n",
      "frames = glob.glob(dataFolder + sampleData + \"frame-*.png\")\n",
      "mattes = glob.glob(dataFolder + sampleData + \"matte-*.png\")\n",
      "frames = np.sort(frames)\n",
      "mattes = np.sort(mattes)#[0:len(frames)-10]\n",
      "numFrames = len(frames)\n",
      "frameSize = cv2.imread(frames[0]).shape\n",
      "print numFrames, len(mattes)\n",
      "\n",
      "lowThresh = 96\n",
      "highThresh = lowThresh*2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1280 1280\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = cv2.cvtColor(cv2.imread(frames[0]), cv2.COLOR_BGR2RGB)\n",
      "matte = cv2.cvtColor(cv2.imread(mattes[0]), cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "imgEdges = cv2.Canny(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), lowThresh, highThresh)\n",
      "matteEdges = cv2.Canny(matte, lowThresh, highThresh)\n",
      "matteEdges = cv2.dilate(matteEdges, np.ones((6,6),dtype=np.uint8))\n",
      "matteEdges = cv2.erode(matteEdges, np.ones((6,6),dtype=np.uint8))\n",
      "\n",
      "# figure(); imshow(imgEdges*(matte/255.0), interpolation='nearest')\n",
      "figure(); imshow(matteEdges, interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "<matplotlib.image.AxesImage at 0x7eff368e9a10>"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## find points on matte edges\n",
      "edgePoints = np.argwhere(matteEdges == np.max(matteEdges))\n",
      "## closes point to top-left (i.e.) [0, 0]\n",
      "startPoint = edgePoints[np.argmin(np.sum(edgePoints, axis=1)), :]\n",
      "print startPoint\n",
      "scatter(startPoint[1], startPoint[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[179 661]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "<matplotlib.collections.PathCollection at 0x7eff3697e5d0>"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "edgePoints"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "array([[161, 662],\n",
        "       [161, 663],\n",
        "       [162, 660],\n",
        "       ..., \n",
        "       [487, 647],\n",
        "       [487, 648],\n",
        "       [487, 649]])"
       ]
      }
     ],
     "prompt_number": 34
    }
   ],
   "metadata": {}
  }
 ]
}