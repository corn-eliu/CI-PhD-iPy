{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import scipy as sp\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import glob\n",
    "import itertools\n",
    "\n",
    "import scipy.sparse\n",
    "import PIL.Image\n",
    "import pyamg\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import opengm\n",
    "import soundfile as sf\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import shutil, errno\n",
    "\n",
    "def copyanything(src, dst):\n",
    "    try:\n",
    "        shutil.copytree(src, dst)\n",
    "    except OSError as exc: # python >2.5\n",
    "        if exc.errno == errno.ENOTDIR:\n",
    "            shutil.copy(src, dst)\n",
    "        else: raise\n",
    "\n",
    "\n",
    "DICT_SEQUENCE_NAME = 'semantic_sequence_name'\n",
    "DICT_BBOXES = 'bboxes'\n",
    "DICT_FOOTPRINTS = 'footprints' ## same as bboxes but it indicates the footprint of the sprite on the ground plane\n",
    "DICT_BBOX_ROTATIONS = 'bbox_rotations'\n",
    "DICT_BBOX_CENTERS = 'bbox_centers'\n",
    "DICT_FRAMES_LOCATIONS = 'frame_locs'\n",
    "DICT_MASK_LOCATION = 'frame_masks_location'\n",
    "DICT_SEQUENCE_FRAMES = 'sequence_frames'\n",
    "DICT_SEQUENCE_IDX = 'semantic_sequence_idx' # index of the instantiated sem sequence in the list of all used sem sequences for a synthesised sequence\n",
    "DICT_DESIRED_SEMANTICS = 'desired_semantics' # stores what the desired semantics are for a certain sprite \n",
    "#(I could index them by the frame when the toggle happened instead of using the below but maybe ordering is important and I would lose that using a dict)\n",
    "DICT_FRAME_SEMANTIC_TOGGLE = 'frame_semantic_toggle'# stores the frame index in the generated sequence when the desired semantics have changed\n",
    "DICT_ICON_TOP_LEFT = \"icon_top_left\"\n",
    "DICT_ICON_FRAME_KEY = \"icon_frame_key\"\n",
    "DICT_ICON_SIZE = \"icon_size\"\n",
    "DICT_REPRESENTATIVE_COLOR = 'representative_color'\n",
    "DICT_OFFSET = \"instance_offset\"\n",
    "DICT_SCALE = \"instance_scale\"\n",
    "DICT_FRAME_SEMANTICS = \"semantics_per_frame\"\n",
    "DICT_USED_SEQUENCES = \"used_semantic_sequences\"\n",
    "DICT_SEQUENCE_INSTANCES = \"sequence_instances\"\n",
    "DICT_SEQUENCE_BG = \"sequence_background_image\"\n",
    "DICT_SEQUENCE_LOCATION = \"sequence_location\"\n",
    "DICT_PATCHES_LOCATION = \"sequence_preloaded_patches_location\"\n",
    "DICT_TRANSITION_COSTS_LOCATION = \"sequence_precomputed_transition_costs_location\"\n",
    "\n",
    "GRAPH_MAX_COST = 10000000.0\n",
    "\n",
    "# dataPath = \"/home/ilisescu/PhD/data/\"\n",
    "# dataSet = \"havana/\"\n",
    "\n",
    "# dataPath = \"/media/ilisescu/Data1/PhD/data/\"\n",
    "# dataSet = \"clouds_subsample10/\"\n",
    "# dataSet = \"theme_park_cloudy/\"\n",
    "# dataSet = \"theme_park_sunny/\"\n",
    "# dataSet = \"wave1/\"\n",
    "# dataSet = \"wave1/\"\n",
    "formatString = \"{:05d}.png\"\n",
    "\n",
    "TL_IDX = 0\n",
    "TR_IDX = 1\n",
    "BR_IDX = 2\n",
    "BL_IDX = 3\n",
    "\n",
    "# <codecell>\n",
    "\n",
    "def multivariateNormal(data, mean, var, normalized = True) :\n",
    "    if (data.shape[0] != mean.shape[0] or np.any(data.shape[0] != np.array(var.shape)) \n",
    "        or len(var.shape) != 2 or var.shape[0] != var.shape[1]) :\n",
    "        raise Exception(\"Data shapes don't agree data(\" + np.string_(data.shape) + \") mean(\" + np.string_(mean.shape) + \n",
    "                        \") var(\" + np.string_(var.shape) + \")\")\n",
    "        \n",
    "    D = float(data.shape[0])\n",
    "    n = (1/(np.power(2.0*np.pi, D/2.0)*np.sqrt(np.linalg.det(var))))\n",
    "    if normalized :\n",
    "        p = n*np.exp(-0.5*np.sum(np.dot((data-mean).T, np.linalg.inv(var))*(data-mean).T, axis=-1))\n",
    "    else :\n",
    "        p = np.exp(-0.5*np.sum(np.dot((data-mean).T, np.linalg.inv(var))*(data-mean).T, axis=-1))\n",
    "        \n",
    "    return p\n",
    "\n",
    "def minusLogMultivariateNormal(data, mean, var, normalized = True) :\n",
    "    if (data.shape[0] != mean.shape[0] or np.any(data.shape[0] != np.array(var.shape)) \n",
    "        or len(var.shape) != 2 or var.shape[0] != var.shape[1]) :\n",
    "        raise Exception(\"Data shapes don't agree data(\" + np.string_(data.shape) + \") mean(\" + np.string_(mean.shape) + \n",
    "                        \") var(\" + np.string_(var.shape) + \")\")\n",
    "    \n",
    "    D = float(data.shape[0])\n",
    "    n = -0.5*np.log(np.linalg.det(var))-(D/2.0)*np.log(2.0*np.pi)\n",
    "    if normalized :\n",
    "        p = n -0.5*np.sum(np.dot((data-mean).T, np.linalg.inv(var))*(data-mean).T, axis=-1)\n",
    "    else :\n",
    "        p = -0.5*np.sum(np.dot((data-mean).T, np.linalg.inv(var))*(data-mean).T, axis=-1)\n",
    "        \n",
    "    return -p\n",
    "\n",
    "def vectorisedMinusLogMultiNormal(dataPoints, means, var, normalized = True) :\n",
    "    if (dataPoints.shape[1] != means.shape[1] or np.any(dataPoints.shape[1] != np.array(var.shape)) \n",
    "        or len(var.shape) != 2 or var.shape[0] != var.shape[1]) :\n",
    "        raise Exception(\"Data shapes don't agree data(\" + np.string_(dataPoints.shape) + \") mean(\" + np.string_(means.shape) + \n",
    "                        \") var(\" + np.string_(var.shape) + \")\")\n",
    "    \n",
    "    D = float(dataPoints.shape[1])\n",
    "    n = -0.5*np.log(np.linalg.det(var))-(D/2.0)*np.log(2.0*np.pi)\n",
    "    \n",
    "    ## this does 0.5*dot(dot(data-mean, varInv), data-mean)\n",
    "    varInv = np.linalg.inv(var)\n",
    "    dataMinusMean = dataPoints-means\n",
    "    \n",
    "    ps = []\n",
    "    for i in xrange(int(D)) :\n",
    "        ps.append(np.sum((dataMinusMean)*varInv[:, i], axis=-1))\n",
    "    \n",
    "    ps = np.array(ps).T\n",
    "    \n",
    "    ps = -0.5*np.sum(ps*(dataMinusMean), axis=-1)\n",
    "    \n",
    "    if normalized :\n",
    "        return n-ps\n",
    "    else :\n",
    "        return -ps\n",
    "\n",
    "# <codecell>\n",
    "\n",
    "## used for enlarging bbox used to decide size of patch around it (percentage)\n",
    "PATCH_BORDER = 0.4\n",
    "def getSpritePatch(sprite, frameKey, frameWidth, frameHeight) :\n",
    "    \"\"\"Computes sprite patch based on its bbox\n",
    "    \n",
    "        \\t  sprite      : dictionary containing relevant sprite data\n",
    "        \\t  frameKey    : the key of the frame the sprite patch is taken from\n",
    "        \\t  frameWidth  : width of original image\n",
    "        \\t  frameHeight : height of original image\n",
    "           \n",
    "        return: spritePatch, offset, patchSize,\n",
    "                [left, top, bottom, right] : array of booleans telling whether the expanded bbox touches the corresponding border of the image\"\"\"\n",
    "    \n",
    "    ## get the bbox for the current sprite frame, make it larger and find the rectangular patch to work with\n",
    "    ## boundaries of the patch [min, max]\n",
    "    \n",
    "    ## returns sprite patch based on bbox and returns it along with the offset [x, y] and it's size [rows, cols]\n",
    "    \n",
    "    ## make bbox bigger\n",
    "    largeBBox = sprite[DICT_BBOXES][frameKey].T\n",
    "    ## move to origin\n",
    "    largeBBox = np.dot(np.array([[-sprite[DICT_BBOX_CENTERS][frameKey][0], 1.0, 0.0], \n",
    "                                 [-sprite[DICT_BBOX_CENTERS][frameKey][1], 0.0, 1.0]]), \n",
    "                        np.vstack((np.ones((1, largeBBox.shape[1])), largeBBox)))\n",
    "    ## make bigger\n",
    "    largeBBox = np.dot(np.array([[0.0, 1.0 + PATCH_BORDER, 0.0], \n",
    "                                 [0.0, 0.0, 1.0 + PATCH_BORDER]]), \n",
    "                        np.vstack((np.ones((1, largeBBox.shape[1])), largeBBox)))\n",
    "    ## move back tooriginal center\n",
    "    largeBBox = np.dot(np.array([[sprite[DICT_BBOX_CENTERS][frameKey][0], 1.0, 0.0], \n",
    "                                 [sprite[DICT_BBOX_CENTERS][frameKey][1], 0.0, 1.0]]), \n",
    "                        np.vstack((np.ones((1, largeBBox.shape[1])), largeBBox)))\n",
    "    \n",
    "    xBounds = np.zeros(2); yBounds = np.zeros(2)\n",
    "    \n",
    "    ## make sure xBounds are in between 0 and width and yBounds are in between 0 and height\n",
    "    xBounds[0] = np.max((0, np.min(largeBBox[0, :])))\n",
    "    xBounds[1] = np.min((frameWidth, np.max(largeBBox[0, :])))\n",
    "    yBounds[0] = np.max((0, np.min(largeBBox[1, :])))\n",
    "    yBounds[1] = np.min((frameHeight, np.max(largeBBox[1, :])))\n",
    "    \n",
    "    offset = np.array([np.round(np.array([xBounds[0], yBounds[0]]))], dtype=int).T # [x, y]\n",
    "    patchSize = np.array(np.round(np.array([yBounds[1]-yBounds[0], xBounds[1]-xBounds[0]])), dtype=int) # [rows, cols]\n",
    "    \n",
    "    spritePatch = np.array(Image.open(sprite[DICT_FRAMES_LOCATIONS][frameKey]))[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1], :]\n",
    "    \n",
    "    return spritePatch, offset, patchSize, [np.min((largeBBox)[0, :]) > 0.0 ,\n",
    "                                            np.min((largeBBox)[1, :]) > 0.0 ,\n",
    "                                            np.max((largeBBox)[1, :]) < frameHeight,\n",
    "                                            np.max((largeBBox)[0, :]) < frameWidth]\n",
    "\n",
    "\n",
    "def getPatchPriors(bgPatch, spritePatch, offset, patchSize, sprite, frameKey, prevFrameKey = None, prevFrameAlphaLoc = \"\",\n",
    "                   prevMaskImportance = 0.8, prevMaskDilate = 13, prevMaskBlurSize = 31, prevMaskBlurSigma = 2.5,\n",
    "                   diffPatchImportance = 0.015, diffPatchMultiplier = 1000.0, useOpticalFlow = True, useDiffPatch = False) :\n",
    "    \"\"\"Computes priors for background and sprite patches\n",
    "    \n",
    "        \\t  bgPatch             : background patch\n",
    "        \\t  spritePatch         : sprite patch\n",
    "        \\t  offset              : [x, y] position of patches in the coordinate system of the original images\n",
    "        \\t  patchSize           : num of [rows, cols] per patches\n",
    "        \\t  sprite              : dictionary containing relevant sprite data\n",
    "        \\t  frameKey            : the key of the frame the sprite patch is taken from\n",
    "        \\t  prevFrameKey        : the key of the previous frame\n",
    "        \\t  prevFrameAlphaLoc   : location of the previous frame\n",
    "        \\t  prevMaskImportance  : balances the importance of the prior based on the remapped mask of the previous frame\n",
    "        \\t  prevMaskDilate      : amount of dilation to perform on previous frame's mask\n",
    "        \\t  prevMaskBlurSize    : size of the blurring kernel perfomed on previous frame's mask\n",
    "        \\t  prevMaskBlurSigma   : variance of the gaussian blurring perfomed on previous frame's mask\n",
    "        \\t  diffPatchImportance : balances the importance of the prior based on difference of patch to background\n",
    "        \\t  diffPatchMultiplier : multiplier that changes the scaling of the difference based cost\n",
    "        \\t  useOpticalFlow      : modify sprite prior by the mask of the previous frame\n",
    "        \\t  useDiffPatch        : modify bg prior by difference of sprite to bg patch\n",
    "           \n",
    "        return: bgPrior, spritePrior\"\"\"\n",
    "    \n",
    "    ## get uniform prior for bg patch\n",
    "    bgPrior = -np.log(np.ones(patchSize)/np.prod(patchSize))\n",
    "    \n",
    "    ## get prior for sprite patch\n",
    "    spritePrior = np.zeros(patchSize)\n",
    "    xs = np.ndarray.flatten(np.arange(patchSize[1], dtype=float).reshape((patchSize[1], 1)).repeat(patchSize[0], axis=-1))\n",
    "    ys = np.ndarray.flatten(np.arange(patchSize[0], dtype=float).reshape((1, patchSize[0])).repeat(patchSize[1], axis=0))\n",
    "    data = np.vstack((xs.reshape((1, len(xs))), ys.reshape((1, len(ys)))))\n",
    "    \n",
    "    ## get covariance and means of prior on patch by using the bbox\n",
    "    spriteBBox = sprite[DICT_BBOXES][frameKey].T\n",
    "    segment1 = spriteBBox[:, 0] - spriteBBox[:, 1]\n",
    "    segment2 = spriteBBox[:, 1] - spriteBBox[:, 2]\n",
    "    sigmaX = np.linalg.norm(segment1)/3.7\n",
    "    sigmaY = np.linalg.norm(segment2)/3.7\n",
    "    \n",
    "    rotRadians = sprite[DICT_BBOX_ROTATIONS][frameKey]\n",
    "    \n",
    "    rotMat = np.array([[np.cos(rotRadians), -np.sin(rotRadians)], [np.sin(rotRadians), np.cos(rotRadians)]])\n",
    "    \n",
    "    means = np.reshape(sprite[DICT_BBOX_CENTERS][frameKey], (2, 1)) - offset\n",
    "    covs = np.dot(np.dot(rotMat.T, np.array([[sigmaX**2, 0.0], [0.0, sigmaY**2]])), rotMat)\n",
    "    \n",
    "    spritePrior = np.reshape(minusLogMultivariateNormal(data, means, covs, True), patchSize, order='F')\n",
    "    \n",
    "    ## change the spritePrior using optical flow stuff\n",
    "    if useOpticalFlow and prevFrameKey != None :\n",
    "        prevFrameName = sprite[DICT_FRAMES_LOCATIONS][prevFrameKey].split('/')[-1]\n",
    "        nextFrameName = sprite[DICT_FRAMES_LOCATIONS][frameKey].split('/')[-1]\n",
    "        \n",
    "        if os.path.isfile(prevFrameAlphaLoc+prevFrameName) :\n",
    "            alpha = np.array(Image.open(prevFrameAlphaLoc+prevFrameName))[:, :, -1]/255.0\n",
    "\n",
    "            flow = cv2.calcOpticalFlowFarneback(cv2.cvtColor(np.array(Image.open(dataPath+dataSet+nextFrameName)), cv2.COLOR_RGB2GRAY), \n",
    "                                                cv2.cvtColor(np.array(Image.open(dataPath+dataSet+prevFrameName)), cv2.COLOR_RGB2GRAY), \n",
    "                                                0.5, 3, 15, 3, 5, 1.1, 0)\n",
    "        \n",
    "            ## remap alpha according to flow\n",
    "            remappedFg = cv2.remap(alpha, flow[:, :, 0]+allXs, flow[:, :, 1]+allYs, cv2.INTER_LINEAR)\n",
    "            ## get patch\n",
    "            remappedFgPatch = remappedFg[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1]]\n",
    "            remappedFgPatch = cv2.GaussianBlur(cv2.morphologyEx(remappedFgPatch, cv2.MORPH_DILATE, \n",
    "                                                                cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (prevMaskDilate, prevMaskDilate))), \n",
    "                                               (prevMaskBlurSize, prevMaskBlurSize), prevMaskBlurSigma)\n",
    "\n",
    "            spritePrior = (1.0-prevMaskImportance)*spritePrior + prevMaskImportance*(-np.log((remappedFgPatch+0.01)/np.sum(remappedFgPatch+0.01)))\n",
    "    \n",
    "    \n",
    "    if useDiffPatch :\n",
    "        ## change the background prior to give higher cost for pixels to be classified as background if the difference between bgPatch and spritePatch is high\n",
    "        diffPatch = np.reshape(vectorisedMinusLogMultiNormal(spritePatch.reshape((np.prod(patchSize), 3)), \n",
    "                                                             bgPatch.reshape((np.prod(patchSize), 3)), \n",
    "                                                             np.eye(3)*diffPatchMultiplier, True), patchSize)\n",
    "        bgPrior = (1.0-diffPatchImportance)*bgPrior + diffPatchImportance*diffPatch\n",
    "        \n",
    "    \n",
    "    return bgPrior, spritePrior\n",
    "\n",
    "# <codecell>\n",
    "\n",
    "## from https://github.com/fbessho/PyPoi/blob/master/pypoi/poissonblending.py\n",
    "def blend(img_target, img_source, img_mask, offset=(0, 0)):\n",
    "    # compute regions to be blended\n",
    "    region_source = (\n",
    "        max(-offset[0], 0),\n",
    "        max(-offset[1], 0),\n",
    "        min(img_target.shape[0] - offset[0], img_source.shape[0]),\n",
    "        min(img_target.shape[1] - offset[1], img_source.shape[1]))\n",
    "    region_target = (\n",
    "        max(offset[0], 0),\n",
    "        max(offset[1], 0),\n",
    "        min(img_target.shape[0], img_source.shape[0] + offset[0]),\n",
    "        min(img_target.shape[1], img_source.shape[1] + offset[1]))\n",
    "    region_size = (region_source[2] - region_source[0], region_source[3] - region_source[1])\n",
    "\n",
    "    # clip and normalize mask image\n",
    "    img_mask = img_mask[region_source[0]:region_source[2], region_source[1]:region_source[3]]\n",
    "    img_mask[img_mask == 0] = False\n",
    "    img_mask[img_mask != False] = True\n",
    "\n",
    "    # create coefficient matrix\n",
    "    A = scipy.sparse.identity(np.prod(region_size), format='lil')\n",
    "    for y in range(region_size[0]):\n",
    "        for x in range(region_size[1]):\n",
    "            if img_mask[y, x]:\n",
    "                index = x + y * region_size[1]\n",
    "                A[index, index] = 4\n",
    "                if index + 1 < np.prod(region_size):\n",
    "                    A[index, index + 1] = -1\n",
    "                if index - 1 >= 0:\n",
    "                    A[index, index - 1] = -1\n",
    "                if index + region_size[1] < np.prod(region_size):\n",
    "                    A[index, index + region_size[1]] = -1\n",
    "                if index - region_size[1] >= 0:\n",
    "                    A[index, index - region_size[1]] = -1\n",
    "    A = A.tocsr()\n",
    "    \n",
    "    # create poisson matrix for b\n",
    "    P = pyamg.gallery.poisson(img_mask.shape)\n",
    "\n",
    "    startTime = time.time()\n",
    "    # for each layer (ex. RGB)\n",
    "    for num_layer in range(img_target.shape[2]):\n",
    "        # get subimages\n",
    "        t = img_target[region_target[0]:region_target[2], region_target[1]:region_target[3], num_layer]\n",
    "        s = img_source[region_source[0]:region_source[2], region_source[1]:region_source[3], num_layer]\n",
    "        t = t.flatten()\n",
    "        s = s.flatten()\n",
    "\n",
    "        # create b\n",
    "        b = P * s\n",
    "        for y in range(region_size[0]):\n",
    "            for x in range(region_size[1]):\n",
    "                if not img_mask[y, x]:\n",
    "                    index = x + y * region_size[1]\n",
    "                    b[index] = t[index]\n",
    "\n",
    "        # solve Ax = b\n",
    "        x = pyamg.solve(A, b, verb=False, tol=1e-10)\n",
    "\n",
    "        # assign x to target image\n",
    "        x = np.reshape(x, region_size)\n",
    "        x[x > 255] = 255\n",
    "        x[x < 0] = 0\n",
    "        x = np.array(x, img_target.dtype)\n",
    "        img_target[region_target[0]:region_target[2], region_target[1]:region_target[3], num_layer] = x\n",
    "\n",
    "    return img_target\n",
    "\n",
    "# <codecell>\n",
    "\n",
    "def getPoissonBlended(backgroundLoc, frameLoc, maskLoc, fgOffset) :\n",
    "#     print \"BG\", backgroundLoc, \"FRAME\", frameLoc, \"MASK\", maskLoc\n",
    "    im = np.array(Image.open(maskLoc))\n",
    "    imgSize = im.shape[0:2]\n",
    "\n",
    "    visiblePixelsGlobalIndices = np.argwhere(im[:, :, -1] != 0)\n",
    "    topLeftPos = np.min(visiblePixelsGlobalIndices, axis=0)\n",
    "    patchSize = np.max(visiblePixelsGlobalIndices, axis=0) - topLeftPos + 1\n",
    "#         topLeftPos = np.copy(preloadedSpritePatches[spriteIdx][frameIdx]['top_left_pos'])\n",
    "#         patchSize = np.copy(preloadedSpritePatches[spriteIdx][frameIdx]['patch_size'])\n",
    "#         visiblePixelsGlobalIndices = preloadedSpritePatches[spriteIdx][frameIdx]['visible_indices']+topLeftPos\n",
    "    \n",
    "    \n",
    "    ## when the mask touches the border of the patch there's some weird white halos going on so I enlarge the patch slightly\n",
    "    ## not sure what happens when the patch goes outside of the bounds of the original image...\n",
    "    topLeftPos -= 1\n",
    "    patchSize += 2\n",
    "    ## make sure we're within bounds\n",
    "    topLeftPos[np.argwhere(topLeftPos < 0)] = 0\n",
    "    patchSize[(topLeftPos+patchSize) > imgSize] += (imgSize-(topLeftPos+patchSize))[(topLeftPos+patchSize) > imgSize]\n",
    "\n",
    "\n",
    "    img_target = np.asarray(Image.open(backgroundLoc))[:, :, 0:3]\n",
    "    img_target.flags.writeable = True\n",
    "\n",
    "    img_mask = np.asarray(Image.open(maskLoc))[topLeftPos[0]:topLeftPos[0]+patchSize[0], topLeftPos[1]:topLeftPos[1]+patchSize[1], -1]\n",
    "    img_mask.flags.writeable = True\n",
    "    ## make sure that borders of mask are assigned to bg\n",
    "    img_mask[0, :] = 0; img_mask[-1, :] = 0; img_mask[:, 0] = 0; img_mask[:, -1] = 0\n",
    "\n",
    "    img_source = np.asarray(Image.open(frameLoc))[topLeftPos[0]:topLeftPos[0]+patchSize[0], topLeftPos[1]:topLeftPos[1]+patchSize[1], :]\n",
    "\n",
    "#         sourceImg = np.asarray(PIL.Image.open(dataPath+dataSet+spriteName+inputFolderSuffix+\"/\"+frameName))[topLeftPos[0]:topLeftPos[0]+patchSize[0], \n",
    "#                                                                                                             topLeftPos[1]:topLeftPos[1]+patchSize[1], :-1]\n",
    "#         mask = np.copy(img_mask.reshape((patchSize[0], patchSize[1], 1)))/255.0\n",
    "\n",
    "#         img_source = np.array(sourceImg*mask + np.asarray(PIL.Image.open(dataPath+dataSet+\"median.png\"))[topLeftPos[0]:topLeftPos[0]+patchSize[0], \n",
    "#                                                                                                          topLeftPos[1]:topLeftPos[1]+patchSize[1], :]*(1.0-mask), dtype=uint8)\n",
    "\n",
    "\n",
    "    img_source.flags.writeable = True\n",
    "\n",
    "#     figure(); imshow(np.copy(img_target))\n",
    "#     figure(); imshow(np.copy(img_source))\n",
    "#     figure(); imshow(np.copy(img_mask))\n",
    "#     print fgOffset, offset\n",
    "    \n",
    "    img_ret = blend(img_target, img_source, img_mask, offset=(topLeftPos[0]+fgOffset[0], topLeftPos[1]+fgOffset[1]))\n",
    "\n",
    "\n",
    "    maskedFinal = np.zeros((img_target.shape[0], img_target.shape[1], 4), dtype=np.uint8)\n",
    "    maskedFinal[visiblePixelsGlobalIndices[:, 0], visiblePixelsGlobalIndices[:, 1], :-1] = img_ret[visiblePixelsGlobalIndices[:, 0]+fgOffset[0], \n",
    "                                                                                                   visiblePixelsGlobalIndices[:, 1]+fgOffset[1], :]\n",
    "    maskedFinal[visiblePixelsGlobalIndices[:, 0], visiblePixelsGlobalIndices[:, 1], -1] = 255\n",
    "\n",
    "#     PIL.Image.fromarray(np.uint8(maskedFinal)).save(dataPath+dataSet+spriteName+inputFolderSuffix+\"-blended/\"+frameName)\n",
    "#         figure(); imshow(maskedFinal)\n",
    "#     figure(); imshow(img_target)\n",
    "    result = np.copy(np.uint8(maskedFinal))\n",
    "#     figure(); imshow(result)\n",
    "    del img_mask\n",
    "    del img_source\n",
    "    del img_target\n",
    "    del maskedFinal\n",
    "    del img_ret\n",
    "    return result\n",
    "\n",
    "def compareBBoxes(x, y, verbose=False) :\n",
    "    xBBoxLocs = np.argwhere(x==1)\n",
    "    yBBoxLocs = np.argwhere(y==1)\n",
    "    xColRange = [np.min(xBBoxLocs[:, 1]), np.max(xBBoxLocs[:, 1])]\n",
    "    yColRange = [np.min(yBBoxLocs[:, 1]), np.max(yBBoxLocs[:, 1])]\n",
    "    if verbose :\n",
    "        print xColRange, yColRange, len(xBBoxLocs), len(yBBoxLocs)\n",
    "    \n",
    "    overlapColRange = list(set(range(xColRange[0], xColRange[1]+1)).intersection(range(yColRange[0], yColRange[1]+1)))\n",
    "    \n",
    "    if len(overlapColRange) == 0 :\n",
    "        if verbose :\n",
    "            print \"returning not overlapping\"\n",
    "        return 0\n",
    "    overlapColRange = [np.min(overlapColRange), np.max(overlapColRange)]\n",
    "        \n",
    "    if verbose :\n",
    "        print \"overlap\", overlapColRange\n",
    "        \n",
    "    validXBBoxLocs = np.all([xBBoxLocs[:, 1] >= overlapColRange[0], xBBoxLocs[:, 1] <= overlapColRange[1]], axis=0)\n",
    "    validYBBoxLocs = np.all([yBBoxLocs[:, 1] >= overlapColRange[0], yBBoxLocs[:, 1] <= overlapColRange[1]], axis=0)\n",
    "    \n",
    "    if np.max(xBBoxLocs[validXBBoxLocs, 0]) > np.max(yBBoxLocs[validYBBoxLocs, 0]) :\n",
    "        if verbose :\n",
    "            print \"x > y\"\n",
    "        return 1\n",
    "    elif np.max(xBBoxLocs[validXBBoxLocs, 0]) < np.max(yBBoxLocs[validYBBoxLocs, 0]) :\n",
    "        if verbose :\n",
    "            print \"x < y\"\n",
    "        return -1\n",
    "    else :\n",
    "        if verbose :\n",
    "            print \"x == y\"\n",
    "        return 0\n",
    "\n",
    "\n",
    "if len(sys.argv) != 5 :\n",
    "        print \"To run specify parameters: [base/directory/of/synthesised_sequence.npy threshold1 threshold2 doBlendImages]\"\n",
    "        print \"values for threshold1 are above 1 and values for threshold2 are between 0 and 1\"\n",
    "        print \"values for doBlendImages are 0 if False and 1 if True\"\n",
    "else :\n",
    "        print sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4]\n",
    "    \n",
    "baseLoc = np.string_(sys.argv[1])\n",
    "doComputePoisson = bool(sys.argv[4])\n",
    "\n",
    "if doComputePoisson :\n",
    "    if not os.path.isdir(baseLoc+\"blended/\") :\n",
    "        os.mkdir(baseLoc+\"blended/\")\n",
    "\n",
    "    synthSeq = np.load(baseLoc+\"synthesised_sequence.npy\").item()\n",
    "    bgLoc = synthSeq[DICT_SEQUENCE_BG]\n",
    "\n",
    "    bgImage = np.array(Image.open(bgLoc))[:, :, 0:3]\n",
    "\n",
    "    semanticSequences = []\n",
    "    for usedSeqLoc in synthSeq[DICT_USED_SEQUENCES] :\n",
    "        semanticSequences.append(np.load(usedSeqLoc).item())\n",
    "\n",
    "    minFrames = 10000\n",
    "    for i in xrange(len(synthSeq[DICT_SEQUENCE_INSTANCES])) :\n",
    "        minFrames = np.min((minFrames, len(synthSeq[DICT_SEQUENCE_INSTANCES][i][DICT_SEQUENCE_FRAMES])))\n",
    "\n",
    "    maxFramesToRender = 2000\n",
    "\n",
    "\n",
    "    avgTime = 0.0\n",
    "    for iterNum, f in enumerate(np.arange(minFrames)[0:]) :\n",
    "        t = time.time()\n",
    "        for sIdx, seq in enumerate(synthSeq[DICT_SEQUENCE_INSTANCES][0:]) :\n",
    "            seq1Idx = seq[DICT_SEQUENCE_IDX]\n",
    "            frame1Idx = seq[DICT_SEQUENCE_FRAMES][f]\n",
    "\n",
    "    #         ##### HACK for tetris necessary because I mirrored the sequence #####\n",
    "    #         oldLength = (len(semanticSequences[seq1Idx][DICT_BBOXES].keys())+1)/2\n",
    "    #         frame1Idx = np.concatenate((arange(oldLength), arange(oldLength-2, -1, -1)))[frame1Idx]\n",
    "    #         #####################################################################\n",
    "\n",
    "            if frame1Idx < len(semanticSequences[seq1Idx][DICT_BBOXES].keys()) :\n",
    "                frame1Key = np.sort(semanticSequences[seq1Idx][DICT_BBOXES].keys())[frame1Idx]\n",
    "                frame1Offset = seq[DICT_OFFSET]\n",
    "                frame1Scale = seq[DICT_SCALE]\n",
    "            else :\n",
    "                frame1Key = -1\n",
    "                frame1Offset = seq[DICT_OFFSET]\n",
    "                frame1Scale = seq[DICT_SCALE]\n",
    "                \n",
    "            if not os.path.isfile(baseLoc+\"blended/frame-{0:05}-\".format(frame1Key) + \"{0:02}.png\".format(sIdx)) :\n",
    "\n",
    "                if frame1Key in semanticSequences[seq1Idx][DICT_FRAMES_LOCATIONS] :\n",
    "\n",
    "                    spritePatch, offset, patchSize, touchedBorders = getSpritePatch(semanticSequences[seq1Idx], frame1Key, bgImage.shape[1], bgImage.shape[0])\n",
    "\n",
    "                    sprite1 = getPoissonBlended(bgLoc,\n",
    "                                                \"/\".join(semanticSequences[seq1Idx][DICT_MASK_LOCATION].split(\"/\")[:-2])+\"/frame-{0:05}.png\".format(frame1Key+1),\n",
    "                                                semanticSequences[seq1Idx][DICT_MASK_LOCATION]+\"frame-{0:05}.png\".format(frame1Key+1), frame1Offset[::-1])\n",
    "\n",
    "\n",
    "                    ## dealing with scale and offsets WELL NO SCALE REALLY BUT FUCK IT\n",
    "                    tmp = np.zeros_like(sprite1)\n",
    "                    if tmp[offset[1]+frame1Offset[1]:offset[1]+frame1Offset[1]+patchSize[0],\n",
    "                        offset[0]+frame1Offset[0]:offset[0]+frame1Offset[0]+patchSize[1], :].shape == sprite1[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1], :].shape :\n",
    "                        \n",
    "                        tmp[offset[1]+frame1Offset[1]:offset[1]+frame1Offset[1]+patchSize[0],\n",
    "                            offset[0]+frame1Offset[0]:offset[0]+frame1Offset[0]+patchSize[1], :] = sprite1[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1], :]\n",
    "                    sprite1 = np.copy(tmp)\n",
    "                    del tmp\n",
    "                    Image.fromarray(sprite1.astype(np.uint8)).save(baseLoc+\"blended/frame-{0:05}-\".format(frame1Key) + \"{0:02}.png\".format(sIdx))\n",
    "\n",
    "        avgTime = (avgTime*iterNum + time.time()-t)/(iterNum+1)\n",
    "        remainingTime = avgTime*(maxFramesToRender-iterNum-1)/60.0\n",
    "        sys.stdout.write('\\r' + \"Done image \" + np.string_(iterNum) + \" of \" + np.string_(maxFramesToRender) +\n",
    "                         \" (avg time: \" + np.string_(avgTime) + \" secs --- remaining: \" +\n",
    "                         np.string_(int(np.floor(remainingTime))) + \":\" + np.string_(int((remainingTime - np.floor(remainingTime))*60)) + \")\")\n",
    "        sys.stdout.flush()\n",
    "    print \n",
    "    print \"done\"\n",
    "\n",
    "\n",
    "synthSeq = np.load(baseLoc+\"synthesised_sequence.npy\").item()\n",
    "bgLoc = synthSeq[DICT_SEQUENCE_BG]\n",
    "\n",
    "bgImage = np.array(Image.open(bgLoc))[:, :, 0:3]\n",
    "\n",
    "semanticSequences = []\n",
    "for usedSeqLoc in synthSeq[DICT_USED_SEQUENCES] :\n",
    "    semanticSequences.append(np.load(usedSeqLoc).item())\n",
    "\n",
    "minFrames = 10000\n",
    "for i in xrange(len(synthSeq[DICT_SEQUENCE_INSTANCES])) :\n",
    "    minFrames = np.min((minFrames, len(synthSeq[DICT_SEQUENCE_INSTANCES][i][DICT_SEQUENCE_FRAMES])))\n",
    "\n",
    "\n",
    "## super mario planes\n",
    "# thresh = 4.5\n",
    "# alpha = 0.15\n",
    "\n",
    "## wave\n",
    "# thresh = 4.0\n",
    "# alpha = 0.25\n",
    "\n",
    "thresh = float(sys.argv[2])\n",
    "alpha = float(sys.argv[3])\n",
    "\n",
    "\n",
    "kSize = 15\n",
    "sigma = 11\n",
    "\n",
    "usePoisson = bool(sys.argv[4])\n",
    "\n",
    "maxFramesToRender = 2000\n",
    "\n",
    "\n",
    "avgTime = 0.0\n",
    "for iterNum, f in enumerate(np.arange(minFrames)[:maxFramesToRender]) :\n",
    "    \n",
    "#     maxYs = []\n",
    "#     for seqInstance in synthSeq[DICT_SEQUENCE_INSTANCES] :\n",
    "#         seqIdx = seqInstance[DICT_SEQUENCE_IDX]\n",
    "#         frameIdx = seqInstance[DICT_SEQUENCE_FRAMES][f]\n",
    "#         if frameIdx < len(semanticSequences[seqIdx][DICT_BBOXES].keys()) :\n",
    "#             frameKey = np.sort(semanticSequences[seqIdx][DICT_BBOXES].keys())[frameIdx]\n",
    "#             maxYs.append(np.max(semanticSequences[seqIdx][DICT_BBOXES][frameKey][:, 1]))\n",
    "#         else :\n",
    "#             maxYs.append(0.0)\n",
    "#     print \"sequencesOrder\", maxYs, np.argsort(maxYs)\n",
    "#     sequencesOrder = np.argsort(maxYs)\n",
    "    \n",
    "    renderedBBoxes = []\n",
    "    instancesToRender = []\n",
    "    for i, seqInstance in enumerate(synthSeq[DICT_SEQUENCE_INSTANCES]) :\n",
    "        seqIdx = seqInstance[DICT_SEQUENCE_IDX]\n",
    "        frameIdx = seqInstance[DICT_SEQUENCE_FRAMES][f]\n",
    "        if frameIdx >= 0 and frameIdx < len(semanticSequences[seqIdx][DICT_FRAMES_LOCATIONS].keys()) :\n",
    "            frameKey = np.sort(semanticSequences[seqIdx][DICT_FRAMES_LOCATIONS].keys())[frameIdx]\n",
    "            if frameKey in semanticSequences[seqIdx][DICT_BBOXES].keys() :\n",
    "                img = np.zeros((bgImage.shape[0], bgImage.shape[1]), np.uint8)\n",
    "                cv2.fillConvexPoly(img, semanticSequences[seqIdx][DICT_BBOXES][frameKey].astype(int)[[0, 1, 2, 3, 0], :], 1)\n",
    "                renderedBBoxes.append(np.copy(img))\n",
    "                instancesToRender.append(i)\n",
    "#                 gwv.showCustomGraph(img)\n",
    "                \n",
    "    sequencesOrder = [i[0] for i in sorted(enumerate(renderedBBoxes), key=lambda x:x[1], cmp=compareBBoxes)]\n",
    "    sequencesOrder = np.array(instancesToRender)[sequencesOrder]\n",
    "#     print sequencesOrder\n",
    "    \n",
    "    t = time.time()\n",
    "    if len(sequencesOrder) > 0 :\n",
    "    #     outputFrame = np.zeros((bgImage.shape[0], bgImage.shape[1], 4), np.uint8)\n",
    "        seq1Idx = synthSeq[DICT_SEQUENCE_INSTANCES][sequencesOrder[0]][DICT_SEQUENCE_IDX]\n",
    "        frame1Idx = synthSeq[DICT_SEQUENCE_INSTANCES][sequencesOrder[0]][DICT_SEQUENCE_FRAMES][f]    \n",
    "\n",
    "        ##### HACK for tetris necessary because I mirrored the sequence #####\n",
    "    #     oldLength = (len(semanticSequences[seq1Idx][DICT_BBOXES].keys())+1)/2\n",
    "    # #     print \"la\", frame1Idx, np.concatenate((arange(oldLength), arange(oldLength-2, -1, -1))),\n",
    "    #     frame1Idx = np.concatenate((arange(oldLength), arange(oldLength-2, -1, -1)))[frame1Idx]\n",
    "    # #     print frame1Idx\n",
    "        #####################################################################\n",
    "\n",
    "        if frame1Idx >= 0 and frame1Idx < len(semanticSequences[seq1Idx][DICT_FRAMES_LOCATIONS].keys()) :\n",
    "            frame1Key = np.sort(semanticSequences[seq1Idx][DICT_FRAMES_LOCATIONS].keys())[frame1Idx]\n",
    "            if frame1Key not in semanticSequences[seq1Idx][DICT_BBOXES].keys() :\n",
    "                frame1Key = -1\n",
    "        else :\n",
    "            frame1Key = -1\n",
    "\n",
    "        frame1Offset = synthSeq[DICT_SEQUENCE_INSTANCES][sequencesOrder[0]][DICT_OFFSET]\n",
    "        frame1Scale = synthSeq[DICT_SEQUENCE_INSTANCES][sequencesOrder[0]][DICT_SCALE]\n",
    "\n",
    "        if frame1Key in semanticSequences[seq1Idx][DICT_FRAMES_LOCATIONS] :\n",
    "\n",
    "            spritePatch, offset, patchSize, touchedBorders = getSpritePatch(semanticSequences[seq1Idx], frame1Key, bgImage.shape[1], bgImage.shape[0])\n",
    "            bgPrior, spritePrior = getPatchPriors(bgImage[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1], :], \n",
    "                                                  spritePatch, offset, patchSize, semanticSequences[seq1Idx], frame1Key)\n",
    "            fullSprite1Prior = np.zeros(bgImage.shape[0:2])\n",
    "            fullSprite1Prior[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1]] = np.copy(1.0-spritePrior/np.max(spritePrior))\n",
    "            fullSprite1Prior /= np.max(fullSprite1Prior)\n",
    "\n",
    "            ## dealing with scale and offsets WELL NO SCALE REALLY BUT FUCK IT\n",
    "            hasLoaded = False\n",
    "            if usePoisson :\n",
    "                if semanticSequences[seq1Idx][DICT_MASK_LOCATION]+\"blended/frame-{0:05}.png\".format(frame1Key+1) :\n",
    "                    sprite1 = np.array(Image.open(semanticSequences[seq1Idx][DICT_MASK_LOCATION]+\"blended/frame-{0:05}.png\".format(frame1Key+1)))\n",
    "                else :\n",
    "                    if os.path.isfile(baseLoc+\"blended/frame-{0:05}-\".format(frame1Key) + \"{0:02}.png\".format(sequencesOrder[0])) :\n",
    "                        sprite1 = np.array(Image.open(baseLoc+\"blended/frame-{0:05}-\".format(frame1Key) + \"{0:02}.png\".format(sequencesOrder[0])))\n",
    "        #                 print \"loading\", 0\n",
    "                        hasLoaded = True\n",
    "                    else :\n",
    "                        sprite1 = getPoissonBlended(bgLoc,\n",
    "                                                    \"/\".join(semanticSequences[seq1Idx][DICT_MASK_LOCATION].split(\"/\")[:-2])+\"/frame-{0:05}.png\".format(frame1Key+1),\n",
    "                                                    semanticSequences[seq1Idx][DICT_MASK_LOCATION]+\"frame-{0:05}.png\".format(frame1Key+1), frame1Offset[::-1])\n",
    "            else :\n",
    "                sprite1 = np.array(Image.open(semanticSequences[seq1Idx][DICT_MASK_LOCATION]+\"frame-{0:05}.png\".format(frame1Key+1)))\n",
    "\n",
    "            outputFrame = sprite1\n",
    "            outputPrior = fullSprite1Prior\n",
    "\n",
    "            if not hasLoaded :\n",
    "                tmp = np.zeros_like(outputFrame)\n",
    "                tmp[offset[1]+frame1Offset[1]:offset[1]+frame1Offset[1]+patchSize[0],\n",
    "                    offset[0]+frame1Offset[0]:offset[0]+frame1Offset[0]+patchSize[1], :] = outputFrame[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1], :]\n",
    "                outputFrame = np.copy(tmp)\n",
    "                del tmp\n",
    "\n",
    "            tmp = np.zeros_like(outputPrior)\n",
    "            tmp[offset[1]+frame1Offset[1]:offset[1]+frame1Offset[1]+patchSize[0],\n",
    "                offset[0]+frame1Offset[0]:offset[0]+frame1Offset[0]+patchSize[1]] = outputPrior[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1]]\n",
    "            outputPrior = np.copy(tmp)\n",
    "            del tmp\n",
    "\n",
    "        else :\n",
    "            outputFrame = np.zeros((bgImage.shape[0], bgImage.shape[1], 4), np.uint8)\n",
    "            outputPrior = np.zeros(bgImage.shape[0:2])\n",
    "\n",
    "        tmpAssignment = np.zeros(bgImage.shape[0:2])\n",
    "\n",
    "    #     for sIdx, seq in zip(arange(1, len(synthSeq[DICT_SEQUENCE_INSTANCES])), synthSeq[DICT_SEQUENCE_INSTANCES][1:]) :\n",
    "        for sIdx in sequencesOrder[1:] : #[1, 0] : #[1, 2, 3, 14, 13, 4, 5, 6, 7, 8, 9, 10, 11, 12] :\n",
    "            seq = synthSeq[DICT_SEQUENCE_INSTANCES][sIdx]\n",
    "\n",
    "            seq2Idx = seq[DICT_SEQUENCE_IDX]\n",
    "            frame2Idx = seq[DICT_SEQUENCE_FRAMES][f]\n",
    "            ##### HACK for tetris necessary because I mirrored the sequence #####\n",
    "    #         oldLength = (len(semanticSequences[seq2Idx][DICT_BBOXES].keys())+1)/2\n",
    "    # #         print \"la\", frame2Idx, np.concatenate((arange(oldLength), arange(oldLength-2, -1, -1))),\n",
    "    #         frame2Idx = np.concatenate((arange(oldLength), arange(oldLength-2, -1, -1)))[frame2Idx]\n",
    "    # #         print frame2Idx\n",
    "            #####################################################################\n",
    "\n",
    "            if frame2Idx >= 0 and frame2Idx < len(semanticSequences[seq2Idx][DICT_FRAMES_LOCATIONS].keys()) :\n",
    "                frame2Key = np.sort(semanticSequences[seq2Idx][DICT_FRAMES_LOCATIONS].keys())[frame2Idx]\n",
    "                if frame2Key not in semanticSequences[seq2Idx][DICT_BBOXES].keys() :\n",
    "                    frame2Key = -1\n",
    "            else :\n",
    "                frame2Key = -1\n",
    "\n",
    "            frame2Offset = seq[DICT_OFFSET]\n",
    "            frame2Scale = seq[DICT_SCALE]\n",
    "\n",
    "            if frame2Key in semanticSequences[seq2Idx][DICT_FRAMES_LOCATIONS] :\n",
    "\n",
    "    #             print frame2Key, semanticSequences[seq2Idx][DICT_MASK_LOCATION]+\"frame-{0:05}.png\".format(frame2Key+1), frame2Offset, frame2Scale\n",
    "    #             print \n",
    "\n",
    "\n",
    "                spritePatch, offset, patchSize, touchedBorders = getSpritePatch(semanticSequences[seq2Idx], frame2Key, bgImage.shape[1], bgImage.shape[0])\n",
    "                bgPrior, spritePrior = getPatchPriors(bgImage[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1], :], \n",
    "                                                      spritePatch, offset, patchSize, semanticSequences[seq2Idx], frame2Key)\n",
    "                fullSprite2Prior = np.zeros(bgImage.shape[0:2])\n",
    "                fullSprite2Prior[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1]] = np.copy(1.0-spritePrior/np.max(spritePrior))\n",
    "                fullSprite2Prior /= np.max(fullSprite2Prior)\n",
    "\n",
    "                hasLoaded = False\n",
    "                if usePoisson :\n",
    "                    if semanticSequences[seq2Idx][DICT_MASK_LOCATION]+\"blended/frame-{0:05}.png\".format(frame2Key+1) :\n",
    "                        sprite2 = np.array(Image.open(semanticSequences[seq2Idx][DICT_MASK_LOCATION]+\"blended/frame-{0:05}.png\".format(frame2Key+1)))\n",
    "                    else :\n",
    "                        if os.path.isfile(baseLoc+\"blended/frame-{0:05}-\".format(frame2Key) + \"{0:02}.png\".format(sIdx)) :\n",
    "                            sprite2 = np.array(Image.open(baseLoc+\"blended/frame-{0:05}-\".format(frame2Key) + \"{0:02}.png\".format(sIdx)))\n",
    "        #                     print \"loading\", sIdx; sys.stdout.flush()\n",
    "                            hasLoaded = True\n",
    "                        else :\n",
    "                            sprite2 = getPoissonBlended(bgLoc,\n",
    "                                                        \"/\".join(semanticSequences[seq2Idx][DICT_MASK_LOCATION].split(\"/\")[:-2])+\"/frame-{0:05}.png\".format(frame2Key+1),\n",
    "                                                        semanticSequences[seq2Idx][DICT_MASK_LOCATION]+\"frame-{0:05}.png\".format(frame2Key+1), frame2Offset[::-1])\n",
    "                else :\n",
    "                    sprite2 = np.array(Image.open(semanticSequences[seq2Idx][DICT_MASK_LOCATION]+\"frame-{0:05}.png\".format(frame2Key+1)))\n",
    "\n",
    "                ## dealing with scale and offsets\n",
    "\n",
    "                if not hasLoaded :\n",
    "                    tmp = np.zeros_like(sprite2)\n",
    "                    tmp[offset[1]+frame2Offset[1]:offset[1]+frame2Offset[1]+patchSize[0],\n",
    "                        offset[0]+frame2Offset[0]:offset[0]+frame2Offset[0]+patchSize[1], :] = sprite2[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1], :]\n",
    "                    sprite2 = np.copy(tmp)\n",
    "                    del tmp\n",
    "\n",
    "                tmp = np.zeros_like(fullSprite2Prior)\n",
    "                tmp[offset[1]+frame2Offset[1]:offset[1]+frame2Offset[1]+patchSize[0],\n",
    "                    offset[0]+frame2Offset[0]:offset[0]+frame2Offset[0]+patchSize[1]] = fullSprite2Prior[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1]]\n",
    "                fullSprite2Prior = np.copy(tmp)\n",
    "                del tmp\n",
    "\n",
    "\n",
    "    #             tmp = np.zeros_like(sprite2)\n",
    "    #             tmp[frame1Offset[1]:, frame1Offset[0]:, :] = sprite2[:tmp.shape[0]-frame2Offset[1], :tmp.shape[1]-frame2Offset[0], :]\n",
    "    #             sprite2 = np.copy(tmp)\n",
    "    #             del tmp\n",
    "\n",
    "    #             tmp = np.zeros_like(fullSprite2Prior)\n",
    "    #             tmp[frame1Offset[1]:, frame1Offset[0]:] = fullSprite2Prior[:tmp.shape[0]-frame2Offset[1], :tmp.shape[1]-frame2Offset[0]]\n",
    "    #             fullSprite2Prior = np.copy(tmp)\n",
    "    #             del tmp\n",
    "\n",
    "\n",
    "                ## only doing the checks for the overlapping pixels\n",
    "                ambiguousIdxs = np.argwhere(np.all(((outputFrame[:, :, -1] != 0).reshape((outputFrame.shape[0], outputFrame.shape[1], 1)),\n",
    "                                                    (sprite2[:, :, -1] != 0).reshape((sprite2.shape[0], sprite2.shape[1], 1))), axis=0)[:, :, -1])\n",
    "\n",
    "                ## get background differences\n",
    "                outputBgDiff = np.zeros(bgImage.shape[0:2])\n",
    "                outputBgDiff[ambiguousIdxs[:, 0], ambiguousIdxs[:, 1]] = np.sqrt(np.sum((bgImage[ambiguousIdxs[:, 0], ambiguousIdxs[:, 1], :]-\n",
    "                                                                                         outputFrame[ambiguousIdxs[:, 0], ambiguousIdxs[:, 1], :-1])**2, axis=-1))\n",
    "                outputBgDiff = cv2.GaussianBlur(outputBgDiff, (kSize, kSize), sigma)#*1.2\n",
    "                outputBgDiff = outputBgDiff*alpha+(1.0-alpha)*outputPrior\n",
    "\n",
    "\n",
    "                diffSprite2 = np.zeros(bgImage.shape[0:2])\n",
    "                diffSprite2[ambiguousIdxs[:, 0], ambiguousIdxs[:, 1]] = np.sqrt(np.sum((bgImage[ambiguousIdxs[:, 0], ambiguousIdxs[:, 1], :]-\n",
    "                                                                                        sprite2[ambiguousIdxs[:, 0], ambiguousIdxs[:, 1], :-1])**2, axis=-1))\n",
    "                diffSprite2 = cv2.GaussianBlur(diffSprite2, (kSize, kSize), sigma)#*1.2\n",
    "                diffSprite2 = diffSprite2*alpha+(1.0-alpha)*fullSprite2Prior\n",
    "\n",
    "\n",
    "\n",
    "                compositedImage = np.copy(outputFrame)*(outputFrame[:, :, -1].reshape((bgImage.shape[0], bgImage.shape[1], 1))/255.0)\n",
    "                compositedImage = (compositedImage*(1.0-sprite2[:, :, -1].reshape((bgImage.shape[0], bgImage.shape[1], 1))/255.0) + \n",
    "                                   np.copy(sprite2)*(sprite2[:, :, -1].reshape((bgImage.shape[0], bgImage.shape[1], 1))/255.0))\n",
    "                compositedImage = np.array(compositedImage, dtype=np.uint8)\n",
    "\n",
    "                ## do the checks and update the composited image\n",
    "                for (i, j) in ambiguousIdxs :\n",
    "                    if diffSprite2[i, j] > thresh :\n",
    "                        compositedImage[i, j, :] = sprite2[i, j, :]\n",
    "                        tmpAssignment[i, j] = 1\n",
    "                    elif outputBgDiff[i, j] > thresh :\n",
    "                        compositedImage[i, j, :] = outputFrame[i, j, :]\n",
    "                        tmpAssignment[i, j] = 2\n",
    "                    elif outputBgDiff[i, j] > diffSprite2[i, j] :\n",
    "                        compositedImage[i, j, :] = outputFrame[i, j, :]\n",
    "                        tmpAssignment[i, j] = 2\n",
    "                    else :\n",
    "                        compositedImage[i, j, :] = sprite2[i, j, :]\n",
    "                        tmpAssignment[i, j] = 1\n",
    "\n",
    "                outputFrame = compositedImage\n",
    "                outputPrior += fullSprite2Prior\n",
    "                outputPrior /= np.max(outputPrior)\n",
    "                \n",
    "    else :\n",
    "        outputFrame = np.zeros((bgImage.shape[0], bgImage.shape[1], 4), np.uint8)\n",
    "        \n",
    "    Image.fromarray(outputFrame).save(baseLoc+\"frame-{0:05}.png\".format(f+1 ))\n",
    "#     figure(); imshow(outputFrame)\n",
    "#     figure(); imshow(np.array(Image.open(baseLoc+\"frame-{0:05}.png\".format(f+1 ))))\n",
    "    \n",
    "    avgTime = (avgTime*iterNum + time.time()-t)/(iterNum+1)\n",
    "    remainingTime = avgTime*(maxFramesToRender-iterNum-1)/60.0\n",
    "    sys.stdout.write('\\r' + \"Done image \" + np.string_(iterNum) + \" of \" + np.string_(maxFramesToRender) +\n",
    "                     \" (avg time: \" + np.string_(avgTime) + \" secs --- remaining: \" +\n",
    "                     np.string_(int(np.floor(remainingTime))) + \":\" + np.string_(int((remainingTime - np.floor(remainingTime))*60)) + \")\")\n",
    "    sys.stdout.flush()\n",
    "print \n",
    "print \"done\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
