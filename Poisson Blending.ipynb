{
 "metadata": {
  "name": "",
  "signature": "sha256:ae45d68de533f6ad97838248e6015db5768ce242a8c482b9887be7f5bf370477"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab\n",
      "import numpy as np\n",
      "import scipy.sparse\n",
      "import PIL.Image\n",
      "import pyamg\n",
      "import glob\n",
      "import os\n",
      "import sys\n",
      "\n",
      "DICT_SPRITE_NAME = 'sprite_name'\n",
      "DICT_BBOXES = 'bboxes'\n",
      "DICT_BBOX_ROTATIONS = 'bbox_rotations'\n",
      "DICT_BBOX_CENTERS = 'bbox_centers'\n",
      "DICT_FRAMES_LOCATIONS = 'frame_locs'\n",
      "DICT_SEQUENCE_FRAMES = 'sequence_frames'\n",
      "DICT_SPRITE_IDX = 'sprite_idx' # stores the index in the self.trackedSprites array of the sprite used in the generated sequence\n",
      "DICT_DESIRED_SEMANTICS = 'desired_semantics' # stores what the desired semantics are for a certain sprite \n",
      "#(I could index them by the frame when the toggle happened instead of using the below but maybe ordering is important and I would lose that using a dict)\n",
      "DICT_FRAME_SEMANTIC_TOGGLE = 'frame_semantic_toggle'# stores the frame index in the generated sequence when the desired semantics have changed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: TkAgg\n",
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# dataPath = \"/home/ilisescu/PhD/data/\"\n",
      "# dataSet = \"havana/\"\n",
      "dataPath = \"/media/ilisescu/Data1/PhD/data/\"\n",
      "# dataSet = \"clouds_subsample10/\"\n",
      "# dataSet = \"theme_park_cloudy/\"\n",
      "# dataSet = \"theme_park_sunny/\"\n",
      "dataSet = \"wave1/\"\n",
      "# preloadedSpritePatches = list(np.load(dataPath + dataSet + \"preloadedSpritePatches.npy\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## load \n",
      "# trackedSprites = []\n",
      "# for sprite in np.sort(glob.glob(dataPath + dataSet + \"sprite*.npy\")) :\n",
      "#     trackedSprites.append(np.load(sprite).item())\n",
      "#     print trackedSprites[-1][DICT_SPRITE_NAME]\n",
      "    \n",
      "## load \n",
      "trackedSprites = []\n",
      "for sprite in np.sort(glob.glob(dataPath + dataSet + \"semantic_sequence*.npy\")) :\n",
      "    trackedSprites.append(np.load(sprite).item())\n",
      "    print trackedSprites[-1]['semantic_sequence_name']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "aron1\n",
        "ferran1\n",
        "james1\n",
        "moos1\n",
        "peter1\n",
        "sara1\n",
        "tara1\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## from https://github.com/fbessho/PyPoi/blob/master/pypoi/poissonblending.py\n",
      "def blend(img_target, img_source, img_mask, offset=(0, 0)):\n",
      "    # compute regions to be blended\n",
      "    region_source = (\n",
      "        max(-offset[0], 0),\n",
      "        max(-offset[1], 0),\n",
      "        min(img_target.shape[0] - offset[0], img_source.shape[0]),\n",
      "        min(img_target.shape[1] - offset[1], img_source.shape[1]))\n",
      "    region_target = (\n",
      "        max(offset[0], 0),\n",
      "        max(offset[1], 0),\n",
      "        min(img_target.shape[0], img_source.shape[0] + offset[0]),\n",
      "        min(img_target.shape[1], img_source.shape[1] + offset[1]))\n",
      "    region_size = (region_source[2] - region_source[0], region_source[3] - region_source[1])\n",
      "\n",
      "    # clip and normalize mask image\n",
      "    img_mask = img_mask[region_source[0]:region_source[2], region_source[1]:region_source[3]]\n",
      "    img_mask[img_mask == 0] = False\n",
      "    img_mask[img_mask != False] = True\n",
      "\n",
      "    # create coefficient matrix\n",
      "    A = scipy.sparse.identity(np.prod(region_size), format='lil')\n",
      "    for y in range(region_size[0]):\n",
      "        for x in range(region_size[1]):\n",
      "            if img_mask[y, x]:\n",
      "                index = x + y * region_size[1]\n",
      "                A[index, index] = 4\n",
      "                if index + 1 < np.prod(region_size):\n",
      "                    A[index, index + 1] = -1\n",
      "                if index - 1 >= 0:\n",
      "                    A[index, index - 1] = -1\n",
      "                if index + region_size[1] < np.prod(region_size):\n",
      "                    A[index, index + region_size[1]] = -1\n",
      "                if index - region_size[1] >= 0:\n",
      "                    A[index, index - region_size[1]] = -1\n",
      "    A = A.tocsr()\n",
      "\n",
      "    # create poisson matrix for b\n",
      "    P = pyamg.gallery.poisson(img_mask.shape)\n",
      "\n",
      "    # for each layer (ex. RGB)\n",
      "    for num_layer in range(img_target.shape[2]):\n",
      "        # get subimages\n",
      "        t = img_target[region_target[0]:region_target[2], region_target[1]:region_target[3], num_layer]\n",
      "        s = img_source[region_source[0]:region_source[2], region_source[1]:region_source[3], num_layer]\n",
      "        t = t.flatten()\n",
      "        s = s.flatten()\n",
      "\n",
      "        # create b\n",
      "        b = P * s\n",
      "        for y in range(region_size[0]):\n",
      "            for x in range(region_size[1]):\n",
      "                if not img_mask[y, x]:\n",
      "                    index = x + y * region_size[1]\n",
      "                    b[index] = t[index]\n",
      "\n",
      "        # solve Ax = b\n",
      "        x = pyamg.solve(A, b, verb=False, tol=1e-10)\n",
      "\n",
      "        # assign x to target image\n",
      "        x = np.reshape(x, region_size)\n",
      "        x[x > 255] = 255\n",
      "        x[x < 0] = 0\n",
      "        x = np.array(x, img_target.dtype)\n",
      "        img_target[region_target[0]:region_target[2], region_target[1]:region_target[3], num_layer] = x\n",
      "\n",
      "    return img_target\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imgSize = np.array(np.asarray(PIL.Image.open(dataPath+dataSet+\"median.png\")).shape[0:2])\n",
      "# inputFolderSuffix = \"-masked\"#-blended/\"\n",
      "inputFolderSuffix = \"-maskedFlow\"#-blended/\"\n",
      "for spriteIdx in arange(len(trackedSprites))[-1:] :\n",
      "    sortedKeys = np.sort(trackedSprites[spriteIdx][DICT_FRAMES_LOCATIONS].keys())\n",
      "#     spriteName = trackedSprites[spriteIdx][DICT_SPRITE_NAME]\n",
      "    spriteName = trackedSprites[spriteIdx]['semantic_sequence_name']\n",
      "    \n",
      "    if not os.path.isdir(dataPath+dataSet+spriteName+inputFolderSuffix+\"-blended/\"):\n",
      "        os.makedirs(dataPath+dataSet+spriteName+inputFolderSuffix+\"-blended/\")\n",
      "        \n",
      "    for frameIdx in arange(len(sortedKeys)) :\n",
      "        frameName = trackedSprites[spriteIdx][DICT_FRAMES_LOCATIONS][sortedKeys[frameIdx]].split(os.sep)[-1]\n",
      "        \n",
      "        \n",
      "        im = np.array(PIL.Image.open(dataPath+dataSet+spriteName+inputFolderSuffix+\"/\"+frameName))\n",
      "        \n",
      "        visiblePixelsGlobalIndices = np.argwhere(im[:, :, -1] != 0)\n",
      "        topLeftPos = np.min(visiblePixelsGlobalIndices, axis=0)\n",
      "        patchSize = np.max(visiblePixelsGlobalIndices, axis=0) - topLeftPos + 1\n",
      "#         topLeftPos = np.copy(preloadedSpritePatches[spriteIdx][frameIdx]['top_left_pos'])\n",
      "#         patchSize = np.copy(preloadedSpritePatches[spriteIdx][frameIdx]['patch_size'])\n",
      "#         visiblePixelsGlobalIndices = preloadedSpritePatches[spriteIdx][frameIdx]['visible_indices']+topLeftPos\n",
      "        \n",
      "        ## when the mask touches the border of the patch there's some weird white halos going on so I enlarge the patch slightly\n",
      "        ## not sure what happens when the patch goes outside of the bounds of the original image...\n",
      "        topLeftPos -= 1\n",
      "        patchSize += 2\n",
      "        ## make sure we're within bounds\n",
      "        topLeftPos[np.argwhere(topLeftPos < 0)] = 0\n",
      "        patchSize[(topLeftPos+patchSize) > imgSize] += (imgSize-(topLeftPos+patchSize))[(topLeftPos+patchSize) > imgSize]\n",
      "        \n",
      "        \n",
      "        img_target = np.asarray(PIL.Image.open(dataPath+dataSet+\"median.png\"))[:, :, 0:3]\n",
      "        img_target.flags.writeable = True\n",
      "        \n",
      "        img_mask = np.asarray(PIL.Image.open(dataPath+dataSet+spriteName+inputFolderSuffix+\"/\"+frameName))[topLeftPos[0]:topLeftPos[0]+patchSize[0], \n",
      "                                                                                                           topLeftPos[1]:topLeftPos[1]+patchSize[1], -1]\n",
      "        img_mask.flags.writeable = True\n",
      "        ## make sure that borders of mask are assigned to bg\n",
      "        img_mask[0, :] = 0; img_mask[-1, :] = 0; img_mask[:, 0] = 0; img_mask[:, -1] = 0\n",
      "        \n",
      "        img_source = np.asarray(PIL.Image.open(trackedSprites[spriteIdx][DICT_FRAMES_LOCATIONS][sortedKeys[frameIdx]]))[topLeftPos[0]:topLeftPos[0]+patchSize[0], \n",
      "                                                                                                                        topLeftPos[1]:topLeftPos[1]+patchSize[1], :]\n",
      "        \n",
      "#         sourceImg = np.asarray(PIL.Image.open(dataPath+dataSet+spriteName+inputFolderSuffix+\"/\"+frameName))[topLeftPos[0]:topLeftPos[0]+patchSize[0], \n",
      "#                                                                                                             topLeftPos[1]:topLeftPos[1]+patchSize[1], :-1]\n",
      "#         mask = np.copy(img_mask.reshape((patchSize[0], patchSize[1], 1)))/255.0\n",
      "        \n",
      "#         img_source = np.array(sourceImg*mask + np.asarray(PIL.Image.open(dataPath+dataSet+\"median.png\"))[topLeftPos[0]:topLeftPos[0]+patchSize[0], \n",
      "#                                                                                                          topLeftPos[1]:topLeftPos[1]+patchSize[1], :]*(1.0-mask), dtype=uint8)\n",
      "        \n",
      "            \n",
      "        img_source.flags.writeable = True\n",
      "        \n",
      "        \n",
      "        img_ret = blend(img_target, img_source, img_mask, offset=(topLeftPos[0], topLeftPos[1]))\n",
      "        \n",
      "        \n",
      "        maskedFinal = np.zeros((img_target.shape[0], img_target.shape[1], 4), dtype=np.uint8)\n",
      "        maskedFinal[visiblePixelsGlobalIndices[:, 0], visiblePixelsGlobalIndices[:, 1], :-1] = img_ret[visiblePixelsGlobalIndices[:, 0], \n",
      "                                                                                                       visiblePixelsGlobalIndices[:, 1], :]\n",
      "        maskedFinal[visiblePixelsGlobalIndices[:, 0], visiblePixelsGlobalIndices[:, 1], -1] = 255\n",
      "        \n",
      "        PIL.Image.fromarray(np.uint8(maskedFinal)).save(dataPath+dataSet+spriteName+inputFolderSuffix+\"-blended/\"+frameName)\n",
      "#         figure(); imshow(maskedFinal)\n",
      "        del img_mask\n",
      "        del img_source\n",
      "        del img_target\n",
      "        del maskedFinal\n",
      "        del img_ret\n",
      "#         del sourceImg\n",
      "#         del mask\n",
      "        \n",
      "        sys.stdout.write('\\r' + \"Processed image \" + np.string_(frameIdx) + \" (\" + np.string_(len(sortedKeys)) + \")\")\n",
      "        sys.stdout.flush()\n",
      "    print\n",
      "    print \"done with sprite\", trackedSprites[spriteIdx]['semantic_sequence_name']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Processed image 0 (1176)"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# figure(); imshow(img_target)\n",
      "print np.asarray(PIL.Image.open(dataPath+dataSet+\"median.png\")).shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(720, 1280, 4)\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del img_mask\n",
      "del img_source\n",
      "del img_target\n",
      "del maskedFinal\n",
      "del img_ret\n",
      "del sourceImg\n",
      "del mask"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    }
   ],
   "metadata": {}
  }
 ]
}