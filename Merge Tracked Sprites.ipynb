{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab\n",
      "import opengm\n",
      "import numpy as np\n",
      "import cv2\n",
      "import time\n",
      "import os\n",
      "# import graph_tool as gt\n",
      "from PIL import Image\n",
      "import scipy.io as sio\n",
      "import GraphWithValues as gwv\n",
      "import sys\n",
      "import glob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: TkAgg\n",
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "S_IDX = 0\n",
      "T_IDX = 1\n",
      "ST_COST = 2\n",
      "S_LABEL = 3\n",
      "T_LABEL = 4\n",
      "S_A_COLOR = np.arange(5, 8, dtype=int)\n",
      "S_B_COLOR = np.arange(8, 11, dtype=int)\n",
      "T_A_COLOR = np.arange(11, 14, dtype=int)\n",
      "T_B_COLOR = np.arange(14, 17, dtype=int)\n",
      "print S_IDX, T_IDX, ST_COST, S_LABEL, T_LABEL, S_A_COLOR, S_B_COLOR, T_A_COLOR, T_B_COLOR\n",
      "\n",
      "DICT_SPRITE_NAME = 'sprite_name'\n",
      "DICT_BBOX_AFFINES = 'bbox_affines'\n",
      "DICT_NUM_FRAMES = 'num_frames'\n",
      "DICT_FRAMES_LOCATIONS = 'frame_locs'\n",
      "\n",
      "## used for enlarging bbox used to decide size of patch around it (percentage)\n",
      "PATCH_BORDER = 0.4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 1 2 3 4 [5 6 7] [ 8  9 10] [11 12 13] [14 15 16]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def multivariateNormal(data, mean, var, normalized = True) :\n",
      "    if (data.shape[0] != mean.shape[0] or np.any(data.shape[0] != np.array(var.shape)) \n",
      "        or len(var.shape) != 2 or var.shape[0] != var.shape[1]) :\n",
      "        raise Exception(\"Data shapes don't agree data(\" + np.string_(data.shape) + \") mean(\" + np.string_(mean.shape) + \n",
      "                        \") var(\" + np.string_(var.shape) + \")\")\n",
      "        \n",
      "    D = float(data.shape[0])\n",
      "    n = (1/(np.power(2.0*np.pi, D/2.0)*np.sqrt(np.linalg.det(var))))\n",
      "    if normalized :\n",
      "        p = n*np.exp(-0.5*np.sum(np.dot((data-mean).T, np.linalg.inv(var))*(data-mean).T, axis=-1))\n",
      "    else :\n",
      "        p = np.exp(-0.5*np.sum(np.dot((data-mean).T, np.linalg.inv(var))*(data-mean).T, axis=-1))\n",
      "        \n",
      "    return p\n",
      "\n",
      "def minusLogMultivariateNormal(data, mean, var, normalized = True) :\n",
      "    if (data.shape[0] != mean.shape[0] or np.any(data.shape[0] != np.array(var.shape)) \n",
      "        or len(var.shape) != 2 or var.shape[0] != var.shape[1]) :\n",
      "        raise Exception(\"Data shapes don't agree data(\" + np.string_(data.shape) + \") mean(\" + np.string_(mean.shape) + \n",
      "                        \") var(\" + np.string_(var.shape) + \")\")\n",
      "    \n",
      "    D = float(data.shape[0])\n",
      "    n = -0.5*np.log(np.linalg.det(var))-(D/2.0)*np.log(2.0*np.pi)\n",
      "    if normalized :\n",
      "        p = n -0.5*np.sum(np.dot((data-mean).T, np.linalg.inv(var))*(data-mean).T, axis=-1)\n",
      "    else :\n",
      "        p = -0.5*np.sum(np.dot((data-mean).T, np.linalg.inv(var))*(data-mean).T, axis=-1)\n",
      "        \n",
      "    return -p\n",
      "\n",
      "def vectorisedMinusLogMultiNormal(dataPoints, means, var, normalized = True) :\n",
      "    if (dataPoints.shape[1] != means.shape[1] or np.any(dataPoints.shape[1] != np.array(var.shape)) \n",
      "        or len(var.shape) != 2 or var.shape[0] != var.shape[1]) :\n",
      "        raise Exception(\"Data shapes don't agree data(\" + np.string_(dataPoints.shape) + \") mean(\" + np.string_(means.shape) + \n",
      "                        \") var(\" + np.string_(var.shape) + \")\")\n",
      "    \n",
      "    D = float(dataPoints.shape[1])\n",
      "    n = -0.5*np.log(np.linalg.det(var))-(D/2.0)*np.log(2.0*np.pi)\n",
      "    \n",
      "    ## this does 0.5*dot(dot(data-mean, varInv), data-mean)\n",
      "    varInv = np.linalg.inv(var)\n",
      "    dataMinusMean = dataPoints-means\n",
      "    \n",
      "    ps = []\n",
      "    for i in xrange(int(D)) :\n",
      "        ps.append(np.sum((dataMinusMean)*varInv[:, i], axis=-1))\n",
      "    \n",
      "    ps = np.array(ps).T\n",
      "    \n",
      "    ps = -0.5*np.sum(ps*(dataMinusMean), axis=-1)\n",
      "    \n",
      "    if normalized :\n",
      "        return n-ps\n",
      "    else :\n",
      "        return -ps"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 267
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getGridPairIndices(width, height) :\n",
      "## deal with pixels that have East and South neighbours i.e. all of them apart from last column and last row\n",
      "    pairIdxs = np.zeros(((width*height-(width+height-1))*2, 2), dtype=int)\n",
      "## each column contains idxs [0, h-2]\n",
      "    idxs = np.arange(0, height-1, dtype=int).reshape((height-1, 1)).repeat(width-1, axis=-1)\n",
      "## each column contains idxs [0, h-2]+h*i where i is the column index \n",
      "## (i.e. now I have indices of all nodes in the grid apart from last col and row)\n",
      "    idxs += (np.arange(0, width-1)*height).reshape((1, width-1)).repeat(height-1, axis=0)\n",
      "    # figure(); imshow(idxs)\n",
      "## now flatten idxs and repeat once so that I have the idx for each node that has E and S neighbours twice\n",
      "    idxs = np.ndarray.flatten(idxs.T).repeat(2)\n",
      "## idxs for each \"left\" node (that is connected to the edge) are the ones just computed\n",
      "    pairIdxs[:, 0] = idxs\n",
      "## idxs for each \"right\" node are to the E and S so need to sum \"left\" idx to height and to 1\n",
      "# print np.ndarray.flatten(np.array([[patchSize[0]], [1]]).repeat(np.prod(patchSize)-(np.sum(patchSize)-1), axis=-1).T)\n",
      "    pairIdxs[:, 1] = idxs + np.ndarray.flatten(np.array([[height], [1]]).repeat(width*height-(width+height-1), axis=-1).T)\n",
      "    \n",
      "## deal with pixels that have only East neighbours\n",
      "## get \"left\" nodes\n",
      "    leftNodes = np.arange(height-1, width*height-1, height)\n",
      "## now connect \"left\" nodes to the nodes to their East (i.e. sum to height) and add them to the list of pair indices\n",
      "    pairIdxs = np.concatenate((pairIdxs, np.array([leftNodes, leftNodes+height]).T), axis=0)\n",
      "    \n",
      "## deal with pixels that have only South neighbours\n",
      "## get \"top\" nodes\n",
      "    topNodes = np.arange(width*height-height, width*height-1)\n",
      "## now connect \"to\" nodes to the nodes to their South (i.e. sum to 1) and add them to the list of pair indices\n",
      "    pairIdxs = np.concatenate((pairIdxs, np.array([topNodes, topNodes+1]).T), axis=0)\n",
      "    \n",
      "    return pairIdxs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 413
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getGraphcutOnOverlap(patchA, patchB, patchAPixels, patchBPixels, multiplier, unaryPriorPatchA, unaryPriorPatchB) :\n",
      "    \"\"\"Computes pixel labels using graphcut given two same size patches\n",
      "    \n",
      "        \\t  patchA           : patch A\n",
      "        \\t  patchB           : patch B\n",
      "        \\t  patchAPixels     : pixels that are definitely to be taken from patch A\n",
      "        \\t  patchBPixels     : pixels that are definitely to be taken from patch B\n",
      "        \\t  multiplier       : sigma multiplier for rgb space normal\n",
      "        \\t  unaryPriorPatchA : prior cost ditribution for patchA labels\n",
      "        \\t  unaryPriorPatchB : prior cost ditribution for patchB labels\n",
      "           \n",
      "        return: reshapedLabels = labels for each pixel\"\"\"\n",
      "    \n",
      "    if np.all(patchA.shape != patchB.shape) :\n",
      "        raise Exception(\"The two specified patches have different shape so graph cannot be built\")\n",
      "        \n",
      "    if patchA.dtype != np.float64 or patchB.dtype != np.float64 :\n",
      "        raise Exception(\"The two specified patches are not of type float64! Check there is no overflow when computing costs\")\n",
      "    \n",
      "    h, width = patchA.shape[0:2]\n",
      "    maxCost = 10000000.0#np.sys.float_info.max\n",
      "    \n",
      "    s = time.time()\n",
      "    ## build graph\n",
      "    numLabels = 2\n",
      "    numNodes = h*width+numLabels\n",
      "    gm = opengm.gm(numpy.ones(numNodes,dtype=opengm.label_type)*numLabels)\n",
      "    \n",
      "    ## Last 2 nodes are patch A and B respectively\n",
      "    idxPatchANode = numNodes - 2\n",
      "    idxPatchBNode = numNodes - 1\n",
      "    \n",
      "        \n",
      "    ## get unary functions\n",
      "    unaries = np.zeros((numNodes,numLabels))\n",
      "    \n",
      "    ## fix label for nodes representing patch A and B to have label 0 and 1 respectively\n",
      "    unaries[idxPatchANode, :] = [0.0, maxCost]\n",
      "    unaries[idxPatchBNode, :] = [maxCost, 0.0]\n",
      "    \n",
      "    ## set unaries based on the priors given for both patches\n",
      "    unaries[0:h*width, 0] = unaryPriorPatchA\n",
      "    unaries[0:h*width, 1] = unaryPriorPatchB\n",
      "    \n",
      "    # add functions\n",
      "    fids = gm.addFunctions(unaries)\n",
      "    # add first order factors\n",
      "    gm.addFactors(fids, arange(0, numNodes, 1))\n",
      "    \n",
      "    \n",
      "    ## get factor indices for the overlap grid of pixels\n",
      "    stmp = time.time()\n",
      "#     pairIndices = np.array(opengm.secondOrderGridVis(width,h,True))\n",
      "    pairIndices = getGridPairIndices(width, h)\n",
      "#     print \"pairIndices took\", time.time()-stmp, \"seconds\"\n",
      "#     sys.stdout.flush()\n",
      "    ## get pairwise functions for those nodes\n",
      "#     pairwise = np.zeros(len(pairIndices))\n",
      "#     for pair, i in zip(pairIndices, arange(len(pairIndices))) :\n",
      "#         sPix = np.array([int(np.mod(pair[0],h)), int(pair[0]/h)])\n",
      "#         tPix = np.array([int(np.mod(pair[1],h)), int(pair[1]/h)])\n",
      "        \n",
      "# #         pairwise[i] = norm(patchA[sPix[0], sPix[1], :] - patchB[sPix[0], sPix[1], :])\n",
      "# #         pairwise[i] += norm(patchA[tPix[0], tPix[1], :] - patchB[tPix[0], tPix[1], :])\n",
      "\n",
      "#         pairwise[i] = minusLogMultivariateNormal(patchA[sPix[0], sPix[1], :].reshape((3, 1)), patchB[sPix[0], sPix[1], :].reshape((3, 1)), np.eye(3)*multiplier, False)\n",
      "#         pairwise[i] += minusLogMultivariateNormal(patchA[tPix[0], tPix[1], :].reshape((3, 1)), patchB[tPix[0], tPix[1], :].reshape((3, 1)), np.eye(3)*multiplier, False)\n",
      "        \n",
      "#         fid = gm.addFunction(np.array([[0.0, pairwise[i]],[pairwise[i], 0.0]]))\n",
      "#         gm.addFactor(fid, pair)\n",
      "        \n",
      "    sPixs = np.array([np.mod(pairIndices[:, 0],h), pairIndices[:, 0]/h], dtype=int).T\n",
      "    tPixs = np.array([np.mod(pairIndices[:, 1],h), pairIndices[:, 1]/h], dtype=int).T\n",
      "    \n",
      "    pairwise = vectorisedMinusLogMultiNormal(patchA[sPixs[:, 0], sPixs[:, 1], :], patchB[sPixs[:, 0], sPixs[:, 1], :], np.eye(3)*multiplier, False)\n",
      "    pairwise += vectorisedMinusLogMultiNormal(patchA[tPixs[:, 0], tPixs[:, 1], :], patchB[tPixs[:, 0], tPixs[:, 1], :], np.eye(3)*multiplier, False)\n",
      "        \n",
      "    fids = gm.addFunctions(np.array([[0.0, 1.0],[1.0, 0.0]]).reshape((1, 2, 2)).repeat(len(pairwise), axis=0)*\n",
      "                           pairwise.reshape((len(pairwise), 1, 1)).repeat(2, axis=1).repeat(2, axis=2))\n",
      "    \n",
      "    gm.addFactors(fids, pairIndices)\n",
      "            \n",
      "    \n",
      "    # add function used for connecting the patch variables\n",
      "    fid = gm.addFunction(np.array([[0.0, maxCost],[maxCost, 0.0]]))\n",
      "    \n",
      "    # connect patch A to definite patch A pixels\n",
      "    if len(patchAPixels) > 0 :\n",
      "        patchAFactors = np.hstack((patchAPixels.reshape((len(patchAPixels), 1)), np.ones((len(patchAPixels), 1), dtype=uint)*idxPatchANode))\n",
      "        gm.addFactors(fid, patchAFactors)\n",
      "    \n",
      "    # connect patch B to definite patch B pixels\n",
      "    if len(patchBPixels) > 0 :\n",
      "        patchBFactors = np.hstack((patchBPixels.reshape((len(patchBPixels), 1)), np.ones((len(patchBPixels), 1), dtype=uint)*idxPatchBNode))\n",
      "        gm.addFactors(fid, patchBFactors)\n",
      "    \n",
      "#     print \"graph setup took\", time.time()-s, \"seconds\"\n",
      "#     sys.stdout.flush()\n",
      "    s = time.time()\n",
      "    graphCut = opengm.inference.GraphCut(gm=gm)\n",
      "    graphCut.infer()\n",
      "#     print \"graph inference took\", time.time()-s, \"seconds\"\n",
      "#     sys.stdout.flush()\n",
      "    \n",
      "    labels = np.array(graphCut.arg(), dtype=int)\n",
      "    \n",
      "    reshapedLabels = np.reshape(np.copy(labels[0:-numLabels]), patchA.shape[0:2], 'F')\n",
      "#     print gm\n",
      "#     print gm.evaluate(labels)\n",
      "    \n",
      "    return reshapedLabels, unaries, pairwise, gm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 417
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get3WayLabelling(patchA, patchB, patchC, patchAPixels, patchBPixels, patchCPixels, multiplier, unaryPriorPatchA, unaryPriorPatchB, unaryPriorPatchC) :\n",
      "    \"\"\"Computes pixel labels using graphcut given two same size patches\n",
      "    \n",
      "        \\t  patchA           : patch A\n",
      "        \\t  patchB           : patch B\n",
      "        \\t  patchAPixels     : pixels that are definitely to be taken from patch A\n",
      "        \\t  patchBPixels     : pixels that are definitely to be taken from patch B\n",
      "        \\t  multiplier       : sigma multiplier for rgb space normal\n",
      "        \\t  unaryPriorPatchA : prior cost ditribution for patchA labels\n",
      "        \\t  unaryPriorPatchB : prior cost ditribution for patchB labels\n",
      "           \n",
      "        return: reshapedLabels = labels for each pixel\"\"\"\n",
      "    \n",
      "    if np.all(patchA.shape != patchB.shape) :\n",
      "        raise Exception(\"The two specified patches have different shape so graph cannot be built\")\n",
      "        \n",
      "    if patchA.dtype != np.float64 or patchB.dtype != np.float64 :\n",
      "        raise Exception(\"The two specified patches are not of type float64! Check there is no overflow when computing costs\")\n",
      "    \n",
      "    h, width = patchA.shape[0:2]\n",
      "    maxCost = 10000000.0#np.sys.float_info.max\n",
      "    \n",
      "    ## build graph\n",
      "    numLabels = 3\n",
      "    numNodes = h*width+numLabels\n",
      "    gm = opengm.gm(numpy.ones(numNodes,dtype=opengm.label_type)*numLabels)\n",
      "    \n",
      "    ## Last 3 nodes are patch A, B and C respectively\n",
      "    idxPatchANode = numNodes - 3\n",
      "    idxPatchBNode = numNodes - 2\n",
      "    idxPatchCNode = numNodes - 1\n",
      "    \n",
      "        \n",
      "    ## get unary functions\n",
      "    unaries = np.zeros((numNodes,numLabels))\n",
      "    \n",
      "    print h, width, unaries.shape\n",
      "    \n",
      "    ## fix label for nodes representing patch A and B to have label 0 and 1 respectively\n",
      "    unaries[idxPatchANode, :] = [0.0, maxCost, maxCost]\n",
      "    unaries[idxPatchBNode, :] = [maxCost, 0.0, maxCost]\n",
      "    unaries[idxPatchCNode, :] = [maxCost, maxCost, 0.0]\n",
      "    \n",
      "    ## set unaries based on the priors given for both patches\n",
      "    unaries[0:h*width, 0] = unaryPriorPatchA\n",
      "    unaries[0:h*width, 1] = unaryPriorPatchB\n",
      "    unaries[0:h*width, 2] = unaryPriorPatchC\n",
      "    \n",
      "    # add functions\n",
      "    fids = gm.addFunctions(unaries)\n",
      "    # add first order factors\n",
      "    gm.addFactors(fids, arange(0, numNodes, 1))\n",
      "    \n",
      "    \n",
      "    ## get factor indices for the overlap grid of pixels\n",
      "    pairIndices = np.array(opengm.secondOrderGridVis(width,h,True))\n",
      "    ## get pairwise functions for those nodes\n",
      "    pairwiseAB = np.zeros((len(pairIndices), 1))\n",
      "    pairwiseAC = np.zeros((len(pairIndices), 1))\n",
      "    pairwiseBC = np.zeros((len(pairIndices), 1))\n",
      "    for pair, i in zip(pairIndices, arange(len(pairIndices))) :\n",
      "        sPix = np.array([int(np.mod(pair[0],h)), int(pair[0]/h)])\n",
      "        tPix = np.array([int(np.mod(pair[1],h)), int(pair[1]/h)])\n",
      "        \n",
      "#         pairwise[i] = norm(patchA[sPix[0], sPix[1], :] - patchB[sPix[0], sPix[1], :])\n",
      "#         pairwise[i] += norm(patchA[tPix[0], tPix[1], :] - patchB[tPix[0], tPix[1], :])\n",
      "\n",
      "        pairwiseAB[i] = minusLogMultivariateNormal(patchA[sPix[0], sPix[1], :].reshape((3, 1)), patchB[sPix[0], sPix[1], :].reshape((3, 1)), np.eye(3)*multiplier, False)\n",
      "        pairwiseAB[i] += minusLogMultivariateNormal(patchA[tPix[0], tPix[1], :].reshape((3, 1)), patchB[tPix[0], tPix[1], :].reshape((3, 1)), np.eye(3)*multiplier, False)\n",
      "        \n",
      "        pairwiseAC[i] = minusLogMultivariateNormal(patchA[sPix[0], sPix[1], :].reshape((3, 1)), patchC[sPix[0], sPix[1], :].reshape((3, 1)), np.eye(3)*multiplier, False)\n",
      "        pairwiseAC[i] += minusLogMultivariateNormal(patchA[tPix[0], tPix[1], :].reshape((3, 1)), patchC[tPix[0], tPix[1], :].reshape((3, 1)), np.eye(3)*multiplier, False)\n",
      "        \n",
      "#         pairwiseBC[i] = minusLogMultivariateNormal(patchB[sPix[0], sPix[1], :].reshape((3, 1)), patchC[sPix[0], sPix[1], :].reshape((3, 1)), np.eye(3)*multiplier, False)\n",
      "#         pairwiseBC[i] += minusLogMultivariateNormal(patchB[tPix[0], tPix[1], :].reshape((3, 1)), patchC[tPix[0], tPix[1], :].reshape((3, 1)), np.eye(3)*multiplier, False)\n",
      "        ## sPix is above tPix\n",
      "        if sPix[0] < tPix[0] :\n",
      "            pairwiseBC[i] = gradientCostsY[sPix[0], sPix[1]] + gradientCostsY[tPix[0], tPix[1]]\n",
      "        ## sPix is to the left of tPix\n",
      "        elif sPix[1] < tPix[1] :\n",
      "            pairwiseBC[i] = gradientCostsY[sPix[0], sPix[1]] + gradientCostsY[tPix[0], tPix[1]]\n",
      "        else :\n",
      "            print \"OH OH\", sPix, tPix\n",
      "            \n",
      "#         pairwiseBC[i] = maxCost\n",
      "        \n",
      "        pairwiseCB = np.copy(pairwiseBC[i])\n",
      "#         if sPix[0] < tPix[0] :\n",
      "#             pairwiseCB = pairwiseCB*10.0\n",
      "        \n",
      "        fid = gm.addFunction(np.array([[0.0, pairwiseAB[i], pairwiseAC[i]],[pairwiseAB[i], 0.0, pairwiseBC[i]],[pairwiseAC[i], pairwiseBC[i], 0.0]]))\n",
      "        gm.addFactor(fid, pair)\n",
      "            \n",
      "    \n",
      "    # add function used for connecting the patch variables\n",
      "    fid = gm.addFunction(np.array([[0.0, maxCost, maxCost],[maxCost, 0.0, maxCost],[maxCost, maxCost, 0.0]]))\n",
      "    \n",
      "    # connect patch A to definite patch A pixels\n",
      "    if len(patchAPixels) > 0 :\n",
      "        patchAFactors = np.hstack((patchAPixels.reshape((len(patchAPixels), 1)), np.ones((len(patchAPixels), 1), dtype=uint)*idxPatchANode))\n",
      "        gm.addFactors(fid, patchAFactors)\n",
      "    \n",
      "    # connect patch B to definite patch B pixels\n",
      "    if len(patchBPixels) > 0 :\n",
      "        patchBFactors = np.hstack((patchBPixels.reshape((len(patchBPixels), 1)), np.ones((len(patchBPixels), 1), dtype=uint)*idxPatchBNode))\n",
      "        gm.addFactors(fid, patchBFactors)\n",
      "        \n",
      "    # connect patch B to definite patch B pixels\n",
      "    if len(patchCPixels) > 0 :\n",
      "        patchCFactors = np.hstack((patchCPixels.reshape((len(patchCPixels), 1)), np.ones((len(patchCPixels), 1), dtype=uint)*idxPatchCNode))\n",
      "        gm.addFactors(fid, patchCFactors)\n",
      "    \n",
      "    \n",
      "#     graphCut = opengm.inference.GraphCut(gm=gm)\n",
      "    trws = opengm.inference.TrwsExternal(gm=gm)\n",
      "    trws.infer()\n",
      "    \n",
      "    labels = np.array(trws.arg(), dtype=int)\n",
      "    print labels.shape\n",
      "    \n",
      "    reshapedLabels = np.reshape(np.copy(labels[0:-numLabels]), patchA.shape[0:2], 'F')\n",
      "    print gm\n",
      "    \n",
      "    return reshapedLabels, unaries, np.hstack((pairwiseAB, pairwiseAC, pairwiseBC)), gm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## load the tracked sprites\n",
      "trackedSprites = [{\n",
      "                   DICT_SPRITE_NAME:'havana_red_car_plusrot', \n",
      "                   DICT_BBOX_AFFINES:sio.loadmat(\"../ASLA tracker/result/havana_red_car_plusrot/Result/result.mat\")['result'], \n",
      "                   DICT_NUM_FRAMES:0, \n",
      "                   DICT_FRAMES_LOCATIONS:[]\n",
      "                   }, \n",
      "                  {\n",
      "                   DICT_SPRITE_NAME:'havana_bus', \n",
      "                   DICT_BBOX_AFFINES:sio.loadmat(\"../ASLA tracker/result/havana_bus/Result/result.mat\")['result'], \n",
      "                   DICT_NUM_FRAMES:0, \n",
      "                   DICT_FRAMES_LOCATIONS:[]\n",
      "                   }\n",
      "                  ]\n",
      "\n",
      "numOfSprites = len(trackedSprites)\n",
      "## setting number of frames from the number of tracked bboxes\n",
      "for i in arange(numOfSprites) :\n",
      "    trackedSprites[i][DICT_NUM_FRAMES] = len(trackedSprites[i][DICT_BBOX_AFFINES])\n",
      "## setting frame locations for the tracked sprites\n",
      "for i in arange(numOfSprites) :\n",
      "    trackedSprites[i][DICT_FRAMES_LOCATIONS] = np.sort(glob.glob(\"../ASLA tracker/Datasets/\" + trackedSprites[i][DICT_SPRITE_NAME] + \"/*.png\"))\n",
      "\n",
      "## default corners of bbox to be transformed by the affine matrix transformation using function below\n",
      "## [x, y] coords for each corner\n",
      "bboxDefaultCorners = np.array([ [1,-16,-16], [1,16,-16], [1,16,16], [1,-16,16], [1,-16,-16] ]).T\n",
      "def getAffMat(p) :\n",
      "    return np.array([[p[0], p[2], p[3]], [p[1], p[4], p[5]]]);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## load background image\n",
      "bgImage = np.array(Image.open(\"../data/havana/median.png\"))\n",
      "\n",
      "## frame index of sprites to merge together\n",
      "currentFramePerSprite = [263, 160]\n",
      "\n",
      "## get the bboxes for each sprite at current frame and find the offset and size of the subpatch of the total image to work with\n",
      "## boundaries of the patch [min, max]\n",
      "xBounds = np.array([bgImage.shape[1], 0.0])\n",
      "yBounds = np.array([bgImage.shape[0], 0.0])\n",
      "figure(); imshow(bgImage)\n",
      "for i in arange(numOfSprites) :\n",
      "    ## plot bbox\n",
      "    spriteBBox = np.dot(getAffMat(trackedSprites[i][DICT_BBOX_AFFINES][currentFramePerSprite[i], :]), bboxDefaultCorners)\n",
      "    plot(spriteBBox[0, :], spriteBBox[1, :])\n",
      "    \n",
      "    ## make bbox bigger\n",
      "    largeBBox = np.dot(np.array([[0.0, 0.0, 1.0+PATCH_BORDER], [0.0, 1.0+PATCH_BORDER, 0.0]]), bboxDefaultCorners)\n",
      "    ## transform according to affine transformation\n",
      "    largeBBox = np.dot(getAffMat(trackedSprites[i][DICT_BBOX_AFFINES][currentFramePerSprite[i], :]), \n",
      "                        np.vstack((np.ones((1, largeBBox.shape[1])), largeBBox)))\n",
      "    \n",
      "    xBounds[0] = np.min((xBounds[0], np.min(largeBBox[0, :])))\n",
      "    xBounds[1] = np.max((xBounds[1], np.max(largeBBox[0, :])))\n",
      "    yBounds[0] = np.min((yBounds[0], np.min(largeBBox[1, :])))\n",
      "    yBounds[1] = np.max((yBounds[1], np.max(largeBBox[1, :])))\n",
      "    \n",
      "offset = np.array([np.round(np.array([xBounds[0], yBounds[0]]))], dtype=int).T # [x, y]\n",
      "patchSize = np.array(np.round(np.array([yBounds[1]-yBounds[0], xBounds[1]-xBounds[0]])), dtype=int) # [rows, cols]\n",
      "print offset, patchSize\n",
      "\n",
      "plot([offset[0], offset[0]+patchSize[1], offset[0]+patchSize[1], offset[0], offset[0]], \n",
      "     [offset[1], offset[1], offset[1]+patchSize[0], offset[1]+patchSize[0], offset[1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[753]\n",
        " [253]] [223 171]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7f83bfd84710>]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## get image patches based on offset and patchSize\n",
      "bgPatch = np.copy(bgImage[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1], :])\n",
      "figure(); imshow(bgPatch)\n",
      "\n",
      "spritePatches = np.zeros((numOfSprites, patchSize[0], patchSize[1], bgImage.shape[-1]), dtype=uint8)\n",
      "for i in arange(numOfSprites) :\n",
      "    spritePatches[i, :, :, :] = np.array(Image.open(trackedSprites[i][DICT_FRAMES_LOCATIONS][currentFramePerSprite[i]]))[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1], :]\n",
      "    figure(); imshow(spritePatches[i, :, :, :])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(); imshow(np.sum(np.power(spritePatches[0]-bgPatch, 2), axis=-1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "<matplotlib.image.AxesImage at 0x7f55688655d0>"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## precompute pixel pairs for all edges in the patch\n",
      "gridEdges1D = np.array(opengm.secondOrderGridVis(patchSize[1],patchSize[0],True))\n",
      "gridEdges2D = np.zeros((len(gridEdges1D), 4))\n",
      "\n",
      "gridEdges2D[:, 0] = np.mod(gridEdges1D[:, 0], patchSize[0])\n",
      "gridEdges2D[:, 1] = np.array(gridEdges1D[:, 0]/patchSize[0], dtype=int)\n",
      "gridEdges2D[:, 2] = np.mod(gridEdges1D[:, 1], patchSize[0])\n",
      "gridEdges2D[:, 3] = np.array(gridEdges1D[:, 1]/patchSize[0], dtype=int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## get uniform prior for bg patch\n",
      "bgPrior = -np.log(np.ones(patchSize)/np.prod(patchSize))\n",
      "\n",
      "## get priors for all sprite patches\n",
      "spritePriors = np.zeros((numOfSprites, patchSize[0], patchSize[1]))\n",
      "xs = np.ndarray.flatten(np.arange(patchSize[1], dtype=float).reshape((patchSize[1], 1)).repeat(patchSize[0], axis=-1))\n",
      "ys = np.ndarray.flatten(np.arange(patchSize[0], dtype=float).reshape((1, patchSize[0])).repeat(patchSize[1], axis=0))\n",
      "data = np.vstack((xs.reshape((1, len(xs))), ys.reshape((1, len(ys)))))\n",
      "\n",
      "for i in arange(numOfSprites) :\n",
      "    ## get covariance and means of prior on patch by using the bbox\n",
      "    spriteBBox = np.dot(getAffMat(trackedSprites[i][DICT_BBOX_AFFINES][currentFramePerSprite[i], :]), bboxDefaultCorners)\n",
      "    segment1 = spriteBBox[:, 0] - spriteBBox[:, 1]\n",
      "    segment2 = spriteBBox[:, 1] - spriteBBox[:, 2]\n",
      "    sigmaX = np.linalg.norm(segment1)/2.0\n",
      "    sigmaY = np.linalg.norm(segment2)/2.0\n",
      "\n",
      "    ## find rotation as described here http://math.stackexchange.com/questions/612006/decomposing-an-affine-transformation\n",
      "    A11 = getAffMat(trackedSprites[spriteIdx][DICT_BBOX_AFFINES][f, :])[0, 1]\n",
      "    A21 = getAffMat(trackedSprites[spriteIdx][DICT_BBOX_AFFINES][f, :])[1, 1]\n",
      "    rotRadians = np.pi-np.arctan(A21/A11)\n",
      "\n",
      "    rotMat = np.array([[np.cos(rotRadians), -np.sin(rotRadians)], [np.sin(rotRadians), np.cos(rotRadians)]])\n",
      "    \n",
      "    means = np.reshape(trackedSprites[i][DICT_BBOX_AFFINES][currentFramePerSprite[i], 0:2], (2, 1)) - offset\n",
      "    covs = np.dot(np.dot(rotMat.T, np.array([[sigmaX**2, 0.0], [0.0, sigmaY**2]])), rotMat)\n",
      "    \n",
      "    print sigmaX, sigmaY, rotRadians, means\n",
      "    spritePriors[i, :, :] = np.reshape(minusLogMultivariateNormal(data, means, covs, True), patchSize, order='F')\n",
      "    \n",
      "    \n",
      "    figure(); imshow(spritePriors[i])\n",
      "#     gwv.showCustomGraph(np.reshape(multivariateNormal(data, means, covs, True), patchSize, order='F'))\n",
      "#     gwv.showCustomGraph(np.reshape(minusLogMultivariateNormal(data, means, covs, True), patchSize, order='F'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "57.1985262458 30.9390847809 3.12248405791 [[  90.33426982]\n",
        " [ 178.0451755 ]]\n",
        "37.4794198804"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 66.3908356928 2.72496276622 [[  86.03059067]\n",
        " [ 106.40438299]]\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(); imshow(spritePatches[0])\n",
      "sobelY = np.array([[-1, -1, -1], [0, 0, 0], [1, 2, 1]])\n",
      "sobelX = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
      "gradientsY = cv2.filter2D(cv2.cvtColor(spritePatches[0], cv2.cv.CV_RGB2GRAY)/255.0, -1, sobelY)\n",
      "gradientsX = cv2.filter2D(cv2.cvtColor(spritePatches[0], cv2.cv.CV_RGB2GRAY)/255.0, -1, sobelX)\n",
      "figure(); imshow(gradientsY, interpolation='nearest', cmap=get_cmap(\"Greys\"))\n",
      "figure(); imshow(gradientsX, interpolation='nearest', cmap=get_cmap(\"Greys\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "<matplotlib.image.AxesImage at 0x7fc408c5ea50>"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gradientCostsY = np.exp(np.abs(gradientsY)/(0.3*np.mean(np.abs(gradientsY))))\n",
      "gradientCostsY /= np.sum(gradientCostsY)\n",
      "gradientCostsY = -log(gradientCostsY)/10.0\n",
      "gradientCostsX = np.exp(np.abs(gradientsX)/(0.3*np.mean(np.abs(gradientsX))))\n",
      "gradientCostsX /= np.sum(gradientCostsX)\n",
      "gradientCostsX = -log(gradientCostsX)/10.0\n",
      "#figure(); imshow\n",
      "gwv.showCustomGraph(gradientCostsY)#, interpolation='nearest', cmap=get_cmap(\"Greys\"))\n",
      "#figure(); imshow\n",
      "gwv.showCustomGraph(gradientCostsY)#, interpolation='nearest', cmap=get_cmap(\"Greys\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.max(gradientCostsX), np.max(gradientCostsY), np.min(gradientCostsX), np.min(gradientCostsY)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5.76389593757 1.44994088419 0.000150177605816 0.140647200408\n"
       ]
      }
     ],
     "prompt_number": 218
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## get depth prior for bg by fitting a plane to the floor\n",
      "userDefinedPoints = np.array([[291, 713], [336, 945], [337, 642], [398, 879]], dtype=float)\n",
      "defaultPlanePoints = np.array([[0, 0], [0, patchSize[1]], [patchSize[0], 0], [patchSize[0], patchSize[1]]], dtype=float)\n",
      "# defaultPlanePoints = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=float)\n",
      "figure(); imshow(bgImage)\n",
      "scatter(userDefinedPoints[:, 1], userDefinedPoints[:, 0])\n",
      "\n",
      "# hom = cv2.findHomography(defaultPlanePoints, userDefinedPoints)[0]\n",
      "hom = cv2.findHomography(userDefinedPoints, defaultPlanePoints)[0]\n",
      "print hom"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ -3.54140540e+01   6.86910529e+00   5.40781763e+03]\n",
        " [ -9.18493616e+00  -5.95080371e+00   6.91573947e+03]\n",
        " [ -2.97808067e-02  -6.02943673e-03   1.00000000e+00]]\n"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure();\n",
      "transformedGrid = np.dot(hom, np.concatenate((userDefinedPoints.T, np.ones((1, userDefinedPoints.T.shape[-1]))), axis=0))\n",
      "transformedGrid /= transformedGrid[-1, :]\n",
      "scatter(transformedGrid[1, :], transformedGrid[0, :])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 101,
       "text": [
        "<matplotlib.collections.PathCollection at 0x7ff4f9f579d0>"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print transformedGrid"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ -0.00000000e+00   4.83225368e-16   1.00000000e+00   1.00000000e+00]\n",
        " [ -0.00000000e+00   1.00000000e+00  -5.50508307e-16   1.00000000e+00]\n",
        " [  1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00]]\n"
       ]
      }
     ],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.concatenate((userDefinedPoints.T, np.ones((1, userDefinedPoints.T.shape[-1]))), axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 291.  336.  337.  398.]\n",
        " [ 713.  945.  642.  879.]\n",
        " [   1.    1.    1.    1.]]\n"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(); imshow(bgImage)\n",
      "xs = np.ndarray.flatten(np.arange(patchSize[1], dtype=float).reshape((patchSize[1], 1)).repeat(patchSize[0], axis=-1))\n",
      "ys = np.ndarray.flatten(np.arange(patchSize[0], dtype=float).reshape((1, patchSize[0])).repeat(patchSize[1], axis=0))\n",
      "\n",
      "pointGrid = np.vstack((ys.reshape((1, len(ys))), xs.reshape((1, len(xs)))))\n",
      "transformedGrid = np.dot(hom, np.concatenate((pointGrid, np.ones((1, pointGrid.shape[-1]))), axis=0))\n",
      "transformedGrid /= transformedGrid[-1, :]\n",
      "scatter(transformedGrid[1, 0:-1:100], transformedGrid[0, 0:-1:100])\n",
      "# scatter(data[1, 0:-1:100], data[0, 0:-1:100], marker='.')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 85,
       "text": [
        "<matplotlib.collections.PathCollection at 0x7ff4fa33c5d0>"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## get grid of points with origin in the middle of the image\n",
      "gridXs = np.ndarray.flatten(np.arange(-bgImage.shape[1]/2, bgImage.shape[1]/2, dtype=float).reshape((bgImage.shape[1], 1)).repeat(bgImage.shape[0], axis=-1))\n",
      "gridYs = np.ndarray.flatten(np.arange(-bgImage.shape[0]/2, bgImage.shape[0]/2, dtype=float).reshape((1, bgImage.shape[0])).repeat(bgImage.shape[1], axis=0))\n",
      "\n",
      "pointGrid = np.vstack((gridYs.reshape((1, len(gridYs))), gridXs.reshape((1, len(gridXs))), np.ones((1, len(gridXs)))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gridXs = np.ndarray.flatten(np.arange(bgImage.shape[1], dtype=float).reshape((bgImage.shape[1], 1)).repeat(bgImage.shape[0], axis=-1))\n",
      "gridYs = np.ndarray.flatten(np.arange(bgImage.shape[0], dtype=float).reshape((1, bgImage.shape[0])).repeat(bgImage.shape[1], axis=0))\n",
      "\n",
      "pointGrid = np.vstack((gridYs.reshape((1, len(gridYs))), gridXs.reshape((1, len(gridXs))), np.ones((1, len(gridXs)))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = np.dot(hom, pointGrid)\n",
      "tmp /= tmp[-1, :]\n",
      "tmp[:, np.any(tmp > 1000, axis=0)] = 1000\n",
      "tmp[:, np.any(tmp < -1000, axis=0)] = -1000\n",
      "\n",
      "# print tmp.shape\n",
      "gwv.showCustomGraph(tmp[0, :].reshape(bgImage.shape[0:2], order='F'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.any(tmp > 1000, axis=0).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(921600,)\n"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.max(tmp[1, :])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1144055.96434\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## merge two overlapping patches\n",
      "\n",
      "h = patchSize[0]\n",
      "w = patchSize[1]\n",
      "\n",
      "## force one ring of pixels on the edge of the patch to come from patch A (i.e. the bg)\n",
      "patAPixs = np.arange(0, h, dtype=uint)\n",
      "patAPixs = np.unique(np.concatenate((patAPixs, np.arange(0, h*(w-1)+1, h, dtype=uint))))\n",
      "patAPixs = np.unique(np.concatenate((patAPixs, np.arange(0, h*(w-1)+1, h, dtype=uint)+h-1)))\n",
      "patAPixs = np.unique(np.concatenate((patAPixs, np.arange(h*(w-1), h*w, dtype=uint))))\n",
      "\n",
      "## force small square of size squarePadding*2 + 1 around center of patch to come from patch B (i.e. the car)\n",
      "squarePadding = 6\n",
      "rows = np.ndarray.flatten(arange((h/2)-squarePadding, (h/2)+squarePadding+1).reshape((squarePadding*2+1, 1)).repeat(squarePadding*2+1, axis=-1))\n",
      "cols = np.ndarray.flatten(arange((w/2)-squarePadding, (w/2)+squarePadding+1).reshape((1, squarePadding*2+1)).repeat(squarePadding*2+1, axis=0))\n",
      "patBPixs = rows + cols*h\n",
      "patBPixs = np.empty(0)\n",
      "\n",
      "patA = np.copy(bgPatch/255.0)\n",
      "patB = np.copy(spritePatches[0]/255.0)\n",
      "\n",
      "labels, unaryCosts, pairCosts, graphModel = getGraphcutOnOverlap(patA, patB, patAPixs, patBPixs, 0.001, \n",
      "                                                   bgPrior.reshape(np.prod(patchSize), order='F'),\n",
      "                                                   spritePriors[0].reshape(np.prod(patchSize), order='F'))\n",
      "\n",
      "figure(); imshow(labels, interpolation='nearest')\n",
      "\n",
      "outputPatch = np.zeros(patA.shape, dtype=uint8)\n",
      "for i in xrange(labels.shape[0]) :\n",
      "    for j in xrange(labels.shape[1]) :\n",
      "        if labels[i, j] == 0 :\n",
      "            outputPatch[i, j, :] = patA[i, j, :]*255\n",
      "        else :\n",
      "            outputPatch[i, j, :] = patB[i, j, :]*255\n",
      "            \n",
      "figure(); imshow(outputPatch, interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-number of variables :38135\n",
        "-number of function(type-0)114008\n",
        "-number of function(type-1)0\n",
        "-number of function(type-2)0\n",
        "-number of function(type-3)0\n",
        "-number of function(type-4)0\n",
        "-number of function(type-5)0\n",
        "-number of function(type-6)0\n",
        "-number of function(type-7)0\n",
        "-number of factors :114791\n",
        "-max. factor order :2\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "<matplotlib.image.AxesImage at 0x7fc408d5ded0>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## merge three overlapping patches\n",
      "\n",
      "h = patchSize[0]\n",
      "w = patchSize[1]\n",
      "\n",
      "## force one ring of pixels on the edge of the patch to come from patch A (i.e. the bg)\n",
      "patAPixs = np.arange(0, h, dtype=uint)\n",
      "patAPixs = np.unique(np.concatenate((patAPixs, np.arange(0, h*(w-1)+1, h, dtype=uint))))\n",
      "patAPixs = np.unique(np.concatenate((patAPixs, np.arange(0, h*(w-1)+1, h, dtype=uint)+h-1)))\n",
      "patAPixs = np.unique(np.concatenate((patAPixs, np.arange(h*(w-1), h*w, dtype=uint))))\n",
      "\n",
      "## force small square of size squarePadding*2 + 1 around center of patch to come from patch B (i.e. the car)\n",
      "squarePadding = 6\n",
      "rows = np.ndarray.flatten(arange((h/2)-squarePadding, (h/2)+squarePadding+1).reshape((squarePadding*2+1, 1)).repeat(squarePadding*2+1, axis=-1))\n",
      "cols = np.ndarray.flatten(arange((w/2)-squarePadding, (w/2)+squarePadding+1).reshape((1, squarePadding*2+1)).repeat(squarePadding*2+1, axis=0))\n",
      "patBPixs = rows + cols*h\n",
      "patBPixs = np.empty(0)\n",
      "patCPixs = np.empty(0)\n",
      "\n",
      "patA = np.copy(bgPatch/255.0)\n",
      "patB = np.copy(spritePatches[0]/255.0)\n",
      "patC = np.copy(spritePatches[1]/255.0)\n",
      "\n",
      "labels, unaryCosts, pairCosts, graphModel = get3WayLabelling(patA, patB, patC, patAPixs, patBPixs, patCPixs, 0.005, \n",
      "                                                   bgPrior.reshape(np.prod(patchSize), order='F'),\n",
      "                                                   spritePriors[0].reshape(np.prod(patchSize), order='F'),\n",
      "                                                   spritePriors[1].reshape(np.prod(patchSize), order='F'))\n",
      "# labels, unaryCosts, pairCosts = get3WayLabelling(patA, patB, patC, patAPixs, patBPixs, patCPixs, 0.005, \n",
      "#                                                    bgPrior.reshape(np.prod(patchSize), order='F'),\n",
      "#                                                    (spritePriors[0]*(1.0-weightedDiffAB/np.max(weightedDiffAB))).reshape(np.prod(patchSize), order='F'),\n",
      "#                                                    (spritePriors[1]*(1.0-weightedDiffAC/np.max(weightedDiffAC))).reshape(np.prod(patchSize), order='F'))\n",
      "\n",
      "figure(); imshow(labels, interpolation='nearest')\n",
      "\n",
      "outputPatch = np.zeros(patA.shape, dtype=uint8)\n",
      "for i in xrange(labels.shape[0]) :\n",
      "    for j in xrange(labels.shape[1]) :\n",
      "        if labels[i, j] == 0 :\n",
      "            outputPatch[i, j, :] = patA[i, j, :]*255\n",
      "        elif labels[i, j] == 1 :\n",
      "            outputPatch[i, j, :] = patB[i, j, :]*255\n",
      "        else :\n",
      "            outputPatch[i, j, :] = patC[i, j, :]*255\n",
      "            \n",
      "figure(); imshow(outputPatch, interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "223 171 (38136, 3)\n",
        "(38136,)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-number of variables :38136\n",
        "-number of function(type-0)114009\n",
        "-number of function(type-1)0\n",
        "-number of function(type-2)0\n",
        "-number of function(type-3)0\n",
        "-number of function(type-4)0\n",
        "-number of function(type-5)0\n",
        "-number of function(type-6)0\n",
        "-number of function(type-7)0\n",
        "-number of factors :114792\n",
        "-max. factor order :2\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "<matplotlib.image.AxesImage at 0x7f556793ca10>"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## load the tracked sprites\n",
      "DICT_SPRITE_NAME = 'sprite_name'\n",
      "# DICT_BBOX_AFFINES = 'bbox_affines'\n",
      "DICT_BBOXES = 'bboxes'\n",
      "DICT_BBOX_ROTATIONS = 'bbox_rotations'\n",
      "DICT_BBOX_CENTERS = 'bbox_centers'\n",
      "# DICT_NUM_FRAMES = 'num_frames'\n",
      "# DICT_START_FRAME = 'start_frame'\n",
      "DICT_FRAMES_LOCATIONS = 'frame_locs'\n",
      "\n",
      "dataPath = \"/home/ilisescu/PhD/data/\"\n",
      "dataSet = \"havana/\"\n",
      "formatString = \"{:05d}.png\"\n",
      "\n",
      "TL_IDX = 0\n",
      "TR_IDX = 1\n",
      "BR_IDX = 2\n",
      "BL_IDX = 3\n",
      "\n",
      "## load dataSet relevant data\n",
      "frameLocs = np.sort(glob.glob(dataPath + dataSet + \"/frame-*.png\"))\n",
      "numOfFrames = len(frameLocs)\n",
      "numOfTrackedSprites = 0\n",
      "bgImage = np.array(Image.open(dataPath + dataSet + \"median.png\"))\n",
      "\n",
      "trackedSprites = []\n",
      "for sprite in glob.glob(dataPath + dataSet + \"sprite*.npy\") :\n",
      "    trackedSprites.append(np.load(sprite).item())\n",
      "\n",
      "## merge tracked sprite with bg\n",
      "spriteIdx = 0\n",
      "sequenceLength = len(trackedSprites[spriteIdx][DICT_BBOXES])\n",
      "showFigs = False\n",
      "\n",
      "outputPath = dataPath + dataSet + trackedSprites[spriteIdx][DICT_SPRITE_NAME] + \"-mergedWithBG/\"\n",
      "\n",
      "if outputPath != None and not os.path.isdir(outputPath):\n",
      "    os.makedirs(outputPath)\n",
      "\n",
      "if showFigs :\n",
      "    figure(); imshow(bgImage)\n",
      "\n",
      "startTime = time.time()\n",
      "for f, frameCount in zip(np.sort(trackedSprites[spriteIdx][DICT_BBOXES].keys()), xrange(len(trackedSprites[spriteIdx][DICT_BBOXES].keys()))):#[1109:1110]:#sequenceLength):\n",
      "    ## get the bbox for the current sprite frame, make it larger and find the rectangular patch to work with\n",
      "    ## boundaries of the patch [min, max]\n",
      "    \n",
      "    s = time.time()\n",
      "    xBounds = np.array([bgImage.shape[1], 0.0])\n",
      "    yBounds = np.array([bgImage.shape[0], 0.0])\n",
      "    \n",
      "    \n",
      "    if showFigs :\n",
      "        ## plot bbox\n",
      "        spriteBBox = np.vstack((trackedSprites[spriteIdx][DICT_BBOXES][f], trackedSprites[spriteIdx][DICT_BBOXES][f][0, :])).T\n",
      "        plot(spriteBBox[0, :], spriteBBox[1, :])\n",
      "    \n",
      "    ## make bbox bigger\n",
      "    largeBBox = trackedSprites[spriteIdx][DICT_BBOXES][f].T\n",
      "    ## move to origin\n",
      "    largeBBox = np.dot(np.array([[-trackedSprites[spriteIdx][DICT_BBOX_CENTERS][f][0], 1.0, 0.0], \n",
      "                                 [-trackedSprites[spriteIdx][DICT_BBOX_CENTERS][f][1], 0.0, 1.0]]), \n",
      "                        np.vstack((np.ones((1, largeBBox.shape[1])), largeBBox)))\n",
      "    ## make bigger\n",
      "    largeBBox = np.dot(np.array([[0.0, 1.0 + PATCH_BORDER, 0.0], \n",
      "                                 [0.0, 0.0, 1.0 + PATCH_BORDER]]), \n",
      "                        np.vstack((np.ones((1, largeBBox.shape[1])), largeBBox)))\n",
      "    ## move back tooriginal center\n",
      "    largeBBox = np.dot(np.array([[trackedSprites[spriteIdx][DICT_BBOX_CENTERS][f][0], 1.0, 0.0], \n",
      "                                 [trackedSprites[spriteIdx][DICT_BBOX_CENTERS][f][1], 0.0, 1.0]]), \n",
      "                        np.vstack((np.ones((1, largeBBox.shape[1])), largeBBox)))\n",
      "    \n",
      "    \n",
      "    ## make sure xBounds are in between 0 and width and yBounds are in between 0 and height\n",
      "    xBounds[0] = np.max((0, np.min(largeBBox[0, :])))\n",
      "    xBounds[1] = np.min((bgImage.shape[1], np.max(largeBBox[0, :])))\n",
      "    yBounds[0] = np.max((0, np.min(largeBBox[1, :])))\n",
      "    yBounds[1] = np.min((bgImage.shape[0], np.max(largeBBox[1, :])))\n",
      "    \n",
      "#     print xBounds, yBounds\n",
      "    \n",
      "    offset = np.array([np.round(np.array([xBounds[0], yBounds[0]]))], dtype=int).T # [x, y]\n",
      "    patchSize = np.array(np.round(np.array([yBounds[1]-yBounds[0], xBounds[1]-xBounds[0]])), dtype=int) # [rows, cols]\n",
      "#     print offset, patchSize\n",
      "    \n",
      "    if showFigs :\n",
      "        plot([offset[0], offset[0]+patchSize[1], offset[0]+patchSize[1], offset[0], offset[0]], \n",
      "             [offset[1], offset[1], offset[1]+patchSize[0], offset[1]+patchSize[0], offset[1]])\n",
      "\n",
      "    ## get image patches based on offset and patchSize\n",
      "    bgPatch = np.copy(bgImage[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1], :])\n",
      "    \n",
      "    if showFigs :\n",
      "        figure(); imshow(bgPatch)\n",
      "    \n",
      "    \n",
      "    spritePatch = np.copy(np.array(Image.open(trackedSprites[spriteIdx][DICT_FRAMES_LOCATIONS][f]))[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1], :])\n",
      "    \n",
      "    if showFigs :\n",
      "        figure(); imshow(spritePatch)\n",
      "        \n",
      "    \n",
      "#     print \"patch fetch took\", time.time()-s, \"seconds\"\n",
      "#     sys.stdout.flush()\n",
      "    s = time.time()\n",
      "        \n",
      "#     ## precompute pixel pairs for all edges in the patch\n",
      "#     gridEdges1D = np.array(opengm.secondOrderGridVis(patchSize[1],patchSize[0],True))\n",
      "#     print \"grideEdges1D took\", time.time()-s, \"seconds\"\n",
      "#     sys.stdout.flush()\n",
      "#     s = time.time()\n",
      "\n",
      "#     gridEdges2D = np.zeros((len(gridEdges1D), 4))\n",
      "    \n",
      "#     gridEdges2D[:, 0] = np.mod(gridEdges1D[:, 0], patchSize[0])\n",
      "#     gridEdges2D[:, 1] = np.array(gridEdges1D[:, 0]/patchSize[0], dtype=int)\n",
      "#     gridEdges2D[:, 2] = np.mod(gridEdges1D[:, 1], patchSize[0])\n",
      "#     gridEdges2D[:, 3] = np.array(gridEdges1D[:, 1]/patchSize[0], dtype=int)\n",
      "\n",
      "#     print \"grideEdges2D took\", time.time()-s, \"seconds\"\n",
      "#     sys.stdout.flush()\n",
      "#     s = time.time()\n",
      "\n",
      "    ## get uniform prior for bg patch\n",
      "    bgPrior = -np.log(np.ones(patchSize)/np.prod(patchSize))\n",
      "    \n",
      "    ## get priors for all sprite patches\n",
      "    spritePrior = np.zeros(patchSize)\n",
      "    xs = np.ndarray.flatten(np.arange(patchSize[1], dtype=float).reshape((patchSize[1], 1)).repeat(patchSize[0], axis=-1))\n",
      "    ys = np.ndarray.flatten(np.arange(patchSize[0], dtype=float).reshape((1, patchSize[0])).repeat(patchSize[1], axis=0))\n",
      "    data = np.vstack((xs.reshape((1, len(xs))), ys.reshape((1, len(ys)))))\n",
      "    \n",
      "    ## get covariance and means of prior on patch by using the bbox\n",
      "    spriteBBox = trackedSprites[spriteIdx][DICT_BBOXES][f].T\n",
      "    segment1 = spriteBBox[:, 0] - spriteBBox[:, 1]\n",
      "    segment2 = spriteBBox[:, 1] - spriteBBox[:, 2]\n",
      "    sigmaX = np.linalg.norm(segment1)/3.7\n",
      "    sigmaY = np.linalg.norm(segment2)/3.7\n",
      "\n",
      "#     ## find rotation as described here http://math.stackexchange.com/questions/612006/decomposing-an-affine-transformation\n",
      "#     A11 = getAffMat(trackedSprites[spriteIdx][DICT_BBOX_AFFINES][f, :])[0, 1]\n",
      "#     A21 = getAffMat(trackedSprites[spriteIdx][DICT_BBOX_AFFINES][f, :])[1, 1]\n",
      "# #     rotRadians = np.pi-np.arctan(A21/A11)\n",
      "#     rotRadians = np.arccos(np.dot((segment1)/np.linalg.norm(segment1), np.array([1.0, 0.0])))\n",
      "#     b = np.array([1.0, 0.0])\n",
      "#     ## arctan2 is computed based on formula: a[0]*b[1]-b[0]*a[1], a[0]*b[0]+a[1]*b[1]) where b = [1, 0] and a = segment1\n",
      "#     rotRadians = np.mod(np.arctan2(-segment1[1], segment1[0]),2*np.pi)\n",
      "#     print \"rotation\", rotRadians*180.0/np.pi\n",
      "    rotRadians = trackedSprites[spriteIdx][DICT_BBOX_ROTATIONS][f]\n",
      "    \n",
      "    rotMat = np.array([[np.cos(rotRadians), -np.sin(rotRadians)], [np.sin(rotRadians), np.cos(rotRadians)]])\n",
      "    \n",
      "    means = np.reshape(trackedSprites[spriteIdx][DICT_BBOX_CENTERS][f], (2, 1)) - offset\n",
      "    covs = np.dot(np.dot(rotMat.T, np.array([[sigmaX**2, 0.0], [0.0, sigmaY**2]])), rotMat)\n",
      "    \n",
      "#     print sigmaX, sigmaY, rotRadians, means\n",
      "    spritePrior = np.reshape(minusLogMultivariateNormal(data, means, covs, True), patchSize, order='F')\n",
      "    \n",
      "#     print \"sprite prior took\", time.time()-s, \"seconds\"\n",
      "#     sys.stdout.flush()\n",
      "    s = time.time()\n",
      "    \n",
      "    \n",
      "    if showFigs :\n",
      "        figure(); imshow(spritePrior)\n",
      "#         gwv.showCustomGraph(np.reshape(multivariateNormal(data, means, covs, True), patchSize, order='F'))\n",
      "#         gwv.showCustomGraph(np.reshape(minusLogMultivariateNormal(data, means, covs, True), patchSize, order='F'))\n",
      "\n",
      "    ## merge two overlapping patches\n",
      "\n",
      "    h = patchSize[0]\n",
      "    w = patchSize[1]\n",
      "    \n",
      "    patAPixs = np.empty(0, dtype=uint)\n",
      "    patBPixs = np.empty(0, dtype=uint)\n",
      "    \n",
      "    ## force small square of size squarePadding*2 + 1 around center of patch to come from patch B (i.e. the car)\n",
      "    squarePadding = 6\n",
      "    rows = np.ndarray.flatten(arange((h/2)-squarePadding, (h/2)+squarePadding+1).reshape((squarePadding*2+1, 1)).repeat(squarePadding*2+1, axis=-1))\n",
      "    cols = np.ndarray.flatten(arange((w/2)-squarePadding, (w/2)+squarePadding+1).reshape((1, squarePadding*2+1)).repeat(squarePadding*2+1, axis=0))\n",
      "    patBPixs = np.unique(np.concatenate((patBPixs, np.array(rows + cols*h, dtype=uint))))\n",
      "    \n",
      "    ## force one ring of pixels on the edge of the patch to come from patch A (i.e. the bg) (unless that column/row is intersected by the bbox)\n",
      "    if np.min((largeBBox)[0, :]) > 0.0 :\n",
      "#         print \"adding left column to A\"\n",
      "        patAPixs = np.unique(np.concatenate((patAPixs, np.arange(0, h, dtype=uint)[1:-1])))\n",
      "    else :\n",
      "#         print \"adding left column to B\"\n",
      "        patBPixs = np.unique(np.concatenate((patBPixs, np.arange(0, h, dtype=uint)[1:-1])))\n",
      "    if np.min((largeBBox)[1, :]) > 0.0 :\n",
      "#         print \"adding top row to A\"\n",
      "        patAPixs = np.unique(np.concatenate((patAPixs, np.arange(0, h*(w-1)+1, h, dtype=uint)[1:-1])))\n",
      "    else :\n",
      "#         print \"adding top row to B\"\n",
      "        patBPixs = np.unique(np.concatenate((patBPixs, np.arange(0, h*(w-1)+1, h, dtype=uint)[1:-1])))\n",
      "    if np.max((largeBBox)[1, :]) < bgImage.shape[0] :\n",
      "#         print \"adding bottom row to A\"\n",
      "        patAPixs = np.unique(np.concatenate((patAPixs, np.arange(0, h*(w-1)+1, h, dtype=uint)[1:-1]+h-1)))\n",
      "    else :\n",
      "#         print \"adding bottom row to B\"\n",
      "        patBPixs = np.unique(np.concatenate((patBPixs, np.arange(0, h*(w-1)+1, h, dtype=uint)[1:-1]+h-1)))\n",
      "    if np.max((largeBBox)[0, :]) < bgImage.shape[1] :\n",
      "#         print \"adding right column to A\"\n",
      "        patAPixs = np.unique(np.concatenate((patAPixs, np.arange(h*(w-1), h*w, dtype=uint)[1:-1])))\n",
      "    else :\n",
      "#         print \"adding right column to B\"\n",
      "        patBPixs = np.unique(np.concatenate((patBPixs, np.arange(h*(w-1), h*w, dtype=uint)[1:-1])))\n",
      "    \n",
      "#     patBPixs = np.empty(0)\n",
      "    \n",
      "    patA = np.copy(bgPatch/255.0)\n",
      "    patB = np.copy(spritePatch/255.0)\n",
      "    \n",
      "#     print \"patch pixels took\", time.time()-s, \"seconds\"\n",
      "#     sys.stdout.flush()\n",
      "    s = time.time()\n",
      "    \n",
      "    labels, unaryCosts, pairCosts, graphModel = getGraphcutOnOverlap(patA, patB, patAPixs, patBPixs, 0.001, \n",
      "                                                       bgPrior.reshape(np.prod(patchSize), order='F'),\n",
      "                                                       spritePrior.reshape(np.prod(patchSize), order='F'))\n",
      "    \n",
      "#     print \"graphcut took\", time.time()-s, \"seconds\"\n",
      "#     sys.stdout.flush()\n",
      "    s = time.time()\n",
      "    \n",
      "    if showFigs :\n",
      "        figure(); imshow(labels, interpolation='nearest')\n",
      "    \n",
      "    outputPatch = np.zeros(patA.shape, dtype=uint8)\n",
      "    for i in xrange(labels.shape[0]) :\n",
      "        for j in xrange(labels.shape[1]) :\n",
      "            if labels[i, j] == 0 :\n",
      "                outputPatch[i, j, :] = patA[i, j, :]*255\n",
      "            else :\n",
      "                outputPatch[i, j, :] = patB[i, j, :]*255\n",
      "    \n",
      "    if showFigs :\n",
      "        figure(); imshow(outputPatch, interpolation='nearest')\n",
      "        \n",
      "        \n",
      "    currentFrame = np.copy(bgImage)\n",
      "    currentFrame[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1], :] = np.copy(outputPatch)\n",
      "    \n",
      "    frameMask = np.zeros(bgImage.shape, dtype=np.uint8)\n",
      "#     frameMask[offset[1]:offset[1]+patchSize[0], offset[0]:offset[0]+patchSize[1], :] = labels*255\n",
      "    ## offest is (x, y) whereas argwhere returns (row, col)\n",
      "    fgIdxs = np.argwhere(labels == 1) + offset[::-1].T\n",
      "    frameMask[fgIdxs[:, 0], fgIdxs[:, 1], :] = 255\n",
      "    \n",
      "    if showFigs :\n",
      "        figure(); imshow(currentFrame)\n",
      "        figure(); imshow(np.array(Image.open(trackedSprites[spriteIdx][DICT_FRAMES_LOCATIONS][f])))\n",
      "    \n",
      "#     saveLoc = outputPath + trackedSprites[spriteIdx][DICT_FRAMES_LOCATIONS][f].split('/')[-1]\n",
      "    \n",
      "    Image.fromarray((currentFrame).astype(numpy.uint8)).save(outputPath + trackedSprites[spriteIdx][DICT_FRAMES_LOCATIONS][f].split('/')[-1])\n",
      "    Image.fromarray((frameMask).astype(numpy.uint8)).save(outputPath + \"mask-\" + trackedSprites[spriteIdx][DICT_FRAMES_LOCATIONS][f].split('/')[-1])\n",
      "    \n",
      "#     print \"saving took\", time.time()-s, \"seconds\"\n",
      "#     sys.stdout.flush()\n",
      "    sys.stdout.write('\\r' + \"Done \" + np.string_(frameCount+1) + \" images of \" + np.string_(len(trackedSprites[spriteIdx][DICT_BBOXES].keys())))\n",
      "    sys.stdout.flush()\n",
      "    \n",
      "print \n",
      "print \"total time:\", time.time() - startTime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 1 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 2 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 3 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 4 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 5 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 6 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 7 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 8 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 9 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 10 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 11 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 12 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 13 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 14 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 15 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 16 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 17 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 18 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 19 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 20 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 21 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 22 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 23 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 24 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 25 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 26 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 27 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 28 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 29 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 30 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 31 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 32 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 33 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 34 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 35 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 36 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 37 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 38 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 39 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 40 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 41 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 42 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 43 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 44 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 45 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 46 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 47 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 48 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 49 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 50 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 51 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 52 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 53 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 54 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 55 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 56 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 57 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 58 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 59 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 60 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 61 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 62 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 63 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 64 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 65 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 66 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 67 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 68 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 69 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 70 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 71 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 72 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 73 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 74 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 75 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 76 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 77 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 78 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 79 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 80 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 81 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 82 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 83 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 84 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 85 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 86 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 87 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 88 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 89 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 90 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 91 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 92 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 93 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 94 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 95 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 96 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 97 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 98 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 99 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 100 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 101 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 102 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 103 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 104 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 105 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 106 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 107 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 108 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 109 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 110 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 111 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 112 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 113 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 114 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 115 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 116 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 117 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 118 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 119 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 120 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 121 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 122 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 123 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 124 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 125 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 126 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 127 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 128 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 129 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 130 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 131 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 132 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 133 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 134 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 135 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 136 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 137 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 138 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 139 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 140 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 141 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 142 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 143 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 144 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 145 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 146 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 147 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 148 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 149 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 150 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 151 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 152 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 153 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 154 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 155 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 156 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 157 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 158 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 159 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 160 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 161 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 162 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 163 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 164 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 165 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 166 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 167 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 168 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 169 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 170 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 171 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 172 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 173 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 174 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 175 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 176 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 177 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 178 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 179 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 180 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 181 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 182 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 183 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 184 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 185 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 186 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 187 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 188 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 189 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 190 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 191 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 192 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 193 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 194 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 195 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 196 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 197 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 198 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 199 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 200 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 201 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 202 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 203 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 204 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 205 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 206 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 207 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 208 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 209 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 210 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 211 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 212 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 213 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 214 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 215 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 216 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 217 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 218 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 219 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 220 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 221 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 222 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 223 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 224 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 225 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 226 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 227 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 228 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 229 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 230 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 231 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 232 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 233 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 234 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 235 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 236 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 237 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 238 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 239 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 240 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 241 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 242 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 243 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 244 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 245 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 246 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 247 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 248 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 249 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 250 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 251 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 252 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 253 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 254 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 255 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 256 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 257 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 258 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 259 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 260 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 261 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 262 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 263 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 264 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 265 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 266 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 267 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 268 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 269 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 270 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 271 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 272 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 273 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 274 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 275 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 276 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 277 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 278 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 279 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 280 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 281 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 282 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 283 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 284 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 285 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 286 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 287 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 288 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 289 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 290 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 291 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 292 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 293 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 294 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 295 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 296 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 297 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 298 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 299 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 300 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 301 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 302 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 303 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 304 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 305 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 306 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 307 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 308 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 309 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 310 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 311 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 312 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 313 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 314 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 315 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 316 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 317 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 318 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 319 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 320 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 321 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 322 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 323 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 324 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 325 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 326 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 327 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 328 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 329 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 330 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 331 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 332 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 333 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 334 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 335 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 336 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 337 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 338 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 339 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 340 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 341 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 342 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 343 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 344 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 345 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 346 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 347 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 348 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 349 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 350 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 351 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 352 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 353 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 354 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 355 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 356 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 357 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 358 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 359 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 360 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 361 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 362 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 363 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 364 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 365 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 366 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 367 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 368 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 369 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 370 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 371 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 372 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 373 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 374 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 375 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 376 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 377 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 378 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 379 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 380 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 381 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 382 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 383 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 384 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 385 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 386 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 387 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 388 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 389 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 390 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 391 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 392 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 393 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 394 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 395 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 396 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 397 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 398 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 399 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 400 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 401 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 402 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 403 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 404 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 405 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 406 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 407 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 408 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 409 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 410 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 411 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 412 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 413 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 414 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 415 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 416 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 417 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 418 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 419 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 420 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 421 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 422 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 423 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 424 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 425 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 426 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 427 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 428 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 429 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 430 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 431 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 432 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 433 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 434 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 435 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 436 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 437 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 438 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 439 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 440 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 441 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 442 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 443 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 444 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 445 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 446 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 447 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 448 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 449 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 450 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 451 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 452 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 453 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 454 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 455 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 456 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 457 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 458 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 459 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 460 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 461 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 462 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 463 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 464 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 465 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 466 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 467 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 468 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 469 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 470 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 471 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 472 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 473 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 474 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 475 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 476 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 477 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 478 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 479 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 480 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 481 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 482 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 483 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 484 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 485 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 486 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 487 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 488 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 489 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 490 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 491 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 492 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 493 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 494 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 495 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 496 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 497 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 498 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 499 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 500 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 501 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 502 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 503 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 504 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 505 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 506 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 507 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 508 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 509 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 510 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 511 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 512 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 513 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 514 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 515 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 516 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 517 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 518 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 519 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 520 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 521 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 522 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 523 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 524 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 525 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 526 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 527 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 528 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 529 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 530 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 531 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 532 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 533 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 534 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 535 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 536 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 537 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 538 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 539 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 540 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 541 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 542 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 543 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 544 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 545 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 546 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 547 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 548 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 549 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Done 550 images of 550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "total time: 0.361674070358\n"
       ]
      }
     ],
     "prompt_number": 420
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = np.zeros(patchSize)\n",
      "tmp[np.array(np.mod(patAPixs, patchSize[0]), dtype=int), np.array(patAPixs/patchSize[0], dtype=int)] += 1\n",
      "tmp[np.array(np.mod(patBPixs, patchSize[0]), dtype=int), np.array(patBPixs/patchSize[0], dtype=int)] += 2\n",
      "figure(); imshow(tmp, interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 77,
       "text": [
        "<matplotlib.image.AxesImage at 0x7fe8b70e5a10>"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(); imshow(bgImage)\n",
      "\n",
      "transform = getAffMat(trackedSprites[spriteIdx][DICT_BBOX_AFFINES][f, :])\n",
      "transform[1, 0] = 500\n",
      "transform[0, 0] = 400\n",
      "\n",
      "## get the bbox for the current sprite frame, make it larger and find the rectangular patch to work with\n",
      "## boundaries of the patch [min, max]\n",
      "xBounds = np.array([bgImage.shape[1], 0.0])\n",
      "yBounds = np.array([bgImage.shape[0], 0.0])\n",
      "\n",
      "## plot bbox\n",
      "spriteBBox = np.dot(transform, bboxDefaultCorners)\n",
      "plot(spriteBBox[0, :], spriteBBox[1, :])\n",
      "\n",
      "\n",
      "largeBBox = np.dot(np.array([[0.0, 0.0, 1.0+PATCH_BORDER], [0.0, 1.0+PATCH_BORDER, 0.0]]), bboxDefaultCorners)\n",
      "## transform according to affine transformation\n",
      "largeBBox = np.dot(transform, np.vstack((np.ones((1, largeBBox.shape[1])), largeBBox)))\n",
      "plot(largeBBox[0, :], largeBBox[1, :])\n",
      "\n",
      "## make sure xBounds are in between 0 and width and yBounds are in between 0 and height\n",
      "xBounds[0] = np.max((0, np.min(largeBBox[0, :])))\n",
      "xBounds[1] = np.min((bgImage.shape[1], np.max(largeBBox[0, :])))\n",
      "yBounds[0] = np.max((0, np.min(largeBBox[1, :])))\n",
      "yBounds[1] = np.min((bgImage.shape[0], np.max(largeBBox[1, :])))\n",
      "\n",
      "#     print xBounds, yBounds\n",
      "\n",
      "offset = np.array([np.round(np.array([xBounds[0], yBounds[0]]))], dtype=int).T # [x, y]\n",
      "patchSize = np.array(np.round(np.array([yBounds[1]-yBounds[0], xBounds[1]-xBounds[0]])), dtype=int) # [rows, cols]\n",
      "\n",
      "plot([offset[0], offset[0]+patchSize[1], offset[0]+patchSize[1], offset[0], offset[0]], \n",
      "     [offset[1], offset[1], offset[1]+patchSize[0], offset[1]+patchSize[0], offset[1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 172,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7fc406403490>]"
       ]
      }
     ],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if np.min((largeBBox)[0, :]) > 0.0 :\n",
      "    print \"adding left column\"\n",
      "#     patAPixs = np.arange(0, h, dtype=uint)\n",
      "if np.min((largeBBox)[1, :]) > 0.0 :\n",
      "    print \"adding top row\"\n",
      "#     patAPixs = np.unique(np.concatenate((patAPixs, np.arange(0, h*(w-1)+1, h, dtype=uint))))\n",
      "if np.max((largeBBox)[1, :]) < bgImage.shape[0] :\n",
      "    print \"adding bottom row\"\n",
      "#     patAPixs = np.unique(np.concatenate((patAPixs, np.arange(0, h*(w-1)+1, h, dtype=uint)+h-1)))\n",
      "if np.max((largeBBox)[0, :]) < bgImage.shape[1] :\n",
      "    print \"adding right column\"\n",
      "#     patAPixs = np.unique(np.concatenate((patAPixs, np.arange(h*(w-1), h*w, dtype=uint))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "adding left column\n",
        "adding top row\n",
        "adding bottom row\n",
        "adding right column\n"
       ]
      }
     ],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labs = np.copy(labels).reshape(np.prod(patchSize), order='F')\n",
      "cutEdges = np.zeros(patchSize)\n",
      "cutSpriteEdges = np.zeros(patchSize)\n",
      "for factor in graphModel.factors(order=2) :\n",
      "    varIdxs = factor.variableIndices\n",
      "    if varIdxs[0] < np.prod(patchSize) and varIdxs[1] < np.prod(patchSize) :\n",
      "        sPix = np.array([int(np.mod(varIdxs[0],h)), int(varIdxs[0]/h)])\n",
      "        tPix = np.array([int(np.mod(varIdxs[1],h)), int(varIdxs[1]/h)])\n",
      "        if (labs[varIdxs[0]] == 1 and labs[varIdxs[1]] == 2) or (labs[varIdxs[1]] == 1 and labs[varIdxs[0]] == 2) :\n",
      "            print varIdxs, factor[labs[varIdxs[0]], labs[varIdxs[1]]]\n",
      "            cutSpriteEdges[sPix[0], sPix[1]] = factor[labs[varIdxs[0]], labs[varIdxs[1]]]\n",
      "            cutSpriteEdges[tPix[0], tPix[1]] = factor[labs[varIdxs[0]], labs[varIdxs[1]]]\n",
      "            \n",
      "        if labs[varIdxs[0]] - labs[varIdxs[1]] != 0 :\n",
      "            cutEdges[sPix[0], sPix[1]] = factor[labs[varIdxs[0]], labs[varIdxs[1]]]\n",
      "            cutEdges[tPix[0], tPix[1]] = factor[labs[varIdxs[0]], labs[varIdxs[1]]]\n",
      "            \n",
      "gwv.showCustomGraph(cutEdges)\n",
      "gwv.showCustomGraph(cutSpriteEdges)\n",
      "print np.max(cutEdges), np.unique(np.sort(np.ndarray.flatten(cutEdges)))[1]\n",
      "print np.max(cutSpriteEdges), np.unique(np.sort(np.ndarray.flatten(cutSpriteEdges)))[1]\n",
      "print np.sum(cutEdges)\n",
      "print np.sum(cutSpriteEdges)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[9731, 9732, ] 3.83404029228\n",
        "[10177, 10178, ] 3.83899973805\n",
        "[10400, 10401, ] 3.8489186296\n",
        "[12187, 12410, ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.85387807537\n",
        "[12410, 12411, ] 3.82660112362\n",
        "[12633, 12634, ] 3.82908084651\n",
        "[12856, 12857, ] 3.84395918383\n",
        "[13079, 13080, ] 3.86131724403\n",
        "[13302, 13303, ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.87123613557\n",
        "[13525, 13526, ] 3.88611447289\n",
        "[13748, 13749, ] 3.88859419577\n",
        "[13971, 13972, ] 3.89355364154\n",
        "[14194, 14195, ] 3.90347253309\n",
        "[14417, 14418, ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.91091170175\n",
        "[14640, 14641, ] 3.91339142463\n",
        "[14863, 14864, ] 3.92083059329\n",
        "[15086, 15087, ] 3.92331031618\n",
        "[15309, 15310, ] 3.92083059329\n",
        "[15532, 15533, ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.91091170175\n",
        "[15755, 15756, ] 3.88859419577\n",
        "[15978, 15979, ] 3.86131724403\n",
        "[16201, 16202, ] 3.84643890671\n",
        "[16424, 16425, ] 3.84643890671\n",
        "[16647, 16648, ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.8315605694\n",
        "[16870, 16871, ] 3.81420250919\n",
        "[17093, 17094, ] 3.79436472611\n",
        "[17316, 17317, ] 3.77204722013\n",
        "[17539, 17540, ] 3.75468915993\n",
        "[17762, 17763, ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.74477026839\n",
        "[17985, 17986, ] 3.7249324853\n",
        "[18208, 18209, ] 3.70261497933\n",
        "[18431, 18432, ] 3.68277719624\n",
        "[18654, 18655, ] 3.67037858181\n",
        "[18877, 18878, ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.67037858181\n",
        "[19100, 19101, ] 3.65797996738\n",
        "[19323, 19324, ] 3.60590578677\n",
        "[19546, 19547, ] 3.52903437731\n",
        "[19769, 19770, ] 3.50671687134\n",
        "[19992, 19993, ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.50423714845\n",
        "[20215, 20216, ] 3.48191964248\n",
        "[20438, 20439, ] 3.45464269073\n",
        "[20661, 20662, ] 3.41744684744\n",
        "[20884, 20885, ] 3.39264961858\n",
        "[21107, 21108, ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.3728118355\n",
        "[21330, 21331, ] 3.35545377529\n",
        "[21553, 21554, ] 3.33561599221\n",
        "[21776, 21777, ] 3.32073765489\n",
        "[21999, 22000, ] 3.32321737778\n",
        "[22222, 22223, ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.34057543798\n",
        "[22445, 22446, ] 3.34801460664\n",
        "[22668, 22669, ] 3.34305516086\n",
        "[22891, 22892, ] 3.34057543798\n",
        "[23114, 23115, ] 3.38521044993\n",
        "[23337, 23338, ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.45712241362\n",
        "[23560, 23561, ] 3.51663576288\n",
        "[23783, 23784, ] 3.55383160617\n",
        "[24006, 24007, ] 3.57366938926\n",
        "[24229, 24230, ] 3.66045969027\n",
        "[24452, 24453, ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.82412140074\n",
        "[24675, 24676, ] 3.92331031618\n",
        "[24898, 24899, ] 3.96298588235\n",
        "[25121, 25122, ] 3.91587114752\n",
        "3.96298588235"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.00307574009996\n",
        "3.96298588235 3.32073765489\n",
        "862.23692813\n",
        "453.524654449\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labs = np.copy(labels).reshape(np.prod(patchSize), order='F')\n",
      "cutEdges = np.zeros(patchSize)\n",
      "cutSpriteEdges = np.zeros(patchSize)\n",
      "for factor in graphModel.factors(order=2) :\n",
      "    varIdxs = factor.variableIndices\n",
      "    if varIdxs[0] < np.prod(patchSize) and varIdxs[1] < np.prod(patchSize) :\n",
      "        sPix = np.array([int(np.mod(varIdxs[0],h)), int(varIdxs[0]/h)])\n",
      "        tPix = np.array([int(np.mod(varIdxs[1],h)), int(varIdxs[1]/h)])\n",
      "        if (labs[varIdxs[0]] == 1 and labs[varIdxs[1]] == 2) or (labs[varIdxs[1]] == 1 and labs[varIdxs[0]] == 2) :\n",
      "#             print varIdxs, factor.max()\n",
      "            cutSpriteEdges[sPix[0], sPix[1]] = factor[labs[varIdxs[0]], labs[varIdxs[1]]]\n",
      "            cutSpriteEdges[tPix[0], tPix[1]] = factor[labs[varIdxs[0]], labs[varIdxs[1]]]\n",
      "            \n",
      "        if labs[varIdxs[0]] - labs[varIdxs[1]] != 0 :\n",
      "            cutEdges[sPix[0], sPix[1]] = factor[labs[varIdxs[0]], labs[varIdxs[1]]]\n",
      "            cutEdges[tPix[0], tPix[1]] = factor[labs[varIdxs[0]], labs[varIdxs[1]]]\n",
      "            \n",
      "gwv.showCustomGraph(cutEdges)\n",
      "gwv.showCustomGraph(cutSpriteEdges)\n",
      "print np.max(cutEdges), np.unique(np.sort(np.ndarray.flatten(cutEdges)))[1]\n",
      "# print np.max(cutSpriteEdges), np.unique(np.sort(np.ndarray.flatten(cutSpriteEdges)))[1]\n",
      "print np.sum(cutEdges)\n",
      "print np.sum(cutSpriteEdges)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 36.0046136101 0.00307574009996\n",
        "1454.33602461\n",
        "0.0\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print factor[0, 2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000000.0\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = np.all(np.concatenate(((diffAB < diffAC).reshape((223, 171, 1)), (labels == 1).reshape((223, 171, 1))), axis=-1), axis=-1)\n",
      "tmp = (diffAC - diffAB) > 0.08\n",
      "\n",
      "tmpPatch = np.zeros(patA.shape, dtype=uint8)\n",
      "for i in xrange(labels.shape[0]) :\n",
      "    for j in xrange(labels.shape[1]) :\n",
      "        if labels[i, j] == 0 :\n",
      "            tmpPatch[i, j, :] = patA[i, j, :]*255\n",
      "        elif labels[i, j] == 1 and not tmp[i, j] :\n",
      "            tmpPatch[i, j, :] = patB[i, j, :]*255\n",
      "        else :\n",
      "            tmpPatch[i, j, :] = patC[i, j, :]*255\n",
      "            \n",
      "figure(); imshow(tmpPatch, interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 254,
       "text": [
        "<matplotlib.image.AxesImage at 0x7ffb68faced0>"
       ]
      }
     ],
     "prompt_number": 254
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(); imshow(spritePatches[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 271,
       "text": [
        "<matplotlib.image.AxesImage at 0x7ffb689cfe50>"
       ]
      }
     ],
     "prompt_number": 271
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "diffAB = np.sum(np.power(patA - patB, 2), axis=-1)\n",
      "\n",
      "diffAC = np.sum(np.power(patA - patC, 2), axis=-1)\n",
      "\n",
      "diffBC = np.sum(np.power(patB - patC, 2), axis=-1)\n",
      "\n",
      "sumDiffABAC = np.copy(diffAB+diffAC)\n",
      "\n",
      "maxVal = np.max((np.max(diffAB), np.max(diffAC), np.max(diffBC), np.max(sumDiffABAC)))\n",
      "\n",
      "figure(); imshow(diffAB, vmin=0, vmax=maxVal)\n",
      "figure(); imshow(diffAC, vmin=0, vmax=maxVal)\n",
      "figure(); imshow(diffBC, vmin=0, vmax=maxVal)\n",
      "figure(); imshow(sumDiffABAC, vmin=0, vmax=maxVal)\n",
      "print maxVal"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.71272587466\n"
       ]
      }
     ],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(); imshow(spritePriors[0], interpolation='nearest')\n",
      "figure(); imshow(spritePriors[0]*(1.0-diffAB/np.max(diffAB)), interpolation='nearest')\n",
      "\n",
      "figure(); imshow(spritePriors[1], interpolation='nearest')\n",
      "figure(); imshow(spritePriors[1]*(1.0-diffAC/np.max(diffAC)), interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 219,
       "text": [
        "<matplotlib.image.AxesImage at 0x7ffb6b9effd0>"
       ]
      }
     ],
     "prompt_number": 219
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weightedDiffAB = np.exp(-spritePriors[0])/np.sum(np.exp(-spritePriors[0]))*diffAB\n",
      "weightedDiffAC = np.exp(-spritePriors[1])/np.sum(np.exp(-spritePriors[1]))*diffAC\n",
      "\n",
      "figure(); imshow(spritePriors[0]*(1.0-weightedDiffAB/np.max(weightedDiffAB)), interpolation='nearest')\n",
      "figure(); imshow(spritePriors[1]*(1.0-weightedDiffAC/np.max(weightedDiffAC)), interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 220,
       "text": [
        "<matplotlib.image.AxesImage at 0x7ffb6b8d8750>"
       ]
      }
     ],
     "prompt_number": 220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(); imshow(np.exp(-spritePriors[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 214,
       "text": [
        "<matplotlib.image.AxesImage at 0x7ffb6cb10fd0>"
       ]
      }
     ],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## cut a patch from input image based on enlarged bbox\n",
      "spriteIdx = 1\n",
      "path = \"../data/havana/cutPatches/\"\n",
      "for i in arange(trackedSprites[spriteIdx][DICT_NUM_FRAMES]) :\n",
      "    img = np.array(Image.open(trackedSprites[spriteIdx][DICT_FRAMES_LOCATIONS][i]))\n",
      "    \n",
      "    ## make bbox bigger\n",
      "    largeBBox = np.dot(np.array([[0.0, 0.0, 1.2], [0.0, 1.2, 0.0]]), bboxDefaultCorners)\n",
      "    ## transform according to affine transformation\n",
      "    largeBBox = np.dot(getAffMat(trackedSprites[spriteIdx][DICT_BBOX_AFFINES][i, :]), \n",
      "                        np.vstack((np.ones((1, largeBBox.shape[1])), largeBBox)))\n",
      "    \n",
      "    offS = np.array([np.round(np.array([np.min(largeBBox[0, :]), np.min(largeBBox[1, :])]))], dtype=int).T # [x, y]\n",
      "    pSize = np.array(np.round(np.array([np.max(largeBBox[1, :])-np.min(largeBBox[1, :]), \n",
      "                                            np.max(largeBBox[0, :])-np.min(largeBBox[0, :])])), dtype=int) # [rows, cols]\n",
      "    \n",
      "    \n",
      "    Image.fromarray((img[offS[1]:offS[1]+pSize[0], offS[0]:offS[0]+pSize[1]]).astype(numpy.uint8)).save(path+trackedSprites[spriteIdx][DICT_SPRITE_NAME] +\"/\" + np.string_(i) + \".png\")\n",
      "    \n",
      "#     figure(); imshow(img)\n",
      "#     plot([offset[0], offset[0]+patchSize[1], offset[0]+patchSize[1], offset[0], offset[0]], \n",
      "#      [offset[1], offset[1], offset[1]+patchSize[0], offset[1]+patchSize[0], offset[1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## visualise an image of the pairwise costs for a given graph (the even indices are nodes and odd are edges, hence the doubled patchSize)\n",
      "for i in arange(pairCosts.shape[-1]) :\n",
      "    edgeMapImg = -0.01*np.ones(np.array(patchSize)*2)\n",
      "    \n",
      "    edgeMapImg[np.array((gridEdges2D[:, 2]*2+gridEdges2D[:, 0]*2)/2, dtype=int), \n",
      "               np.array((gridEdges2D[:, 3]*2+gridEdges2D[:, 1]*2)/2, dtype=int)] = np.copy(pairCosts[:, i])#/np.max(pairCosts[:, i]))\n",
      "    \n",
      "    figure(); imshow(np.copy(edgeMapImg), interpolation='nearest', vmin=0.0, vmax=np.max(pairCosts))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 240
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gwv.showCustomGraph(gradientsY)\n",
      "figure(); imshow(labels, interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 245,
       "text": [
        "<matplotlib.image.AxesImage at 0x7ff4f8a45890>"
       ]
      }
     ],
     "prompt_number": 245
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## save an image\n",
      "Image.fromarray((outputPatch).astype(numpy.uint8)).save(\"havana_car150_merged.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## visualize patch definite pixels\n",
      "tmp = np.zeros(patchSize)\n",
      "tmp[np.mod(patAPixs, h), np.array(patAPixs/h, dtype=int)] = 1\n",
      "figure(); imshow(tmp, interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dda(points, imgSize):\n",
      "    ## digital differential analyzer\n",
      "    ## points is 2XN array where points[:, 0] = [x, y] coords\n",
      "    result = np.zeros(imgSize, dtype=int)\n",
      "    \n",
      "    for i in arange(points.shape[-1]-1) :\n",
      "        m = (points[1, i+1] - points[1, i])/(points[0, i+1] - points[0, i])\n",
      "        xStart = points[0, i]\n",
      "        yStart = points[1, i]\n",
      "        xEnd = points[0, i+1]\n",
      "        yEnd = points[1, i+1]\n",
      "        x = float(np.copy(xStart))\n",
      "        y = float(np.copy(yStart))\n",
      "        print \"i=\", i, xStart, yStart, xEnd, yEnd, m\n",
      "        result[y, x] = 1\n",
      "        if np.abs(m) <= 1.0 :\n",
      "            while int(np.round(x)) != int(np.round(xEnd)) or int(np.round(y)) != int(np.round(yEnd)) :\n",
      "                if xStart < xEnd :\n",
      "                    x += 1\n",
      "                    y += m\n",
      "                else :\n",
      "                    x -= 1\n",
      "                    y -= m\n",
      "                    \n",
      "#                 print int(np.round(x)), int(np.round(y)), int(np.round(xEnd)), int(np.round(yEnd))\n",
      "                result[int(np.round(y)), int(np.round(x))] = 1\n",
      "        else :\n",
      "            while int(np.round(x)) != int(np.round(xEnd)) or int(np.round(y)) != int(np.round(yEnd)) :\n",
      "                if yStart < yEnd :\n",
      "                    y += 1\n",
      "                    x += 1.0/m\n",
      "                else :\n",
      "                    y -= 1\n",
      "                    x -= 1.0/m\n",
      "                    \n",
      "#                 print int(np.round(x)), int(np.round(y)), int(np.round(xEnd)), int(np.round(yEnd))\n",
      "                result[int(np.round(y)), int(np.round(x))] = 1\n",
      "                \n",
      "    return result\n",
      "\n",
      "tmp = dda(bbox, carImg.shape[0:2])\n",
      "figure(); imshow(tmp, interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### visualize pairwise costs image\n",
      "def interpolate(val, y0, x0, y1, x1):\n",
      "    return (val-x0)*(y1-y0)/(x1-x0) + y0;\n",
      "\n",
      "def base(val):\n",
      "    if val <= -0.75 :\n",
      "        return 0\n",
      "    elif val <= -0.25 :\n",
      "        return interpolate(val, 0.0, -0.75, 1.0, -0.25)\n",
      "    elif val <= 0.25 :\n",
      "        return 1.0\n",
      "    elif val <= 0.75 :\n",
      "        return interpolate(val, 1.0, 0.25, 0.0, 0.75)\n",
      "    else :\n",
      "        return 0.0\n",
      "\n",
      "\n",
      "def red(gray) :\n",
      "    return base(gray - 0.5 )\n",
      "\n",
      "def green(gray) :\n",
      "    return base(gray)\n",
      "\n",
      "def blue(gray) :\n",
      "    return base(gray + 0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}