{
 "metadata": {
  "name": "",
  "signature": "sha256:912b10e64cedb2d099925a7948c268524895072976116b1d219c0bde914b9d00"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Imports and defines\n",
      "%pylab\n",
      "import numpy as np\n",
      "import sys\n",
      "import scipy as sp\n",
      "\n",
      "import cv2\n",
      "import time\n",
      "import os\n",
      "import scipy.io as sio\n",
      "import glob\n",
      "\n",
      "from PIL import Image\n",
      "\n",
      "from sklearn import ensemble\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.mixture import GMM\n",
      "from sklearn.datasets.samples_generator import make_blobs\n",
      "from skimage.feature import hog\n",
      "from skimage import color\n",
      "\n",
      "import GraphWithValues as gwv\n",
      "import VideoTexturesUtils as vtu\n",
      "import opengm\n",
      "\n",
      "DICT_SPRITE_NAME = 'sprite_name'\n",
      "DICT_BBOXES = 'bboxes'\n",
      "DICT_FOOTPRINTS = 'footprints' ## same as bboxes but it indicates the footprint of the sprite on the ground plane\n",
      "DICT_BBOX_ROTATIONS = 'bbox_rotations'\n",
      "DICT_BBOX_CENTERS = 'bbox_centers'\n",
      "DICT_FRAMES_LOCATIONS = 'frame_locs'\n",
      "DICT_SEQUENCE_FRAMES = 'sequence_frames'\n",
      "DICT_SPRITE_IDX = 'sprite_idx' # stores the index in the self.trackedSprites array of the sprite used in the generated sequence\n",
      "DICT_DESIRED_SEMANTICS = 'desired_semantics' # stores what the desired semantics are for a certain sprite \n",
      "#(I could index them by the frame when the toggle happened instead of using the below but maybe ordering is important and I would lose that using a dict)\n",
      "DICT_FRAME_SEMANTIC_TOGGLE = 'frame_semantic_toggle'# stores the frame index in the generated sequence when the desired semantics have changed\n",
      "DICT_MEDIAN_COLOR = 'median_color'\n",
      "\n",
      "DATA_IMAGE = 'image_data'\n",
      "DATA_MASK = 'mask_data'\n",
      "DATA_TRACK_BBOX = 'track_bbox_data'\n",
      "DATA_TRACK_BBOX_CENTERS = 'track_bbox_centers_data'\n",
      "\n",
      "# dataPath = \"/home/ilisescu/PhD/data/\"\n",
      "# dataSet = \"havana/\"\n",
      "# dataSet = \"pendulum/\"\n",
      "dataPath = \"/media/ilisescu/Data1/PhD/data/\"\n",
      "# dataSet = \"clouds_subsample10/\"\n",
      "# dataSet = \"splashes_water/\"\n",
      "# dataSet = \"small_waterfall/\"\n",
      "dataSet = \"eu_flag_ph_left/\"\n",
      "formatString = \"{:05d}.png\"\n",
      "\n",
      "TL_IDX = 0\n",
      "TR_IDX = 1\n",
      "BR_IDX = 2\n",
      "BL_IDX = 3\n",
      "hogOrientations = 9\n",
      "pixelsPerCell = 16"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## load \n",
      "trackedSprites = []\n",
      "for sprite in np.sort(glob.glob(dataPath + dataSet + \"sprite*.npy\")) :\n",
      "    trackedSprites.append(np.load(sprite).item())\n",
      "    print trackedSprites[-1][DICT_SPRITE_NAME]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getFisherEncoding(feats, featsShape, gmm) :\n",
      "    \"\"\"Take feats feature vector and encode it using Fisher encoding\n",
      "    \n",
      "           feats: feature vector\n",
      "           featsShape: shape that feats had when the gmm was fitted (if e.g. feats are hog features and it has been flattened)\n",
      "           gmm: a fitted sklearn.mixture.GMM model\n",
      "           \n",
      "        return: 1D encoded feature vector encodedFeats\"\"\"\n",
      "    \n",
      "    if gmm != None :\n",
      "        try :\n",
      "            modelMeans = gmm.means_\n",
      "            numComponents = modelMeans.shape[0]\n",
      "            featDim = featsShape[-1]\n",
      "            ##get prior probability pi for each component\n",
      "            priors = gmm.weights_\n",
      "            ##get posterior probabilities q for each data point and each component\n",
      "            posteriors = gmm.predict_proba(np.reshape(feats, featsShape))\n",
      "            \n",
      "            us = np.empty(0)\n",
      "            vs = np.empty(0)\n",
      "            ## this one uses the formulation given by vlfeat\n",
      "            for k in xrange(numComponents) :\n",
      "                ## get covariance matrix for component k\n",
      "                kCompCov = gmm.covars_[k, :]\n",
      "                \n",
      "                kCompMeansRep = modelMeans[k, :].reshape((1, featDim)).repeat(featsShape[0], axis=0)\n",
      "                kCompCovRep = kCompCov.reshape((1, featDim)).repeat(featsShape[0], axis=0)\n",
      "                kCompPostRep = posteriors[:, k].reshape((featsShape[0], 1)).repeat(featDim, axis=-1)\n",
      "                \n",
      "                uk = np.sum(kCompPostRep*(np.reshape(feats, featsShape)-kCompMeansRep)/kCompCovRep, axis=0)\n",
      "                uk /= (featsShape[0]*np.sqrt(priors[k]))\n",
      "                us = np.concatenate((us, uk))\n",
      "                \n",
      "                vk = np.sum(kCompPostRep*((((np.reshape(feats, featsShape)-kCompMeansRep)/kCompCovRep)**2)-1), axis=0)\n",
      "                vk /= (featsShape[0]*np.sqrt(2*priors[k]))\n",
      "                vs = np.concatenate((vs, vk))\n",
      "                \n",
      "            encodedFeats = np.concatenate((us, vs))\n",
      "            return encodedFeats\n",
      "        except Exception :\n",
      "            raise Exception, \"Unfitted gmm\"\n",
      "    else :\n",
      "        print \"No gm model has been specified\"\n",
      "        return feats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fitGMM(trainingFeats, ncomp) :\n",
      "    \"\"\"Takes a set of features trainingFeats and returns Gaussian Mixture Model with ncomp components\n",
      "        Descriptors of an image can be softly assinged to each K Gaussian component and used for Fisher encoding\n",
      "    \n",
      "           trainingFeats: training features\n",
      "           ncomp: number of gaussians in the GMM\n",
      "           \n",
      "        return: gmm model\"\"\"\n",
      "    \n",
      "    model = GMM(n_components=ncomp, covariance_type='diag')\n",
      "    model.fit(trainingFeats)\n",
      "    return model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getHOGFeats(imageData, visHogs = False) :\n",
      "    \"\"\"Take RGB imageData and compute HOG features. The returned features are flattened to a 1D array from an array of shape\n",
      "        (len(feats)/orientations, orientations) where the first orientations number of values represent the hog features of the\n",
      "        top left cell and then counting cells right row-wise (i.e. do first row left to right, then second and so on)\n",
      "    \n",
      "           imageData: input RGB image data\n",
      "           \n",
      "        return: 1D vector feats\"\"\"\n",
      "    \n",
      "    feats = hog(color.rgb2gray(imageData), orientations=hogOrientations, \n",
      "                     pixels_per_cell=(pixelsPerCell, pixelsPerCell), \n",
      "                     cells_per_block=(1, 1), visualise=visHogs)\n",
      "    if visHogs :\n",
      "        gwv.showCustomGraph(feats[1])\n",
      "        return feats[0]\n",
      "    else :\n",
      "        return feats\n",
      "\n",
      "def getSemanticsData(rawSemanticData, frameIdx) :\n",
      "    \"\"\"Extracts the necessay data from rawSemanticData for the desired frame at frameIdx.\n",
      "    \n",
      "           semanticData: data attached to a semantic label (e.g. a tracked sprite)\n",
      "           frameIdx: index of the frame in semanticData to compute features for          \n",
      "           \n",
      "        return: dictionary of extracted data which includes :\n",
      "                        RGB data for desired patch imageData\n",
      "                        mask for desired patch maskData\"\"\"\n",
      "    \n",
      "\n",
      "    frameKey = np.sort(rawSemanticData[DICT_FRAMES_LOCATIONS].keys())[frameIdx]\n",
      "    frameName = rawSemanticData[DICT_FRAMES_LOCATIONS][frameKey].split(os.sep)[-1]\n",
      "#     print frameName\n",
      "\n",
      "    semanticsData = {}\n",
      "\n",
      "    if DICT_SPRITE_NAME in rawSemanticData.keys() :\n",
      "        maskDir = dataPath + dataSet + rawSemanticData[DICT_SPRITE_NAME] + \"-masked-blended\"\n",
      "    \n",
      "        ## get mask and find patch to deal with\n",
      "        maskImg = np.array(cv2.imread(maskDir+\"/\"+frameName, cv2.CV_LOAD_IMAGE_UNCHANGED), dtype=np.uint8)[:, :, -1]\n",
      "        imgSize = np.array(maskImg.shape)\n",
      "        visiblePixels = np.argwhere(maskImg != 0)\n",
      "        enlargePatchBy = 20\n",
      "        topLeft = np.min(visiblePixels, axis=0) - enlargePatchBy\n",
      "        patchSize = np.max(visiblePixels, axis=0) - topLeft + 1 + 2*enlargePatchBy\n",
      "        \n",
      "        ## make sure we're within bounds\n",
      "        topLeft[np.argwhere(topLeft < 0)] = 0\n",
      "        patchSize[(topLeft+patchSize) > imgSize] += (imgSize-(topLeft+patchSize))[(topLeft+patchSize) > imgSize]\n",
      "        \n",
      "        imageData = np.asarray(Image.open(rawSemanticData[DICT_FRAMES_LOCATIONS][frameKey]))[topLeft[0]:topLeft[0]+patchSize[0], topLeft[1]:topLeft[1]+patchSize[1], :]\n",
      "        maskData = maskImg[topLeft[0]:topLeft[0]+patchSize[0], topLeft[1]:topLeft[1]+patchSize[1]]\n",
      "        \n",
      "        semanticsData[DATA_IMAGE] = imageData\n",
      "        semanticsData[DATA_MASK] = maskData\n",
      "    else :\n",
      "        semanticsData[DATA_IMAGE] = np.asarray(Image.open(rawSemanticData[DICT_FRAMES_LOCATIONS][frameKey]))\n",
      "    \n",
      "    if DICT_BBOXES in rawSemanticData.keys() :\n",
      "        semanticsData[DATA_TRACK_BBOX] = rawSemanticData[DICT_BBOXES][frameKey]\n",
      "        \n",
      "    if DICT_BBOX_CENTERS in rawSemanticData.keys() :\n",
      "        semanticsData[DATA_TRACK_BBOX_CENTERS] = rawSemanticData[DICT_BBOX_CENTERS][frameKey]\n",
      "    \n",
      "    return semanticsData\n",
      "    \n",
      "    \n",
      "def getSemanticsFeatures(semanticsData, gmModel, getHog = False, verbose = False) :\n",
      "    \"\"\"Computes relevant features given the data in semanticsData.\n",
      "    \n",
      "           semanticsData: data attached to a semantic label (e.g. a color patch )\n",
      "           gmModel[sklearn.mixture.GMM]: trained gaussian mixture model used for computing fisher encoding of hog features           \n",
      "           \n",
      "        return: 1D vector features\"\"\"\n",
      "\n",
      "\n",
      "    if DATA_IMAGE in semanticsData.keys() :\n",
      "    \n",
      "        hogFeats = getHOGFeats(semanticsData[DATA_IMAGE])\n",
      "        \n",
      "        if DATA_MASK in semanticsData.keys() :\n",
      "            patchSize = np.array(semanticsData[DATA_MASK].shape)\n",
      "            \n",
      "            ########### THIS KEEPS FEATS WHO'S CELL CENTER IS INSIDE MASK ###########\n",
      "#             ## get coords of cells centers\n",
      "#             rowCoords = np.arange(pixelsPerCell/2, patchSize[0]-pixelsPerCell/2, pixelsPerCell)\n",
      "#             colCoords = np.arange(pixelsPerCell/2, patchSize[1]-pixelsPerCell/2, pixelsPerCell)\n",
      "            \n",
      "#             cellGridRows = len(rowCoords)#int(np.round(float(patchSize[0]-pixelsPerCell/2)/pixelsPerCell))\n",
      "#             cellGridCols = len(colCoords)#int(np.round(float(patchSize[1]-pixelsPerCell/2)/pixelsPerCell))\n",
      "            \n",
      "#             rowCoords = rowCoords.reshape((1, cellGridRows)).repeat(cellGridCols)\n",
      "#             colCoords = np.ndarray.flatten(colCoords.reshape((1, cellGridCols)).repeat(cellGridRows, axis=0))\n",
      "            \n",
      "            ## check which centers are within the mask and only keep those\n",
      "#             hogFeats = hogFeats[(semanticsData[DATA_MASK][rowCoords, colCoords] != 0).repeat(hogOrientations)]\n",
      "\n",
      "            \n",
      "            ########### THIS KEEPS FEATS WHO'S CELL'S EXTENT FALLS INSIDE THE MASK ###########\n",
      "            \n",
      "            ## make an image that contains the index of a hog cell for the extent of the cell (lots of colored squares :))\n",
      "            allIdxs = -np.ones(patchSize, dtype=int)\n",
      "            numRowIdxs = len(np.arange(0, patchSize[0], pixelsPerCell)) - 1\n",
      "            numColIdxs = len(np.arange(0, patchSize[1], pixelsPerCell)) - 1\n",
      "            gridIdxs = np.arange(numColIdxs, dtype=int).reshape((1, numColIdxs)).repeat(numRowIdxs*pixelsPerCell, axis=0).repeat(pixelsPerCell, axis=-1)\n",
      "            gridIdxs += np.arange(numRowIdxs, dtype=int).reshape((numRowIdxs, 1)).repeat(numColIdxs*pixelsPerCell, axis=-1).repeat(pixelsPerCell, axis=0)*numColIdxs\n",
      "            allIdxs[:gridIdxs.shape[0], :gridIdxs.shape[1]] = gridIdxs\n",
      "            \n",
      "            ## find which of the cells fall inside the mask and keep them\n",
      "            visiblePixels = np.argwhere(semanticsData[DATA_MASK] != 0)\n",
      "            hogsToKeep = np.zeros(numRowIdxs*numColIdxs, dtype=bool)\n",
      "            hogsToKeep[np.unique(allIdxs[visiblePixels[:, 0], visiblePixels[:, 1]])] = True\n",
      "            \n",
      "            hogFeats = hogFeats[hogsToKeep.repeat(hogOrientations)]\n",
      "            \n",
      "        if getHog :\n",
      "            if verbose :\n",
      "                print \"return hog feats only\"\n",
      "            return hogFeats\n",
      "        \n",
      "        features = np.empty(0)\n",
      "        if gmModel != None :\n",
      "            features = getFisherEncoding(hogFeats, (len(hogFeats)/hogOrientations, hogOrientations), gmModel)\n",
      "            \n",
      "            if verbose :\n",
      "                print \"added hog fisher encoding\"\n",
      "            \n",
      "        if DATA_TRACK_BBOX in semanticsData.keys() :\n",
      "            ## compute area of bbox\n",
      "            area = np.linalg.norm(semanticsData[DATA_TRACK_BBOX][TL_IDX, :] - semanticsData[DATA_TRACK_BBOX][TR_IDX, :])\n",
      "            area *= np.linalg.norm(semanticsData[DATA_TRACK_BBOX][TR_IDX, :] - semanticsData[DATA_TRACK_BBOX][BR_IDX, :])\n",
      "            \n",
      "            features = np.concatenate((features, [area]))\n",
      "            \n",
      "            if verbose :\n",
      "                print \"added bbox area\"\n",
      "            \n",
      "        if DATA_TRACK_BBOX_CENTERS in semanticsData.keys() :\n",
      "            features = np.concatenate((features, semanticsData[DATA_TRACK_BBOX_CENTERS]))\n",
      "            \n",
      "            if verbose :\n",
      "                print \"added bbox center\"\n",
      "            \n",
      "        return features\n",
      "    \n",
      "    return None\n",
      "#     return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def aabb2obbDist(aabb, obb, verbose = False) :\n",
      "    if verbose :\n",
      "        figure(); plot(aabb[:, 0], aabb[:, 1])\n",
      "        plot(obb[:, 0], obb[:, 1])\n",
      "    minDist = 100000000.0\n",
      "    colors = ['r', 'g', 'b', 'y']\n",
      "    for i, j in zip(arange(4), np.mod(arange(1, 5), 4)) :\n",
      "        m = (obb[j, 1] - obb[i, 1]) / (obb[j, 0] - obb[i, 0])\n",
      "        b = obb[i, 1] - (m * obb[i, 0]);\n",
      "        ## project aabb points onto obb segment\n",
      "        projPoints = np.dot(np.hstack((aabb, np.ones((len(aabb), 1)))), np.array([[1, m, -m*b], [m, m**2, b]]).T)/(m**2+1)\n",
      "        if np.all(np.negative(np.isnan(projPoints))) :\n",
      "            ## find distances\n",
      "            dists = np.linalg.norm(projPoints-aabb, axis=-1)\n",
      "#             dists = aabb2pointsDist(aabb, projPoints)\n",
      "            ## find closest point\n",
      "            closestPoint = np.argmin(dists)\n",
      "            ## if rs is between 0 and 1 the point is on the segment\n",
      "            rs = np.sum((obb[j, :]-obb[i, :])*(aabb-obb[i, :]), axis=1)/(np.linalg.norm(obb[j, :]-obb[i, :])**2)\n",
      "            if verbose :\n",
      "                print projPoints\n",
      "                scatter(projPoints[:, 0], projPoints[:, 1], c=colors[i])\n",
      "                print dists\n",
      "                print closestPoint\n",
      "                print rs\n",
      "            ## if closestPoint is on the segment\n",
      "            if rs[closestPoint] > 0.0 and rs[closestPoint] < 1.0 :\n",
      "#                 print \"in\", aabb2pointDist(aabb, projPoints[closestPoint, :])\n",
      "                minDist = np.min((minDist, aabb2pointDist(aabb, projPoints[closestPoint, :])))\n",
      "            else :\n",
      "#                 print \"out\", aabb2pointDist(aabb, obb[i, :]), aabb2pointDist(aabb, obb[j, :])\n",
      "                minDist = np.min((minDist, aabb2pointDist(aabb, obb[i, :]), aabb2pointDist(aabb, obb[j, :])))\n",
      "\n",
      "    return minDist\n",
      "\n",
      "\n",
      "def aabb2pointDist(aabb, point) :\n",
      "    dx = np.max((np.min(aabb[:, 0]) - point[0], 0, point[0] - np.max(aabb[:, 0])))\n",
      "    dy = np.max((np.min(aabb[:, 1]) - point[1], 0, point[1] - np.max(aabb[:, 1])))\n",
      "    return np.sqrt(dx**2 + dy**2);\n",
      "\n",
      "def aabb2pointsDist(aabb, points) :\n",
      "    dx = np.max(np.vstack((np.min(aabb[:, 0]) - points[:, 0], np.zeros(len(points)), points[:, 0] - np.max(aabb[:, 0]))), axis=0)\n",
      "    dy = np.max(np.vstack((np.min(aabb[:, 1]) - points[:, 1], np.zeros(len(points)), points[:, 1] - np.max(aabb[:, 1]))), axis=0)\n",
      "    return np.sqrt(dx**2 + dy**2);\n",
      "\n",
      "\n",
      "def getShiftedSpriteTrackDist(firstSprite, secondSprite, shift) :\n",
      "    \n",
      "    spriteTotalLength = np.zeros(2, dtype=int)\n",
      "    spriteTotalLength[0] = len(firstSprite[DICT_BBOX_CENTERS])\n",
      "    spriteTotalLength[1] = len(secondSprite[DICT_BBOX_CENTERS])\n",
      "    \n",
      "    ## find the overlapping sprite subsequences\n",
      "    ## length of overlap is the minimum between length of the second sequence and length of the first sequence - the advantage it has n the second sequence\n",
      "    overlapLength = np.min((spriteTotalLength[0]-shift, spriteTotalLength[1]))\n",
      "    \n",
      "    frameRanges = np.zeros((2, overlapLength), dtype=int)\n",
      "    frameRanges[0, :] = np.arange(shift, overlapLength + shift)\n",
      "    frameRanges[1, :] = np.arange(overlapLength)\n",
      "    \n",
      "    totalDistance, distances = getOverlappingSpriteTracksDistance(firstSprite, secondSprite, frameRanges)\n",
      "    \n",
      "    return totalDistance, distances, frameRanges\n",
      "\n",
      "\n",
      "def getOverlappingSpriteTracksDistance(firstSprite, secondSprite, frameRanges, doEarlyOut = True, verbose = False) :\n",
      "#     ## for now the distance is only given by the distance between bbox center but can add later other things like bbox overlapping region\n",
      "#     bboxCenters0 = np.array([firstSprite[DICT_BBOX_CENTERS][x] for x in np.sort(firstSprite[DICT_BBOX_CENTERS].keys())[frameRanges[0, :]]])\n",
      "#     bboxCenters1 = np.array([secondSprite[DICT_BBOX_CENTERS][x] for x in np.sort(secondSprite[DICT_BBOX_CENTERS].keys())[frameRanges[1, :]]])\n",
      "    \n",
      "#     centerDistance = np.linalg.norm(bboxCenters0-bboxCenters1, axis=1)\n",
      "    \n",
      "#     totDist = np.min(centerDistance)\n",
      "#     allDists = centerDistance\n",
      "    \n",
      "    firstSpriteKeys = np.sort(firstSprite[DICT_BBOX_CENTERS].keys())\n",
      "    secondSpriteKeys = np.sort(secondSprite[DICT_BBOX_CENTERS].keys())\n",
      "    allDists = np.zeros(frameRanges.shape[-1])\n",
      "    for i in xrange(frameRanges.shape[-1]) :\n",
      "        \n",
      "        allDists[i] = getSpritesBBoxDist(firstSprite[DICT_BBOX_ROTATIONS][firstSpriteKeys[frameRanges[0, i]]],\n",
      "                                          firstSprite[DICT_BBOXES][firstSpriteKeys[frameRanges[0, i]]], \n",
      "                                          secondSprite[DICT_BBOXES][secondSpriteKeys[frameRanges[1, i]]])\n",
      "        \n",
      "        if verbose and np.mod(i, frameRanges.shape[-1]/100) == 0 :\n",
      "            sys.stdout.write('\\r' + \"Computed image pair \" + np.string_(i) + \" of \" + np.string_(frameRanges.shape[-1]))\n",
      "            sys.stdout.flush()\n",
      "        \n",
      "        ## early out since you can't get lower than 0\n",
      "        if doEarlyOut and allDists[i] == 0.0 :\n",
      "            break\n",
      "            \n",
      "    totDist = np.min(allDists)\n",
      "#     return np.sum(centerDistance)/len(centerDistance), centerDistance    \n",
      "    return totDist, allDists\n",
      "\n",
      "def getSpritesBBoxDist(theta, bbox1, bbox2) :\n",
      "    rotMat = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n",
      "    bbox1 = np.dot(rotMat, bbox1.T).T\n",
      "    bbox2 = np.dot(rotMat, bbox2.T).T\n",
      "    ## if the bboxes coincide then the distance is set to 0\n",
      "    if np.all(np.abs(bbox1 - bbox2) <= 10**-10) :\n",
      "        return 0.0\n",
      "    else :\n",
      "        return aabb2obbDist(bbox1, bbox2)\n",
      "    \n",
      "# print getOverlappingSpriteTracksDistance(trackedSprites[3], trackedSprites[0], np.array([[1020], [400]]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tmpData = getSemanticsData(trackedSprites[0], 155)\n",
      "# tmp = getSemanticsFeatures(getSemanticsData(trackedSprites[0], 155), None, True)\n",
      "print len(tmp)/hogOrientations\n",
      "print tmpData\n",
      "print getSemanticsData(trackedSprites[0], 155)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Hacking together a way to consider full frame features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## HACK ##\n",
      "## read the video frames and treat as a sprite that only has frame locations\n",
      "frameLocs = np.sort(glob.glob(dataPath + dataSet + \"/frame-*.png\"))\n",
      "numOfFrames = len(frameLocs)\n",
      "print numOfFrames\n",
      "semanticEntities = []\n",
      "semanticEntity = {DICT_FRAMES_LOCATIONS:{}}\n",
      "for f in xrange(numOfFrames) :\n",
      "    semanticEntity[DICT_FRAMES_LOCATIONS][f] = frameLocs[f]\n",
      "semanticEntities.append(semanticEntity)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## get random frames from each tracked sprite and get their hog features to then train the GMM\n",
      "numLeaveOut = 0\n",
      "numFramesPerEntity = 20\n",
      "gmmTrainingFeats = np.empty(0)\n",
      "for entity in semanticEntities:\n",
      "    for frameIdx in random.choice(arange(numLeaveOut, len(entity[DICT_FRAMES_LOCATIONS])-numLeaveOut), numFramesPerEntity, replace=False) :\n",
      "        tmp = len(gmmTrainingFeats)\n",
      "        gmmTrainingFeats = np.concatenate((gmmTrainingFeats, getSemanticsFeatures(getSemanticsData(entity, frameIdx), None, True)))\n",
      "        print \"added\", (len(gmmTrainingFeats)-tmp), \"features from\", \"semantic entity\", \"at frame\", frameIdx\n",
      "#     break\n",
      "        \n",
      "gmmTrainingFeats = gmmTrainingFeats.reshape((len(gmmTrainingFeats)/hogOrientations, hogOrientations))\n",
      "gmModel = fitGMM(gmmTrainingFeats, 15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "############################################ TEST TEST TEST TEST ############################################ \n",
      "spriteIdx = -1\n",
      "for i in xrange(len(trackedSprites)) :\n",
      "    if trackedSprites[i][DICT_SPRITE_NAME] == 'red_car1' :\n",
      "        spriteIdx = i\n",
      "        break\n",
      "print \"using sprite\", trackedSprites[spriteIdx][DICT_SPRITE_NAME]\n",
      "\n",
      "## semantics for reshuffling are binary i.e. each frame has label 1 (i.e. sprite visible) and extra frame at beginning has label 0\n",
      "semanticLabels = np.zeros((len(trackedSprites[spriteIdx][DICT_BBOX_CENTERS])+1, 2))\n",
      "## label 0 means sprite not visible (i.e. only show the first empty frame)\n",
      "semanticLabels[0, 0] = 1.0\n",
      "semanticLabels[1:, 1] = 1.0\n",
      "delay = 8\n",
      "desiredLabel = np.array([1.0, 0.0]).reshape((1, 2))#.repeat(300-delay/2, axis=0)\n",
      "desiredLabel = np.concatenate((desiredLabel, toggleLabelsSmoothly(np.array([[1.0, 0.0]]), delay)))\n",
      "desiredLabel = np.concatenate((desiredLabel, np.array([0.0, 1.0]).reshape((1, 2)).repeat(600-delay, axis=0)))\n",
      "# semanticDist = np.sum(np.power(semanticLabels-desiredLabel, 2), axis=-1)\n",
      "desiredLabel = window.burstSemanticsToggle(np.array([1.0, 0.0]), 300, 2, 20)\n",
      "# desiredLabel = np.array([1.0, 0.0]).reshape((1, 2)).repeat(300, axis=0)\n",
      "\n",
      "tic = time.time()\n",
      "unaries, pairwise = getMRFCosts(semanticLabels, desiredLabel, 0, 300)\n",
      "print \"computed costs in\", time.time() - tic; sys.stdout.flush()\n",
      "# gwv.showCustomGraph(unaries[1:, :], title=\"unaries\")\n",
      "tic = time.time()\n",
      "minCostTraversal, minCost = solveMRF(unaries, pairwise)\n",
      "print \"solved in\", time.time() - tic; sys.stdout.flush()\n",
      "print minCostTraversal"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## start with generating two sequences one for an instance of red_car1 and one for white_bus1 such that they would be colliding\n",
      "spriteIndices = np.array([0, 3])\n",
      "sequenceStartFrames = np.array([0, 580])\n",
      "sequenceLength = 450\n",
      "generatedSequences = np.zeros((len(spriteIndices), sequenceLength), dtype=int)\n",
      "allUnaries = []\n",
      "allPairwise = []\n",
      "allNodesConnectedToLabel = []\n",
      "\n",
      "## now generate initial conflicting sequences to be resolved later\n",
      "\n",
      "for idx in xrange(len(spriteIndices)) :\n",
      "    spriteTotalLength = len(trackedSprites[spriteIndices[idx]][DICT_BBOX_CENTERS])\n",
      "\n",
      "    spriteSemanticLabels = np.zeros((spriteTotalLength+1, 2))\n",
      "    ## label 0 means sprite not visible (i.e. only show the first empty frame)\n",
      "    spriteSemanticLabels[0, 0] = 1.0\n",
      "    spriteSemanticLabels[1:, 1] = 1.0\n",
      "\n",
      "    tic = time.time()\n",
      "    if idx == 0 : \n",
      "        spriteDesiredSemantics = np.array([1.0, 0.0]).reshape((1, 2))\n",
      "        spriteDesiredSemantics = np.concatenate((spriteDesiredSemantics, toggleLabelsSmoothly(np.array([1.0, 0.0]).reshape((1, 2)), 8)))\n",
      "        spriteDesiredSemantics = np.concatenate((spriteDesiredSemantics, np.roll(np.array([1.0, 0.0]).reshape((1, 2)), 1).repeat(sequenceLength-8-1, axis=0)))\n",
      "        \n",
      "        unaries, pairwise = getMRFCosts(spriteSemanticLabels, spriteDesiredSemantics, sequenceStartFrames[idx], sequenceLength)\n",
      "    else :\n",
      "        unaries, pairwise = getMRFCosts(spriteSemanticLabels, np.array([1.0, 0.0]).reshape((1, 2)).repeat(sequenceLength, axis=0), sequenceStartFrames[idx], sequenceLength)\n",
      "    allUnaries.append(unaries)\n",
      "    allPairwise.append(pairwise)\n",
      "    \n",
      "    jumpCosts = spriteDistMats[idx][1:, :-1]**2\n",
      "    viableJumps = np.argwhere(jumpCosts < 0.2)\n",
      "    viableJumps = viableJumps[np.ndarray.flatten(np.argwhere(jumpCosts[viableJumps[:, 0], viableJumps[:, 1]] > 0.1))]\n",
      "    ## add 1 to indices because of the 0th frame, and then 5, 4 from the filtering and 1 from going from distances to costs\n",
      "    allPairwise[idx][viableJumps[:, 0]+1+1+4, viableJumps[:, 1]+1+1+4] = jumpCosts[viableJumps[:, 0], viableJumps[:, 1]]\n",
      "    \n",
      "    ## now try and do the optimization completely vectorized\n",
      "    ## number of edges connected to each label node of variable n (pairwise stores node at arrow tail as cols and at arrow head as rows)\n",
      "    maxEdgesPerLabel = np.max(np.sum(np.array(pairwise.T != np.max(pairwise.T), dtype=int), axis=-1))\n",
      "    ## initialize this to index of connected label node with highest edge cost (which is then used as padding)\n",
      "    ## it contains for each label node of variable n (indexed by rows), all the label nodes of variable n-1 it is connected to by non infinite cost edge (indexed by cols)\n",
      "    nodesConnectedToLabel = np.argmax(pairwise.T, axis=-1).reshape((len(pairwise.T), 1)).repeat(maxEdgesPerLabel, axis=-1)\n",
      "    \n",
      "    sparseIndices = np.where(pairwise != np.max(pairwise))\n",
      "    # print sparseIndices\n",
      "    tailIndices = sparseIndices[0]\n",
      "    headIndices = sparseIndices[1]\n",
      "    \n",
      "    ## this contains which label of variable n-1 is connected to which label of variable n\n",
      "    indicesInLabelSpace = [list(tailIndices[np.where(headIndices == i)[0]]) for i in np.unique(headIndices)]\n",
      "    \n",
      "    for headLabel, tailLabels in zip(arange(0, len(nodesConnectedToLabel)), indicesInLabelSpace) :\n",
      "        nodesConnectedToLabel[headLabel, 0:len(tailLabels)] = tailLabels    \n",
      "        \n",
      "    allNodesConnectedToLabel.append(nodesConnectedToLabel)\n",
      "    \n",
      "    # gwv.showCustomGraph(unaries)\n",
      "    print \"computed costs for sprite\", spriteIndices[idx], \"in\", time.time() - tic; sys.stdout.flush()\n",
      "    tic = time.time()\n",
      "    # minCostTraversal, minCost = solveMRF(unaries, pairwise)\n",
      "#     minCostTraversal, minCost = solveSparseDynProgMRF(unaries.T, pairwise.T, nodesConnectedToLabel)\n",
      "    minCostTraversal, minCost = solveSparseDynProgMRF(allUnaries[idx].T, allPairwise[idx].T, allNodesConnectedToLabel[idx])\n",
      "    \n",
      "    print \"solved traversal for sprite\", spriteIndices[idx] , \"in\", time.time() - tic; sys.stdout.flush()\n",
      "    generatedSequences[idx, :] = minCostTraversal\n",
      "\n",
      "print generatedSequences\n",
      "\n",
      "count = 0\n",
      "while True :\n",
      "    print \"iteration\", count, \n",
      "    ## get distance between every pairing of frames in the generatedSequences\n",
      "    areCompatible = np.zeros(generatedSequences.shape[-1], dtype=bool)\n",
      "    areCompatible[np.any(generatedSequences < 1, axis=0)] = True\n",
      "    \n",
      "    compatibDist, allCompatibDists = getOverlappingSpriteTracksDistance(trackedSprites[spriteIndices[0]], trackedSprites[spriteIndices[1]], generatedSequences)\n",
      "    print \"incompatibilities to solve\", len(np.argwhere(allCompatibDists <= 1.0)); sys.stdout.flush()\n",
      "#     print allCompatibDists\n",
      "    \n",
      "    areCompatible[allCompatibDists > 1.0] = True\n",
      "    \n",
      "#     if not np.all(areCompatible) :\n",
      "#         for idx in arange(len(spriteIndices))[0:1] :\n",
      "            \n",
      "#             allUnaries[idx][np.negative(areCompatible), generatedSequences[idx, np.negative(areCompatible)]] += 1000.0 #10000000.0\n",
      "#             ## if I fix spriteIndices[1] then I can find out all combinations of frames between spriteIndices[0] and the generated sequence for spriteIndices[1]\n",
      "# #             gwv.showCustomGraph(allUnaries[idx])\n",
      "            \n",
      "#             tic = time.time()\n",
      "#             minCostTraversal, minCost = solveSparseDynProgMRF(allUnaries[idx].T, allPairwise[idx].T, allNodesConnectedToLabel[idx])\n",
      "            \n",
      "#             print \"solved traversal for sprite\", spriteIndices[idx] , \"in\", time.time() - tic; sys.stdout.flush()\n",
      "# #             print minCostTraversal, minCost\n",
      "            \n",
      "#             generatedSequences[idx, :] = minCostTraversal\n",
      "#     else :\n",
      "#         break\n",
      "    \n",
      "    count += 1\n",
      "    if count > 0 :\n",
      "        break\n",
      "print generatedSequences"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## extract features for all sprites\n",
      "allFeats = {}\n",
      "for entityIdx in [0] : #arange(len(trackedSprites)) :\n",
      "    entityFeats = []\n",
      "    for frameIdx in xrange(len(semanticEntities[entityIdx][DICT_FRAMES_LOCATIONS])) :\n",
      "#         feats = getSemanticsFeatures(getSemanticsData(semanticEntities[entityIdx], frameIdx), gmModel)#, False, True)\n",
      "        feats = getSemanticsFeatures(getSemanticsData(semanticEntities[entityIdx], frameIdx), None, True)\n",
      "        entityFeats.append(feats)\n",
      "        sys.stdout.write('\\r' + \"Done with frame \" + np.string_(frameIdx) + \" of \" + np.string_(len(semanticEntities[entityIdx][DICT_FRAMES_LOCATIONS])))\n",
      "        sys.stdout.flush()\n",
      "    \n",
      "    print\n",
      "    print \"done with semantic entity\"\n",
      "    allFeats[entityIdx] = entityFeats\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 461
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spriteTotLength = len(trackedSprites[0][DICT_BBOX_CENTERS])\n",
      "\n",
      "spriteSequence = generatedSequences[1, :][generatedSequences[1, :]-1 >= 0]#.reshape((1, sequenceLength)).repeat(spriteTotLength)-1\n",
      "# bob = np.vstack((np.ndarray.flatten(arange(spriteTotLength).reshape((1, spriteTotLength)).repeat(sequenceLength, axis=0)), \n",
      "#                  generatedSequences[1, :].reshape((1, sequenceLength)).repeat(spriteTotLength)-1))\n",
      "bob = np.vstack((np.ndarray.flatten(arange(spriteTotLength).reshape((1, spriteTotLength)).repeat(len(spriteSequence), axis=0)), \n",
      "                 spriteSequence.reshape((1, len(spriteSequence))).repeat(spriteTotLength)-1))\n",
      "\n",
      "# dist, allDists = getOverlappingSpriteTracksDistance(trackedSprites[spriteIndices[0]], trackedSprites[spriteIndices[1]], bob, False, True)\n",
      "## just get the dists from spritesCompatibility\n",
      "allDists = spritesCompatibility[bob[0, :], bob[1, :]].reshape((len(spriteSequence), spriteTotLength))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 462
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(allDists.reshape((len(spriteSequence), spriteTotLength)))\n",
      "# print allDists.reshape((sequenceLength, spriteTotLength))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 469
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## if I fix spriteIndices[1] then I can find out all combinations of frames between spriteIndices[0] and the generated sequence for spriteIndices[1]\n",
      "idx = 0\n",
      "modifiedUnaries = np.copy(allUnaries[idx])\n",
      "incompatiblePairs = np.argwhere(allDists.reshape((len(spriteSequence), spriteTotLength)) <= 1.0)\n",
      "# incompatiblePairs = incompatiblePairs[np.ndarray.flatten(np.argwhere(allDists.reshape((sequenceLength, spriteTotLength))[incompatiblePairs[:, 0], incompatiblePairs[:, 1]] >= 0.1)), :]\n",
      "modifiedUnaries[incompatiblePairs[:, 0], incompatiblePairs[:, 1]+1] = 1e7\n",
      "gwv.showCustomGraph(modifiedUnaries)\n",
      "\n",
      "tic = time.time()\n",
      "minCostTraversal, minCost = solveSparseDynProgMRF(modifiedUnaries.T, allPairwise[idx].T, allNodesConnectedToLabel[idx])\n",
      "print \"solved traversal for sprite\", spriteIndices[idx] , \"in\", time.time() - tic; sys.stdout.flush()\n",
      "print minCostTraversal, minCost"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 463
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gwv.showCustomGraph(spriteDistMats[1])\n",
      "tmp = np.copy(spritesCompatibility)\n",
      "tmp[sequenceStartFrames[0]-1, 5:-5+1] += spriteDistMats[1][1:, :-1][sequenceStartFrames[1]-1, :]\n",
      "gwv.showCustomGraph(tmp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 379
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print trackedSprites[spriteIndices[idx]][DICT_SPRITE_NAME]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "debugSequence = []\n",
      "for idx in xrange(len(spriteIndices)) :\n",
      "    debugSequence.append({\n",
      "                          DICT_SPRITE_NAME:trackedSprites[spriteIndices[idx]][DICT_SPRITE_NAME],\n",
      "                          DICT_SPRITE_IDX:spriteIndices[idx],\n",
      "                          DICT_SEQUENCE_FRAMES:generatedSequences[idx, :],\n",
      "                          DICT_DESIRED_SEMANTICS:np.array([1.0, 0.0]).reshape((1, 2)).repeat(sequenceLength, axis=0)\n",
      "                          })\n",
      "    if idx == 0 :\n",
      "        debugSequence[idx][DICT_SEQUENCE_FRAMES] = minCostTraversal#np.ones(sequenceLength)*200\n",
      "np.save(dataPath+dataSet+\"generatedSequence-debug.npy\", debugSequence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 464
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "incompatibleDistances = np.copy(spritesCompatibility)\n",
      "incompatiblePairs = np.argwhere(incompatibleDistances <= 1.0)\n",
      "incompatibleDistances[incompatiblePairs[:, 0], incompatiblePairs[:, 1]] = 1e7\n",
      "gwv.showCustomGraph(incompatibleDistances)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 468
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## compute L2 distance between bbox centers for given sprites\n",
      "spriteDistMats = []\n",
      "for idx in xrange(len(spriteIndices)) :\n",
      "    bboxCenters = np.array([trackedSprites[spriteIndices[idx]][DICT_BBOX_CENTERS][x] for x in np.sort(trackedSprites[spriteIndices[idx]][DICT_BBOX_CENTERS].keys())])\n",
      "    l2DistMat = np.zeros((len(bboxCenters), len(bboxCenters)))\n",
      "    for c in xrange(len(bboxCenters)) :\n",
      "        l2DistMat[c, c:] = np.linalg.norm(bboxCenters[c].reshape((1, 2)).repeat(len(bboxCenters)-c, axis=0) - bboxCenters[c:], axis=1)\n",
      "        l2DistMat[c:, c] = l2DistMat[c, c:]\n",
      "            \n",
      "    spriteDistMats.append(vtu.filterDistanceMatrix(l2DistMat, 4, False))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## compute compatibility distance for every frame pairing between sprites\n",
      "## compute L2 distance between bbox centers for given sprites\n",
      "spritesCompatibility = np.zeros((len(trackedSprites[spriteIndices[0]][DICT_BBOX_CENTERS]), len(trackedSprites[spriteIndices[1]][DICT_BBOX_CENTERS])))\n",
      "\n",
      "for frame in np.arange(len(trackedSprites[spriteIndices[0]][DICT_BBOX_CENTERS])) :\n",
      "    spriteTotLength = len(trackedSprites[spriteIndices[1]][DICT_BBOX_CENTERS])\n",
      "    frameRanges = np.vstack((np.ones(spriteTotLength, dtype=int)*frame, np.arange(spriteTotLength, dtype=int).reshape((1, spriteTotLength))))\n",
      "    compatibilityDist, allCompatibilityDists = getOverlappingSpriteTracksDistance(trackedSprites[spriteIndices[0]], trackedSprites[spriteIndices[1]], frameRanges, False)\n",
      "    spritesCompatibility[frame, :] = allCompatibilityDists\n",
      "    \n",
      "    sys.stdout.write('\\r' + \"Computed frame \" + np.string_(frame) + \" of \" + np.string_(len(trackedSprites[spriteIndices[0]][DICT_BBOX_CENTERS])))\n",
      "    sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 313
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(spritesCompatibility)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 311
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = np.clip(spriteDistMats[0], 0.1, 0.3)#*(spriteDistMats[0] <= 1.0)\n",
      "gwv.showCustomGraph(tmp)\n",
      "# probs, cumProbs = vtu.getProbabilities(spriteDistMats[0][1:, 0:-1], 0.01, None, True)\n",
      "probs, cumProbs = vtu.getProbabilities(tmp[1:, 0:-1], 0.001, None, False)\n",
      "gwv.showCustomGraph(probs)\n",
      "gwv.showCustomGraph(cumProbs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spriteIndex = 0\n",
      "gwv.showCustomGraph(allPairwise[spriteIndex])\n",
      "gwv.showCustomGraph(spriteDistMats[spriteIndex])\n",
      "\n",
      "pairwiseWithDist = np.ones_like(allPairwise[spriteIndex])* 5\n",
      "jumpCosts = spriteDistMats[spriteIndex][1:, :-1]**2\n",
      "viableJumps = np.argwhere(jumpCosts < 0.2)\n",
      "viableJumps = viableJumps[np.ndarray.flatten(np.argwhere(jumpCosts[viableJumps[:, 0], viableJumps[:, 1]] > 0.1))]\n",
      "## add 1 to indices because of the 0th frame, and then 5, 4 from the filtering and 1 from going from distances to costs\n",
      "pairwiseWithDist[viableJumps[:, 0]+1, viableJumps[:, 1]+1] = jumpCosts[viableJumps[:, 0], viableJumps[:, 1]]\n",
      "gwv.showCustomGraph(pairwiseWithDist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print viableJumps.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 200
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# np.all((jumpCosts < 2.0, jumpCosts > 0.1), axis=0)\n",
      "print np.argwhere(jumpCosts[viableJumps[:, 0], viableJumps[:, 1]] > 0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 197
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "minCostTraversal, minCost = solveSparseDynProgMRF(allUnaries[spriteIndex].T, pairwiseWithDist.T, allNodesConnectedToLabel[spriteIndex])\n",
      "print minCostTraversal"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(tmp.reshape(spriteDistMats[spriteIndex].shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.argwhere(tmp.reshape(spriteDistMats[spriteIndex].shape) < 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "From here on there's stuff using the hardcoded compatibility measure and assumes the sprite loops till the end of its sequence without jumping around in the timeline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## load tracked sprites\n",
      "trackedSprites = []\n",
      "for sprite in np.sort(glob.glob(dataPath + dataSet + \"sprite*.npy\")) :\n",
      "    trackedSprites.append(np.load(sprite).item())\n",
      "## load generated sequence\n",
      "generatedSequence = list(np.load(dataPath + dataSet + \"generatedSequence-2015-05-02_19:41:52.npy\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## try to learn from a labelled incompatibility and use it to not repeat the error\n",
      "## I know there's an incompatibility between two instances of red_car1 at frame 431 of the generated sequence loaded above\n",
      "labelledSequenceFrame = 413\n",
      "## here find which sprites were labelled eventually when I have a scribble but for now I just need to find the 2 sprites that I\n",
      "## saw were incompatible\n",
      "for seq in generatedSequence :\n",
      "    print seq[DICT_SPRITE_NAME], seq[DICT_SEQUENCE_FRAMES][labelledSequenceFrame]\n",
      "    ## here eventually check if scribble touches the current sprite by for instance checking whether scribble intersects the\n",
      "    ## sprite's bbox at frame seq[DICT_SEQUENCE_FRAMES][labelledSequenceFrame]\n",
      "\n",
      "## for now I know the two red_car1 sprites that collide at frame 413 are number 2 and 6 in the generatedSequence\n",
      "incompatibleSpriteTracks = np.array([2, 6])\n",
      "spriteIndices = [] ## index of given sprite in trackedSprites\n",
      "spriteSemanticLabels = []\n",
      "print\n",
      "print \"incompatible sprites\", incompatibleSpriteTracks, \":\",\n",
      "for i in xrange(len(incompatibleSpriteTracks)) :\n",
      "    print generatedSequence[incompatibleSpriteTracks[i]][DICT_SPRITE_NAME] + \"(\", \n",
      "    print np.string_(int(generatedSequence[incompatibleSpriteTracks[i]][DICT_SEQUENCE_FRAMES][labelledSequenceFrame])) + \")\",\n",
      "    \n",
      "    spriteIndices.append(generatedSequence[incompatibleSpriteTracks[i]][DICT_SPRITE_IDX])\n",
      "    \n",
      "    ## compute semantic labels for each sprite which for the reshuffling case are binary \n",
      "    ## i.e. each frame has label 1 (i.e. sprite visible) and extra frame at beginning has label 0\n",
      "    semanticLabels = np.zeros((len(trackedSprites[spriteIndices[i]][DICT_BBOX_CENTERS])+1, 2))\n",
      "    ## label 0 means sprite not visible (i.e. only show the first empty frame)\n",
      "    semanticLabels[0, 0] = 1.0\n",
      "    semanticLabels[1:, 1] = 1.0\n",
      "    \n",
      "    spriteSemanticLabels.append(semanticLabels)\n",
      "print\n",
      "\n",
      "\n",
      "## given that I know what sprites are incompatible and in what configuration, how do I go about getting a compatibility measure for all configurations?\n",
      "## and is there a way to get a compatibility measure for all the sprites combinations and all their configurations from it?\n",
      "\n",
      "## for now just use sprite center distance to characterise a certain configuration and later on use other cues like bbox overlap and RGB L2 distance\n",
      "## compute bbox center distance between the given configuration of incompatible sprites\n",
      "if len(incompatibleSpriteTracks) == 2 :\n",
      "    ## subtracting 1 here because in generatedSequence there is an extra frame for each frame denoting the sprite being invisible\n",
      "    spriteFrame = np.zeros(2, dtype=int)\n",
      "    spriteFrame[0] = generatedSequence[incompatibleSpriteTracks[0]][DICT_SEQUENCE_FRAMES][labelledSequenceFrame]-1\n",
      "    spriteFrame[1] = generatedSequence[incompatibleSpriteTracks[1]][DICT_SEQUENCE_FRAMES][labelledSequenceFrame]-1\n",
      "    \n",
      "    shift = np.abs(spriteFrame[0]-spriteFrame[1])\n",
      "    whosFirst = int(np.argmax(spriteFrame))\n",
      "    print whosFirst\n",
      "    \n",
      "    totalDistance, distances, frameRanges = getShiftedSpriteTrackDist(trackedSprites[spriteIndices[whosFirst]], \n",
      "                                                                      trackedSprites[spriteIndices[whosFirst-1]], shift)\n",
      "    print totalDistance\n",
      "    \n",
      "    possibleShifts = np.arange(-len(trackedSprites[spriteIndices[0]][DICT_BBOX_CENTERS])+1, \n",
      "                               len(trackedSprites[spriteIndices[1]][DICT_BBOX_CENTERS]), dtype=int)\n",
      "#     allDistances = np.zeros(len(possibleShifts))\n",
      "#     for shift, i in zip(possibleShifts, xrange(len(allDistances))) :\n",
      "#         if shift < 0 :\n",
      "#             totalDistance, distances, frameRanges = getShiftedSpriteTrackDist(trackedSprites[spriteIndices[0]], \n",
      "#                                                                               trackedSprites[spriteIndices[1]], -shift)\n",
      "#         else :\n",
      "#             totalDistance, distances, frameRanges = getShiftedSpriteTrackDist(trackedSprites[spriteIndices[1]], \n",
      "#                                                                               trackedSprites[spriteIndices[0]], shift)\n",
      "            \n",
      "#         allDistances[i] = totalDistance\n",
      "        \n",
      "#         sys.stdout.write('\\r' + \"Done \" + np.string_(i) + \" shifts of \" + np.string_(len(allDistances)))\n",
      "#         sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sequenceLength = 101\n",
      "toggleDelay = 8\n",
      "## simulating situation where I'm inserting sprite 6 into the loaded generatedSequence at startFrame\n",
      "## this makes sure that I get the labelled incompatible situation (i.e. sprite 2 is at frame 72 and sprite 6 at 111) if I don't do anything about compatibility\n",
      "startFrame = 413#-111-toggleDelay/2\n",
      "\n",
      "## semantics for sprite 6\n",
      "spriteDesiredSemantics = np.array([1.0, 0.0]).reshape((1, 2))\n",
      "spriteDesiredSemantics = np.concatenate((spriteDesiredSemantics, toggleLabelsSmoothly(np.array([1.0, 0.0]).reshape((1, 2)), toggleDelay)))\n",
      "spriteDesiredSemantics = np.concatenate((spriteDesiredSemantics, np.roll(np.array([1.0, 0.0]).reshape((1, 2)), 1).repeat(sequenceLength-toggleDelay-1, axis=0)))\n",
      "\n",
      "## also need to simulate a situation where the semantics for a sprite are toggled before a certain sprite has been toggled but is already part of the \n",
      "## sequence which is really the situation I'm in in the loaded generated sequence (i.e. I added sprite 2 at time t and then added sprite 6 at a later\n",
      "## time but before sprite 2 in the sequence time line so, chronologically, sprite 6 is added later but is incompatible with a sprite the will be shown\n",
      "## later in the sequence) but I guess when I add a new sprite, I need to check if it's compatible with all the sprites in the sequence although I'm not sure\n",
      "## how that would work\n",
      "\n",
      "\n",
      "conflictingSpriteTotalLength = len(trackedSprites[spriteIndices[1]][DICT_BBOX_CENTERS])\n",
      "print conflictingSpriteTotalLength\n",
      "\n",
      "conflictingSpriteSemanticLabels = np.zeros((conflictingSpriteTotalLength+1, 2))\n",
      "## label 0 means sprite not visible (i.e. only show the first empty frame)\n",
      "conflictingSpriteSemanticLabels[0, 0] = 1.0\n",
      "conflictingSpriteSemanticLabels[1:, 1] = 1.0\n",
      "\n",
      "## now optimize the sprite I'm changing the semantic label of (i.e. I want to show now)\n",
      "## optimize without caring about compatibility\n",
      "tic = time.time()\n",
      "unaries, pairwise = getMRFCosts(conflictingSpriteSemanticLabels, spriteDesiredSemantics, 0, sequenceLength)\n",
      "\n",
      "## now try and do the optimization completely vectorized\n",
      "## number of edges connected to each label node of variable n (pairwise stores node at arrow tail as cols and at arrow head as rows)\n",
      "maxEdgesPerLabel = np.max(np.sum(np.array(pairwise.T != np.max(pairwise.T), dtype=int), axis=-1))\n",
      "## initialize this to index of connected label node with highest edge cost (which is then used as padding)\n",
      "## it contains for each label node of variable n (indexed by rows), all the label nodes of variable n-1 it is connected to by non infinite cost edge (indexed by cols)\n",
      "nodesConnectedToLabel = np.argmax(pairwise.T, axis=-1).reshape((len(pairwise.T), 1)).repeat(maxEdgesPerLabel, axis=-1)\n",
      "\n",
      "sparseIndices = np.where(pairwise != np.max(pairwise))\n",
      "# print sparseIndices\n",
      "tailIndices = sparseIndices[0]\n",
      "headIndices = sparseIndices[1]\n",
      "\n",
      "## this contains which label of variable n-1 is connected to which label of variable n\n",
      "indicesInLabelSpace = [list(tailIndices[np.where(headIndices == i)[0]]) for i in np.unique(headIndices)]\n",
      "\n",
      "for headLabel, tailLabels in zip(arange(0, len(nodesConnectedToLabel)), indicesInLabelSpace) :\n",
      "    nodesConnectedToLabel[headLabel, 0:len(tailLabels)] = tailLabels    \n",
      "\n",
      "# gwv.showCustomGraph(unaries)\n",
      "print \"computed costs for sprite\", incompatibleSpriteTracks[1], \"in\", time.time() - tic; sys.stdout.flush()\n",
      "tic = time.time()\n",
      "# minCostTraversal, minCost = solveMRF(unaries, pairwise)\n",
      "minCostTraversal, minCost = solveSparseDynProgMRF(unaries.T, pairwise.T, nodesConnectedToLabel)\n",
      "\n",
      "print \"solved traversal for sprite\", incompatibleSpriteTracks[1] , \"in\", time.time() - tic; sys.stdout.flush()\n",
      "print minCostTraversal, minCost\n",
      "\n",
      "count = 0\n",
      "unariesToUpdate = np.zeros_like(unaries, dtype=np.bool)\n",
      "while True :\n",
      "    ## check whether the sprite is compatible with existing sprites in the generated sequence\n",
      "    tic = time.time()\n",
      "    for i in xrange(len(generatedSequence)) :\n",
      "        if i != incompatibleSpriteTracks[1] and i == 7 :\n",
      "            overlappingSequence = np.array(generatedSequence[i][DICT_SEQUENCE_FRAMES][startFrame:startFrame+sequenceLength], dtype=int)\n",
      "#             print overlappingSequence\n",
      "            \n",
      "            spriteTotalLength = len(trackedSprites[generatedSequence[i][DICT_SPRITE_IDX]][DICT_BBOX_CENTERS])\n",
      "            spriteSemanticLabels = np.zeros((spriteTotalLength+1, 2))\n",
      "            ## label 0 means sprite not visible (i.e. only show the first empty frame)\n",
      "            spriteSemanticLabels[0, 0] = 1.0\n",
      "            spriteSemanticLabels[1:, 1] = 1.0\n",
      "            \n",
      "#             print spriteTotalLength\n",
      "#             print overlappingSequence\n",
      "#             print minCostTraversal\n",
      "            isCompatible = np.zeros(len(minCostTraversal), dtype=np.bool)\n",
      "            \n",
      "            ## if the semantic labels are different, the sprites are compatible with each in the reshuffling case but need to figure out how to deal with this\n",
      "            ## in a general way\n",
      "#             isCompatible[np.all(spriteSemanticLabels[overlappingSequence] != conflictingSpriteSemanticLabels[minCostTraversal], axis = 1)] = True\n",
      "            ### HACK ??? ### if one of the frame is 0 it means the two sprites are compatible\n",
      "            isCompatible[np.any(np.array(np.vstack((overlappingSequence.reshape((1, len(overlappingSequence))),\n",
      "                                                    minCostTraversal.reshape((1, len(minCostTraversal))))), dtype=int) == 0, axis = 0)] = True\n",
      "#             print isCompatible\n",
      "            frameRanges = synchedSequence2FullOverlap(np.array(np.vstack((overlappingSequence.reshape((1, len(overlappingSequence)))-1,\n",
      "                                                                          minCostTraversal.reshape((1, len(minCostTraversal)))-1)), dtype=int), \n",
      "                                                      np.array((spriteTotalLength, conflictingSpriteTotalLength)))\n",
      "#             print frameRanges\n",
      "            \n",
      "            if frameRanges != None :\n",
      "#                 totalDistance, distances = getOverlappingSpriteTracksDistance(trackedSprites[generatedSequence[i][DICT_SPRITE_IDX]], trackedSprites[0], frameRanges)\n",
      "                \n",
      "                ## references precomputedDistances instead of recomputing\n",
      "                \n",
      "                spriteIdxs = np.array([generatedSequence[i][DICT_SPRITE_IDX], generatedSequence[incompatibleSpriteTracks[1]][DICT_SPRITE_IDX]])\n",
      "                sortIdxs = np.argsort(spriteIdxs)\n",
      "                pairing = np.string_(spriteIdxs[sortIdxs][0]) + np.string_(spriteIdxs[sortIdxs][1])\n",
      "                pairingShift = frameRanges[sortIdxs, 0][1]-frameRanges[sortIdxs, 0][0]\n",
      "                totalDistance = precomputedDistances[pairing][pairingShift]\n",
      "                \n",
      "                print totalDistance, precomputedDistances[pairing][pairingShift], pairing, pairingShift, frameRanges[sortIdxs, 0]\n",
      "                \n",
      "                ## find all pairs of frame that show the same label as the desired label (i.e. [0.0, 1.0])\n",
      "                tmp = np.all(spriteSemanticLabels[overlappingSequence] == conflictingSpriteSemanticLabels[minCostTraversal], axis=1)\n",
      "                if totalDistance > 50.0 : \n",
      "                    isCompatible[np.all((np.all(conflictingSpriteSemanticLabels[minCostTraversal] == np.array([0.0, 1.0]), axis=1), tmp), axis=0)] = True\n",
      "            else :\n",
      "                print \"sprites not overlapping\"\n",
      "            \n",
      "#             print isCompatible\n",
      "    print \"la\", time.time() - tic\n",
      "    count += 1\n",
      "    if np.any(np.negative(isCompatible)) :\n",
      "        ## when I do the check for all the sprites in the sequence I would have to take an AND over all the isCompatible arrays but now I know there's only 1 sprite\n",
      "        \n",
      "        ## keep track of unaries to change\n",
      "        unariesToUpdate[np.arange(len(minCostTraversal), dtype=int)[np.negative(isCompatible)], minCostTraversal[np.negative(isCompatible)]] = True\n",
      "        ## change the unaries to increase the cost for the frames where the isCompatible is False\n",
      "#         unaries[np.arange(len(minCostTraversal), dtype=int)[np.negative(isCompatible)], minCostTraversal[np.negative(isCompatible)]] += 1000.0\n",
      "        unaries[np.argwhere(unariesToUpdate)[:, 0], np.argwhere(unariesToUpdate)[:, 1]] += 1000.0\n",
      "    #     gwv.showCustomGraph(unaries)\n",
      "        tic = time.time()\n",
      "#         minCostTraversal, minCost = solveMRF(unaries, pairwise)\n",
      "        minCostTraversal, minCost = solveSparseDynProgMRF(unaries.T, pairwise.T, nodesConnectedToLabel)\n",
      "        if True or np.mod(count, 10) == 0 :\n",
      "            print \"iterarion\", count, \": solved traversal for sprite\", incompatibleSpriteTracks[1] , \"in\", time.time() - tic; sys.stdout.flush()\n",
      "#             print minCostTraversal, minCost\n",
      "        \n",
      "        if count == 200 :\n",
      "            break\n",
      "    else :\n",
      "        print \"done biatch\"\n",
      "        print minCostTraversal\n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = 2\n",
      "for cost, path, i in zip(minCosts[:, tmp], minCostPaths[:, tmp], xrange(1, minCosts.shape[0])) :\n",
      "    if np.mod(i-1, 5) == 0 :\n",
      "        print \"{0:03d} - {1:03d}\\t\".format(i-1, i+3), \n",
      "    print cost, \"{0:03d}\".format(int(path)), \"\\t\",\n",
      "    if np.mod(i, 5) == 0 :\n",
      "        print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sio.savemat(dataPath + dataSet + \"allFramesHogs_NoEncoding\", {\"hogFeats\":allFeats[0]})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.sqrt(np.sum(np.power(allFeats[0][0]-allFeats[0][100], 2)))\n",
      "featSize = len(allFeats[0][0])\n",
      "diffVec = (allFeats[0][0]-allFeats[0][100]).reshape((featSize, 1))\n",
      "print np.sqrt(np.dot(diffVec.T, diffVec))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import optimize\n",
      "## example optimization\n",
      "def rosen(x):\n",
      "    \"\"\"The Rosenbrock function\"\"\"\n",
      "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n",
      "\n",
      "def rosen_der(x):\n",
      "    xm = x[1:-1]\n",
      "    xm_m1 = x[:-2]\n",
      "    xm_p1 = x[2:]\n",
      "    der = zeros_like(x)\n",
      "    der[1:-1] = 200*(xm-xm_m1**2) - 400*(xm_p1 - xm**2)*xm - 2*(1-xm)\n",
      "    der[0] = -400*x[0]*(x[1]-x[0]**2) - 2*(1-x[0])\n",
      "    der[-1] = 200*(x[-1]-x[-2]**2)\n",
      "    return der\n",
      "\n",
      "iterNum = 0\n",
      "def printStats(xk) :\n",
      "    global iterNum\n",
      "    global x0\n",
      "    print iterNum, np.mean(np.abs(xk-x0)); sys.stdout.flush()\n",
      "    iterNum += 1\n",
      "\n",
      "x0 = [1.3, 0.7, 0.8, 1.9, 1.2]\n",
      "xopt = optimize.fmin_ncg(rosen, x0, fprime=rosen_der, callback=printStats)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hogFeats = sio.loadmat(dataPath + dataSet + \"allFramesHogs.mat\")[\"hogFeats\"]\n",
      "print hogFeats.shape\n",
      "\n",
      "## get feats of subsequent frames\n",
      "goodPairsIdxs = np.array([np.arange(len(hogFeats)-1, dtype=int), np.arange(1, len(hogFeats), dtype=int)])\n",
      "print goodPairsIdxs\n",
      "## ABS DIST\n",
      "goodExamplesData = np.sqrt((hogFeats[goodPairsIdxs[0, :], :]-hogFeats[goodPairsIdxs[1, :], :])**2)\n",
      "print goodExamplesData.shape\n",
      "\n",
      "## get feats of random pairings that are considered bad\n",
      "numBadExamples = 500\n",
      "minIdxsDiff = 10\n",
      "badPairsIdxs = np.sort(np.array([np.random.choice(np.arange(len(hogFeats)), numBadExamples), \n",
      "                                 np.random.choice(np.arange(len(hogFeats)), numBadExamples)]), axis=0)\n",
      "\n",
      "print len(np.argwhere(np.abs(badPairsIdxs[0, :]-badPairsIdxs[1, :]) < minIdxsDiff)), \"invalid pairs\"\n",
      "for pairIdx in xrange(numBadExamples) :\n",
      "    idxDiff = np.abs(badPairsIdxs[0, pairIdx] - badPairsIdxs[1, pairIdx])\n",
      "    tmp = idxDiff\n",
      "    newPair = badPairsIdxs[:, pairIdx]\n",
      "    while idxDiff < minIdxsDiff :\n",
      "        newPair = np.sort(np.random.choice(np.arange(len(hogFeats)), 2))\n",
      "        idxDiff = np.abs(newPair[0] - newPair[1])\n",
      "#     print badPairsIdxs[:, pairIdx], newPair, tmp\n",
      "    badPairsIdxs[:, pairIdx] = newPair\n",
      "#     if badPairsIdxs[pairIdx, 0] - badPairsIdxs[pairIdx, 1] < minIdxsDiff\n",
      "\n",
      "# print badPairsIdxs\n",
      "print len(np.argwhere(np.abs(badPairsIdxs[0, :]-badPairsIdxs[1, :]) < minIdxsDiff)), \"invalid pairs\"\n",
      "## ABS DIST\n",
      "badExamplesData = np.sqrt((hogFeats[badPairsIdxs[0, :], :]-hogFeats[badPairsIdxs[1, :], :])**2)\n",
      "print badExamplesData.shape\n",
      "\n",
      "tic = time.time()\n",
      "regressor = ensemble.ExtraTreesRegressor(n_estimators=100, n_jobs=4, verbose=0)\n",
      "regressor.fit(list(np.concatenate((goodExamplesData, badExamplesData))), \n",
      "              list(np.concatenate((np.zeros(len(goodExamplesData)), np.ones(len(badExamplesData))))))\n",
      "print \"regressor trained in\", time.time()-tic; sys.stdout.flush()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allPairsHogs = []\n",
      "for i in xrange(len(hogFeats)) :\n",
      "    for j in xrange(i+1, len(hogFeats)) :\n",
      "        ## ABS DIST\n",
      "        allPairsHogs.append(np.sqrt((hogFeats[i, :]-hogFeats[j, :])**2))\n",
      "        \n",
      "    sys.stdout.write('\\r' + \"Done with row \" + np.string_(i) + \" of \" + np.string_(len(hogFeats)))\n",
      "    sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tic = time.time()\n",
      "dists = regressor.predict(allPairsHogs)\n",
      "print \"distance regressed in\", time.time()-tic; sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numFrames = len(hogFeats)\n",
      "regressedDist = np.ones((numFrames, numFrames))\n",
      "flatRegressedDist = list(np.copy(dists))\n",
      "for i in xrange(numFrames-1) :\n",
      "    regressedDist[i, i+1:] = flatRegressedDist[:numFrames-(i+1)]\n",
      "    regressedDist[i+1:, i] = regressedDist[i, i+1:]\n",
      "    del flatRegressedDist[:numFrames-(i+1)]\n",
      "# print flatRegressedDist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(regressedDist)\n",
      "## set all backwards jumps to 1 as well\n",
      "regressedDist[np.arange(1, len(regressedDist)), np.arange(0, len(regressedDist)-1)] = 1.0\n",
      "filteredRegressed = vtu.filterDistanceMatrix(regressedDist, 4, False)\n",
      "gwv.showCustomGraph(filteredRegressed)\n",
      "futureRegressed = vtu.estimateFutureCost(0.999, 2.0, filteredRegressed)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs, cumProbs = vtu.getProbabilities(filteredRegressed, 0.005, None, True)\n",
      "gwv.showCustomGraph(probs)\n",
      "gwv.showCustomGraph(cumProbs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bob = [638, 669]\n",
      "filtSize = 4\n",
      "gwv.showCustomGraph(regressedDist[bob[0]-filtSize:bob[1]-filtSize, bob[0]-filtSize:bob[1]-filtSize])\n",
      "gwv.showCustomGraph(filteredRegressed[bob[0]:bob[1], bob[0]:bob[1]])\n",
      "gwv.showCustomGraph(vtu.filterDistanceMatrix(regressedDist[bob[0]-filtSize*2:bob[1], bob[0]-filtSize*2:bob[1]], 4, False))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# l2Dist = np.load(dataPath+\"Videos/6489810.avi_distanceMatrix.npy\")\n",
      "gwv.showCustomGraph(l2Dist)\n",
      "gwv.showCustomGraph(vtu.filterDistanceMatrix(l2Dist, 4, False))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(np.argwhere(filteredRegressed == 0.0))\n",
      "print filteredRegressed.shape\n",
      "print (664-1)*2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 146
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Hack over"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## get random frames from each tracked sprite and get their hog features to then train the GMM\n",
      "numLeaveOut = 30\n",
      "numFramesPerSprite = 50\n",
      "gmmTrainingFeats = np.empty(0)\n",
      "for sprite in trackedSprites:\n",
      "    for frameIdx in random.choice(arange(numLeaveOut, len(sprite[DICT_BBOX_CENTERS])-numLeaveOut), numFramesPerSprite, replace=False) :\n",
      "        tmp = len(gmmTrainingFeats)\n",
      "        gmmTrainingFeats = np.concatenate((gmmTrainingFeats, getSemanticsFeatures(getSemanticsData(sprite, frameIdx), None, True)))\n",
      "        print \"added\", (len(gmmTrainingFeats)-tmp), \"features from\", sprite[DICT_SPRITE_NAME], \"at frame\", frameIdx\n",
      "#     break\n",
      "        \n",
      "gmmTrainingFeats = gmmTrainingFeats.reshape((len(gmmTrainingFeats)/hogOrientations, hogOrientations))\n",
      "\n",
      "gmModel = fitGMM(gmmTrainingFeats, 15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "validationSetSize = int(len(gmmTrainingFeats)*0.1)\n",
      "validationSet = random.choice(arange(len(gmmTrainingFeats)), validationSetSize, replace=False)\n",
      "trainingSet = np.setdiff1d(arange(len(gmmTrainingFeats)), validationSet)\n",
      "\n",
      "for numComponents in xrange(5, 128, 1) :\n",
      "    print numComponents,\n",
      "    gmModel = fitGMM(gmmTrainingFeats[trainingSet, :], numComponents)\n",
      "    print gmModel.converged_, \n",
      "    print \"finished training\",\n",
      "    sys.stdout.flush()\n",
      "    gmScores = gmModel.score(gmmTrainingFeats[validationSet, :])\n",
      "    print \"\\t->\\tavg score is\", np.mean(gmScores)\n",
      "    sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 316
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## extract features for all sprites\n",
      "allFeats = {}\n",
      "for spriteIdx in [0, 3] : #arange(len(trackedSprites)) :\n",
      "    spriteFeats = []\n",
      "    for frameIdx in xrange(len(trackedSprites[spriteIdx][DICT_BBOXES])) :\n",
      "        feats = getSemanticsFeatures(getSemanticsData(trackedSprites[spriteIdx], frameIdx), gmModel)#, False, True)\n",
      "        spriteFeats.append(feats)\n",
      "        sys.stdout.write('\\r' + \"Done with frame \" + np.string_(frameIdx) + \" of \" + np.string_(len(trackedSprites[spriteIdx][DICT_BBOXES])))\n",
      "        sys.stdout.flush()\n",
      "    \n",
      "    print\n",
      "    print \"done with sprite\", spriteIdx, trackedSprites[spriteIdx][DICT_SPRITE_NAME]\n",
      "    allFeats[spriteIdx] = spriteFeats\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## compute L2 distance between bbox centers for given sprites\n",
      "spriteDistMats = {}\n",
      "for spriteIdx in [0, 3] :\n",
      "    bboxCenters = np.array([trackedSprites[spriteIdx][DICT_BBOX_CENTERS][x] for x in np.sort(trackedSprites[spriteIdx][DICT_BBOX_CENTERS].keys())])\n",
      "    l2DistMat = np.zeros((len(bboxCenters), len(bboxCenters)))\n",
      "    for c in xrange(len(bboxCenters)) :\n",
      "        l2DistMat[c, c:] = np.linalg.norm(bboxCenters[c].reshape((1, 2)).repeat(len(bboxCenters)-c, axis=0) - bboxCenters[c:], axis=1)\n",
      "        l2DistMat[c:, c] = l2DistMat[c, c:]\n",
      "            \n",
      "    spriteDistMats[spriteIdx] = vtu.filterDistanceMatrix(l2DistMat, 4, False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ## precompute images on which the bbox of a sprite is rendered\n",
      "# for spriteIdx in arange(len(trackedSprites))[0:1] :\n",
      "#     allBBoxImages = []\n",
      "#     imageSize = np.array(Image.open(trackedSprites[spriteIdx][DICT_FRAMES_LOCATIONS][trackedSprites[spriteIdx][DICT_FRAMES_LOCATIONS].keys()[0]])).shape[0:2]\n",
      "#     for i in xrange(len(trackedSprites[spriteIdx][DICT_BBOXES])) :\n",
      "#         img = np.zeros(imageSize, dtype=np.uint8)\n",
      "#         cv2.drawContours(img, [int32(trackedSprites[spriteIdx][DICT_BBOXES][np.sort(trackedSprites[spriteIdx][DICT_BBOXES].keys())[i]]).reshape((4, 1, 2))], 0, 1, cv2.cv.CV_FILLED)\n",
      "#         allBBoxImages.append(img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 506
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.argwhere(isnan(allPairFeatures))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## compute pair feats for all frame pairs for each sprite individually\n",
      "allSpritesPairFeats = {}\n",
      "for spriteIdx in [0, 3] : ##arange(len(trackedSprites))[0:1] :\n",
      "    allPairFeatures = []\n",
      "    imageSize = np.array(Image.open(trackedSprites[spriteIdx][DICT_FRAMES_LOCATIONS][trackedSprites[spriteIdx][DICT_FRAMES_LOCATIONS].keys()[0]])).shape[0:2]\n",
      "    for i in xrange(len(trackedSprites[spriteIdx][DICT_BBOXES])) :\n",
      "        for j in xrange(i+1, len(trackedSprites[spriteIdx][DICT_BBOXES])) :\n",
      "#             ## L2 DIST\n",
      "#             pairFeats = np.sqrt(np.sum(np.power(allFeats[spriteIdx][i]-allFeats[spriteIdx][j],2), axis=-1))\n",
      "            ## ABS DIST\n",
      "            pairFeats = np.sqrt((allFeats[spriteIdx][i]-allFeats[spriteIdx][j])**2)\n",
      "#             ## MEAN\n",
      "#             pairFeats = np.mean(np.hstack((allFeats[spriteIdx][i], allFeats[spriteIdx][j])), axis=1)\n",
      "            \n",
      "            ## compute percentage of overlapping area by first drawing the bboxes onto images and then ANDing and ORing them to get instersection area and total area\n",
      "#             intersection = np.logical_and(allBBoxImages[i],allBBoxImages[j])\n",
      "#             totalArea = np.logical_or(allBBoxImages[i],allBBoxImages[j])\n",
      "#             pairFeats = np.concatenate((pairFeats, [float(len(np.argwhere(intersection)))/float(len(np.argwhere(totalArea)))]))\n",
      "            \n",
      "            ## compute bbox distance\n",
      "            pairFeats = np.concatenate((pairFeats, [getOverlappingSpriteTracksDistance(trackedSprites[spriteIdx], trackedSprites[spriteIdx], np.array([[i], [j]]))[0]]))\n",
      "\n",
      "            allPairFeatures.append(pairFeats)\n",
      "        sys.stdout.write('\\r' + \"Done with row \" + np.string_(i) + \" of \" + np.string_(len(trackedSprites[spriteIdx][DICT_BBOXES])))\n",
      "        sys.stdout.flush()\n",
      "    \n",
      "    print\n",
      "    print \"done with sprite\", spriteIdx, trackedSprites[spriteIdx][DICT_SPRITE_NAME]\n",
      "    allSpritesPairFeats[spriteIdx] = allPairFeatures"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 248
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(allSpritesPairFeats[0][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 249
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numFrames = len(trackedSprites[spriteIdxs[0]][DICT_BBOXES])\n",
      "print numFrames\n",
      "visSpritePairFeats = np.zeros((numFrames, numFrames))\n",
      "tmp = [allSpritesPairFeats[0][x][-5] for x in xrange(len(allSpritesPairFeats[0]))]\n",
      "for i in xrange(numFrames-1) :\n",
      "    visSpritePairFeats[i, i+1:] = tmp[:numFrames-(i+1)]\n",
      "    visSpritePairFeats[i+1:, i] = visSpritePairFeats[i, i+1:]\n",
      "    del tmp[:numFrames-(i+1)]\n",
      "    sys.stdout.write('\\r' + \"Done with row \" + np.string_(i) + \" of \" + np.string_(numFrames))\n",
      "    sys.stdout.flush()\n",
      "    \n",
      "gwv.showCustomGraph(visSpritePairFeats)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 254
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numFrames = len(trackedSprites[spriteIdx][DICT_BBOXES])\n",
      "regressedDist = np.zeros((numFrames, numFrames))\n",
      "prevStop = 0\n",
      "for i in xrange(numFrames-1) :\n",
      "    regressedDist[i, i+1:] = flatRegressedDist[:numFrames-(i+1)]\n",
      "    regressedDist[i+1:, i] = regressedDist[i, i+1:]\n",
      "    del flatRegressedDist[:numFrames-(i+1)]\n",
      "print flatRegressedDist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## get pairs with smallest current distance to use as good examples of labelled pairs\n",
      "spriteIdx = 0\n",
      "spriteNumFrames = spriteDistMats[spriteIdx].shape[0]\n",
      "upperTriangleIndices = np.argwhere(np.triu(np.ones((spriteNumFrames, spriteNumFrames)), k=1) == 1)\n",
      "bestFirstPairs = np.argsort(spriteDistMats[spriteIdx][upperTriangleIndices[:, 0], upperTriangleIndices[:, 1]])\n",
      "bestPercentageToUse = 0.1\n",
      "pairsToUseAsLabelled = upperTriangleIndices[bestFirstPairs, :][:int(bestPercentageToUse*len(bestFirstPairs))]\n",
      "\n",
      "pairsToUseAsLabelledDists = spriteDistMats[spriteIdx][pairsToUseAsLabelled[:, 0], pairsToUseAsLabelled[:, 1]].reshape((len(pairsToUseAsLabelled), 1))\n",
      "pairsToUseAsLabelledDists /= np.max(spriteDistMats[spriteIdx])\n",
      "# print np.concatenate((pairsToUseAsLabelled, np.ones((len(pairsToUseAsLabelled), 1))), axis=-1)\n",
      "print np.concatenate((pairsToUseAsLabelled, pairsToUseAsLabelledDists), axis=-1)\n",
      "print len(pairsToUseAsLabelled)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(spriteDistMats[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 719
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Get labelled pairs of compatible/not compatible frames and learn compatibility\n",
      "\n",
      "# userLabelledExamples = np.array([[180, 185, 0.0], \n",
      "#                           [173, 164, 0.0], \n",
      "#                           [87, 368, 1.0], \n",
      "#                           [47, 182, 1.0], \n",
      "#                           [223, 304, 1.0], \n",
      "#                           [329, 418, 1.0], \n",
      "#                           [403, 468, 1.0], \n",
      "#                           [490, 72, 1.0]])\n",
      "\n",
      "\n",
      "userLabelledExamples = np.array([[180, 185, 0.0], \n",
      "                          [173, 164, 0.0], \n",
      "                          [87, 368, 1.0]])\n",
      "\n",
      "labelledPairs = np.concatenate((np.concatenate((pairsToUseAsLabelled+4, pairsToUseAsLabelledDists), axis=-1), \n",
      "                                userLabelledExamples), axis=0)\n",
      "\n",
      "# labelledPairs = np.array([[180, 185, 0.0], \n",
      "#                           [173, 164, 0.0], \n",
      "#                           [87, 368, 1.0], \n",
      "#                           [47, 182, 1.0], \n",
      "#                           [223, 304, 1.0], \n",
      "#                           [329, 418, 1.0], \n",
      "#                           [403, 468, 1.0], \n",
      "#                           [490, 72, 1.0]])\n",
      "\n",
      "labelledData = []\n",
      "for pair in labelledPairs :\n",
      "#     ## L2 DIST\n",
      "#     pairFeats = np.sqrt(np.sum(np.power(allFeats[0][int(pair[0])]-allFeats[0][int(pair[1])],2), axis=-1))\n",
      "    ## ABS DIST\n",
      "    pairFeats = np.sqrt((allFeats[0][int(pair[0])]-allFeats[0][int(pair[1])])**2)\n",
      "#     ## MEAN\n",
      "#     pairFeats = np.mean(np.hstack((allFeats[0][int(pair[0])], allFeats[0][int(pair[1])])), axis=1)\n",
      "    labelledData.append(pairFeats)\n",
      "\n",
      "tic = time.time()\n",
      "try :\n",
      "    del regressor\n",
      "except :\n",
      "    print \"no regressor\"\n",
      "regressor = ensemble.ExtraTreesRegressor(n_estimators=100, n_jobs=4, verbose=0)\n",
      "regressor.fit(labelledData, list(labelledPairs[:, -1]))\n",
      "print \"regressor trained in\", time.time()-tic\n",
      "\n",
      "tic = time.time()\n",
      "dists = regressor.predict(allSpritesPairFeats[spriteIdx])\n",
      "print \"distance regressed in\", time.time()-tic\n",
      "flatRegressedDist = list(np.copy(dists))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numFrames = len(trackedSprites[spriteIdx][DICT_BBOXES])\n",
      "regressedDist = np.zeros((numFrames, numFrames))\n",
      "prevStop = 0\n",
      "for i in xrange(numFrames-1) :\n",
      "    regressedDist[i, i+1:] = flatRegressedDist[:numFrames-(i+1)]\n",
      "    regressedDist[i+1:, i] = regressedDist[i, i+1:]\n",
      "    del flatRegressedDist[:numFrames-(i+1)]\n",
      "print flatRegressedDist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(regressedDist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "From here on it's about compatibility learning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for spriteIdxs in [[0, 3]] :#arange(len(trackedSprites))[0:1] :\n",
      "    allSpritePairsPairFeatures = []\n",
      "#     imageSize = np.array(Image.open(trackedSprites[spriteIdx][DICT_FRAMES_LOCATIONS][trackedSprites[spriteIdx][DICT_FRAMES_LOCATIONS].keys()[0]])).shape[0:2]\n",
      "    for i in xrange(len(trackedSprites[spriteIdxs[0]][DICT_BBOXES])) :\n",
      "        tmp = len(allSpritePairsPairFeatures)\n",
      "        for j in xrange(len(trackedSprites[spriteIdxs[1]][DICT_BBOXES])) :\n",
      "#             ## L2 DIST\n",
      "#             pairFeats = np.sqrt(np.sum(np.power(allFeats[spriteIdx][i]-allFeats[spriteIdx][j],2), axis=-1))\n",
      "            ## ABS DIST\n",
      "            pairFeats = np.sqrt((allFeats[spriteIdxs[0]][i]-allFeats[spriteIdxs[1]][j])**2)\n",
      "#             ## MEAN\n",
      "#             pairFeats = np.mean(np.hstack((allFeats[spriteIdx][i], allFeats[spriteIdx][j])), axis=1)\n",
      "            \n",
      "            ## compute percentage of overlapping area by first drawing the bboxes onto images and then ANDing and ORing them to get instersection area and total area\n",
      "#             intersection = np.logical_and(allBBoxImages[i],allBBoxImages[j])\n",
      "#             totalArea = np.logical_or(allBBoxImages[i],allBBoxImages[j])\n",
      "#             pairFeats = np.concatenate((pairFeats, [float(len(np.argwhere(intersection)))/float(len(np.argwhere(totalArea)))]))\n",
      "\n",
      "            ## compute bbox distance\n",
      "            pairFeats = np.concatenate((pairFeats, [getOverlappingSpriteTracksDistance(trackedSprites[spriteIdxs[0]], trackedSprites[spriteIdxs[1]], np.array([[i], [j]]))[0]]))\n",
      "\n",
      "            allSpritePairsPairFeatures.append(pairFeats)\n",
      "        sys.stdout.write('\\r' + \"Done with row \" + np.string_(i) + \" of \" + np.string_(len(trackedSprites[spriteIdxs[0]][DICT_BBOXES])) + \" added \" + np.string_(len(allSpritePairsPairFeatures)-tmp))\n",
      "        sys.stdout.flush()\n",
      "    \n",
      "    print\n",
      "    print \"done with sprite pair\", spriteIdxs, trackedSprites[spriteIdxs[0]][DICT_SPRITE_NAME], trackedSprites[spriteIdxs[1]][DICT_SPRITE_NAME]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(allSpritePairsPairFeatures[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numFrames = np.array([len(trackedSprites[spriteIdxs[0]][DICT_BBOXES]), len(trackedSprites[spriteIdxs[1]][DICT_BBOXES])])\n",
      "print numFrames\n",
      "visSpritePairsPairFeats = np.zeros((numFrames[0], numFrames[1]))\n",
      "# tmp = list(np.copy(allSpritePairsPairFeatures))\n",
      "# print len(tmp); sys.stdout.flush()\n",
      "# prevStop = 0 \n",
      "for i in xrange(numFrames[0]) :\n",
      "#     print i, numFrames[1], prevStop, prevStop+numFrames[1]\n",
      "#     prevStop += numFrames[1]\n",
      "#     visSpritePairsPairFeats[i, :] = np.sum(np.array(tmp[:numFrames[1]]), axis=-1)\n",
      "#     visSpritePairsPairFeats[i, :] = np.sum(np.array(allSpritePairsPairFeatures[i*numFrames[1]:(i+1)*numFrames[1]]), axis=-1)\n",
      "\n",
      "#     visSpritePairsPairFeats[i, :] = np.sum(np.array(allSpritePairsPairFeatures[i*numFrames[1]:(i+1)*numFrames[1]])[:, :-4], axis=-1)\n",
      "    visSpritePairsPairFeats[i, :] = np.array(allSpritePairsPairFeatures[i*numFrames[1]:(i+1)*numFrames[1]])[:, -1]\n",
      "    \n",
      "#     classifiedCompatibilities[i+1:, i] = regressedDist[i, i+1:]\n",
      "#     del tmp[:numFrames[1]]\n",
      "    sys.stdout.write('\\r' + \"Done with row \" + np.string_(i) + \" of \" + np.string_(numFrames[0]))\n",
      "    sys.stdout.flush()\n",
      "# print len(tmp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(visSpritePairsPairFeats)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## fictitious generated sequence such that white_bus1 and red_car1 clash at frames 1011 and 338 respectively\n",
      "sequenceLength = 1350\n",
      "generatedSequence = {}\n",
      "generatedSequence[0] = np.zeros(sequenceLength, dtype=int)\n",
      "generatedSequence[0][679:679+numFrames[0]+1] = arange(numFrames[0]+1)\n",
      "generatedSequence[3] = np.zeros(sequenceLength, dtype=int)\n",
      "generatedSequence[3][6:6+numFrames[1]+1] = arange(numFrames[1]+1)\n",
      "\n",
      "## user marks pair 338 - 1011 as incompatible but do -1 as frame 0 is the invisible frame\n",
      "incompatiblePair = np.array([338, 1011]) - 1\n",
      "incompatiblePairDist = visSpritePairsPairFeats[incompatiblePair[0], incompatiblePair[1]]\n",
      "pairingsInSequence = np.concatenate((generatedSequence[0].reshape((1, sequenceLength)), generatedSequence[3].reshape((1, sequenceLength))), axis=0)-1\n",
      "pairingsInSequence = pairingsInSequence[:, np.all(pairingsInSequence >= 0, axis=0)]\n",
      "print pairingsInSequence\n",
      "# figure(); plot(visSpritePairsPairFeats[pairingsInSequence[0, :], pairingsInSequence[1, :]] - incompatiblePairDist)\n",
      "# plot(arange(len(pairingsInSequence.T)), zeros(len(pairingsInSequence.T)))\n",
      "\n",
      "## since the distance matrix is filtered I need to get rid of some frames\n",
      "# get rid of first 4 frames\n",
      "validPairingsForDist = np.all(pairingsInSequence >= 4, axis=0) ## 4 is the size of the filter\n",
      "# get rid of last 4 frames\n",
      "validPairingsForDist = np.all((validPairingsForDist, np.all(pairingsInSequence < (numFrames-4).reshape((2, 1)), axis=0)), axis=0) ## 4 is the size of the filter\n",
      "validPairingsIdxs = np.ndarray.flatten(np.argwhere(validPairingsForDist))\n",
      "# print validPairingsForDist\n",
      "pairingsIHaveDistFor = pairingsInSequence[:, validPairingsForDist]-4\n",
      "print pairingsIHaveDistFor\n",
      "\n",
      "## now get distances of overlapping frames to the labelled frames according to their respective distance matrices\n",
      "distsToLabelledFrames = np.zeros(pairingsIHaveDistFor.shape)\n",
      "distsToLabelledFrames[0, :] = spriteDistMats[0][incompatiblePair[0], pairingsIHaveDistFor[0, :]]\n",
      "distsToLabelledFrames[1, :] = spriteDistMats[3][incompatiblePair[1], pairingsIHaveDistFor[1, :]]\n",
      "\n",
      "# figure(); plot(distsToLabelledFrames[0, :])\n",
      "# figure(); plot(distsToLabelledFrames[1, :])\n",
      "# figure(); plot(np.sum(distsToLabelledFrames, axis=0))\n",
      "totalDists = np.sum(distsToLabelledFrames, axis=0)\n",
      "averageDist = np.mean(totalDists)\n",
      "## pairs who's total distance to their respective labelled frames are smaller than some percentage of the mean\n",
      "percentage = 0.9\n",
      "print averageDist*percentage\n",
      "pairsToUseAsCompatible = pairingsInSequence[:, validPairingsIdxs[np.negative(totalDists < averageDist*percentage)]]\n",
      "print pairsToUseAsCompatible.shape\n",
      "# print validPairingsIdxs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 272
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Get labelled pairs and try to learn a distance\n",
      "## 0 = incompatible, 1 = compatible\n",
      "# userLabelledExamples = np.array([[165, 73, 0, 3, 1],\n",
      "#                           [475, 1104, 0, 3, 1],\n",
      "#                           [377, 852, 0, 3, 1],\n",
      "#                           [222, 1139, 0, 3, 1],\n",
      "#                           [340, 1020, 0, 3, 0],\n",
      "#                           [313, 1049, 0, 3, 0],\n",
      "#                           [382, 1000, 0, 3, 0],\n",
      "#                           [332, 1083, 0, 3, 0]])\n",
      "# userLabelledExamples = np.array([[165, 73, 0, 3, 1],\n",
      "#                           [470, 1154, 0, 3, 1],\n",
      "#                           [73, 200, 0, 3, 1],\n",
      "#                           [150, 500, 0, 3, 1],\n",
      "#                           [360, 450, 0, 3, 1],\n",
      "#                           [34, 1210, 0, 3, 1],\n",
      "#                           [340, 1020, 0, 3, 0]])\n",
      "userLabelledExamples = np.array([[337, 1010, 0, 3, 0],\n",
      "                                 [340, 1020, 0, 3, 0]])\n",
      "\n",
      "labelledPairs = np.concatenate((np.concatenate((pairsToUseAsCompatible.T, np.array([[0, 3, 1]]).repeat(len(pairsToUseAsCompatible.T), axis=0)), axis=-1), \n",
      "                                userLabelledExamples), axis=0)\n",
      "\n",
      "labelledData = []\n",
      "for pair in labelledPairs :\n",
      "#     ## L2 DIST\n",
      "#     pairFeats = np.sqrt(np.sum(np.power(allFeats[0][int(pair[0])]-allFeats[0][int(pair[1])],2), axis=-1))\n",
      "    ## ABS DIST\n",
      "    pairFeats = np.sqrt((allFeats[pair[2]][pair[0]]-allFeats[pair[3]][pair[1]])**2)\n",
      "#     ## MEAN\n",
      "#     pairFeats = np.mean(np.hstack((allFeats[0][int(pair[0])], allFeats[0][int(pair[1])])), axis=1)\n",
      "    \n",
      "    ## compute bbox distance\n",
      "    pairFeats = np.concatenate((pairFeats, [getOverlappingSpriteTracksDistance(trackedSprites[pair[2]], trackedSprites[pair[3]], np.array([[pair[0]], [pair[1]]]))[0]]))\n",
      "    \n",
      "    labelledData.append(pairFeats)\n",
      "\n",
      "tic = time.time()\n",
      "try :\n",
      "    del classifier\n",
      "except :\n",
      "    print \"no classifier\"\n",
      "    \n",
      "classifier = ensemble.ExtraTreesClassifier(n_estimators=100, n_jobs=4, verbose=0)#, max_features=None, criterion='entropy')\n",
      "# classifier = svm.LinearSVC()\n",
      "classifier.fit(np.array(labelledData)[:, -4:], list(labelledPairs[:, -1]))\n",
      "print \"classifier trained in\", time.time()-tic; sys.stdout.flush()\n",
      "\n",
      "tic = time.time()\n",
      "compatibilities = classifier.predict(np.array(allSpritePairsPairFeatures)[:, -4:])\n",
      "print \"compatibility found in\", time.time()-tic; sys.stdout.flush()\n",
      "flatCompatibilities = list(np.copy(compatibilities))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 283
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numFrames = np.array([len(trackedSprites[spriteIdxs[0]][DICT_BBOXES]), len(trackedSprites[spriteIdxs[1]][DICT_BBOXES])])\n",
      "print numFrames\n",
      "classifiedCompatibilities = np.zeros((numFrames[0], numFrames[1]))\n",
      "# prevStop = 0 \n",
      "for i in xrange(numFrames[0]) :\n",
      "#     print i, numFrames[1], prevStop, prevStop+numFrames[1]\n",
      "#     prevStop += numFrames[1]\n",
      "    classifiedCompatibilities[i, :] = flatCompatibilities[:numFrames[1]]\n",
      "#     classifiedCompatibilities[i+1:, i] = regressedDist[i, i+1:]\n",
      "    del flatCompatibilities[:numFrames[1]]\n",
      "print len(flatCompatibilities)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 284
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gwv.showCustomGraph(classifiedCompatibilities)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 285
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = cv2.cvtColor(cv2.imread(trackedSprites[0][DICT_FRAMES_LOCATIONS][2094]), cv2.COLOR_BGR2GRAY)\n",
      "contours, h = cv2.findContours(img, mode=cv2.RETR_LIST, method=cv2.CHAIN_APPROX_SIMPLE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 451
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [int32(trackedSprites[0][DICT_BBOXES][np.sort(trackedSprites[0][DICT_BBOXES].keys())[180]]).reshape((4, 1, 2))]\n",
      "print contours"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 472
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blank = np.zeros(img.shape[0:2])\n",
      "img1 = blank.copy()\n",
      "cv2.drawContours(img1, [int32(trackedSprites[0][DICT_BBOXES][np.sort(trackedSprites[0][DICT_BBOXES].keys())[180]]).reshape((4, 1, 2))], 0, 1, cv2.cv.CV_FILLED)\n",
      "img2 = blank.copy()\n",
      "cv2.drawContours(img2, [int32(trackedSprites[0][DICT_BBOXES][np.sort(trackedSprites[0][DICT_BBOXES].keys())[450]]).reshape((4, 1, 2))], 0, 1, cv2.cv.CV_FILLED)\n",
      "intersection = np.logical_and(img1,img2)\n",
      "totalArea = np.logical_or(img1,img2)\n",
      "print len(np.argwhere(intersection)), len(np.argwhere(totalArea))\n",
      "# img2 = blank.copy()\n",
      "# cv2.drawContours(img2,contours, 0, cv2.cv.Scalar(255, 255, 255), cv2.cv.CV_FILLED)\n",
      "# cv2.findContours(\n",
      "# figure(); imshow(totalArea)\n",
      "# print img2\n",
      "# cv2.drawContours("
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 498
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "semData = getSemanticsData(sprite, frameIdx) #getSemanticsData(trackedSprites[0], 450)\n",
      "patchSize = np.array(semData[DATA_MASK].shape)\n",
      "print patchSize\n",
      "allIdxs = -np.ones(patchSize, dtype=int)\n",
      "numRowIdxs = len(np.arange(0, patchSize[0], pixelsPerCell)) - 1\n",
      "numColIdxs = len(np.arange(0, patchSize[1], pixelsPerCell)) - 1\n",
      "print numRowIdxs\n",
      "print numColIdxs\n",
      "gridIdxs = np.arange(numColIdxs, dtype=int).reshape((1, numColIdxs)).repeat(numRowIdxs*pixelsPerCell, axis=0).repeat(pixelsPerCell, axis=-1)\n",
      "gridIdxs += np.arange(numRowIdxs, dtype=int).reshape((numRowIdxs, 1)).repeat(numColIdxs*pixelsPerCell, axis=-1).repeat(pixelsPerCell, axis=0)*numColIdxs\n",
      "allIdxs[:gridIdxs.shape[0], :gridIdxs.shape[1]] = gridIdxs\n",
      "gwv.showCustomGraph(allIdxs)\n",
      "\n",
      "visiblePixels = np.argwhere(semData[DATA_MASK] != 0)\n",
      "print np.unique(allIdxs[visiblePixels[:, 0], visiblePixels[:, 1]])\n",
      "hogsToKeep = np.zeros(numRowIdxs*numColIdxs, dtype=bool)\n",
      "hogsToKeep[np.unique(allIdxs[visiblePixels[:, 0], visiblePixels[:, 1]])] = True\n",
      "print hogsToKeep\n",
      "gwv.showCustomGraph(semData[DATA_MASK])\n",
      "gca().set_autoscale_on(False)\n",
      "scatter(colCoords, rowCoords)\n",
      "scatter(colCoords[hogsToKeep], rowCoords[hogsToKeep], c='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 387
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print visiblePixels.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 362
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rowCoords = np.arange(pixelsPerCell/2, patchSize[0]-pixelsPerCell/2, pixelsPerCell)\n",
      "colCoords = np.arange(pixelsPerCell/2, patchSize[1]-pixelsPerCell/2, pixelsPerCell)\n",
      "\n",
      "cellGridRows = len(rowCoords)#int(np.round(float(patchSize[0]-pixelsPerCell/2)/pixelsPerCell))\n",
      "cellGridCols = len(colCoords)#int(np.round(float(patchSize[1]-pixelsPerCell/2)/pixelsPerCell))\n",
      "\n",
      "rowCoords = rowCoords.reshape((1, cellGridRows)).repeat(cellGridCols)\n",
      "colCoords = np.ndarray.flatten(colCoords.reshape((1, cellGridCols)).repeat(cellGridRows, axis=0))\n",
      "\n",
      "## check which centers are within the mask and only keep those\n",
      "gwv.showCustomGraph(semData[DATA_MASK])\n",
      "gca().set_autoscale_on(False)\n",
      "scatter(colCoords, rowCoords)\n",
      "scatter(colCoords[semData[DATA_MASK][rowCoords, colCoords] != 0], rowCoords[semData[DATA_MASK][rowCoords, colCoords] != 0], c='r')\n",
      "# hogFeats = hogFeats[(semanticsData[DATA_MASK][rowCoords, colCoords] != 0).repeat(hogOrientations)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 386
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print feats.shape[0]/hogOrientations\n",
      "patchSize = np.array([132, 194])\n",
      "cellGridRows = int(np.round(float(patchSize[0]-pixelsPerCell/2)/pixelsPerCell))\n",
      "cellGridCols = int(np.round(float(patchSize[1]-pixelsPerCell/2)/pixelsPerCell))\n",
      "rowCoords = np.arange(pixelsPerCell/2, patchSize[0], pixelsPerCell).reshape((1, cellGridRows)).repeat(cellGridCols)\n",
      "colCoords = np.ndarray.flatten(np.arange(pixelsPerCell/2, patchSize[1], pixelsPerCell).reshape((1, cellGridCols)).repeat(cellGridRows, axis=0))\n",
      "print rowCoords\n",
      "print colCoords\n",
      "\n",
      "figure(); imshow(vis, interpolation='nearest'); gca().set_autoscale_on(False); scatter(colCoords, rowCoords, c='r')\n",
      "figure(); imshow(mask, interpolation='nearest')\n",
      "# ylim(131, 0)\n",
      "# xlim(0, 193)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 171
    }
   ],
   "metadata": {}
  }
 ]
}