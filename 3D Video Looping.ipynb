{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "from __future__ import print_function\n",
    "from matplotlib import cm\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import pyassimp\n",
    "import opengm\n",
    "import cv2\n",
    "from scipy import ndimage as spimg\n",
    "from scipy import special\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn import linear_model\n",
    "\n",
    "from skimage import measure\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "sys.path.append('CMT tracker/')\n",
    "import CMT\n",
    "import triangulate\n",
    "from ICPmatching import icp\n",
    "\n",
    "from PySide import QtGui, QtCore, QtOpenGL\n",
    "from PySide.QtOpenGL import QGLWidget, QGLFormat\n",
    "\n",
    "import OpenGL.GL as gl\n",
    "import OpenGL.arrays.vbo as glvbo\n",
    "import OpenGL.GL.EXT.texture_filter_anisotropic as tfa\n",
    "from PIL import Image\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "app = QtGui.QApplication(sys.argv)\n",
    "\n",
    "DICT_SEQUENCE_NAME = 'semantic_sequence_name'\n",
    "DICT_BBOXES = 'bboxes'\n",
    "DICT_FOOTPRINTS = 'footprints' ## same as bboxes but it indicates the footprint of the sprite on the ground plane\n",
    "DICT_BBOX_ROTATIONS = 'bbox_rotations'\n",
    "DICT_BBOX_CENTERS = 'bbox_centers'\n",
    "DICT_FRAMES_LOCATIONS = 'frame_locs'\n",
    "DICT_MASK_LOCATION = 'frame_masks_location'\n",
    "DICT_ICON_TOP_LEFT = \"icon_top_left\"\n",
    "DICT_ICON_FRAME_KEY = \"icon_frame_key\"\n",
    "DICT_ICON_SIZE = \"icon_size\"\n",
    "DICT_REPRESENTATIVE_COLOR = 'representative_color'\n",
    "DICT_FRAME_SEMANTICS = \"semantics_per_frame\"\n",
    "DICT_NUM_SEMANTICS = \"number_of_semantic_classes\"\n",
    "DICT_PATCHES_LOCATION = \"sequence_preloaded_patches_location\"\n",
    "DICT_TRANSITION_COSTS_LOCATION = \"sequence_precomputed_transition_costs_location\"\n",
    "# DICT_FRAME_COMPATIBILITY_LABELS = 'compatibiliy_labels_per_frame'\n",
    "DICT_LABELLED_FRAMES = 'labelled_frames' ## includes the frames labelled for the semantic labels (the first [DICT_FRAME_SEMANTICS].shape[1])\n",
    "DICT_NUM_EXTRA_FRAMES = 'num_extra_frames' ## same len as DICT_LABELLED_FRAMES\n",
    "DICT_CONFLICTING_SEQUENCES = 'conflicting_sequences'\n",
    "DICT_DISTANCE_MATRIX_LOCATION = 'sequence_precomputed_distance_matrix_location' ## for label propagation\n",
    "DICT_SEQUENCE_LOCATION = \"sequence_location\"\n",
    "\n",
    "DICT_FILMED_DATASET_BASE_LOC = 'filmed_dataset_base_location'\n",
    "\n",
    "DICT_FILMED_OBJECT_NAME = 'filmed_object_name'\n",
    "DICT_TRAJECTORY_POINTS = 'trajectory_points'\n",
    "DICT_NEEDS_UNDISTORT = 'do_undistort_trajectory_points'\n",
    "DICT_OBJECT_BILLBOARD_ORIENTATION = 'object_color_billboard_orientation_angle'\n",
    "DICT_OBJECT_BILLBOARD_SCALE = 'object_color_bilboard_scale'\n",
    "DICT_TRACK_LOCATION='track_points_location'\n",
    "\n",
    "DICT_FILMED_SCENE_BASE_LOC = 'filmed_scene_base_location'\n",
    "DICT_CAMERA_EXTRINSICS = 'camera_extrinsics'\n",
    "DICT_CAMERA_INTRINSICS = 'camera_intrinsics'\n",
    "DICT_DISTORTION_PARAMETER = 'distortion_parameter'\n",
    "DICT_DISTORTION_RATIO = 'distortion_ratio'\n",
    "DICT_DOWNSAMPLED_FRAMES_RATE = 'downsampled_frames_rate'\n",
    "DICT_COMMENTS = \"comments_and_info\"\n",
    "DICT_GROUND_MESH_POINTS = 'camera_ground_plane_mesh_points'\n",
    "DICT_GROUND_MESH_SEGS_EXTRUDE = 'ground_plane_mesh_segments_to_extrude'\n",
    "DICT_OBJECT_LENGTH = 'object_bounding_volume_length'\n",
    "DICT_OBJECT_WIDTH = 'object_bounding_volume_width'\n",
    "DICT_OBJECT_HEIGHT = 'object_bounding_volume_height'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## compute euclidean distance assuming f is an array where each row is a flattened image (1xN array, N=W*H*Channels)\n",
    "## euclidean distance defined as the length of the the displacement vector:\n",
    "## len(q-p) = sqrt(len(q)^2+len(p)^2 - 2*dot(p, q)) where p and q are two images in vector format and 1xN size\n",
    "def ssd(f) :\n",
    "    ## gives sum over squared intensity values for each image\n",
    "    ff = np.sum(f*f, axis=1)\n",
    "    ## first term is sum between each possible combination of frames\n",
    "    ## second term is the the dot product between each frame as in the formula above\n",
    "    d = np.reshape(ff, [len(ff),1])+ff.T - 2*np.dot(f, f.T)\n",
    "    return d\n",
    "\n",
    "def ssd2(f1, f2) :\n",
    "    ## gives sum over squared intensity values for each image\n",
    "    ff1 = np.sum(f1*f1, axis=1)\n",
    "    ff2 = np.sum(f2*f2, axis=1)\n",
    "#     print ff1.shape\n",
    "#     print ff2.shape\n",
    "    ## first term is sum between each possible combination of frames\n",
    "    ## second term is the the dot product between each frame as in the formula above\n",
    "#     print \"askdfh\", np.repeat(np.reshape(ff1, [len(ff1),1]), len(ff2), axis=1).shape, np.repeat(np.reshape(ff2, [1, len(ff2)]), len(ff1), axis=0).shape\n",
    "    d = np.repeat(np.reshape(ff1, [len(ff1),1]), len(ff2), axis=1)+np.repeat(np.reshape(ff2, [1, len(ff2)]), len(ff1), axis=0) - 2*np.dot(f1, f2.T)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compile_vertex_shader(source):\n",
    "    \"\"\"Compile a vertex shader from source.\"\"\"\n",
    "    vertex_shader = gl.glCreateShader(gl.GL_VERTEX_SHADER)\n",
    "    gl.glShaderSource(vertex_shader, source)\n",
    "    gl.glCompileShader(vertex_shader)\n",
    "    # check compilation error\n",
    "    result = gl.glGetShaderiv(vertex_shader, gl.GL_COMPILE_STATUS)\n",
    "    if not(result):\n",
    "        raise RuntimeError(gl.glGetShaderInfoLog(vertex_shader))\n",
    "    return vertex_shader\n",
    "\n",
    "def compile_fragment_shader(source):\n",
    "    \"\"\"Compile a fragment shader from source.\"\"\"\n",
    "    fragment_shader = gl.glCreateShader(gl.GL_FRAGMENT_SHADER)\n",
    "    gl.glShaderSource(fragment_shader, source)\n",
    "    gl.glCompileShader(fragment_shader)\n",
    "    # check compilation error\n",
    "    result = gl.glGetShaderiv(fragment_shader, gl.GL_COMPILE_STATUS)\n",
    "    if not(result):\n",
    "        raise RuntimeError(gl.glGetShaderInfoLog(fragment_shader))\n",
    "    return fragment_shader\n",
    "\n",
    "def link_shader_program(vertex_shader, fragment_shader):\n",
    "    \"\"\"Create a shader program from compiled shaders.\"\"\"\n",
    "    program = gl.glCreateProgram()\n",
    "    gl.glAttachShader(program, vertex_shader)\n",
    "    gl.glAttachShader(program, fragment_shader)\n",
    "    gl.glLinkProgram(program)\n",
    "    # check linking error\n",
    "    result = gl.glGetProgramiv(program, gl.GL_LINK_STATUS)\n",
    "    if not(result):\n",
    "        raise RuntimeError(gl.glGetProgramInfoLog(program))\n",
    "    return program\n",
    "\n",
    "def compileShaders(vs, fs) :\n",
    "    # compile the vertex shader\n",
    "    try :\n",
    "        compiledVS = compile_vertex_shader(vs)\n",
    "    except Exception as e :\n",
    "        print(\"VS COMPILE ERROR:\", e.message, file=sys.stderr)\n",
    "        sys.stderr.flush()\n",
    "    # compile the fragment shader\n",
    "    try :\n",
    "        compiledFS = compile_fragment_shader(fs)\n",
    "    except Exception as e :\n",
    "        print(\"FS COMPILE ERROR:\", e.message, file=sys.stderr)\n",
    "        sys.stderr.flush()\n",
    "    # link shader program\n",
    "    try :\n",
    "        return link_shader_program(compiledVS, compiledFS)\n",
    "    except Exception as e :\n",
    "        print(\"LINK PROGRAM ERROR:\", e.message, file=sys.stderr)\n",
    "        sys.stderr.flush()\n",
    "\n",
    "# Vertex shader\n",
    "VS_HEAD_LIGHT = \"\"\"\n",
    "#version 330\n",
    "// Attribute variable that contains coordinates of the vertices.\n",
    "layout(location = 0) in vec3 position_model;\n",
    "layout(location = 1) in vec2 uv_model;\n",
    "layout(location = 2) in vec3 normal_model;\n",
    "layout(location = 3) in vec3 barycentric_model;\n",
    "\n",
    "// the data to be sent to the fragment shader\n",
    "out Data {\n",
    "    vec2 uv_model;\n",
    "    vec3 position_world;\n",
    "    vec3 normal_camera;\n",
    "    vec3 eye_camera;\n",
    "    vec3 l_dir_camera;\n",
    "    vec3 barycentric_model;\n",
    "} DataOut;\n",
    "\n",
    "uniform mat4 m_pvm;\n",
    "uniform mat4 m_m;\n",
    "uniform mat4 m_v;\n",
    "uniform vec3 l_pos_world;\n",
    "\n",
    "// Main function, which needs to set `gl_Position`.\n",
    "void main()\n",
    "{\n",
    "    gl_Position = m_pvm * vec4(position_model, 1.0);\n",
    "\n",
    "    DataOut.position_world = (m_m * vec4(position_model, 1.0)).xyz;\n",
    "\n",
    "    vec3 position_camera = (m_v * vec4(DataOut.position_world, 1.0)).xyz;\n",
    "    DataOut.eye_camera = -position_camera;\n",
    "\n",
    "    vec3 l_pos_camera = (m_v * vec4(l_pos_world,1.0)).xyz;\n",
    "    DataOut.l_dir_camera = l_pos_camera - position_camera;\n",
    "\n",
    "    DataOut.normal_camera = (m_v * m_m * vec4(normal_model, 0.0)).xyz; // Only correct if ModelMatrix does not scale the model ! Use its inverse transpose if not.\n",
    "\n",
    "    DataOut.uv_model = uv_model;\n",
    "    DataOut.barycentric_model = barycentric_model;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Fragment shader\n",
    "FS_HEAD_LIGHT = \"\"\"\n",
    "#version 330\n",
    "\n",
    "uniform vec4 diffuse_m;\n",
    "uniform vec4 ambient_m;\n",
    "uniform vec4 specular_m;\n",
    "uniform float shininess_m;\n",
    "\n",
    "uniform vec3 l_pos_world;\n",
    "uniform vec3 l_color;\n",
    "uniform float l_power;\n",
    "uniform bool show_edges;\n",
    "\n",
    "// the data received from the vertex shader\n",
    "in Data {\n",
    "    vec2 uv_model;\n",
    "    vec3 position_world;\n",
    "    vec3 normal_camera;\n",
    "    vec3 eye_camera;\n",
    "    vec3 l_dir_camera;\n",
    "    vec3 barycentric_model;\n",
    "} DataIn;\n",
    "\n",
    "out vec4 out_color;\n",
    "\n",
    "float edgeFactor()\n",
    "{\n",
    "    vec3 d = fwidth(DataIn.barycentric_model);\n",
    "    vec3 a3 = smoothstep(vec3(0.0), d*1.0, DataIn.barycentric_model);\n",
    "    return min(min(a3.x, a3.y), a3.z);\n",
    "}\n",
    "\n",
    "// Main fragment shader function.\n",
    "void main()\n",
    "{\n",
    "    float distance = length(l_pos_world - DataIn.position_world);\n",
    "\n",
    "    vec3 n = normalize(DataIn.normal_camera);\n",
    "    vec3 l = normalize(DataIn.l_dir_camera);\n",
    "    float cosTheta = clamp(dot(n,l), 0.0, 1.0);\n",
    "\n",
    "    vec3 e = normalize(DataIn.eye_camera);\n",
    "    vec3 r = reflect(-l, n);\n",
    "    float cosAlpha = clamp(dot(e,r), 0.0, 1.0);\n",
    "    \n",
    "    vec4 shading_color = ambient_m +\n",
    "                         diffuse_m*vec4(l_color, 1.0)*l_power*cosTheta +//(distance*distance) + \n",
    "                         specular_m*vec4(l_color, 1.0)*l_power*pow(cosAlpha,shininess_m);//(distance*distance);\n",
    "    \n",
    "    if (show_edges) {\n",
    "        out_color.xyz = mix(vec3(0.0), shading_color.xyz, edgeFactor());\n",
    "    }\n",
    "    else {\n",
    "        out_color = shading_color;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Vertex shader\n",
    "VS_DIR_LIGHT = \"\"\"\n",
    "#version 330\n",
    "\n",
    "layout(location = 0) in vec3 position_model;\n",
    "layout(location = 1) in vec2 uv_model;\n",
    "layout(location = 2) in vec3 normal_model;\n",
    "layout(location = 3) in vec3 barycentric_model;\n",
    "\n",
    "uniform mat4 m_pvm;\n",
    "uniform mat4 m_m;\n",
    "uniform mat4 m_v;\n",
    "\n",
    "// the data to be sent to the fragment shader\n",
    "out Data {\n",
    "    vec3 normal_camera;\n",
    "    vec4 eye_camera;\n",
    "    vec3 barycentric_model;\n",
    "} DataOut;\n",
    "\n",
    "void main () {\n",
    "\n",
    "    DataOut.normal_camera = normalize(m_v * m_m * vec4(normal_model, 0.0)).xyz;\n",
    "    DataOut.eye_camera = vec4(-(m_v * m_m * vec4(position_model, 1.0)).xyz, 1.0);\n",
    "\n",
    "    gl_Position = m_pvm * vec4(position_model, 1.0);\n",
    "    \n",
    "    DataOut.barycentric_model = barycentric_model;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Fragment shader\n",
    "FS_DIR_LIGHT = \"\"\"\n",
    "#version 330\n",
    "\n",
    "uniform vec4 diffuse_m;\n",
    "uniform vec4 ambient_m;\n",
    "uniform vec4 specular_m;\n",
    "uniform float shininess_m;\n",
    "\n",
    "uniform vec3 l_dir;\n",
    "uniform vec3 l_color;\n",
    "uniform float l_power;\n",
    "uniform bool show_edges;\n",
    "\n",
    "in Data {\n",
    "    vec3 normal_camera;\n",
    "    vec4 eye_camera;\n",
    "    vec3 barycentric_model;\n",
    "} DataIn;\n",
    "\n",
    "out vec4 out_color;\n",
    "\n",
    "float edgeFactor()\n",
    "{\n",
    "    vec3 d = fwidth(DataIn.barycentric_model);\n",
    "    vec3 a3 = smoothstep(vec3(0.0), d*1.0, DataIn.barycentric_model);\n",
    "    return min(min(a3.x, a3.y), a3.z);\n",
    "}\n",
    "\n",
    "void main() {\n",
    "    // set the specular term to black\n",
    "    vec4 spec = vec4(0.0);\n",
    "\n",
    "    // normalize both input vectors\n",
    "    vec3 n = normalize(DataIn.normal_camera);\n",
    "    vec3 e = normalize(vec3(DataIn.eye_camera));\n",
    "\n",
    "    float intensity = max(dot(n,l_dir), 0.0);\n",
    "\n",
    "    // if the vertex is lit compute the specular color\n",
    "    if (intensity > 0.0) {\n",
    "        // compute the half vector\n",
    "        vec3 h = normalize(l_dir + e);\n",
    "        // compute the specular term into spec\n",
    "        float intSpec = max(dot(h,n), 0.0);\n",
    "        spec = specular_m * pow(intSpec,shininess_m);\n",
    "    }\n",
    "    vec4 shading_color = max((intensity * diffuse_m + spec)*vec4(l_color, 1.0)*l_power, ambient_m);\n",
    "    \n",
    "    if (show_edges) {\n",
    "        out_color.xyz = mix(vec3(0.0), shading_color.xyz, edgeFactor());\n",
    "    }\n",
    "    else {\n",
    "        out_color = shading_color;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Vertex shader\n",
    "VS_COLOR_NO_SHADE = \"\"\"\n",
    "#version 330\n",
    "\n",
    "layout(location = 0) in vec3 position_model;\n",
    "layout(location = 1) in vec3 color;\n",
    "\n",
    "uniform mat4 m_pvm;\n",
    "uniform float camera_dist;\n",
    "\n",
    "out Data {\n",
    "    vec3 color;\n",
    "} DataOut;\n",
    "\n",
    "void main () {\n",
    "    gl_Position = m_pvm * vec4(position_model*camera_dist, 1.0);\n",
    "    DataOut.color = color;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Fragment shader\n",
    "FS_COLOR_NO_SHADE = \"\"\"\n",
    "#version 330\n",
    "\n",
    "out vec4 out_color;\n",
    "\n",
    "in Data {\n",
    "    vec3 color;\n",
    "} DataIn;\n",
    "\n",
    "void main() {\n",
    "    out_color = vec4(DataIn.color, 1.0);\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Vertex shader\n",
    "VS_IMAGE = \"\"\"\n",
    "#version 330\n",
    "\n",
    "layout(location = 0) in vec3 position_model;\n",
    "layout(location = 1) in vec2 uv_model;\n",
    "\n",
    "uniform mat4 m_pvm;\n",
    "uniform mat4 m_v;\n",
    "\n",
    "out Data {\n",
    "    vec2 uv_model;\n",
    "} DataOut;\n",
    "\n",
    "void main () {\n",
    "    gl_Position = m_pvm * vec4(position_model, 1.0);\n",
    "    DataOut.uv_model = uv_model;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Fragment shader\n",
    "FS_IMAGE = \"\"\"\n",
    "#version 330\n",
    "\n",
    "uniform sampler2D texture_sampler;\n",
    "\n",
    "out vec4 out_color;\n",
    "\n",
    "in Data {\n",
    "    vec2 uv_model;\n",
    "} DataIn;\n",
    "\n",
    "void main() {\n",
    "    out_color = texture(texture_sampler, DataIn.uv_model);\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Vertex shader\n",
    "VS_PROJECTIVE = \"\"\"\n",
    "#version 330\n",
    "\n",
    "layout(location = 0) in vec3 position_model;\n",
    "\n",
    "uniform mat4 m_pvm;\n",
    "uniform mat4 m_proj_mat;\n",
    "\n",
    "out Data {\n",
    "    vec4 vertex_proj;\n",
    "} DataOut;\n",
    "\n",
    "void main () {\n",
    "    gl_Position = m_pvm * vec4(position_model, 1.0);\n",
    "    DataOut.vertex_proj = m_proj_mat * vec4(position_model, 1.0);\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Fragment shader\n",
    "FS_PROJECTIVE = \"\"\"\n",
    "#version 330\n",
    "\n",
    "uniform sampler2D texture_sampler;\n",
    "\n",
    "out vec4 out_color;\n",
    "\n",
    "in Data {\n",
    "    vec4 vertex_proj;\n",
    "} DataIn;\n",
    "\n",
    "void main() {\n",
    "    vec2 uv_model;\n",
    "    uv_model.x = (DataIn.vertex_proj.x/DataIn.vertex_proj.w+1.0)/2.0;\n",
    "    uv_model.y = (-DataIn.vertex_proj.y/DataIn.vertex_proj.w+1.0)/2.0;\n",
    "    if(uv_model.x >= 0.0 && uv_model.x <= 1.0 && uv_model.y >= 0.0 && uv_model.y <= 1.0) {\n",
    "        out_color = texture(texture_sampler, uv_model);\n",
    "    }\n",
    "    //else {\n",
    "    //    out_color = vec4(1, 1, 1, 0);\n",
    "    //}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readObj(lines) :\n",
    "    vertices = []\n",
    "    uvs = []\n",
    "    normals = []\n",
    "    faces = []\n",
    "    barycentrics = np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]], np.float32)\n",
    "    for line in lines.split(\"\\n\") :\n",
    "        elements = line.split(\" \")\n",
    "        if elements[0] == \"v\" :\n",
    "            vertices.append(np.array(elements[1:]).astype(np.float32))\n",
    "        elif elements[0] == \"vt\" :\n",
    "            uvs.append(np.array(elements[1:]).astype(np.float32))\n",
    "        elif elements[0] == \"vn\" :\n",
    "            normals.append(np.array(elements[1:]).astype(np.float32))\n",
    "        elif elements[0] == \"f\" :\n",
    "            faces.append(np.empty(0, np.int32))\n",
    "            for i, element in enumerate(elements[1:]) :\n",
    "                faces[-1] = np.concatenate([faces[-1], np.concatenate([np.array(element.split(\"/\")), [i+1]]).astype(np.int32)])\n",
    "    return np.array(vertices), np.array(uvs), np.array(normals), np.array(faces), barycentrics\n",
    "    \n",
    "def reIndexTriangleMesh(vertices, uvs, normals, faces, barycentrics) :\n",
    "    indices_per_vertex = faces.shape[1]/3\n",
    "    in_indices = faces.reshape([len(faces)*3, indices_per_vertex])\n",
    "    kept_indices = np.empty([0, indices_per_vertex], np.uint32)\n",
    "    out_vertices = np.empty([0, vertices.shape[1]], vertices.dtype)\n",
    "    out_uvs = np.empty([0, uvs.shape[1]], uvs.dtype)\n",
    "    out_normals = np.empty([0, normals.shape[1]], normals.dtype)\n",
    "    out_barycentrics = np.empty([0, barycentrics.shape[1]], barycentrics.dtype)\n",
    "    out_indices = np.empty(0, in_indices.dtype)\n",
    "    \n",
    "    for i in xrange(len(in_indices)):\n",
    "        in_index = in_indices[i].reshape([1, indices_per_vertex])\n",
    "        mapDiffs = np.sqrt(np.sum((kept_indices-in_index)**2, axis=1))\n",
    "        if np.any(mapDiffs == 0) :\n",
    "            out_indices = np.concatenate([out_indices, [np.int32(int(np.argwhere(mapDiffs == 0)))]])\n",
    "            continue\n",
    "        kept_indices = np.concatenate([kept_indices, in_index])\n",
    "        in_index = np.copy(in_index)-1\n",
    "        out_vertices = np.concatenate([out_vertices, vertices[in_index[0, 0], :].reshape([1, out_vertices.shape[1]])])\n",
    "        out_uvs = np.concatenate([out_uvs, uvs[in_index[0, 1], :].reshape([1, out_uvs.shape[1]])])\n",
    "        out_normals = np.concatenate([out_normals, normals[in_index[0, 2], :].reshape([1, out_normals.shape[1]])])\n",
    "        out_barycentrics = np.concatenate([out_barycentrics, barycentrics[in_index[0, 3], :].reshape([1, out_barycentrics.shape[1]])])\n",
    "        out_indices = np.concatenate([out_indices, [np.int32(len(kept_indices))-np.int32(1)]])\n",
    "        \n",
    "    \n",
    "    return out_vertices, out_uvs, out_normals, out_barycentrics, out_indices\n",
    "\n",
    "# with open(\"../data/cube.obj\") as objFile :\n",
    "#     objlines = objFile.read()\n",
    "#     a, b, c, d, e = reIndexTriangleMesh(*readObj(objlines))\n",
    "#     print(a.shape)\n",
    "#     print(b.shape)\n",
    "#     print(c.shape)\n",
    "#     print(d.shape)\n",
    "#     print(e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getWorldSpacePosAndNorm(transform, normDirEnd= np.array([[0.0], [0.0], [1.0], [1.0]]), posOnly=False) :\n",
    "    pos = np.dot(transform, np.array([[0.0], [0.0], [0.0], [1.0]])).T\n",
    "    pos = pos[0, :3]/pos[0, 3]\n",
    "    if posOnly :\n",
    "        return pos\n",
    "    norm = np.dot(transform, normDirEnd).T\n",
    "    norm = norm[0, :3]/norm[0, 3]\n",
    "    norm -= pos\n",
    "    norm /= np.linalg.norm(norm)\n",
    "    \n",
    "    return pos, norm\n",
    "\n",
    "def quaternionTo4x4Rotation(quaternion, inverted=False):\n",
    "    x, y, z, w = quaternion\n",
    "    ## quaternion rotation\n",
    "    M = np.array([[1.0 - 2.0*(y**2) - 2.0*(z**2), 2*x*y + 2*w*z, 2*x*z - 2*w*y, 0.0],\n",
    "                  [2*x*y - 2*w*z, 1.0 - 2.0*(x**2) - 2.0*(z**2), 2*y*z + 2*w*x, 0.0],\n",
    "                  [2*x*z + 2*w*y, 2*y*z - 2*w*x, 1.0 - 2.0*(x**2) - 2.0*(y**2), 0.0],\n",
    "                  [0.0, 0.0, 0.0, 1.0]])\n",
    "    ## invert it\n",
    "    if inverted :\n",
    "        M[:-1, :-1] = M[:-1, :-1].T\n",
    "        \n",
    "    return M\n",
    "\n",
    "def angleAxisToQuaternion(angle, axis) :\n",
    "    return np.array([axis[0]*np.sin(angle/2.0), axis[1]*np.sin(angle/2.0), axis[2]*np.sin(angle/2.0), np.cos(angle/2.0)])\n",
    "\n",
    "def rotateAboutPoint(matrix, quaternion, centerPoint) :\n",
    "    M = quaternionTo4x4Rotation(quaternion)\n",
    "    T = np.array([[1.0, 0.0, 0.0, centerPoint[0]],\n",
    "                  [0.0, 1.0, 0.0, centerPoint[1]],\n",
    "                  [0.0, 0.0, 1.0, centerPoint[2]],\n",
    "                  [0.0, 0.0, 0.0, 1.0]])\n",
    "    \n",
    "    return np.dot(T, np.dot(M, np.dot(np.linalg.inv(T), matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDistortionCoeffFromParamAndRatio(distortionParameter, distortionRatio) :\n",
    "    return np.array([distortionParameter, distortionParameter*distortionRatio, 0.0, 0.0, 0.0])\n",
    "    \n",
    "def undistortImage(distortionParameter, distortionRatio, image, cameraIntrinsics, doUncrop=True, interpolation=cv2.INTER_LANCZOS4, doReturnMaps=True) :\n",
    "    distortionCoeff = getDistortionCoeffFromParamAndRatio(distortionParameter, distortionRatio)\n",
    "    \n",
    "    frameSize = np.array([image.shape[1], image.shape[0]])\n",
    "\n",
    "    ## undistort image\n",
    "    if doUncrop :\n",
    "        ## here I was just making the image I project the undistorted pixels to bigger\n",
    "#         sizeDelta = 0.3\n",
    "#         newFrameSize = (frameSize*(1+sizeDelta)).astype(int)\n",
    "#         newIntrinsics = np.copy(cameraIntrinsics)\n",
    "#         newIntrinsics[0, 2] += image.shape[1]*sizeDelta/2.0\n",
    "#         newIntrinsics[1, 2] += image.shape[0]*sizeDelta/2.0\n",
    "        ## here I instead use opencv to figure out the best new camera matrix that includes all possible pixels\n",
    "        newIntrinsics = cv2.getOptimalNewCameraMatrix(cameraIntrinsics, distortionCoeff, tuple(frameSize), 1)[0]\n",
    "        ## the above tends to change the camera center in different way and giving x and y focals different values\n",
    "        ## so I scale the center to match the old intrinsics and the corresponding focals which should bring them to be the same\n",
    "        newIntrinsics[0, [0, 2]] *= cameraIntrinsics[0, 2]/newIntrinsics[0, 2]\n",
    "        newIntrinsics[1, [1, 2]] *= cameraIntrinsics[1, 2]/newIntrinsics[1, 2]\n",
    "        ## the above, changes the focal length to see the full scene, but I want to keep focal length and have a bigger image instead, so I change the intrinsics to get the original focal length but bigger image\n",
    "        scale = np.average([cameraIntrinsics[0, 0]/newIntrinsics[0, 0], cameraIntrinsics[1, 1]/newIntrinsics[1, 1]])\n",
    "        newFrameSize = np.ceil(np.copy(frameSize)*scale).astype(int)\n",
    "        newIntrinsics[0, 0] = cameraIntrinsics[0, 0]\n",
    "        newIntrinsics[1, 1] = cameraIntrinsics[1, 1]\n",
    "        ## I want the camera center to be a full number and the new frame size to be divisible by two\n",
    "        newIntrinsics[:-1, -1] = np.ceil(newFrameSize/2.0)\n",
    "        newFrameSize = np.array(newIntrinsics[:-1, -1]*2, dtype=int)\n",
    "    else :\n",
    "        newIntrinsics = np.copy(cameraIntrinsics)\n",
    "        newFrameSize = np.copy(frameSize)\n",
    "    \n",
    "    map1, map2 = cv2.initUndistortRectifyMap(cameraIntrinsics, distortionCoeff, None, newIntrinsics, tuple(newFrameSize), cv2.CV_32FC1)\n",
    "    undistortedImage = cv2.remap(image, map1, map2, interpolation)\n",
    "    if doReturnMaps :\n",
    "        return undistortedImage, newIntrinsics, distortionCoeff, map1, map2\n",
    "    else :\n",
    "        return undistortedImage, newIntrinsics, distortionCoeff\n",
    "    \n",
    "\n",
    "def line2lineIntersection(line1, line2) :\n",
    "    \"\"\"x1, y1, x2, y2 = line1\n",
    "       x3, y3, x4, y4 = line2\"\"\"\n",
    "    \n",
    "    x1, y1, x2, y2 = line1\n",
    "    x3, y3, x4, y4 = line2\n",
    "    denominator = (x1-x2)*(y3-y4)-(y1-y2)*(x3-x4)\n",
    "    if denominator != 0 :\n",
    "        Px = ((x1*y2-y1*x2)*(x3-x4)-(x1-x2)*(x3*y4-y3*x4))/denominator\n",
    "        Py = ((x1*y2-y1*x2)*(y3-y4)-(y1-y2)*(x3*y4-y3*x4))/denominator\n",
    "        return np.array([Px, Py])\n",
    "    else :\n",
    "        raise RuntimeError(\"lines are parallel\")\n",
    "\n",
    "def isABetweenBandC(a, b, c):\n",
    "    distAB = np.linalg.norm(a-b)\n",
    "    distAC = np.linalg.norm(a-c)\n",
    "    distBC = np.linalg.norm(b-c)\n",
    "    return np.abs(distAB+distAC-distBC) < 1e-10\n",
    "        \n",
    "def cvCameraToOpenGL(cameraExtrinsics, cameraIntrinsics, imageShape) :\n",
    "    \"\"\" return viewMat, projectionMat \"\"\"\n",
    "    \n",
    "    viewMat = np.copy(cameraExtrinsics)\n",
    "    ## flip z and y axis because of opencv vs opengl coord systems\n",
    "    viewMat[2, :] *= -1\n",
    "    viewMat[1, :] *= -1\n",
    "\n",
    "    K = np.copy(cameraIntrinsics)\n",
    "    ## changing signs for the same reason as above for the viewMat\n",
    "    K[:, 2] *= -1\n",
    "    K[:, 1] *= -1\n",
    "    near = 0.1\n",
    "    far = 100.0\n",
    "    projectionMat = np.zeros([4, 4])\n",
    "    projectionMat[:2, :-1] = K[:2, :]\n",
    "    projectionMat[-1, :-1] = K[-1, :]\n",
    "    projectionMat[2, 2] = near + far\n",
    "    projectionMat[2, 3] = near*far\n",
    "\n",
    "    left = 0.0\n",
    "    right = float(imageShape[1])\n",
    "    bottom = float(imageShape[0])\n",
    "    top = 0.0\n",
    "\n",
    "    projectionMat = np.dot(np.array([[2/(right-left), 0, 0, -(right+left)/(right-left)],\n",
    "                                     [0, 2/(top-bottom), 0, -(top+bottom)/(top-bottom)],\n",
    "                                     [0, 0, -2/(far-near), -(far+near)/(far-near)],\n",
    "                                     [0, 0, 0, 1]]), np.copy(projectionMat))\n",
    "    return viewMat, projectionMat\n",
    "\n",
    "def worldToScreenSpace(viewMat, projectionMat, worldSpacePoint, viewportWidth, viewportHeight) :\n",
    "    \"\"\"worldSpacePoint can be either a vector of length 3 or it can be a matrix Nx3\"\"\"\n",
    "    if len(worldSpacePoint.shape) == 1 :\n",
    "        worldSpacePoints = np.reshape(worldSpacePoint, [1, 3])\n",
    "    else :\n",
    "        worldSpacePoints = worldSpacePoint\n",
    "    \n",
    "    screenSpacePoints = np.dot(np.dot(projectionMat, viewMat), np.hstack([worldSpacePoints, np.ones([len(worldSpacePoints), 1])]).T)\n",
    "    screenSpacePoints = screenSpacePoints[:-1, :]/screenSpacePoints[-1, :]\n",
    "    screenSpacePoints = screenSpacePoints.T\n",
    "    \n",
    "    ## from clip space to screen space\n",
    "    screenSpacePoints = np.hstack([((screenSpacePoints[:, 0]+1.0)*viewportWidth/2.0)[:, np.newaxis], \n",
    "                                   ((1.0-screenSpacePoints[:, 1])*viewportHeight/2.0)[:, np.newaxis]])\n",
    "    \n",
    "    if len(worldSpacePoint.shape) == 1 :\n",
    "        return screenSpacePoints.flatten()\n",
    "    else :\n",
    "        return screenSpacePoints\n",
    "\n",
    "def triangulate2DPolygon(poly2D, doReturnIndices=True) :\n",
    "    pts = [(point[0], point[1]) for point in poly2D]\n",
    "    availableIndices = np.ones(len(pts), dtype=bool)\n",
    "    tris = []\n",
    "    plist = pts[::-1] if triangulate.IsClockwise(pts) else pts[:]\n",
    "    while len(plist) >= 3:\n",
    "        a = triangulate.GetEar(plist, np.arange(len(pts), dtype=int), availableIndices, doReturnIndices)\n",
    "        if a == []:\n",
    "            break\n",
    "        if doReturnIndices :\n",
    "            if triangulate.IsClockwise(pts) :\n",
    "                tris.append([len(pts)-1-a[0], len(pts)-1-a[1], len(pts)-1-a[2]])\n",
    "            else :\n",
    "                tris.append(list(a))\n",
    "        else :\n",
    "            tris.append(a)\n",
    "            \n",
    "    return tris\n",
    "\n",
    "def extrudeSegment(points, height, viewLoc, doReturnIndexedVertices=True) :\n",
    "    inputVertices = np.vstack([points, points[::-1, :]+np.array([0.0, 0.0, height])])\n",
    "    outputIndices = [0, 1, 3, 1, 2, 3]\n",
    "    \n",
    "    ## check that the triangle is front facing --> https://www.scratchapixel.com/lessons/3d-basic-rendering/ray-tracing-rendering-a-triangle/single-vs-double-sided-triangle-backface-culling\n",
    "    vertices = inputVertices[outputIndices[:3], :]\n",
    "    N = np.cross(vertices[1, :]-vertices[0, :], vertices[2, :]-vertices[0, :])\n",
    "    N /= np.linalg.norm(N)\n",
    "    viewDir = vertices[0, :]-viewLoc\n",
    "    viewDir /= np.linalg.norm(viewDir)\n",
    "    \n",
    "    ## it is back-facing so need to reverse dir\n",
    "    if np.dot(viewDir, N) > 0 :\n",
    "        outputIndices[0], outputIndices[1] = outputIndices[1], outputIndices[0]\n",
    "        outputIndices[3], outputIndices[4] = outputIndices[4], outputIndices[3]\n",
    "        \n",
    "    if doReturnIndexedVertices :\n",
    "        return inputVertices[outputIndices, :], outputIndices\n",
    "    else :\n",
    "        return inputVertices, outputIndices\n",
    "\n",
    "def isPoint2DInTriangle2D(point2D, triangle2D) :\n",
    "    ## formulas from here http://mathworld.wolfram.com/TriangleInterior.html\n",
    "    v = point2D\n",
    "    v0 = triangle2D[0, :]\n",
    "    v1 = triangle2D[1, :]-v0\n",
    "    v2 = triangle2D[2, :]-v0\n",
    "    \n",
    "    vv2 = np.hstack([v.reshape([2, 1]), v2.reshape([2, 1])])\n",
    "    v0v2 = np.hstack([v0.reshape([2, 1]), v2.reshape([2, 1])])\n",
    "    v1v2 = np.hstack([v1.reshape([2, 1]), v2.reshape([2, 1])])\n",
    "    vv1 = np.hstack([v.reshape([2, 1]), v1.reshape([2, 1])])\n",
    "    v0v1 = np.hstack([v0.reshape([2, 1]), v1.reshape([2, 1])])\n",
    "    \n",
    "    a = (np.linalg.det(vv2)-np.linalg.det(v0v2))/np.linalg.det(v1v2)\n",
    "    b = -(np.linalg.det(vv1)-np.linalg.det(v0v1))/np.linalg.det(v1v2)\n",
    "    \n",
    "    return a > 0 and b > 0 and (a+b) < 1\n",
    "\n",
    "def getGridPointsInPolygon2D(polygon2D, gridSpacing) :\n",
    "    triangles = np.array(triangulate2DPolygon(polygon2D, False))\n",
    "    minBounds = ((np.min(polygon2D, axis=0)>0)*2-1)*np.ceil(np.abs(np.min(polygon2D, axis=0)))\n",
    "    maxBounds = ((np.max(polygon2D, axis=0)>0)*2-1)*np.ceil(np.abs(np.max(polygon2D, axis=0)))\n",
    "\n",
    "    gridPoints = np.mgrid[minBounds[0]:maxBounds[0]+gridSpacing:gridSpacing, minBounds[1]:maxBounds[1]+gridSpacing:gridSpacing]\n",
    "    gridPoints = gridPoints.reshape([2, gridPoints.shape[1]*gridPoints.shape[2]]).T\n",
    "    \n",
    "    validPoints = []\n",
    "    for pointIdx, point in enumerate(gridPoints) :\n",
    "        for triangle in triangles :\n",
    "            if isPoint2DInTriangle2D(point, triangle) :\n",
    "                validPoints.append(pointIdx)\n",
    "                break\n",
    "    return gridPoints[validPoints, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def smoothTrajectory(filterSize, trajectory) :\n",
    "    sigma = filterSize/5.0 #1.2 #2.5\n",
    "    coeff = special.binom(filterSize*2, range(0, filterSize*2 +1))\n",
    "    coeff /= np.sum(coeff)\n",
    "    neighbourIdxs = np.arange(-filterSize, filterSize+1)\n",
    "#     print(coeff, neighbourIdxs)\n",
    "    \n",
    "#     smoothed = np.array([np.convolve(trajectory[:, 0], coeff, mode='valid'),\n",
    "#                          np.convolve(trajectory[:, 1], coeff, mode='valid')]).T.astype(np.float32)\n",
    "    smoothed = np.zeros_like(trajectory)\n",
    "    \n",
    "    for i, point in enumerate(trajectory) :\n",
    "        validIdxs = np.all(np.array([i+neighbourIdxs >= 0, i+neighbourIdxs < len(trajectory)]), axis=0)\n",
    "        closenessToEdge = filterSize*2+1-len(np.argwhere(validIdxs).flatten())\n",
    "        filterCoeffs = coeff**np.exp(closenessToEdge/sigma)\n",
    "        filterCoeffs /= np.sum(filterCoeffs)\n",
    "#         print(i, point, i+neighbourIdxs[validIdxs], closenessToEdge, np.exp(closenessToEdge/sigma), np.round(filterCoeffs, decimals=2)[validIdxs])\n",
    "#         print(np.sum(trajectory[i+neighbourIdxs[validIdxs]]*filterCoeffs[validIdxs].reshape([len(np.argwhere(validIdxs).flatten()), 1]), axis=0))\n",
    "        smoothed[i, :] = np.sum(trajectory[i+neighbourIdxs[validIdxs]]*filterCoeffs[validIdxs].reshape([len(np.argwhere(validIdxs).flatten()), 1]), axis=0)\n",
    "    \n",
    "    return smoothed#[filterSize:-filterSize]\n",
    "\n",
    "# smoothedTrajectory = smoothTrajectory(15, trajectoryPoints)\n",
    "\n",
    "# figure()\n",
    "# imshow(medianImage)\n",
    "# xlim([0, medianImage.shape[1]])\n",
    "# ylim([medianImage.shape[0], 0])\n",
    "# # xlim([510, 1510])\n",
    "# # ylim([760, 460])\n",
    "# scatter(trajectoryPoints[:, 0], trajectoryPoints[:, 1], marker='o', color='blue', facecolors='none')\n",
    "# scatter(smoothedTrajectory[:, 0], smoothedTrajectory[:, 1], marker='x', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ImageLabel(QtGui.QLabel) :\n",
    "    \n",
    "    def __init__(self, text, parent=None):\n",
    "        super(ImageLabel, self).__init__(text, parent)\n",
    "        \n",
    "        self.setMouseTracking(True)\n",
    "        \n",
    "        self.image = None\n",
    "        self.qImage = None\n",
    "        self.bbox = None\n",
    "        self.bboxColor = [0, 255, 255, 255]\n",
    "        \n",
    "    def setImage(self, image) :\n",
    "        if image is not None :\n",
    "            self.image = np.ascontiguousarray(image.copy())\n",
    "            if self.width() != self.image.shape[1] or self.height() != self.image.shape[0] :\n",
    "                self.setFixedSize(self.image.shape[1], self.image.shape[0])\n",
    "            self.qImage = QtGui.QImage(self.image.data, self.image.shape[1], self.image.shape[0], self.image.strides[0], QtGui.QImage.Format_RGB888);\n",
    "            self.update()\n",
    "        else :\n",
    "            self.image = None\n",
    "            self.qImage = None\n",
    "            \n",
    "    def setBBox(self, bbox, bboxColor) :\n",
    "        if bbox is not None :\n",
    "            self.bbox = bbox\n",
    "            self.bboxColor = bboxColor\n",
    "            self.update()\n",
    "        else :\n",
    "            self.bbox = None\n",
    "            self.bboxColor = [0, 255, 255, 255]\n",
    "        \n",
    "    def paintEvent(self, event):\n",
    "        super(ImageLabel, self).paintEvent(event)\n",
    "        painter = QtGui.QPainter(self)\n",
    "        if self.qImage is not None :\n",
    "            painter.drawImage(QtCore.QPoint(0, 0), self.qImage)\n",
    "            \n",
    "        if self.bbox is not None :\n",
    "            painter.setPen(QtGui.QPen(QtGui.QColor.fromRgb(self.bboxColor[0], self.bboxColor[1], self.bboxColor[2], self.bboxColor[3]), 3, \n",
    "                                              QtCore.Qt.SolidLine, QtCore.Qt.SquareCap, QtCore.Qt.MiterJoin))\n",
    "            \n",
    "            painter.drawRect(QtCore.QRectF(self.bbox[0], self.bbox[1], self.bbox[2], self.bbox[3]))\n",
    "            \n",
    "            \n",
    "            painter.drawPoint(QtCore.QPointF(self.bbox[0]+self.bbox[2]/2.0, self.bbox[1]+self.bbox[3]/2.0))\n",
    "            \n",
    "        painter.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GLMaterial() :\n",
    "    def __init__(self) :\n",
    "        self.diffuseComponent = np.array([0.6, 0.6, 0.6, 1.0], np.float32)\n",
    "        self.ambientComponent = np.array([0.06, 0.06, 0.06, 1.0], np.float32)\n",
    "        self.specularComponent = np.array([0.2, 0.2, 0.2, 1.0], np.float32)\n",
    "        self.shininess = np.float32(5.0)\n",
    "    \n",
    "    ## not sure this actually cleans up properly\n",
    "    def __del__(self) :\n",
    "        del self.diffuseComponent, self.ambientComponent, self.specularComponent, self.shininess\n",
    "        \n",
    "class AxesWidget() :\n",
    "    def __init__(self) :\n",
    "        arrowLength = 0.12\n",
    "        arrowSpacing = 0.0 #arrowLength*0.2\n",
    "        self.arrowBodyVerticesBuffer = glvbo.VBO(np.array([[arrowSpacing, 0.0, 0.0], [arrowLength, 0.0, 0.0],\n",
    "                                                           [0.0, arrowSpacing, 0.0], [0.0, arrowLength, 0.0],\n",
    "                                                           [0.0, 0.0, arrowSpacing], [0.0, 0.0, arrowLength]], np.float32), gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        self.arrowBodyColorsBuffer = glvbo.VBO(np.array([[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0]], np.float32), gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        self.arrowBodyIndexBuffer = glvbo.VBO(np.array([0, 1, 2, 3, 4, 5], np.int32), gl.GL_STATIC_DRAW, gl.GL_ELEMENT_ARRAY_BUFFER)\n",
    "        \n",
    "        self.initDone = False\n",
    "        \n",
    "        arrowMesh = pyassimp.load(\"arrowTop.obj\").meshes[0]\n",
    "        inputVertices = arrowMesh.vertices.astype(np.float32)*np.float32(0.65)\n",
    "        verticesArray = np.concatenate([np.dot(inputVertices, np.array([[np.cos(np.pi/2.0), -np.sin(np.pi/2.0), 0.0],\n",
    "                                                                        [np.sin(np.pi/2.0), np.cos(np.pi/2.0), 0.0], [0.0, 0.0, 1.0]], np.float32))+np.array([arrowLength, 0.0, 0.0], np.float32),  #### X arrow\n",
    "                                        inputVertices+np.array([0.0, arrowLength, 0.0], np.float32),                                                                                                #### Y arrow\n",
    "                                        np.dot(inputVertices, np.array([[1.0, 0.0, 0.0], [0.0, np.cos(-np.pi/2.0), -np.sin(-np.pi/2.0)],\n",
    "                                                                        [0.0, np.sin(-np.pi/2.0), np.cos(-np.pi/2.0)]], np.float32))+np.array([0.0, 0.0, arrowLength], np.float32)],                #### Z arrow\n",
    "                                       axis = 0)\n",
    "        \n",
    "        colorArray = np.zeros([3*len(arrowMesh.vertices), 3], np.float32)\n",
    "        colorArray[:len(arrowMesh.vertices), 0] = np.float32(1.0)                          #### X arrow\n",
    "        colorArray[len(arrowMesh.vertices):2*len(arrowMesh.vertices), 1] = np.float32(1.0) #### Y arrow\n",
    "        colorArray[2*len(arrowMesh.vertices):, 2] = np.float32(1.0)                        #### Z arrow\n",
    "        \n",
    "        indicesArray = np.concatenate([arrowMesh.faces.flatten().astype(np.int32),                              #### X arrow\n",
    "                                       arrowMesh.faces.flatten().astype(np.int32)+len(arrowMesh.vertices),      #### Y arrow\n",
    "                                       arrowMesh.faces.flatten().astype(np.int32)+2*len(arrowMesh.vertices)])   #### Z arrow\n",
    "        \n",
    "        self.arrowVerticesBuffer = glvbo.VBO(verticesArray.astype(np.float32), gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        self.arrowColorsBuffer = glvbo.VBO(colorArray.astype(np.float32), gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        self.arrowIndexBuffer = glvbo.VBO(indicesArray.astype(np.int32), gl.GL_STATIC_DRAW, gl.GL_ELEMENT_ARRAY_BUFFER)\n",
    "        self.numIndices = len(indicesArray)\n",
    "        \n",
    "    def setShaders(self) :\n",
    "        self.shaders_program = compileShaders(VS_COLOR_NO_SHADE, FS_COLOR_NO_SHADE)\n",
    "        if self.shaders_program is None :\n",
    "            self.initDone = False\n",
    "            return\n",
    "        self.initDone = True\n",
    "        \n",
    "    def draw(self, cameraDist, pvm) :\n",
    "#         self.setShaders()\n",
    "        if self.initDone :\n",
    "            gl.glClear(gl.GL_DEPTH_BUFFER_BIT)\n",
    "            \n",
    "            gl.glUseProgram(self.shaders_program)\n",
    "            \n",
    "            ## send mvp\n",
    "            gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.shaders_program, \"m_pvm\"), 1, gl.GL_FALSE, pvm.T)\n",
    "            ## send camera distance\n",
    "            gl.glUniform1f(gl.glGetUniformLocation(self.shaders_program, \"camera_dist\"), cameraDist)\n",
    "#             print(cameraDist)\n",
    "\n",
    "            ################ RENDER BODY ################\n",
    "    \n",
    "            ## bind the index buffer\n",
    "            self.arrowBodyIndexBuffer.bind()\n",
    "\n",
    "            ## bind the VBO with vertex data\n",
    "            self.arrowBodyVerticesBuffer.bind()\n",
    "            gl.glEnableVertexAttribArray(0)\n",
    "            # tell OpenGL that the VBO contains an array of vertices\n",
    "            # these vertices contain 3 single precision coordinates\n",
    "            gl.glVertexAttribPointer(0, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "            \n",
    "            ## bind the VBO with color data\n",
    "            self.arrowBodyColorsBuffer.bind()\n",
    "            gl.glEnableVertexAttribArray(1)\n",
    "            gl.glVertexAttribPointer(1, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "            ## draw points from the VBO\n",
    "            gl.glDrawElements(gl.GL_LINES, 6, gl.GL_UNSIGNED_INT, None)\n",
    "\n",
    "            ## clean up\n",
    "            gl.glDisableVertexAttribArray(0)\n",
    "            gl.glDisableVertexAttribArray(1)\n",
    "\n",
    "            ################ RENDER ARROWS ################\n",
    "            \n",
    "            ## bind the index buffer\n",
    "            self.arrowIndexBuffer.bind()\n",
    "\n",
    "            ## bind the VBO with vertex data\n",
    "            self.arrowVerticesBuffer.bind()\n",
    "            gl.glEnableVertexAttribArray(0)\n",
    "            # tell OpenGL that the VBO contains an array of vertices\n",
    "            # these vertices contain 3 single precision coordinates\n",
    "            gl.glVertexAttribPointer(0, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "            \n",
    "            ## bind the VBO with color data\n",
    "            self.arrowColorsBuffer.bind()\n",
    "            gl.glEnableVertexAttribArray(1)\n",
    "            gl.glVertexAttribPointer(1, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "            ## draw points from the VBO\n",
    "            gl.glDrawElements(gl.GL_TRIANGLES, self.numIndices, gl.GL_UNSIGNED_INT, None)\n",
    "\n",
    "            ## clean up\n",
    "            gl.glDisableVertexAttribArray(0)\n",
    "            gl.glDisableVertexAttribArray(1)\n",
    "\n",
    "\n",
    "            gl.glUseProgram(0)\n",
    "\n",
    "class GLMesh() :\n",
    "    def __init__(self, mesh, shaders_program) :\n",
    "        self.modelMat = np.eye(4, dtype=np.float32)\n",
    "        self.material = GLMaterial()\n",
    "        self.shaders_program = shaders_program\n",
    "        self.indices = []\n",
    "        self.vertices = []\n",
    "        \n",
    "        if len(mesh.faces) == 0 and len(mesh.vertices) == 0 :\n",
    "            self.isInvalidMesh = True\n",
    "            self.invalidMeshMessage = \"No Faces or Vertices\"\n",
    "        elif len(mesh.faces) > 0 and len(mesh.vertices) == 0 :\n",
    "            self.isInvalidMesh = True\n",
    "            self.invalidMeshMessage = \"No Vertices even though there are Faces\"\n",
    "        else :\n",
    "            if len(mesh.normals) == 0 :\n",
    "                self.isInvalidMesh = True\n",
    "                self.invalidMeshMessage = \"No Normals\"\n",
    "            else :\n",
    "                self.isInvalidMesh = False\n",
    "                self.invalidMeshMessage = \"\"\n",
    "\n",
    "                if len(mesh.faces) > 0 :\n",
    "                    self.barycentrics = np.array([[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]], np.float32).repeat(len(mesh.faces), axis=0).flatten().reshape([len(mesh.faces.flatten()), 3])\n",
    "                    self.indices = mesh.faces.flatten().astype(np.int32)\n",
    "                    if len(mesh.texturecoords) > 0 :\n",
    "                        self.uvs = mesh.texturecoords.astype(np.float32)\n",
    "                    else :\n",
    "                        self.uvs = np.zeros([len(self.indices), 2], np.float32)\n",
    "                        \n",
    "                    self.indexBuffer = glvbo.VBO(self.indices, gl.GL_STATIC_DRAW, gl.GL_ELEMENT_ARRAY_BUFFER)\n",
    "                    self.barycentricsBuffer = glvbo.VBO(self.barycentrics, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "                    self.uvsBuffer = glvbo.VBO(self.uvs, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "                else :\n",
    "                    self.barycentrics = []\n",
    "                    self.indices = []\n",
    "                    self.uvs = []\n",
    "\n",
    "                self.vertices = mesh.vertices.astype(np.float32)\n",
    "                self.verticesBuffer = glvbo.VBO(self.vertices, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "\n",
    "                self.normals = mesh.normals.astype(np.float32)\n",
    "                self.normalsBuffer = glvbo.VBO(self.normals, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "\n",
    "    ## not sure this actually cleans up properly\n",
    "    def __del__(self) :\n",
    "        del self.material, self.vertices, self.uvs, self.normals, self.barycentrics, self.indices\n",
    "        \n",
    "    def draw(self, projectionMat, viewMat) :\n",
    "        if self.shaders_program != 0 :\n",
    "            if len(self.indices) > 0 :\n",
    "                gl.glUseProgram(self.shaders_program)\n",
    "                \n",
    "                ## send mvp\n",
    "                gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.shaders_program, \"m_pvm\"), 1, gl.GL_FALSE, np.dot(projectionMat, np.dot(viewMat, self.modelMat)).T)\n",
    "                ## send model\n",
    "                gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.shaders_program, \"m_m\"), 1, gl.GL_FALSE, self.modelMat.T)\n",
    "\n",
    "                # send material data\n",
    "                gl.glUniform4fv(gl.glGetUniformLocation(self.shaders_program, \"diffuse_m\"), 1, self.material.diffuseComponent)\n",
    "                gl.glUniform4fv(gl.glGetUniformLocation(self.shaders_program, \"ambient_m\"), 1, self.material.ambientComponent)\n",
    "                gl.glUniform4fv(gl.glGetUniformLocation(self.shaders_program, \"specular_m\"), 1, self.material.specularComponent)\n",
    "                gl.glUniform1f(gl.glGetUniformLocation(self.shaders_program, \"shininess_m\"), self.material.shininess)\n",
    "\n",
    "                ## bind the index buffer\n",
    "                self.indexBuffer.bind()\n",
    "\n",
    "                ## bind the VBO with vertex data\n",
    "                self.verticesBuffer.bind()\n",
    "                gl.glEnableVertexAttribArray(0)\n",
    "                # tell OpenGL that the VBO contains an array of vertices\n",
    "                # these vertices contain 3 single precision coordinates\n",
    "                gl.glVertexAttribPointer(0, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "                ## bind the VBO with uv data\n",
    "                self.uvsBuffer.bind()\n",
    "                gl.glEnableVertexAttribArray(1)\n",
    "                gl.glVertexAttribPointer(1, 2, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "                ## bind the VBO with normal data\n",
    "                self.normalsBuffer.bind()\n",
    "                gl.glEnableVertexAttribArray(2)\n",
    "                gl.glVertexAttribPointer(2, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "                ## bind the VBO with barycentrics data\n",
    "                self.barycentricsBuffer.bind()\n",
    "                gl.glEnableVertexAttribArray(3)\n",
    "                gl.glVertexAttribPointer(3, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "                ## draw points from the VBO\n",
    "                gl.glDrawElements(gl.GL_TRIANGLES, len(self.indices), gl.GL_UNSIGNED_INT, None)\n",
    "\n",
    "                ## clean up\n",
    "                gl.glDisableVertexAttribArray(0)\n",
    "                gl.glDisableVertexAttribArray(1)\n",
    "                gl.glDisableVertexAttribArray(2)\n",
    "                gl.glDisableVertexAttribArray(3)\n",
    "\n",
    "                gl.glUseProgram(0)\n",
    "            else :\n",
    "                print(\"SHOULD BE RENDERING POINT CLOUD\", file=sys.stderr)\n",
    "                \n",
    "class GLPolyline() :\n",
    "    def __init__(self, points, drawColor=np.array([0, 255.0, 0])) :\n",
    "        self.initDone = False\n",
    "        \n",
    "        self.drawColor = drawColor\n",
    "        self.points = np.copy(points)\n",
    "        \n",
    "        self.setGeometryAndBuffers()\n",
    "        \n",
    "    def __del__(self) :\n",
    "        del self.points\n",
    "        \n",
    "    def setShaders(self) :\n",
    "        self.shaders_program = compileShaders(VS_COLOR_NO_SHADE, FS_COLOR_NO_SHADE)\n",
    "        if self.shaders_program is None :\n",
    "            self.initDone = False\n",
    "            return\n",
    "        self.initDone = True\n",
    "        \n",
    "    def setGeometryAndBuffers(self) :\n",
    "        self.indices = np.concatenate([[0], np.arange(1, len(self.points)-1).repeat(2), [len(self.points)-1]]).astype(np.int32)\n",
    "        self.indexBuffer = glvbo.VBO(self.indices, gl.GL_STATIC_DRAW, gl.GL_ELEMENT_ARRAY_BUFFER)\n",
    "        self.verticesBuffer = glvbo.VBO(self.points, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "#         if np.sum(self.drawColor - np.array([0, 255, 255])) == 0 :\n",
    "#             print(self.points, self.indices)\n",
    "        colorArray = np.repeat(np.array([self.drawColor], np.float32)/np.float32(255.0), len(self.points), 0)\n",
    "        self.colorBuffer = glvbo.VBO(colorArray, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        \n",
    "    def draw(self, pvm) :\n",
    "        if self.initDone :\n",
    "            gl.glUseProgram(self.shaders_program)\n",
    "            \n",
    "            ## send mvp\n",
    "            gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.shaders_program, \"m_pvm\"), 1, gl.GL_FALSE, pvm.T)\n",
    "            ## send camera distance\n",
    "            gl.glUniform1f(gl.glGetUniformLocation(self.shaders_program, \"camera_dist\"), np.float32(1.0))\n",
    "#             print(cameraDist)\n",
    "\n",
    "            ################ RENDER BODY ################\n",
    "    \n",
    "            ## bind the index buffer\n",
    "            self.indexBuffer.bind()\n",
    "\n",
    "            ## bind the VBO with vertex data\n",
    "            self.verticesBuffer.bind()\n",
    "            gl.glEnableVertexAttribArray(0)\n",
    "            # tell OpenGL that the VBO contains an array of vertices\n",
    "            # these vertices contain 3 single precision coordinates\n",
    "            gl.glVertexAttribPointer(0, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "            \n",
    "            ## bind the VBO with color data\n",
    "            self.colorBuffer.bind()\n",
    "            gl.glEnableVertexAttribArray(1)\n",
    "            gl.glVertexAttribPointer(1, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "            ## draw points from the VBO\n",
    "            gl.glDrawElements(gl.GL_LINES, len(self.indices), gl.GL_UNSIGNED_INT, None)\n",
    "#             gl.glDrawElements(gl.GL_POINTS, len(self.indices), gl.GL_UNSIGNED_INT, None)\n",
    "\n",
    "            ## clean up\n",
    "            gl.glDisableVertexAttribArray(0)\n",
    "            gl.glDisableVertexAttribArray(1)\n",
    "\n",
    "            gl.glUseProgram(0)\n",
    " \n",
    "                \n",
    "class GLTrajectory() :\n",
    "    def __init__(self, cameraTrajectoryPoints, cameraIntrinsics, cameraExtrinsics, drawColor=np.array([0, 255.0, 0]), doDrawProjectedPoints = True, doSmoothing = True) :\n",
    "        self.initDone = False\n",
    "        \n",
    "        self.doSmoothing = doSmoothing\n",
    "        self.trajectorySmoothness = 5\n",
    "        self.cameraTrajectoryPoints = cameraTrajectoryPoints.astype(np.float32)\n",
    "        self.worldTrajectoryPoints = np.empty([0, 3], np.float32)\n",
    "        self.worldTrajectoryDirections = np.empty([0, 3], np.float32)\n",
    "        self.cameraIntrinsics = cameraIntrinsics.astype(np.float32)\n",
    "        self.cameraExtrinsics = cameraExtrinsics.astype(np.float32)\n",
    "        self.drawColor = drawColor\n",
    "        \n",
    "        self.projectPoints()\n",
    "\n",
    "        if doDrawProjectedPoints :\n",
    "            pointsToDraw = np.copy(self.worldTrajectoryPoints)\n",
    "#             if len(pointsToDraw) > 10 :\n",
    "#                 global tmpTrajPoints\n",
    "#                 tmpTrajPoints = np.copy(pointsToDraw)\n",
    "        else :\n",
    "# #             pointsToDraw = np.copy(self.cameraTrajectoryPoints)\n",
    "#             pointsToDraw = np.dot(np.linalg.inv(cameraIntrinsics), np.concatenate([self.cameraTrajectoryPoints, np.ones([len(self.cameraTrajectoryPoints), 1])], axis=1).T)\n",
    "#             pointsToDraw = (pointsToDraw[:-1, :]/pointsToDraw[-1, :]).T\n",
    "# #             pointsToDraw[:, 0] *= (self.cameraIntrinsics[1, -1]/self.cameraIntrinsics[0, -1])\n",
    "#             print(\"README BITCH\", self.cameraTrajectoryPoints[-1, :])\n",
    "            width, height = self.cameraIntrinsics[:-1, -1]*2\n",
    "            pointsToDraw = np.copy(self.cameraTrajectoryPoints).astype(np.float32)\n",
    "            ## make points between -0.5 and 0.5\n",
    "            pointsToDraw -= np.array([[width/2.0, height/2.0]], np.float32)\n",
    "            pointsToDraw /= np.array([[width, height]], np.float32)\n",
    "            ## scale x-axis to get same aspect ratio as input image\n",
    "            pointsToDraw[:, 0] *= np.float32(width/height)\n",
    "            pointsToDraw = np.concatenate([pointsToDraw, np.zeros([len(pointsToDraw), 1], dtype=np.float32)], axis=1)\n",
    "            \n",
    "        self.polyline = GLPolyline(pointsToDraw, drawColor)\n",
    "        \n",
    "    def __del__(self) :\n",
    "        del self.cameraTrajectoryPoints, self.worldTrajectoryPoints, self.cameraIntrinsics, self.cameraExtrinsics, self.worldTrajectoryDirections, self.polyline\n",
    "        \n",
    "        \n",
    "    def projectPoints(self) :\n",
    "        if True :\n",
    "            inverseT = np.linalg.inv(np.dot(self.cameraIntrinsics, self.cameraExtrinsics[:-1, [0, 1, 3]]))\n",
    "            self.worldTrajectoryPoints = np.dot(inverseT, np.concatenate([self.cameraTrajectoryPoints, np.ones([len(self.cameraTrajectoryPoints), 1], np.float32)], axis=1).T)\n",
    "            self.worldTrajectoryPoints /= self.worldTrajectoryPoints[-1, :]\n",
    "            self.worldTrajectoryPoints[-1, :] = 0\n",
    "            self.worldTrajectoryPoints = self.worldTrajectoryPoints.T.astype(np.float32)\n",
    "        else :\n",
    "            ### HACK : USE HOMOGRAPHY INSTEAD OF CAMERA MATRICES ###\n",
    "            homography = np.array([[11.6261525276, 185.257281938, 818.145590521],\n",
    "                                   [-24.7005245641, 14.5276400234, 272.499203107],\n",
    "                                   [-0.197073111956, 0.178268418299, 1.0]])\n",
    "            self.worldTrajectoryPoints = np.dot(np.linalg.inv(homography), np.concatenate([self.cameraTrajectoryPoints, np.ones([len(self.cameraTrajectoryPoints), 1], np.float32)], axis=1).T)\n",
    "            self.worldTrajectoryPoints /= self.worldTrajectoryPoints[-1, :]\n",
    "            self.worldTrajectoryPoints[-1, :] = 0\n",
    "            self.worldTrajectoryPoints = self.worldTrajectoryPoints.T.astype(np.float32)\n",
    "        \n",
    "        if self.doSmoothing :\n",
    "            ## add a bunch of points at the beginning and end of worldTrjectoryPoints so that the beginning and end points don't deviate massively from the original value\n",
    "#             extraPoints = 15\n",
    "#             self.worldTrajectoryPoints = np.concatenate([self.worldTrajectoryPoints[0, :].reshape([1, 3]).repeat(15, axis=0),\n",
    "#                                                          self.worldTrajectoryPoints,\n",
    "#                                                          self.worldTrajectoryPoints[-1, :].reshape([1, 3]).repeat(15, axis=0)], axis=0)\n",
    "            \n",
    "#             ## smooth trajectory\n",
    "#             self.worldTrajectoryPoints = np.array([spimg.filters.gaussian_filter1d(self.worldTrajectoryPoints[:, 0], self.trajectorySmoothness, axis=0, mode='nearest'),\n",
    "#                                                    spimg.filters.gaussian_filter1d(self.worldTrajectoryPoints[:, 1], self.trajectorySmoothness, axis=0, mode='nearest'),\n",
    "#                                                    spimg.filters.gaussian_filter1d(self.worldTrajectoryPoints[:, 2], self.trajectorySmoothness, axis=0, mode='nearest')]).T.astype(np.float32)[extraPoints:-extraPoints, :]\n",
    "            \n",
    "            self.worldTrajectoryPoints = smoothTrajectory(15, self.worldTrajectoryPoints)\n",
    "\n",
    "            ## reproject points into image space after smoothing\n",
    "            T = np.dot(self.cameraIntrinsics, self.cameraExtrinsics[:-1, [0, 1, 3]])\n",
    "            self.cameraTrajectoryPoints = np.dot(T, np.concatenate([self.worldTrajectoryPoints[:, :-1], np.ones([len(self.worldTrajectoryPoints), 1])], axis=1).T)\n",
    "            self.cameraTrajectoryPoints = (self.cameraTrajectoryPoints[:-1, :]/self.cameraTrajectoryPoints[-1, :]).T\n",
    "            \n",
    "#             print(self.camera)\n",
    "\n",
    "        self.worldTrajectoryDirections = np.array([self.worldTrajectoryPoints[i, :]-self.worldTrajectoryPoints[j, :] for i, j in zip(xrange(1, len(self.worldTrajectoryPoints)),\n",
    "                                                                                                                                     xrange(0, len(self.worldTrajectoryPoints)-1))])\n",
    "        self.worldTrajectoryDirections = np.vstack([self.worldTrajectoryDirections, self.worldTrajectoryDirections[-1, :].reshape([1, self.worldTrajectoryDirections.shape[-1]])])\n",
    "        self.worldTrajectoryDirections /= np.linalg.norm(self.worldTrajectoryDirections, axis=1).reshape([len(self.worldTrajectoryDirections), 1])\n",
    "        for i in xrange(len(self.worldTrajectoryDirections)) :\n",
    "            if np.linalg.norm(self.worldTrajectoryDirections[i, :]) != 1.0 and i > 0 :\n",
    "                self.worldTrajectoryDirections[i, :] = self.worldTrajectoryDirections[i-1, :]\n",
    "        \n",
    "        if len(self.worldTrajectoryPoints) > 10 :\n",
    "            np.save(\"tmp_trajectory_3D.npy\", {\"trajectoryPointsCameraSpace\":self.cameraTrajectoryPoints, \"trajectoryPointsWorldSpace\":self.worldTrajectoryPoints, \n",
    "                                              \"trajectoryDirectionsWorldSpace\":self.worldTrajectoryDirections, \"intrinsics\":self.cameraIntrinsics, \"extrinsics\":self.cameraExtrinsics})\n",
    "        \n",
    "    def setShaders(self) :\n",
    "        self.polyline.setShaders()\n",
    "        self.initDone = True\n",
    "        \n",
    "    def draw(self, pvm) :\n",
    "        if self.initDone :\n",
    "            self.polyline.draw(pvm)\n",
    "\n",
    "class GLBillboard() :\n",
    "    def __init__(self, img, scale, modelMat=np.eye(4, dtype=np.float32), isFrontoParallel = False, rotateAboutPlaneNormal = None, normalizeToPixelSize = False) :\n",
    "        self.initDone = False\n",
    "        self.textureChanged = False\n",
    "        self.pixelSize = 0.01\n",
    "        \n",
    "        self.scale = scale\n",
    "        self.isFrontoParallel = isFrontoParallel\n",
    "        self.doRotateAboutPlaneNormal = rotateAboutPlaneNormal is not None\n",
    "        self.rotateAboutPlaneNormal = np.copy(rotateAboutPlaneNormal)\n",
    "        self.normalizeToPixelSize = normalizeToPixelSize\n",
    "        self.modelMat = np.copy(modelMat)\n",
    "        if self.isFrontoParallel or self.doRotateAboutPlaneNormal :\n",
    "            ## remove any rotations as it won't work if it has rotations\n",
    "            self.modelMat[:-1, :-1] = np.eye(3, dtype=np.float32)            \n",
    "        \n",
    "        self.setTexture(img)\n",
    "        self.setGeometryAndBuffers()\n",
    "        \n",
    "    def __del__(self) :\n",
    "        del self.tex, self.vertices, self.indices, self.uvs\n",
    "        \n",
    "    def setScale(self, scale) :\n",
    "        self.scale = scale\n",
    "        self.setGeometryAndBuffers()\n",
    "        \n",
    "    def setTexture(self, img) :\n",
    "        possibleTexSizes = np.array([128, 256, 512, 1024, 2048])\n",
    "        texSize = possibleTexSizes[np.argwhere(possibleTexSizes-np.max(img.shape[0:2]) >= 0).flatten()[0]]\n",
    "        self.tex = np.zeros([texSize, texSize, 4], np.int8)\n",
    "        self.tex[:img.shape[0], :img.shape[1], :img.shape[2]] = img\n",
    "        ## set alpha channel if inout image is just rgb\n",
    "        if False or img.shape[2] == 3 :\n",
    "            self.tex[:img.shape[0], :img.shape[1], -1] = np.int8(255)\n",
    "            \n",
    "        self.textureChanged = True\n",
    "        [self.maxV, self.maxU] = np.array(img.shape[:2], np.float32)/np.array(self.tex.shape[:2], np.float32)\n",
    "        self.aspectRatio = float(img.shape[1])/float(img.shape[0])\n",
    "        \n",
    "        ## sets scale of the billboard so that it compensates for the size of the texture it shows in such a way that pixels have the same size in the same viewport\n",
    "        ## (without this, the scale of the billboard is fixed so that bigger textures are pasted onto the same billboard and therefore look smaller than smaller textures)\n",
    "        if self.normalizeToPixelSize :\n",
    "#             self.scale = self.pixelSize*img.shape[1]\n",
    "            top, left, width, height = gl.glGetIntegerv(gl.GL_VIEWPORT)\n",
    "#             print(top, left, width, height)\n",
    "            ## the idea here is that I want the ratio of the patch width to the width of the image it comes from, to be the same as the ratio of the viewport width to the width of the same image\n",
    "            ## I know that the height is always 1 and the width is defined wrt it which is why I'm computing this wrt the width\n",
    "            self.scale = float(img.shape[1])/float(1280)*5.36229266*(width/1280.0)\n",
    "            #self.scale = 1.0#float(img.shape[1])/float(1280)*1.0*(width/1280.0)\n",
    "#             print(\"POOP\", img.shape[0], height, height/float(img.shape[0]), self.scale, 2.0*self.scale, )\n",
    "        \n",
    "        self.setGeometryAndBuffers()\n",
    "        \n",
    "    def setGeometryAndBuffers(self) :\n",
    "        ## IMAGE PLANE ##\n",
    "        self.vertices = np.dot(np.array([[self.scale, 0, 0],\n",
    "                                         [0, self.scale, 0],\n",
    "                                         [0, 0, 1.0]], np.float32),\n",
    "                               np.array([[self.aspectRatio/2.0, -0.5, 0.0], [self.aspectRatio/2.0, 0.5, 0.0], [-self.aspectRatio/2.0, -0.5, 0.0],\n",
    "                                         [self.aspectRatio/2.0, 0.5, 0.0], [-self.aspectRatio/2.0, 0.5, 0.0], [-self.aspectRatio/2.0, -0.5, 0.0]], np.float32).T).T\n",
    "        self.indices = np.array([0, 1, 2, 3, 4, 5], np.int32)\n",
    "        self.uvs = np.array([[self.maxU, self.maxV], [self.maxU, 0.0], [0.0, self.maxV],\n",
    "                             [self.maxU, 0.0], [0.0, 0.0], [0.0, self.maxV]], np.float32)\n",
    "\n",
    "        self.verticesBuffer = glvbo.VBO(self.vertices, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        self.indexBuffer = glvbo.VBO(self.indices, gl.GL_STATIC_DRAW, gl.GL_ELEMENT_ARRAY_BUFFER)\n",
    "        self.uvsBuffer = glvbo.VBO(self.uvs, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        \n",
    "    def setShaders(self) :\n",
    "        self.texturedGeometryShadersProgram = compileShaders(VS_IMAGE, FS_IMAGE)\n",
    "        if self.texturedGeometryShadersProgram is None :\n",
    "            self.initDone = False\n",
    "            return\n",
    "        self.initDone = True\n",
    "                \n",
    "        self.textureID = gl.glGenTextures(1)\n",
    "        gl.glPixelStorei(gl.GL_UNPACK_ALIGNMENT,1)\n",
    "        \n",
    "    def draw(self, projectionMat, viewMat, rotDir=None, rotAngle=None) :\n",
    "        if self.initDone :\n",
    "            gl.glUseProgram(self.texturedGeometryShadersProgram)\n",
    "            \n",
    "            ## find rotation to apply so that billboard is frontoparallel\n",
    "            rotMat = np.eye(4, dtype=np.float32)\n",
    "            if self.isFrontoParallel :\n",
    "                pos, norm = getWorldSpacePosAndNorm(self.modelMat)\n",
    "                cameraPos, cameraNorm = getWorldSpacePosAndNorm(np.linalg.pinv(viewMat), np.array([[0.0], [0.0], [-1.0], [1.0]]))\n",
    "                cameraPos, cameraUp = getWorldSpacePosAndNorm(np.linalg.pinv(viewMat), np.array([[0.0], [1.0], [0.0], [1.0]]))\n",
    "                \n",
    "                lookAt = cameraPos-pos\n",
    "                lookAt /= np.linalg.norm(lookAt)\n",
    "                \n",
    "                rightVec = np.cross(cameraUp, lookAt)\n",
    "                upVec = np.cross(lookAt, rightVec)\n",
    "                \n",
    "                rotMat = np.array([[rightVec[0], upVec[0], lookAt[0], 0],\n",
    "                                   [rightVec[1], upVec[1], lookAt[1], 0],\n",
    "                                   [rightVec[2], upVec[2], lookAt[2], 0],\n",
    "                                   [0, 0, 0, 1]])\n",
    "            elif self.doRotateAboutPlaneNormal :\n",
    "                pos, norm = getWorldSpacePosAndNorm(self.modelMat)\n",
    "                cameraPos, cameraNorm = getWorldSpacePosAndNorm(np.linalg.pinv(viewMat), np.array([[0.0], [0.0], [-1.0], [1.0]]))\n",
    "                \n",
    "                lookAt = cameraPos-pos\n",
    "                lookAt /= np.linalg.norm(lookAt)\n",
    "                ## project lookAt onto plane\n",
    "                lookAt = lookAt - np.dot(lookAt, self.rotateAboutPlaneNormal)*self.rotateAboutPlaneNormal\n",
    "                lookAt /= np.linalg.norm(lookAt)\n",
    "                \n",
    "                upVec = np.copy(self.rotateAboutPlaneNormal)\n",
    "                rightVec = np.cross(upVec, lookAt)\n",
    "                rightVec /= np.linalg.norm(rightVec)\n",
    "                \n",
    "                rotMat = np.array([[rightVec[0], upVec[0], lookAt[0], 0],\n",
    "                                   [rightVec[1], upVec[1], lookAt[1], 0],\n",
    "                                   [rightVec[2], upVec[2], lookAt[2], 0],\n",
    "                                   [0, 0, 0, 1]])\n",
    "            \n",
    "            if rotDir is not None and rotAngle is not None :\n",
    "                rotMat = np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(rotAngle, lookAt*rotDir)), rotMat)\n",
    "\n",
    "            ## send mvp\n",
    "            gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.texturedGeometryShadersProgram, \"m_pvm\"), 1, gl.GL_FALSE,\n",
    "                                  np.dot(projectionMat, np.dot(viewMat, np.dot(self.modelMat, rotMat))).T)\n",
    "\n",
    "            if self.textureChanged :\n",
    "                gl.glBindTexture(gl.GL_TEXTURE_2D, self.textureID)\n",
    "                gl.glTexImage2D(gl.GL_TEXTURE_2D, 0, gl.GL_RGBA, self.tex.shape[1], self.tex.shape[0], 0, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, self.tex)\n",
    "                gl.glTexParameterf(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_WRAP_S, gl.GL_CLAMP)\n",
    "                gl.glTexParameterf(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_WRAP_T, gl.GL_CLAMP)\n",
    "                gl.glTexParameterf(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MAG_FILTER, gl.GL_NEAREST)\n",
    "                gl.glTexParameterf(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MIN_FILTER, gl.GL_LINEAR_MIPMAP_LINEAR)\n",
    "                gl.glTexParameterf(gl.GL_TEXTURE_2D, tfa.GL_TEXTURE_MAX_ANISOTROPY_EXT, gl.glGetFloatv(tfa.GL_MAX_TEXTURE_MAX_ANISOTROPY_EXT))\n",
    "                gl.glGenerateMipmap(gl.GL_TEXTURE_2D)\n",
    "                self.textureChanged = False\n",
    "\n",
    "            gl.glActiveTexture(gl.GL_TEXTURE0)\n",
    "            gl.glBindTexture(gl.GL_TEXTURE_2D, self.textureID)\n",
    "            gl.glUniform1i(gl.glGetUniformLocation(self.texturedGeometryShadersProgram, \"texture_sampler\"), 0)\n",
    "\n",
    "            ## bind the index buffer\n",
    "            self.indexBuffer.bind()\n",
    "\n",
    "            ## bind the VBO with vertex data\n",
    "            self.verticesBuffer.bind()\n",
    "            gl.glEnableVertexAttribArray(0)\n",
    "            # tell OpenGL that the VBO contains an array of vertices\n",
    "            # these vertices contain 3 single precision coordinates\n",
    "            gl.glVertexAttribPointer(0, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "            ## bind the VBO with uv data\n",
    "            self.uvsBuffer.bind()\n",
    "            gl.glEnableVertexAttribArray(1)\n",
    "            gl.glVertexAttribPointer(1, 2, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "            ## draw points from the VBO\n",
    "            gl.glDrawElements(gl.GL_TRIANGLES, len(self.indices), gl.GL_UNSIGNED_INT, None)\n",
    "\n",
    "            ## clean up\n",
    "            gl.glDisableVertexAttribArray(0)\n",
    "            gl.glDisableVertexAttribArray(1)\n",
    "\n",
    "            gl.glUseProgram(0)\n",
    "            \n",
    "            \n",
    "class GLCameraFrustum() :\n",
    "    def __init__(self, modelMat, billboardImage, scale) :\n",
    "        self.initFailed = False\n",
    "        self.drawBillboard = True\n",
    "        self.modelMat = modelMat\n",
    "        self.scale = scale\n",
    "        self.zDir = 0.6\n",
    "        \n",
    "        ## translate by zDir and rotate by 180 along x axis so that it faces the camera center\n",
    "        tMat = np.array([[1, 0, 0, 0],\n",
    "                         [0, -1, 0, 0],\n",
    "                         [0, 0, -1, self.zDir],\n",
    "                         [0, 0, 0, 1]], np.float32)\n",
    "        self.imagePlaneBillboard = GLBillboard(billboardImage, scale, np.dot(self.modelMat, tMat))\n",
    "        \n",
    "        self.setGeometryAndBuffers()\n",
    "        \n",
    "    def __del__(self) :\n",
    "        del self.indices, self.vertices, self.imagePlaneBillboard\n",
    "        \n",
    "    def setScale(self, scale) :\n",
    "        self.scale = scale\n",
    "        self.imagePlaneBillboard.setScale(scale)\n",
    "        self.setGeometryAndBuffers()\n",
    "                    \n",
    "    def toggleShowFrustumBillboard(self) :\n",
    "        self.drawBillboard = not self.drawBillboard\n",
    "        \n",
    "    def setImage(self, image) :\n",
    "        self.imagePlaneBillboard.setTexture(image)\n",
    "        \n",
    "    def setShaders(self) :\n",
    "        self.colorNoShadeShadersProgram = compileShaders(VS_COLOR_NO_SHADE, FS_COLOR_NO_SHADE)\n",
    "        if self.colorNoShadeShadersProgram is None :\n",
    "            self.initDone = False\n",
    "            return        \n",
    "        self.imagePlaneBillboard.setShaders()\n",
    "        self.initDone = True\n",
    "        \n",
    "    def setGeometryAndBuffers(self) :\n",
    "        self.vertices = np.dot(np.array([[self.scale, 0, 0],\n",
    "                                         [0, self.scale, 0],\n",
    "                                         [0, 0, 1.0]], np.float32),\n",
    "                               np.array([[-self.imagePlaneBillboard.aspectRatio/2.0, -0.5, self.zDir], [-self.imagePlaneBillboard.aspectRatio/2.0, 0.5, self.zDir],\n",
    "                                         [self.imagePlaneBillboard.aspectRatio/2.0, 0.5, self.zDir], [self.imagePlaneBillboard.aspectRatio/2.0, -0.5, self.zDir], [0.0, 0.0, 0.0],\n",
    "                                         [0.0, 0.0, self.zDir], [0.0, -1.0, 0.0]], np.float32).T).T\n",
    "        self.indices = np.array([0, 1, 1, 2, 2, 3, 3, 0, 0, 4, 1, 4, 2, 4, 3, 4, 4, 5, 4, 6], np.int32)\n",
    "        self.vertices = self.vertices[list(self.indices), :].astype(np.float32)\n",
    "        self.indices = np.arange(len(self.vertices)).astype(np.int32)\n",
    "\n",
    "        self.indexBuffer = glvbo.VBO(self.indices, gl.GL_STATIC_DRAW, gl.GL_ELEMENT_ARRAY_BUFFER)\n",
    "        self.verticesBuffer = glvbo.VBO(self.vertices, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        colorArray = np.repeat(np.array([[1, 0, 0]], np.float32), len(self.vertices), 0)\n",
    "        self.colorBuffer = glvbo.VBO(colorArray, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        \n",
    "    def draw(self, projectionMat, viewMat) :\n",
    "        if self.initDone :\n",
    "            if self.drawBillboard :\n",
    "                self.imagePlaneBillboard.draw(projectionMat, viewMat)\n",
    "            \n",
    "            gl.glUseProgram(self.colorNoShadeShadersProgram)\n",
    "\n",
    "            ## send mvp\n",
    "            gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.colorNoShadeShadersProgram, \"m_pvm\"), 1, gl.GL_FALSE, np.dot(projectionMat, np.dot(viewMat, self.modelMat)).T)\n",
    "            ## send camera distance\n",
    "            gl.glUniform1f(gl.glGetUniformLocation(self.colorNoShadeShadersProgram, \"camera_dist\"), np.float32(1.0))\n",
    "    #             print(cameraDist)\n",
    "\n",
    "            ################ RENDER BODY ################\n",
    "\n",
    "            ## bind the index buffer\n",
    "            self.indexBuffer.bind()\n",
    "\n",
    "            ## bind the VBO with vertex data\n",
    "            self.verticesBuffer.bind()\n",
    "            gl.glEnableVertexAttribArray(0)\n",
    "            # tell OpenGL that the VBO contains an array of vertices\n",
    "            # these vertices contain 3 single precision coordinates\n",
    "            gl.glVertexAttribPointer(0, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "            ## bind the VBO with color data\n",
    "            self.colorBuffer.bind()\n",
    "            gl.glEnableVertexAttribArray(1)\n",
    "            gl.glVertexAttribPointer(1, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "            ## draw points from the VBO\n",
    "            gl.glDrawElements(gl.GL_LINES, len(self.indices), gl.GL_UNSIGNED_INT, None)\n",
    "\n",
    "            ## clean up\n",
    "            gl.glDisableVertexAttribArray(0)\n",
    "            gl.glDisableVertexAttribArray(1)\n",
    "\n",
    "            gl.glUseProgram(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tmpLoc = \"/media/ilisescu/Data1/PhD/data/theme_park_sunny/filmed_object-person2.npy\"\n",
    "# tmpData = np.load(tmpLoc).item()\n",
    "# tmpData[DICT_TRACK_LOCATION] = \"/media/ilisescu/Data1/PhD/data/theme_park_sunny/{0}-track.txt\".format(\"person2\")\n",
    "# np.save(tmpLoc, tmpData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# f = open(\"/home/ilisescu/PhD/data/havana/{0}-track.txt\".format(\"blue_car1\"), 'r')\n",
    "# lines = f.readlines()\n",
    "# vals = [np.array(i.split(\" \")).astype(float) for i in lines]\n",
    "# vals = [(int(i[-1]), i[0:2]) for i in vals]\n",
    "# tmp = dict(vals)\n",
    "# patches = np.load(\"/home/ilisescu/PhD/data/havana/thresh_camera_adjusted_using_billboard_homography_scale-based-on-maxsize-world-billboard_preloaded_patches-blue_car1.npy\").item()\n",
    "# trajectoryPoints = np.array([tmp[key] for key in np.sort(patches.keys())])\n",
    "\n",
    "# filmedObjectData = {DICT_FILMED_OBJECT_NAME : \"blue_car1\",\n",
    "#                     DICT_TRACK_LOCATION : \"/home/ilisescu/PhD/data/havana/{0}-track.txt\".format(\"blue_car1\"),\n",
    "#                     DICT_TRAJECTORY_POINTS : trajectoryPoints,\n",
    "#                     DICT_NEEDS_UNDISTORT : False,\n",
    "#                     DICT_CAMERA_INTRINSICS : np.array([[702.736053, 0.0, 640.0],\n",
    "#                                                        [0.0, 702.736053, 360.0],\n",
    "#                                                        [0.0, 0.0, 1.0]]),\n",
    "#                     DICT_PATCHES_LOCATION : \"/home/ilisescu/PhD/data/havana/thresh_camera_adjusted_using_billboard_homography_scale-based-on-maxsize-world-billboard_preloaded_patches-blue_car1.npy\",\n",
    "#                     DICT_REPRESENTATIVE_COLOR : np.load(\"/home/ilisescu/PhD/data/havana/semantic_sequence-blue_car1.npy\").item()[DICT_REPRESENTATIVE_COLOR]}\n",
    "# np.save(\"/home/ilisescu/PhD/data/havana/filmed_object-blue_car1.npy\", filmedObjectData)\n",
    "\n",
    "\n",
    "# f = open(\"/home/ilisescu/PhD/data/havana/{0}-track.txt\".format(\"red_car1\"), 'r')\n",
    "# lines = f.readlines()\n",
    "# vals = [np.array(i.split(\" \")).astype(float) for i in lines]\n",
    "# vals = [(int(i[-1]), i[0:2]) for i in vals]\n",
    "# tmp = dict(vals)\n",
    "# patches = np.load(\"/home/ilisescu/PhD/data/havana/thresh_camera_adjusted_using_billboard_homography_scale-based-on-maxsize-world-billboard_preloaded_patches-red_car1.npy\").item()\n",
    "# trajectoryPoints = np.array([tmp[key] for key in np.sort(patches.keys())])\n",
    "\n",
    "# filmedObjectData = {DICT_FILMED_OBJECT_NAME : \"red_car1\",\n",
    "#                     DICT_TRACK_LOCATION : \"/home/ilisescu/PhD/data/havana/{0}-track.txt\".format(\"red_car1\"),\n",
    "#                     DICT_TRAJECTORY_POINTS : trajectoryPoints,\n",
    "#                     DICT_NEEDS_UNDISTORT : False,\n",
    "#                     DICT_CAMERA_INTRINSICS : np.array([[702.736053, 0.0, 640.0],\n",
    "#                                                        [0.0, 702.736053, 360.0],\n",
    "#                                                        [0.0, 0.0, 1.0]]),\n",
    "#                     DICT_PATCHES_LOCATION : \"/home/ilisescu/PhD/data/havana/thresh_camera_adjusted_using_billboard_homography_scale-based-on-maxsize-world-billboard_preloaded_patches-red_car1.npy\",\n",
    "#                     DICT_REPRESENTATIVE_COLOR : np.load(\"/home/ilisescu/PhD/data/havana/semantic_sequence-red_car1.npy\").item()[DICT_REPRESENTATIVE_COLOR]}\n",
    "# np.save(\"/home/ilisescu/PhD/data/havana/filmed_object-red_car1.npy\", filmedObjectData)\n",
    "\n",
    "# f = open(\"/home/ilisescu/PhD/data/havana/{0}-track.txt\".format(\"white_bus1\"), 'r')\n",
    "# lines = f.readlines()\n",
    "# vals = [np.array(i.split(\" \")).astype(float) for i in lines]\n",
    "# vals = [(int(i[-1]), i[0:2]) for i in vals]\n",
    "# tmp = dict(vals)\n",
    "# trajectoryPoints = np.array([tmp[key] for key in np.sort(tmp.keys())])\n",
    "\n",
    "# filmedObjectData = {DICT_FILMED_OBJECT_NAME : \"white_bus1\",\n",
    "#                     DICT_TRACK_LOCATION : \"/home/ilisescu/PhD/data/havana/{0}-track.txt\".format(\"white_bus1\"),\n",
    "#                     DICT_TRAJECTORY_POINTS : trajectoryPoints,\n",
    "#                     DICT_NEEDS_UNDISTORT : False,\n",
    "#                     DICT_CAMERA_INTRINSICS : np.array([[702.736053, 0.0, 640.0],\n",
    "#                                                        [0.0, 702.736053, 360.0],\n",
    "#                                                        [0.0, 0.0, 1.0]]),\n",
    "#                     DICT_PATCHES_LOCATION : \"/home/ilisescu/PhD/data/havana/thresh_camera_adjusted_using_billboard_homography_scale-based-on-maxsize-world-billboard_preloaded_patches-red_car1.npy\",\n",
    "#                     DICT_REPRESENTATIVE_COLOR : np.load(\"/home/ilisescu/PhD/data/havana/semantic_sequence-white_bus1.npy\").item()[DICT_REPRESENTATIVE_COLOR]}\n",
    "# np.save(\"/home/ilisescu/PhD/data/havana/filmed_object-white_bus1.npy\", filmedObjectData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# f = open(\"/media/ilisescu/Data1/PhD/data/theme_park_sunny/{0}-track.txt\".format(\"person2\"), 'r')\n",
    "# lines = f.readlines()\n",
    "# vals = [np.array(i.split(\" \")).astype(float) for i in lines]\n",
    "# vals = [(int(i[-1]), i[0:2]) for i in vals]\n",
    "# tmp = dict(vals)\n",
    "\n",
    "# if False :\n",
    "#     patches = np.load(\"/home/ilisescu/PhD/data/havana/thresh_camera_adjusted_using_billboard_homography_scale-based-on-maxsize-world-billboard_preloaded_patches-red_car1.npy\").item()\n",
    "#     trajectoryPoints = np.array([tmp[key] for key in np.sort(patches.keys()) if key in tmp.keys()])\n",
    "# else :\n",
    "#     trajectoryPoints = np.array([tmp[key] for key in np.sort(tmp.keys())])\n",
    "\n",
    "# filmedObjectData = {DICT_FILMED_OBJECT_NAME : \"person2\",\n",
    "#                     DICT_TRACK_LOCATION : \"/media/ilisescu/Data1/PhD/data/theme_park_sunny/{0}-track.txt\".format(\"person2\"),\n",
    "#                     DICT_TRAJECTORY_POINTS : trajectoryPoints,\n",
    "#                     DICT_NEEDS_UNDISTORT : False,\n",
    "#                     DICT_CAMERA_INTRINSICS : np.array([[1275.186144, 0.0z, 480.0],\n",
    "#                                                        [0.0, 1275.186144, 270.0],\n",
    "#                                                        [0.0, 0.0, 1.0]]),\n",
    "#                     DICT_PATCHES_LOCATION : \"/home/ilisescu/PhD/data/havana/thresh_camera_adjusted_using_billboard_homography_scale-based-on-maxsize-world-billboard_preloaded_patches-red_car1.npy\",\n",
    "#                     DICT_REPRESENTATIVE_COLOR : np.load(\"/media/ilisescu/Data1/PhD/data/theme_park_sunny/semantic_sequence-person2.npy\").item()[DICT_REPRESENTATIVE_COLOR]}\n",
    "# np.save(\"/media/ilisescu/Data1/PhD/data/theme_park_sunny/filmed_object-person2.npy\", filmedObjectData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getUndistortedTrajectoryPoints(filmedObjectData, distortionCoeff, undistortedIntrinsics) :\n",
    "    trajectoryPoints = filmedObjectData[DICT_TRAJECTORY_POINTS]\n",
    "    if filmedObjectData[DICT_NEEDS_UNDISTORT] :\n",
    "        ## for the trajectory points to be valid, I need to undistort them (as I'm working in the undistorted space and the objects were tracked in the original image space) \n",
    "        trajectoryPoints = cv2.undistortPoints(trajectoryPoints.reshape((1, len(trajectoryPoints), 2)), filmedObjectData[DICT_CAMERA_INTRINSICS],\n",
    "                                               distortionCoeff, P=undistortedIntrinsics)[0, :, :]\n",
    "    else :\n",
    "        ## or in the case of nuke tracks they were tracked in the cropped undistorted image so I need to account for difference in camera intrinsics\n",
    "        ## THE ABOVE IS NOT TRUE ANYMORE\n",
    "        ## trajectoryPoints = trajectoryPoints + filmedDataset.undistortedIntrinsics[:2, -1] - filmedObjectData[DICT_CAMERA_INTRINSICS][:2, -1]\n",
    "        pass\n",
    "        \n",
    "    return trajectoryPoints\n",
    "\n",
    "class GLFilmedObject() :\n",
    "    def __init__(self, objectLoc, cameraIntrinsics, cameraExtrinsics, isDistorted, distortionCoeff, originalIntrinsics, footprintScale=0.3, footprintAspectRatio=1.75) :\n",
    "        self.initDone = False\n",
    "        self.frameToUseIdx = 0\n",
    "        self.footprintAspectRatio = footprintAspectRatio\n",
    "        self.filmedObjectData = np.load(objectLoc).item()\n",
    "        print(\"LOADED\", self.filmedObjectData[DICT_FILMED_OBJECT_NAME])\n",
    "        self.footprintScale = self.filmedObjectData[DICT_OBJECT_BILLBOARD_SCALE]*footprintScale\n",
    "        self.cameraIntrinsics = cameraIntrinsics\n",
    "        self.cameraExtrinsics = cameraExtrinsics\n",
    "        self.previouslyUsedFrame = 0\n",
    "        \n",
    "        ## rotate by 180 along z axis and translate up by 1\n",
    "        self.modelMat = np.array([[-1, 0, 0, 0],\n",
    "                                  [0, -1, 0, 0],\n",
    "                                  [0, 0, 1, 1],\n",
    "                                  [0, 0, 0, 1]], np.float32)\n",
    "\n",
    "        self.forwardDir = np.array([[1.0], [0.0], [0.0], [1.0]]) ## model space\n",
    "\n",
    "        self.trajectoryPoints = getUndistortedTrajectoryPoints(self.filmedObjectData, distortionCoeff, self.cameraIntrinsics)        \n",
    "        self.trajectory = GLTrajectory(self.trajectoryPoints, cameraIntrinsics, cameraExtrinsics, self.filmedObjectData[DICT_REPRESENTATIVE_COLOR], doSmoothing = False)\n",
    "        \n",
    "#         global tmpTrajectoryCameraSpace\n",
    "#         tmpTrajectoryCameraSpace = np.copy(self.trajectory.cameraTrajectoryPoints)\n",
    "        \n",
    "        ## patches defined previously before getting rid of the havana hardcodes (last one is the one I was using last and likely using now too)\n",
    "#         patchesLoc = \"/camera_adjusted_preloaded_patches-{0}.npy\".format(self.objectData[DICT_SEQUENCE_NAME])\n",
    "#         patchesLoc = \"/camera_adjusted_plus_scale_preloaded_patches-{0}.npy\".format(self.objectData[DICT_SEQUENCE_NAME])\n",
    "#         patchesLoc = \"/camera_adjusted_using_billboard_homography_scale-based-on-world-billboard_preloaded_patches-{0}.npy\".format(self.objectData[DICT_SEQUENCE_NAME])\n",
    "#         patchesLoc = \"/camera_adjusted_using_billboard_homography_scale-based-on-patch_preloaded_patches-{0}.npy\".format(self.objectData[DICT_SEQUENCE_NAME])\n",
    "#         patchesLoc = \"/camera_adjusted_using_billboard_homography_scale-test_preloaded_patches-{0}.npy\".format(self.objectData[DICT_SEQUENCE_NAME])\n",
    "#         patchesLoc = \"/camera_adjusted_using_billboard_homography_scale-based-on-maxsize-world-billboard_preloaded_patches-{0}.npy\".format(self.objectData[DICT_SEQUENCE_NAME])\n",
    "#         patchesLoc = \"/thresh_camera_adjusted_using_billboard_homography_scale-based-on-maxsize-world-billboard_preloaded_patches-{0}.npy\".format(self.objectData[DICT_SEQUENCE_NAME])\n",
    "        \n",
    "        self.patches = np.load(self.filmedObjectData[DICT_PATCHES_LOCATION]).item()\n",
    "        self.sortedPatchKeys = np.sort(self.patches.keys())\n",
    "        print(self.sortedPatchKeys, len(self.sortedPatchKeys), len(self.trajectoryPoints))\n",
    "        \n",
    "        \n",
    "#         self.billboard = GLBillboard(self.getImageFromPatch(-1), 1.0, np.dot(self.modelMat, np.array([[-1, 0, 0, 0],\n",
    "#                                                                                                       [0, -1, 0, 0],\n",
    "#                                                                                                       [0, 0, 1, 0],\n",
    "#                                                                                                       [0, 0, 0, 1]], np.float32)), False, None, True)\n",
    "        \n",
    "#         self.billboard = GLBillboard(self.getImageFromPatch(-1), 1.0, self.modelMat, False, np.array([0, 0, 1], np.float32), True)\n",
    "        ## this is for the latest setup before I switched to using homographies for adjusting patches\n",
    "#         self.billboard = GLBillboard(self.getImageFromPatch(-1), 1.0, self.modelMat, True, None, True)\n",
    "    \n",
    "        ## this is for the patches adjusted using homographies\n",
    "#         self.billboard = GLBillboard(self.getImageFromPatch(-1), 0.72, np.dot(self.modelMat, np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(np.pi, np.array([0.0, 1.0, 0.0]))),\n",
    "#                                                                                                     quaternionTo4x4Rotation(angleAxisToQuaternion(np.pi/2, np.array([1.0, 0.0, 0.0]))))), False, None, False)\n",
    "#         self.billboard = GLBillboard(self.getImageFromPatch(-1), 1.52, np.dot(self.modelMat, np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(np.pi, np.array([0.0, 1.0, 0.0]))),\n",
    "#                                                                                                     quaternionTo4x4Rotation(angleAxisToQuaternion(np.pi/2, np.array([1.0, 0.0, 0.0]))))), False, None, False)\n",
    "#         self.billboard = GLBillboard(self.getImageFromPatch(-1), 1.23, np.dot(self.modelMat, np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(np.pi, np.array([0.0, 1.0, 0.0]))),\n",
    "#                                                                                                     quaternionTo4x4Rotation(angleAxisToQuaternion(-np.pi/2, np.array([1.0, 0.0, 0.0]))))), False, None, False)\n",
    "        self.billboard = GLBillboard(self.getImageFromPatch(-1), self.filmedObjectData[DICT_OBJECT_BILLBOARD_SCALE],\n",
    "                                     np.dot(self.modelMat, np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(np.pi, np.array([0.0, 1.0, 0.0]))),\n",
    "                                                                  quaternionTo4x4Rotation(angleAxisToQuaternion(-np.pi/2, np.array([1.0, 0.0, 0.0]))))), False, None, False)\n",
    "        \n",
    "        \n",
    "        ## move object to the first image on its original trajectory and orient properly\n",
    "        if True :\n",
    "            self.setObjectOnTrajectory(0)\n",
    "        \n",
    "        self.setGeometryAndBuffers()\n",
    "        \n",
    "        ## find directions from center of the car to the center of the camera\n",
    "        cameraPos = getWorldSpacePosAndNorm(np.linalg.inv(self.cameraExtrinsics), posOnly=True)\n",
    "        self.pointToCameraDirectionsWorldSpace = cameraPos.reshape([1, 3]).astype(np.float32) - self.trajectory.worldTrajectoryPoints\n",
    "        self.pointToCameraDistances = np.linalg.norm(self.pointToCameraDirectionsWorldSpace, axis=1).astype(np.float32)\n",
    "        self.pointToCameraDirectionsWorldSpace /= self.pointToCameraDistances.reshape([len(self.pointToCameraDistances), 1])\n",
    "        \n",
    "        self.cameraToObjectDirectionsObjSpace = np.zeros([len(self.trajectory.worldTrajectoryDirections), 3])\n",
    "        for i, direction in enumerate(self.trajectory.worldTrajectoryDirections) :\n",
    "            rotAxis = np.cross(np.array([1, 0, 0]), direction)\n",
    "            rotAxis /= np.linalg.norm(rotAxis)\n",
    "            rotAngle = np.arccos(np.dot(direction, np.array([1, 0, 0])))\n",
    "\n",
    "            M = quaternionTo4x4Rotation(angleAxisToQuaternion(rotAngle, rotAxis))\n",
    "            ## here it works to get the dir like this because the origin is 0 and I'm rotating about it what I would really have to do is rotate the point translated by the direction and then take diff between it and origin \n",
    "            rotatedDir = np.dot(M, np.array([[self.pointToCameraDirectionsWorldSpace[i, 0], self.pointToCameraDirectionsWorldSpace[i, 1], self.pointToCameraDirectionsWorldSpace[i, 2], 1]]).T)\n",
    "            rotatedDir = rotatedDir[:-1, 0]/rotatedDir[-1, 0]\n",
    "            rotatedDir /= np.linalg.norm(rotatedDir)\n",
    "            self.cameraToObjectDirectionsObjSpace[i, :] = -rotatedDir\n",
    "            \n",
    "            ### THIS STUFF FROM HERE ON I\"M NOT REALLY SURE ABOUT\n",
    "            ## this turns the camera towards the object\n",
    "            adjustCamPos, adjustCamNorm = getWorldSpacePosAndNorm(np.linalg.inv(cameraExtrinsics))\n",
    "            adjustAxis = np.cross(-self.pointToCameraDirectionsWorldSpace[i, :], adjustCamNorm)\n",
    "            adjustAxis /= np.linalg.norm(adjustAxis)\n",
    "            adjustAngle = np.arccos(np.clip(np.dot(adjustCamNorm, -self.pointToCameraDirectionsWorldSpace[i, :]), -1, 1))\n",
    "            adjustM = quaternionTo4x4Rotation(angleAxisToQuaternion(adjustAngle, adjustAxis))\n",
    "\n",
    "            camMat = np.eye(4)\n",
    "            camMat[:-1, -1] = rotatedDir\n",
    "            camMat[:-1, :-1] = np.dot(adjustM[:-1, :-1], np.linalg.inv(cameraExtrinsics)[:-1, :-1])\n",
    "\n",
    "            ## this rotates camera to align with ground plane (and the car itself)\n",
    "            _, adjustCamRightVec2 = getWorldSpacePosAndNorm(camMat, np.array([[1, 0, 0, 1]], float).T)\n",
    "            _, adjustCamUpVec2 = getWorldSpacePosAndNorm(camMat, np.array([[0, -1, 0, 1]], float).T)\n",
    "            _, adjustCamNorm2 = getWorldSpacePosAndNorm(camMat)\n",
    "            adjustAxis2 = np.copy(adjustCamNorm2)\n",
    "    #         adjustAngle2 = np.arccos(np.clip(np.dot(adjustCamRightVec2, adjustCamRightVec2*np.array([1, 1, 0], float)), -1, 1)) ## aligns camera right vector to ground plane\n",
    "    #         adjustAngle2 = np.arccos(np.clip(np.dot(adjustCamRightVec2, np.array([1, 0, 0], float)), -1, 1)) ## not sure what this does\n",
    "            if i == len(self.trajectory.worldTrajectoryDirections)-1 :\n",
    "                trajDir = self.trajectory.cameraTrajectoryPoints[i-1, :]-self.trajectory.cameraTrajectoryPoints[i, :]\n",
    "            else :\n",
    "                trajDir = self.trajectory.cameraTrajectoryPoints[i, :]-self.trajectory.cameraTrajectoryPoints[i+1, :]\n",
    "            trajDir /= np.linalg.norm(trajDir) ## CAREFUL HERE AS THE NORM CAN BE 0\n",
    "            adjustAngle2 = np.arccos(np.clip(np.dot(trajDir, np.array([1, 0], float)), -1, 1)) ## align camera space direction to x axis (does it even make sense?)\n",
    "            if np.cross(trajDir, np.array([1, 0], float)) < 0 :\n",
    "                adjustAxis2 *= -1.0\n",
    "\n",
    "\n",
    "            adjustM2 = quaternionTo4x4Rotation(angleAxisToQuaternion(adjustAngle2, adjustAxis2))\n",
    "            camMat[:-1, :-1] = np.dot(M[:-1, :-1], np.dot(adjustM2[:-1, :-1], camMat[:-1, :-1]))\n",
    "            \n",
    "        global tmpDirections\n",
    "        tmpDirections = np.copy(self.cameraToObjectDirectionsObjSpace)\n",
    "        \n",
    "    def __del__(self) :\n",
    "        del self.filmedObjectData, self.cameraIntrinsics, self.cameraExtrinsics, self.trajectory, self.patches, self.sortedPatchKeys\n",
    "        del self.billboard, self.footprintVertices, self.footprintIndices, self.arrowIndices, self.arrowVertices\n",
    "        del self.pointToCameraDirectionsWorldSpace, self.pointToCameraDistances, self.cameraToObjectDirectionsObjSpace, self.trajectoryPoints\n",
    "    \n",
    "    def getImageFromPatch(self, idx) :\n",
    "        ## find offset between location of the trajectory point and the patch center and then center the patch on the point by padding img\n",
    "        patch = self.patches[self.sortedPatchKeys[idx]]\n",
    "#         ## top_left_pos in patch is wrt the original image size whereas the trajectory points are wrt the undistorted image so compensate\n",
    "#         patchTopLeft = (patch['top_left_pos']+((np.array([936, 1664])-np.array([720, 1280]))/2))[::-1]\n",
    "#         pointLocation = np.round(self.trajectory.cameraTrajectoryPoints[idx, :]-patchTopLeft).astype(int)\n",
    "#         print(\"TRAJ POINT, PATCH CENTER, TOP LEFT, POINT IN PATCH\", self.trajectory.cameraTrajectoryPoints[idx, :], patch['patch_size'][::-1]/2, patchTopLeft, pointLocation)\n",
    "        img = np.zeros([patch['patch_size'][0], patch['patch_size'][1], 4], dtype=np.int8)\n",
    "#         print(idx)\n",
    "        img[patch['visible_indices'][:, 0], patch['visible_indices'][:, 1], :] = patch['sprite_colors']\n",
    "        \n",
    "#         print(\"PATCH SIZE\", patch['patch_size'])\n",
    "        \n",
    "        return img[:, :, [2, 1, 0, 3]]\n",
    "    \n",
    "    def setObjectOnTrajectory(self, trajPointIdx) :\n",
    "        self.setObjectPosAndDir(self.trajectory.worldTrajectoryPoints[trajPointIdx, :], self.trajectory.worldTrajectoryDirections[trajPointIdx, :])\n",
    "            \n",
    "    def setObjectPosAndDir(self, positionWorld, directionWorld) :\n",
    "        objPos, objFDir = getWorldSpacePosAndNorm(self.modelMat, self.forwardDir)\n",
    "        adjustAngle = np.arccos(np.clip(np.dot(objFDir, directionWorld), -1, 1))\n",
    "        modelMat = np.copy(self.modelMat)\n",
    "        if np.abs(adjustAngle) > 1e-06 :\n",
    "#             print(adjustAngle, np.cross(directionWorld, objFDir))\n",
    "            adjustAxis = np.cross(directionWorld, objFDir)\n",
    "            adjustAxis /= np.linalg.norm(adjustAxis)\n",
    "            modelMat = np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(adjustAngle, adjustAxis)), self.modelMat)\n",
    "        modelMat[:-1, -1] = positionWorld\n",
    "        \n",
    "        self.setObjectModelMat(modelMat)\n",
    "        \n",
    "    def setObjectModelMat(self, modelMat) :\n",
    "        self.modelMat = modelMat\n",
    "#         if not self.billboard.isFrontoParallel and not self.billboard.doRotateAboutPlaneNormal :\n",
    "# #             self.billboard.modelMat = np.dot(self.modelMat, np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(np.pi, np.array([0.0, 1.0, 0.0]))),\n",
    "# #                                                                    quaternionTo4x4Rotation(angleAxisToQuaternion(-np.pi/2, np.array([1.0, 0.0, 0.0])))))\n",
    "#             self.billboard.modelMat = self.modelMat\n",
    "    \n",
    "    def setShaders(self) :\n",
    "        self.colorNoShadeShadersProgram = compileShaders(VS_COLOR_NO_SHADE, FS_COLOR_NO_SHADE)\n",
    "        if self.colorNoShadeShadersProgram is None :\n",
    "            self.initDone = False\n",
    "            return\n",
    "        \n",
    "        self.trajectory.setShaders()\n",
    "        self.billboard.setShaders()\n",
    "        self.initDone = True\n",
    "        \n",
    "    def setGeometryAndBuffers(self) :\n",
    "        forwardDirPos = [self.footprintAspectRatio/2.0, 0.5, 0.0]*self.forwardDir[:-1, 0]\n",
    "        scaleMat = np.array([[self.footprintScale, 0, 0],\n",
    "                             [0, self.footprintScale, 0],\n",
    "                             [0, 0, 1.0]], np.float32)\n",
    "        ## FOOTPRINT BOX ##\n",
    "        self.footprintVertices = np.dot(scaleMat, np.array([[-self.footprintAspectRatio/2.0, -0.5, 0.0], [-self.footprintAspectRatio/2.0, 0.5, 0.0],\n",
    "                                                            [self.footprintAspectRatio/2.0, 0.5, 0.0], [self.footprintAspectRatio/2.0, -0.5, 0.0], [0.0, 0.0, 0.0],\n",
    "                                                            forwardDirPos], np.float32).T).T\n",
    "        self.footprintIndices = np.array([0, 1, 1, 2, 2, 3, 3, 0, 4, 5], np.int32)\n",
    "        self.footprintVertices = self.footprintVertices[list(self.footprintIndices), :].astype(np.float32)\n",
    "        self.footprintIndices = np.arange(len(self.footprintVertices)).astype(np.int32)\n",
    "\n",
    "        self.footprintIndexBuffer = glvbo.VBO(self.footprintIndices, gl.GL_STATIC_DRAW, gl.GL_ELEMENT_ARRAY_BUFFER)\n",
    "        self.footprintVerticesBuffer = glvbo.VBO(self.footprintVertices, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        colorArray = np.repeat(np.array([[1, 0, 0]], np.float32), len(self.footprintVertices), 0)\n",
    "        self.footprintColorBuffer = glvbo.VBO(colorArray, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        \n",
    "        ## FORWARD DIR ARROW ##\n",
    "        arrowMesh = pyassimp.load(\"arrowTop.obj\").meshes[0]\n",
    "        self.arrowVertices = arrowMesh.vertices.astype(np.float32)*np.float32(self.footprintScale*5.0)\n",
    "        forwardDirPos = np.dot(scaleMat, forwardDirPos)\n",
    "        ## move to position and rotate by 90 along z axis\n",
    "        tMat = np.array([[0, 1, 0, forwardDirPos[0]],\n",
    "                         [-1, 0, 0, forwardDirPos[1]],\n",
    "                         [0, 0, 1, forwardDirPos[2]],\n",
    "                         [0, 0, 0, 1]], np.float32)\n",
    "        \n",
    "        self.arrowVertices = np.dot(tMat, np.concatenate([self.arrowVertices, np.ones([len(self.arrowVertices), 1])], axis=1).T)\n",
    "        self.arrowVertices = (self.arrowVertices[:-1, :]/self.arrowVertices[-1, :]).T\n",
    "        self.arrowIndices = arrowMesh.faces.flatten()\n",
    "        \n",
    "        colorArray = np.repeat(np.array([[1, 0, 0]], np.float32), len(self.arrowVertices), 0)        \n",
    "        self.arrowVerticesBuffer = glvbo.VBO(self.arrowVertices.astype(np.float32), gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        self.arrowColorsBuffer = glvbo.VBO(colorArray.astype(np.float32), gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        self.arrowIndexBuffer = glvbo.VBO(self.arrowIndices.astype(np.int32), gl.GL_STATIC_DRAW, gl.GL_ELEMENT_ARRAY_BUFFER)\n",
    "        \n",
    "    def drawFootprint(self, projectionMat, viewMat) :\n",
    "        gl.glUseProgram(self.colorNoShadeShadersProgram)\n",
    "\n",
    "        ## send mvp\n",
    "        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.colorNoShadeShadersProgram, \"m_pvm\"), 1, gl.GL_FALSE, np.dot(projectionMat, np.dot(viewMat, self.modelMat)).T)\n",
    "        ## send camera distance\n",
    "        gl.glUniform1f(gl.glGetUniformLocation(self.colorNoShadeShadersProgram, \"camera_dist\"), np.float32(1.0))\n",
    "#             print(cameraDist)\n",
    "\n",
    "        ################ RENDER FOOTPRINT BOX ################\n",
    "\n",
    "        ## bind the index buffer\n",
    "        self.footprintIndexBuffer.bind()\n",
    "\n",
    "        ## bind the VBO with vertex data\n",
    "        self.footprintVerticesBuffer.bind()\n",
    "        gl.glEnableVertexAttribArray(0)\n",
    "        # tell OpenGL that the VBO contains an array of vertices\n",
    "        # these vertices contain 3 single precision coordinates\n",
    "        gl.glVertexAttribPointer(0, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "        ## bind the VBO with color data\n",
    "        self.footprintColorBuffer.bind()\n",
    "        gl.glEnableVertexAttribArray(1)\n",
    "        gl.glVertexAttribPointer(1, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "        ## draw points from the VBO\n",
    "        gl.glDrawElements(gl.GL_LINES, len(self.footprintIndices), gl.GL_UNSIGNED_INT, None)\n",
    "\n",
    "        ## clean up\n",
    "        gl.glDisableVertexAttribArray(0)\n",
    "        gl.glDisableVertexAttribArray(1)\n",
    "        \n",
    "        ################ RENDER FORWARD DIR ARROW ################\n",
    "\n",
    "        ## bind the index buffer\n",
    "        self.arrowIndexBuffer.bind()\n",
    "\n",
    "        ## bind the VBO with vertex data\n",
    "        self.arrowVerticesBuffer.bind()\n",
    "        gl.glEnableVertexAttribArray(0)\n",
    "        # tell OpenGL that the VBO contains an array of vertices\n",
    "        # these vertices contain 3 single precision coordinates\n",
    "        gl.glVertexAttribPointer(0, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "        ## bind the VBO with color data\n",
    "        self.arrowColorsBuffer.bind()\n",
    "        gl.glEnableVertexAttribArray(1)\n",
    "        gl.glVertexAttribPointer(1, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "        ## draw points from the VBO\n",
    "        gl.glDrawElements(gl.GL_TRIANGLES, len(self.arrowIndices), gl.GL_UNSIGNED_INT, None)\n",
    "\n",
    "        ## clean up\n",
    "        gl.glDisableVertexAttribArray(0)\n",
    "        gl.glDisableVertexAttribArray(1)\n",
    "\n",
    "        gl.glUseProgram(0)    \n",
    "        \n",
    "    def draw(self, projectionMat, viewMat, doDrawFootprint=True, doDrawTrajectory=True, doDrawColors=True, doDrawMisc=True) :\n",
    "        if self.initDone :\n",
    "            ## find which frame to show\n",
    "            distances = viewToObjectDirAngleDistance(self, viewMat)\n",
    "            tmp = self.frameToUseIdx\n",
    "            self.frameToUseIdx = int(np.argmin(distances).flatten())\n",
    "            if tmp != self.frameToUseIdx :\n",
    "                self.previouslyUsedFrame = tmp\n",
    "\n",
    "            top, left, width, height = gl.glGetIntegerv(gl.GL_VIEWPORT)\n",
    "\n",
    "            ## some movingDirection is nan because of 2 consecutive points being the same but because of the smoothing it's pretty unlikely\n",
    "            if self.frameToUseIdx < len(self.trajectory.cameraTrajectoryPoints)-1 :\n",
    "                movingDirection = self.trajectory.cameraTrajectoryPoints[self.frameToUseIdx+1, :]-self.trajectory.cameraTrajectoryPoints[self.frameToUseIdx, :]\n",
    "                movingDirection /= np.linalg.norm(movingDirection)\n",
    "            else :\n",
    "                movingDirection = self.trajectory.cameraTrajectoryPoints[self.frameToUseIdx, :]-self.trajectory.cameraTrajectoryPoints[self.frameToUseIdx-1, :]\n",
    "                movingDirection /= np.linalg.norm(movingDirection)\n",
    "            ## cameraTrajectoryPoints are not in the same aspect ratio as the objPos and objDirPos because the first are defined using the original camera and the second are defined using the opengl camera\n",
    "            ## so need to compensate for that by (well flipping y first because of opencv convention) removing the distortions due to the viewport aspect ratio\n",
    "            movingDirection[1] *= -1.0\n",
    "            movingDirection[0] *= 1.0/(float(width)/float(height))\n",
    "            movingDirection /= np.linalg.norm(movingDirection)\n",
    "            \n",
    "            ## these are actually in clip space as the camera space would only be after applying viewMat\n",
    "            objPos = getWorldSpacePosAndNorm(self.modelMat, posOnly=True)\n",
    "            objPosInCameraSpace = np.dot(np.dot(projectionMat, viewMat), np.concatenate([objPos, [1]]).reshape([4, 1]))\n",
    "            objPosInCameraSpace = objPosInCameraSpace[:-1, 0]/objPosInCameraSpace[-1, 0]\n",
    "            ## these are actually in screen space from clip space (after projection mat applied)\n",
    "            objPosInClipSpace = np.array([(objPosInCameraSpace[0]+1.0)*width/2.0, (1.0-objPosInCameraSpace[1])*height/2.0])\n",
    "\n",
    "            objDirPosInWorldSpace = np.dot(self.modelMat, self.forwardDir)\n",
    "            objDirPosInWorldSpace = objDirPosInWorldSpace[:3, 0]/objDirPosInWorldSpace[3, 0]\n",
    "            objDirPosInCameraSpace = np.dot(np.dot(projectionMat, viewMat), np.concatenate([objDirPosInWorldSpace, [1]]).reshape([4, 1]))\n",
    "            objDirPosInCameraSpace = objDirPosInCameraSpace[:-1, 0]/objDirPosInCameraSpace[-1, 0]\n",
    "            objDirPosInClipSpace = np.array([(objDirPosInCameraSpace[0]+1.0)*width/2.0, (1.0-objDirPosInCameraSpace[1])*height/2.0])\n",
    "\n",
    "            objMovingDirectionInCameraSpace = objDirPosInCameraSpace[:-1]-objPosInCameraSpace[:-1]#objDirPosInClipSpace-objPosInClipSpace\n",
    "            objMovingDirectionInCameraSpace /= np.linalg.norm(objMovingDirectionInCameraSpace)\n",
    "            \n",
    "            ## moving direction in camera space of requested direction for the filmed object\n",
    "            objDirLine = GLPolyline(np.concatenate([np.concatenate([[objPosInCameraSpace[:-1]], [objPosInCameraSpace[:-1]+objMovingDirectionInCameraSpace]]), np.zeros([2, 1])], axis=1).astype(np.float32),\n",
    "                                    drawColor=np.array([   0.,  0.,    255.]))\n",
    "            objDirLine.setShaders()\n",
    "            ## moving direction in camera space of the tracked object in the frame currently visualized\n",
    "            movingDirLine = GLPolyline(np.concatenate([np.concatenate([[objPosInCameraSpace[:-1]], [objPosInCameraSpace[:-1]+movingDirection]]), np.zeros([2, 1])], axis=1).astype(np.float32),\n",
    "                                       drawColor=np.array([   0.,  255.,    0.]))\n",
    "            movingDirLine.setShaders()\n",
    "            \n",
    "            ## put moving direction back into its original aspect ratio\n",
    "            movingDirection[0] *= (float(width)/float(height))\n",
    "            movingDirection /= np.linalg.norm(movingDirection)\n",
    "            objMovingDirectionInCameraSpace[0] *= (float(width)/float(height))\n",
    "            objMovingDirectionInCameraSpace /= np.linalg.norm(objMovingDirectionInCameraSpace)\n",
    "            \n",
    "            ## THIS SOLVES (THE FUNNY PROBLEM WHERE THE CAR IS POINTING DOWNWARDS WHEN I SHOW A FRAME FROM THE LOWER LEFT CORNER) ONLY IF BILLBOARD IS FRONTOPARALLEL\n",
    "            rotDir = np.cross(objMovingDirectionInCameraSpace, movingDirection)\n",
    "            rotDir /= np.linalg.norm(rotDir)\n",
    "            rotAngle = np.arccos(np.clip(np.dot(objMovingDirectionInCameraSpace, movingDirection), -1.0, 1.0))\n",
    "#             print(\"ROTATION\", rotAngle*180.0/np.pi, rotDir)\n",
    "            \n",
    "\n",
    "            self.billboard.setTexture(self.getImageFromPatch(self.frameToUseIdx))\n",
    "            global tmpDirectionAngleDistances\n",
    "            tmpDirectionAngleDistances = np.copy(distances)\n",
    "    \n",
    "            isDepthTestOn = bool(gl.glGetBooleanv(gl.GL_DEPTH_TEST))\n",
    "            gl.glDisable(gl.GL_DEPTH_TEST)\n",
    "            \n",
    "            if doDrawColors :\n",
    "                if self.billboard.isFrontoParallel :\n",
    "                    self.billboard.draw(projectionMat, viewMat, rotDir=rotDir, rotAngle=rotAngle)\n",
    "                else :\n",
    "                    if not self.billboard.isFrontoParallel and not self.billboard.doRotateAboutPlaneNormal :\n",
    "#                         print(self.frameToUseIdx, self.filmedObjectData[DICT_OBJECT_BILLBOARD_ORIENTATION][self.frameToUseIdx]*180/np.pi, self.modelMat)\n",
    "                        self.billboard.modelMat = np.dot(self.modelMat, np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(self.filmedObjectData[DICT_OBJECT_BILLBOARD_ORIENTATION][self.frameToUseIdx], \n",
    "                                                                                                                             np.array([0.0, 0.0, 1.0]))),\n",
    "                                                                               quaternionTo4x4Rotation(angleAxisToQuaternion(-np.pi/2, np.array([1.0, 0.0, 0.0])))))\n",
    "#                         self.billboard.modelMat = np.dot(np.eye(4, dtype=np.float32), quaternionTo4x4Rotation(angleAxisToQuaternion(-np.pi/2, np.array([1.0, 0.0, 0.0]))))\n",
    "                    \n",
    "                    self.billboard.draw(projectionMat, viewMat)#, rotDir=rotDir, rotAngle=rotAngle)\n",
    "\n",
    "#             print(\"(pos, posFDir, camFDir, camProjFDir)\", pos, posFDir, camFDir, camProjFDir)\n",
    "            \n",
    "            if doDrawTrajectory :\n",
    "                self.trajectory.draw(np.dot(projectionMat, viewMat))\n",
    "                \n",
    "            if doDrawFootprint :\n",
    "                self.drawFootprint(projectionMat, viewMat)\n",
    "            \n",
    "            if doDrawMisc :\n",
    "                ## drawing direction line and such \n",
    "                objDirLine.draw(np.eye(4, dtype=np.float32))\n",
    "                movingDirLine.draw(np.eye(4, dtype=np.float32))\n",
    "\n",
    "                objDirLine.draw(np.dot(projectionMat, viewMat))\n",
    "                movingDirLine.draw(np.dot(projectionMat, viewMat))\n",
    "\n",
    "            if isDepthTestOn :\n",
    "                gl.glEnable(gl.GL_DEPTH_TEST)\n",
    "                \n",
    "def viewToObjectDirAngleDistance(filmedObject, viewMat, overrideObjectMat = None) :\n",
    "    if overrideObjectMat is None :\n",
    "        objectMat = overrideObjectMat\n",
    "    else :\n",
    "        objectMat = filmedObject.modelMat\n",
    "    camPos = getWorldSpacePosAndNorm(np.linalg.inv(viewMat), posOnly=True)\n",
    "    objPos = getWorldSpacePosAndNorm(objectMat, posOnly=True)\n",
    "            \n",
    "    cameraToObjDir = objPos-camPos\n",
    "    cameraToObjDir /= np.linalg.norm(cameraToObjDir)\n",
    "#     cameraToObjDir = np.dot(np.linalg.inv(objectMat), np.concatenate([objPos+cameraToObjDir, [1]]).reshape([4, 1])).flatten()\n",
    "#     cameraToObjDir = cameraToObjDir[:-1]/cameraToObjDir[-1]\n",
    "    ## in object space from world space\n",
    "    cameraPosObjSpace = np.dot(np.linalg.inv(objectMat), np.concatenate([objPos-cameraToObjDir, [1]]).reshape([4, 1])).flatten()\n",
    "    cameraPosObjSpace = cameraPosObjSpace[:-1]/cameraPosObjSpace[-1]\n",
    "    cameraToObjDir = np.zeros(3)-cameraPosObjSpace\n",
    "    cameraToObjDir /= np.linalg.norm(cameraToObjDir)\n",
    "\n",
    "    return np.abs(np.arccos(np.clip(np.dot(cameraToObjDir.reshape([1, 3]), filmedObject.cameraToObjectDirectionsObjSpace.T), -1.0, 1.0))*180.0/np.pi).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filmedSceneData = {DICT_FILMED_SCENE_BASE_LOC : \"/home/ilisescu/PhD/data/havana/\",\n",
    "#                    DICT_CAMERA_EXTRINSICS : np.array([[0.820045839796, 0.57100067645, -0.0385103638868, 1.67922756789],\n",
    "#                                                       [0.22275752409, -0.380450047102, -0.897572753108, -0.831720502302],\n",
    "#                                                       [-0.527165918942, 0.727472328789, -0.439181175316, 6.76268742928],\n",
    "#                                                       [0.0, 0.0, 0.0, 1.0]], np.float32),\n",
    "#                    DICT_CAMERA_INTRINSICS : np.array([[702.736053, 0.0, 640.0],\n",
    "#                                                       [0.0, 702.736053, 360.0],\n",
    "#                                                       [0.0, 0.0, 1.0]]),\n",
    "#                    DICT_DISTORTION_PARAMETER : -0.19,\n",
    "#                    DICT_DISTORTION_RATIO : -0.19,\n",
    "#                    DICT_DOWNSAMPLED_FRAMES_RATE : 4,\n",
    "#                    DICT_COMMENTS : \"the extrinsics are fit using a square defined by checking the vanishing line and taking into account the aspect ratio of the rectangle I fit (rather that assuming it is square)\"}\n",
    "\n",
    "# np.save(\"/home/ilisescu/PhD/data/havana/filmed_scene-havana.npy\", filmedSceneData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tmp = np.array([[0.820045839796, 0.57100067645, -0.0385103638868, 1.67922756789],\n",
    "#                 [0.22275752409, -0.380450047102, -0.897572753108, -0.831720502302],\n",
    "#                 [-0.527165918942, 0.727472328789, -0.439181175316, 6.76268742928],\n",
    "#                 [0.0, 0.0, 0.0, 1.0]], np.float32)\n",
    "# print(np.linalg.inv(tmp))\n",
    "# tmp = np.array([[0.837692028578, 0.146962583737, 0.525998159919, -1.31690405468],\n",
    "#                 [0.546141040765, -0.222903435553, -0.807492428454, 1.23665978954],\n",
    "#                 [-0.00142437669339, 0.963699152952, -0.266986729541, 0.164402319713],\n",
    "#                 [0.0, 0.0, 0.0, 1.0]], np.float32)\n",
    "# print(np.linalg.inv(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filmedSceneData = {DICT_FILMED_SCENE_BASE_LOC : \"/media/ilisescu/Data1/PhD/data/theme_park_sunny/\",\n",
    "#                    DICT_CAMERA_EXTRINSICS : np.array([[0.733156815131, 0.679921283997, 0.013716121742, 0.455885725879],\n",
    "#                                                       [0.0618491087665, -0.0465791408423, -0.996998029779, 0.265190959012],\n",
    "#                                                       [-0.677241295383, 0.73180423011, -0.0762023399981, 2.70396742177],\n",
    "#                                                       [0.0, 0.0, 0.0, 1.0]], np.float32),\n",
    "#                    DICT_CAMERA_INTRINSICS : np.array([[1275.186144, 0.0, 480.0],\n",
    "#                                                       [0.0, 1275.186144, 270.0],\n",
    "#                                                       [0.0, 0.0, 1.0]]),\n",
    "#                    DICT_DISTORTION_PARAMETER : -0.3,\n",
    "#                    DICT_DISTORTION_RATIO : -0.19,\n",
    "#                    DICT_DOWNSAMPLED_FRAMES_RATE : 4,\n",
    "#                    DICT_COMMENTS : \"the extrinsics are fit using a square defined by checking the vanishing line and taking into account the aspect ratio of the rectangle I fit (rather that assuming it is square)\"}\n",
    "\n",
    "# np.save(\"/media/ilisescu/Data1/PhD/data/theme_park_sunny/filmed_scene-theme_park_sunny.npy\", filmedSceneData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # filmedSceneLoc = \"/media/ilisescu/Data1/PhD/data/theme_park_sunny/filmed_scene-theme_park_sunny.npy\"\n",
    "# filmedSceneLoc = \"/home/ilisescu/PhD/data/havana/filmed_scene-havana.npy\"\n",
    "# filmedSceneData = np.load(filmedSceneLoc).item()\n",
    "\n",
    "# cameraExtrinsics = filmedSceneData[DICT_CAMERA_EXTRINSICS]\n",
    "\n",
    "# cameraIntrinsics = filmedSceneData[DICT_CAMERA_INTRINSICS]\n",
    "# originalIntrinsics = np.copy(cameraIntrinsics)\n",
    "\n",
    "# medianImage = np.array(Image.open(filmedSceneData[DICT_FILMED_SCENE_BASE_LOC]+\"median.png\"), np.uint8)\n",
    "\n",
    "# if DICT_DISTORTION_PARAMETER in filmedSceneData.keys() and DICT_DISTORTION_RATIO in filmedSceneData.keys() :\n",
    "#     medianImage, cameraIntrinsics, distortionCoeff, map1, map2 = undistortImage(filmedSceneData[DICT_DISTORTION_PARAMETER], filmedSceneData[DICT_DISTORTION_RATIO], medianImage, cameraIntrinsics)\n",
    "    \n",
    "# figure(); imshow(medianImage)\n",
    "# T = np.dot(cameraIntrinsics, cameraExtrinsics[:-1, [0, 1, 3]])\n",
    "# worldSquareToUse = np.array([[-4, -2], [-4, 3], [1, 3], [1, -2]], float)\n",
    "# cameraSquareToUse = np.dot(T, np.concatenate([worldSquareToUse, np.ones([4, 1])], axis=1).T)\n",
    "# cameraSquareToUse = (cameraSquareToUse[:-1, :]/cameraSquareToUse[-1, :]).T\n",
    "# scatter(cameraSquareToUse[:, 0], cameraSquareToUse[:, 1])\n",
    "\n",
    "# texSize = 1024\n",
    "# homography = cv2.findHomography(cameraSquareToUse, np.array([[0, texSize], [0, 0], [texSize, 0], [texSize, texSize]], float))[0]\n",
    "# tmp = cv2.warpPerspective(medianImage, homography, (texSize, texSize))\n",
    "# figure(); imshow(tmp)#; xlim([0, texSize]), ylim([0, texSize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.imshow(medianImage)\n",
    "\n",
    "# clickedPoints = np.empty([0, 2])\n",
    "\n",
    "# def onclick(event):\n",
    "# #     print('button=%d, x=%d, y=%d, xdata=%f, ydata=%f' %\n",
    "# #           (event.button, event.x, event.y, event.xdata, event.ydata))\n",
    "#     global clickedPoints\n",
    "#     if event.xdata is not None and event.ydata is not None :\n",
    "#         clickedPoints = np.concatenate([clickedPoints, np.array([[event.xdata, event.ydata]])])\n",
    "#         cla()\n",
    "#         gca().imshow(medianImage)\n",
    "#         xlim([0, medianImage.shape[1]-1]); ylim([medianImage.shape[0]-1, 0])\n",
    "#         gca().plot(clickedPoints[:, 0], clickedPoints[:, 1])\n",
    "#         show()\n",
    "#         print(clickedPoints); sys.stdout.flush()\n",
    "\n",
    "# cid = fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## theme park\n",
    "# cameraGroundPoints = np.array([[2.25268817, 434.08064516],\n",
    "#                                [640.0625, 350.75],\n",
    "#                                [1018.875, 411.9375],\n",
    "#                                [1023., 574.875],\n",
    "#                                [1.375, 574.875]])\n",
    "# segmentsToExtrude = [0, 1, 2, 4]\n",
    "\n",
    "## havana\n",
    "# cameraGroundPoints = np.array([[17.30645161290323, 928.4677419354839],\n",
    "#                                [295.85349462365593, 783.5981182795698],\n",
    "#                                [125.68212365591393, 345.3790322580645],\n",
    "#                                [230.23185483870964, 332.0322580645161],\n",
    "#                                [342.5672043010752, 414.33736559139777],\n",
    "#                                [520.5241935483871, 365.3991935483871],\n",
    "#                                [479.3716397849462, 344.26680107526875],\n",
    "#                                [544.9932795698925, 325.35887096774195],\n",
    "#                                [887.5604838709678, 384.307123655914],\n",
    "#                                [1106.6700268817206, 263.07392473118273],\n",
    "#                                [1364.7076612903227, 289.76747311827955],\n",
    "#                                [1531.5423387096776, 457.7143817204301],\n",
    "#                                [1648.3266129032259, 468.8366935483871],\n",
    "#                                [1652.7755376344087, 928.1881720430106]])\n",
    "# segmentsToExtrude = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "# filmedSceneData[DICT_GROUND_MESH_POINTS] = cameraGroundPoints\n",
    "# filmedSceneData[DICT_GROUND_MESH_SEGS_EXTRUDE] = segmentsToExtrude\n",
    "# np.save(filmedSceneLoc, filmedSceneData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## make texture out of medianImage\n",
    "# possibleTexSizes = np.array([128, 256, 512, 1024, 2048])\n",
    "# texSize = possibleTexSizes[np.argwhere(possibleTexSizes-np.max(medianImage.shape[0:2]) >= 0).flatten()[0]]\n",
    "# medianTex = np.zeros([texSize, texSize, 4], np.int8)\n",
    "# medianTex[:medianImage.shape[0], :medianImage.shape[1], :medianImage.shape[2]] = medianImage\n",
    "# ## set alpha channel if inout image is just rgb\n",
    "# medianTex[:medianImage.shape[0], :medianImage.shape[1], -1] = np.int8(255)\n",
    "# [maxV, maxU] = np.array(medianImage.shape[:2], np.float32)/np.array(medianTex.shape[:2], np.float32)\n",
    "\n",
    "# cameraGroundPoints = np.array([[2.25268817, 434.08064516],\n",
    "#                                [640.0625, 350.75],\n",
    "#                                [1018.875, 411.9375],\n",
    "#                                [1023., 574.875],\n",
    "#                                [1.375, 574.875]])\n",
    "# worldGroundPoints = np.dot(np.linalg.inv(np.dot(cameraIntrinsics, cameraExtrinsics[:-1, [0, 1, 3]])), np.concatenate([cameraGroundPoints, np.ones([len(cameraGroundPoints), 1])], axis=1).T)\n",
    "# worldGroundPoints = np.vstack([worldGroundPoints[:-1, :]/worldGroundPoints[-1, :], np.zeros([1, len(cameraGroundPoints)])]).T\n",
    "# ## now figure out vertices, indices and uvs but for this specific case --> there must be an automatic way to figure this out though\n",
    "# vertices = worldGroundPoints[[0, 2, 1, 0, 3, 2, 0, 4, 3], :].astype(np.float32)\n",
    "# indices = np.arange(len(vertices), dtype=np.int32)\n",
    "# ## texture coords origin is bottom left which is why the stuff below does height-ycoord for all camera space points\n",
    "# texCoords = (np.array([[0, medianImage.shape[0]]])+(np.array([[1, -1]])*cameraGroundPoints))/texSize\n",
    "# ## the image is placed at the top of texture so the origin of the image is at (0, maxV) while texCoords assumes it's at (0, 0)\n",
    "# texCoords += np.array([[0.0, maxV]])\n",
    "# uvs = texCoords[[0, 2, 1, 0, 3, 2, 0, 4, 3], :].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# viewMat, projectionMat = cvCameraToOpenGL(cameraExtrinsics, cameraIntrinsics, medianImage.shape[0:2])\n",
    "# print(worldGroundPoints)\n",
    "# print(np.dot(np.dot(projectionMat, viewMat), np.hstack([worldGroundPoints, np.ones([len(worldGroundPoints), 1])]).T)/\n",
    "#       np.dot(np.dot(projectionMat, viewMat), np.hstack([worldGroundPoints, np.ones([len(worldGroundPoints), 1])]).T)[-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# figure(); imshow(medianImage)\n",
    "# plot(cameraGroundPoints[[3, 4, 0, 3, 2, 0, 1, 2], 0], cameraGroundPoints[[3, 4, 0, 3, 2, 0, 1, 2], 1], c=\"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GLProjectiveTextureMesh() :\n",
    "    def __init__(self, vertices, indices, texture, projectionMVP, modelMat=np.eye(4, dtype=np.float32)) :\n",
    "        self.initDone = False\n",
    "        self.textureChanged = True\n",
    "        \n",
    "        self.modelMat = np.copy(modelMat).astype(np.float32)\n",
    "        self.projectionMVP = np.copy(projectionMVP).astype(np.float32)\n",
    "        self.vertices = np.copy(vertices).astype(np.float32)\n",
    "        self.indices = np.copy(indices).astype(np.int32)\n",
    "#         self.uvzs = np.copy(uvzs).astype(np.float32)\n",
    "        self.tex = np.copy(texture).astype(np.int8)\n",
    "        \n",
    "        self.setGeometryAndBuffers()\n",
    "        \n",
    "    def __del__(self) :\n",
    "        del self.tex, self.vertices, self.indices #, self.uvzs\n",
    "        \n",
    "    def setGeometryAndBuffers(self) :\n",
    "        self.verticesBuffer = glvbo.VBO(self.vertices, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        self.indexBuffer = glvbo.VBO(self.indices, gl.GL_STATIC_DRAW, gl.GL_ELEMENT_ARRAY_BUFFER)\n",
    "#         self.uvzsBuffer = glvbo.VBO(self.uvzs, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        \n",
    "    def setShaders(self) :\n",
    "        self.projectiveTextureShadersProgram = compileShaders(VS_PROJECTIVE, FS_PROJECTIVE)\n",
    "        if self.projectiveTextureShadersProgram is None :\n",
    "            self.initDone = False\n",
    "            return\n",
    "        self.initDone = True\n",
    "                \n",
    "        self.textureID = gl.glGenTextures(1)\n",
    "        gl.glPixelStorei(gl.GL_UNPACK_ALIGNMENT,1)\n",
    "        \n",
    "    def draw(self, projectionMat, viewMat) :\n",
    "        if self.initDone :\n",
    "            gl.glUseProgram(self.projectiveTextureShadersProgram)\n",
    "\n",
    "            ## send mvp\n",
    "            gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.projectiveTextureShadersProgram, \"m_pvm\"), 1, gl.GL_FALSE,\n",
    "                                  np.dot(projectionMat, np.dot(viewMat, self.modelMat)).T)\n",
    "            \n",
    "            gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.projectiveTextureShadersProgram, \"m_proj_mat\"), 1, gl.GL_FALSE,\n",
    "                                  self.projectionMVP.T)\n",
    "\n",
    "            if self.textureChanged :\n",
    "                gl.glBindTexture(gl.GL_TEXTURE_2D, self.textureID)\n",
    "                gl.glTexImage2D(gl.GL_TEXTURE_2D, 0, gl.GL_RGBA, self.tex.shape[1], self.tex.shape[0], 0, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, self.tex)\n",
    "                gl.glTexParameterf(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_WRAP_S, gl.GL_CLAMP)\n",
    "                gl.glTexParameterf(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_WRAP_T, gl.GL_CLAMP)\n",
    "                gl.glTexParameterf(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MAG_FILTER, gl.GL_NEAREST)\n",
    "                gl.glTexParameterf(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MIN_FILTER, gl.GL_LINEAR_MIPMAP_LINEAR)\n",
    "                gl.glTexParameterf(gl.GL_TEXTURE_2D, tfa.GL_TEXTURE_MAX_ANISOTROPY_EXT, gl.glGetFloatv(tfa.GL_MAX_TEXTURE_MAX_ANISOTROPY_EXT))\n",
    "                gl.glGenerateMipmap(gl.GL_TEXTURE_2D)\n",
    "                self.textureChanged = False\n",
    "\n",
    "            gl.glActiveTexture(gl.GL_TEXTURE0)\n",
    "            gl.glBindTexture(gl.GL_TEXTURE_2D, self.textureID)\n",
    "            gl.glUniform1i(gl.glGetUniformLocation(self.projectiveTextureShadersProgram, \"texture_sampler\"), 0)\n",
    "\n",
    "            ## bind the index buffer\n",
    "            self.indexBuffer.bind()\n",
    "\n",
    "            ## bind the VBO with vertex data\n",
    "            self.verticesBuffer.bind()\n",
    "            gl.glEnableVertexAttribArray(0)\n",
    "            # tell OpenGL that the VBO contains an array of vertices\n",
    "            # these vertices contain 3 single precision coordinates\n",
    "            gl.glVertexAttribPointer(0, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "            ## bind the VBO with uv data\n",
    "#             self.uvzsBuffer.bind()\n",
    "#             gl.glEnableVertexAttribArray(1)\n",
    "#             gl.glVertexAttribPointer(1, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "            ## draw points from the VBO\n",
    "            gl.glDrawElements(gl.GL_TRIANGLES, len(self.indices), gl.GL_UNSIGNED_INT, None)\n",
    "\n",
    "            ## clean up\n",
    "            gl.glDisableVertexAttribArray(0)\n",
    "            gl.glDisableVertexAttribArray(1)\n",
    "\n",
    "            gl.glUseProgram(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# T = np.dot(cameraIntrinsics, cameraExtrinsics[:-1, [0, 1, 3]])\n",
    "# ## this has to be a square or else I'll get problems further down\n",
    "# worldSquareToUse = np.array([[-4, -2], [-4, 3], [1, 3], [1, -2]], float)\n",
    "# cameraSquareToUse = np.dot(T, np.concatenate([worldSquareToUse, np.ones([4, 1])], axis=1).T)\n",
    "# cameraSquareToUse = (cameraSquareToUse[:-1, :]/cameraSquareToUse[-1, :]).T\n",
    "# texSize = 2000\n",
    "# ## the cameraSquare needs the y coords flipped\n",
    "# ## the world square should be np.array([[0, texSize], [0, 0], [texSize, 0], [texSize, texSize]], float) but if I don't flip it vertically, the coordinate systems don't match\n",
    "# homography = cv2.findHomography(cameraSquareToUse, np.array([[0, texSize], [0, 0], [texSize, 0], [texSize, texSize]], float))[0]\n",
    "# tmp = cv2.warpPerspective(medianImage, homography, (texSize, texSize))\n",
    "# figure(); imshow(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VIDEO_PLAYBACK_FPS = 15\n",
    "class GLFilmedScene() :\n",
    "    def __init__(self, filmedSceneLoc, videoFPS=30, downsampleRate=4, frustumScale=0.5, pointSize=4.0) :\n",
    "        self.initDone = False\n",
    "        self.initFailed = False\n",
    "        self.doRenderModifiedScene = True\n",
    "        self.gridPointToPlaceObjectAt = -1\n",
    "        self.videoFPS = videoFPS\n",
    "        self.playbackFrameSkip = videoFPS/VIDEO_PLAYBACK_FPS\n",
    "        self.downsampleRate = downsampleRate\n",
    "        self.pointSize = np.float32(pointSize)\n",
    "        self.distortionCoeff = np.zeros(5)\n",
    "        self.currentFilmedObject = -1\n",
    "        self.modifiedScene = None\n",
    "        self.costOnGrid = None\n",
    "        \n",
    "        ## loading dictionary containing all necessary data\n",
    "        self.filmedSceneData = np.load(filmedSceneLoc).item()\n",
    "        \n",
    "        self.cameraExtrinsics = self.filmedSceneData[DICT_CAMERA_EXTRINSICS]\n",
    "        self.modelMat = np.linalg.inv(self.cameraExtrinsics)\n",
    "        \n",
    "        self.cameraIntrinsics = self.filmedSceneData[DICT_CAMERA_INTRINSICS]\n",
    "        originalIntrinsics = np.copy(self.cameraIntrinsics)\n",
    "        \n",
    "#         self.medianImage = np.array(Image.open(self.filmedSceneData[DICT_FILMED_SCENE_BASE_LOC]+\"frame-01499.png\"), np.uint8)\n",
    "        self.medianImage = np.array(Image.open(self.filmedSceneData[DICT_FILMED_SCENE_BASE_LOC]+os.sep+\"median.png\"), np.uint8)\n",
    "        \n",
    "        if DICT_DISTORTION_PARAMETER in self.filmedSceneData.keys() and DICT_DISTORTION_RATIO in self.filmedSceneData.keys() :\n",
    "            self.isDistorted = True\n",
    "            self.medianImage, self.cameraIntrinsics, self.distortionCoeff, map1, map2 = undistortImage(self.filmedSceneData[DICT_DISTORTION_PARAMETER], self.filmedSceneData[DICT_DISTORTION_RATIO],\n",
    "                                                                                                       self.medianImage, self.cameraIntrinsics)\n",
    "        else :\n",
    "            self.isDistorted = False\n",
    "            \n",
    "#         self.projectImageGridPoints(self.medianImage)\n",
    "        \n",
    "        self.filmedFramesLocs = np.sort(glob.glob(self.filmedSceneData[DICT_FILMED_SCENE_BASE_LOC]+os.sep+\"frame-*.png\"))\n",
    "        if len(self.filmedFramesLocs) > 0 :\n",
    "            self.currentFrame = 0\n",
    "            downsampledLoc = self.filmedSceneData[DICT_FILMED_SCENE_BASE_LOC]+os.sep+\"downsampledSet-\"+np.string_(self.downsampleRate)+\"x.npy\"\n",
    "            if DICT_DOWNSAMPLED_FRAMES_RATE not in self.filmedSceneData.keys() or self.filmedSceneData[DICT_DOWNSAMPLED_FRAMES_RATE] != self.downsampleRate :\n",
    "                self.filmedSceneData[DICT_DOWNSAMPLED_FRAMES_RATE] = self.downsampleRate\n",
    "                np.save(filmedSceneLoc, self.filmedSceneData)\n",
    "                \n",
    "            if os.path.isfile(downsampledLoc) :\n",
    "                print(\"LOADING\", downsampledLoc); sys.stdout.flush()\n",
    "                self.allFrames = np.load(downsampledLoc)\n",
    "            else :\n",
    "                print(\"WRITING\", downsampledLoc); sys.stdout.flush()\n",
    "                if self.isDistorted :\n",
    "                    firstImg = Image.fromarray(cv2.remap(np.array(Image.open(self.filmedFramesLocs[0])), map1, map2, cv2.INTER_LINEAR).astype(np.uint8))\n",
    "                else :\n",
    "                    firstImg = Image.open(self.filmedFramesLocs[0])\n",
    "                firstImg.thumbnail((firstImg.width/self.downsampleRate, firstImg.height/self.downsampleRate), Image.ANTIALIAS)\n",
    "                firstImg = np.array(firstImg, np.int8)\n",
    "                self.allFrames = np.zeros([len(self.filmedFramesLocs), firstImg.shape[0], firstImg.shape[1], firstImg.shape[2]], np.int8)\n",
    "                self.allFrames[0, :, :, :] = firstImg\n",
    "                for i, imageLoc in enumerate(self.filmedFramesLocs[1:3000]) :\n",
    "                    if self.isDistorted :\n",
    "                        img = Image.fromarray(cv2.remap(np.array(Image.open(imageLoc)), map1, map2, cv2.INTER_LINEAR).astype(np.uint8))\n",
    "                    else :\n",
    "                        img = Image.open(imageLoc)\n",
    "                    img.thumbnail((firstImg.shape[1], firstImg.shape[0]), Image.ANTIALIAS)\n",
    "                    self.allFrames[i, :, :, :] = np.array(img, np.int8)\n",
    "                np.save(downsampledLoc, self.allFrames)\n",
    "#             [self.maxV, self.maxU], self.aspectRatio = self.setFrame(self.allFrames[self.currentFrame, :, :, :])\n",
    "            self.aspectRatio = float(self.allFrames[self.currentFrame, :, :, :].shape[1])/float(self.allFrames[self.currentFrame, :, :, :].shape[0])\n",
    "#             self.setGeometryAndBuffers()\n",
    "\n",
    "            self.playTimer = QtCore.QTimer()\n",
    "            self.playTimer.setInterval(1000/VIDEO_PLAYBACK_FPS)\n",
    "            self.playTimer.timeout.connect(self.requestRender)\n",
    "    #             self.playTimer.start()\n",
    "             \n",
    "            self.cameraFrustum = GLCameraFrustum(self.modelMat, self.allFrames[self.currentFrame, :, :, :], frustumScale)\n",
    "        else :\n",
    "            self.initFailed = True\n",
    "            \n",
    "        self.filmedObjects = []\n",
    "#         for loc in np.sort(glob.glob(filmedSceneLoc+\"semantic_sequence-*.npy\"))[7:8] :\n",
    "        for loc in np.sort(glob.glob(self.filmedSceneData[DICT_FILMED_SCENE_BASE_LOC]+os.sep+\"filmed_object-*.npy\")) :\n",
    "            self.filmedObjects.append(GLFilmedObject(loc, self.cameraIntrinsics, np.linalg.inv(self.modelMat), self.isDistorted, self.distortionCoeff, originalIntrinsics))\n",
    "            \n",
    "        self.showFilmedObject(0)\n",
    "        \n",
    "#         ## PROJECTED GROUND PLANE ONTO BILLBOARD\n",
    "#         T = np.dot(self.cameraIntrinsics, self.cameraExtrinsics[:-1, [0, 1, 3]])\n",
    "#         ## this has to be a square or else I'll get problems further down\n",
    "#         worldSquareToUse = np.array([[-4, -2], [-4, 3], [1, 3], [1, -2]], float)\n",
    "#         cameraSquareToUse = np.dot(T, np.concatenate([worldSquareToUse, np.ones([4, 1])], axis=1).T)\n",
    "#         cameraSquareToUse = (cameraSquareToUse[:-1, :]/cameraSquareToUse[-1, :]).T\n",
    "#         texSize = 2000\n",
    "#         ## the cameraSquare needs the y coords flipped\n",
    "#         ## the world square should be np.array([[0, texSize], [0, 0], [texSize, 0], [texSize, texSize]], float) but if I don't flip it vertically, the coordinate systems don't match\n",
    "#         homography = cv2.findHomography(cameraSquareToUse, np.array([[0, texSize], [0, 0], [texSize, 0], [texSize, texSize]], float))[0]\n",
    "#         tmp = cv2.warpPerspective(self.medianImage, homography, (texSize, texSize))\n",
    "#         position = line2lineIntersection(worldSquareToUse[[0, 2], :].flatten(), worldSquareToUse[[1, 3], :].flatten())\n",
    "#         self.sceneMesh = GLBillboard(tmp, np.max(worldSquareToUse[:, 0])-np.min(worldSquareToUse[:, 0]), np.array([[1, 0, 0, position[0]], [0, 1, 0, position[1]], [0, 0, 1, 0], [0, 0, 0, 1]], dtype=np.float32),\n",
    "#                                      False, None, False)\n",
    "\n",
    "        ## TEXTURED MESH FOR GROUND PLANE\n",
    "#         cameraGroundPoints = np.array([[2.25268817, 434.08064516],\n",
    "#                                        [640.0625, 350.75],\n",
    "#                                        [1018.875, 411.9375],\n",
    "#                                        [1023., 574.875],\n",
    "#                                        [1.375, 574.875]])\n",
    "        cameraGroundPoints = self.filmedSceneData[DICT_GROUND_MESH_POINTS]\n",
    "        worldGroundPoints = np.dot(np.linalg.inv(np.dot(self.cameraIntrinsics, self.cameraExtrinsics[:-1, [0, 1, 3]])), np.concatenate([cameraGroundPoints, np.ones([len(cameraGroundPoints), 1])], axis=1).T)\n",
    "        worldGroundPoints = np.vstack([worldGroundPoints[:-1, :]/worldGroundPoints[-1, :], np.zeros([1, len(cameraGroundPoints)])]).T\n",
    "        ## now triangulate the points \n",
    "        triangleIndices = np.array(triangulate2DPolygon(worldGroundPoints[:, :-1])).flatten()\n",
    "        vertices = worldGroundPoints[triangleIndices, :].astype(np.float32)\n",
    "        indices = np.arange(len(vertices), dtype=np.int32)\n",
    "        projectionViewMat, projectionProjectionMat = cvCameraToOpenGL(self.cameraExtrinsics, self.cameraIntrinsics, self.medianImage.shape[0:2])\n",
    "        \n",
    "        ## extrude some worldGroundPoints up to get some walls\n",
    "        segmentsToExtrude = self.filmedSceneData[DICT_GROUND_MESH_SEGS_EXTRUDE]\n",
    "        segmentsToExtrudeIndices = [[segment, (segment+1) % len(worldGroundPoints)] for segment in segmentsToExtrude]\n",
    "        for segment in segmentsToExtrudeIndices :\n",
    "            newVertices, newIndices = extrudeSegment(worldGroundPoints[segment, :], 5.0, np.linalg.inv(self.cameraExtrinsics)[:-1, -1])\n",
    "            vertices = np.concatenate([vertices, newVertices.astype(np.float32)], axis=0)\n",
    "        indices = np.arange(len(vertices), dtype=np.int32)\n",
    "        \n",
    "        self.sceneMesh = GLProjectiveTextureMesh(vertices, indices, np.concatenate([self.medianImage, np.ones([self.medianImage.shape[0], self.medianImage.shape[1], 1])*255], axis=-1).astype(np.int8),\n",
    "                                                 np.dot(projectionProjectionMat, projectionViewMat))\n",
    "        \n",
    "    ## not sure this actually cleans up properly\n",
    "    def __del__(self) :\n",
    "        del self.allFrames, self.filmedFramesLocs, self.filmedObjects, self.cameraFrustum, self.modifiedScene, self.costOnGrid, self.filmedSceneData, self.sceneMesh\n",
    "        \n",
    "    def showFilmedObject(self, idx) :\n",
    "        if idx >= 0 and idx < len(self.filmedObjects) and idx != self.currentFilmedObject :\n",
    "            self.currentFilmedObject = idx\n",
    "            if self.modifiedScene is not None : \n",
    "                del self.modifiedScene\n",
    "                self.modifiedScene = None\n",
    "            if self.costOnGrid is not None :\n",
    "                del self.costOnGrid\n",
    "                self.costOnGrid = None\n",
    "                \n",
    "            self.modifiedScene = GLModifiedScene(self.medianImage, self.filmedObjects[self.currentFilmedObject], self.cameraExtrinsics, self.cameraIntrinsics)\n",
    "            \n",
    "            cameraGroundPoints = self.filmedSceneData[DICT_GROUND_MESH_POINTS]\n",
    "            worldGroundPoints = np.dot(np.linalg.inv(np.dot(self.cameraIntrinsics, self.cameraExtrinsics[:-1, [0, 1, 3]])), np.concatenate([cameraGroundPoints, np.ones([len(cameraGroundPoints), 1])], axis=1).T)\n",
    "            worldGroundPoints = np.vstack([worldGroundPoints[:-1, :]/worldGroundPoints[-1, :], np.zeros([1, len(cameraGroundPoints)])]).T\n",
    "            \n",
    "            self.costOnGrid = GLCostOnGrid(self.filmedObjects[self.currentFilmedObject], worldGroundPlanePoints=worldGroundPoints)\n",
    "            \n",
    "            if self.initDone :\n",
    "                self.modifiedScene.setShaders()\n",
    "                self.costOnGrid.setShaders()\n",
    "                \n",
    "            return True\n",
    "        else :\n",
    "            return False\n",
    "        \n",
    "    def projectImageGridPoints(self, img) :\n",
    "        frameSize = np.array([img.shape[1], img.shape[0]])\n",
    "        gridDownsample = 1\n",
    "        self.projectedImageGridPoints = np.indices(frameSize/gridDownsample).reshape([2, np.prod(frameSize/gridDownsample)]).T*gridDownsample\n",
    "        self.projectedImageGridColors = img[self.projectedImageGridPoints[:, 1], self.projectedImageGridPoints[:, 0], :].astype(np.float32)/np.float32(255.0)\n",
    "        if True :\n",
    "#             cameraExtrinsics = np.array(self.modelMat.inverted()[0].data()).reshape([4, 4]).T\n",
    "            print(\"README\", self.cameraExtrinsics)\n",
    "            inverseT = np.linalg.inv(np.dot(self.cameraIntrinsics, self.cameraExtrinsics[:-1, [0, 1, 3]]))\n",
    "            self.projectedImageGridPoints = np.dot(inverseT, np.concatenate([self.projectedImageGridPoints, np.ones([len(self.projectedImageGridPoints), 1], np.float32)], axis=1).T)\n",
    "            self.projectedImageGridPoints /= self.projectedImageGridPoints[-1, :]\n",
    "            self.projectedImageGridPoints[-1, :] = 0\n",
    "            self.projectedImageGridPoints = self.projectedImageGridPoints.T.astype(np.float32)\n",
    "            \n",
    "        else :\n",
    "            ### HACK : USE HOMOGRAPHY INSTEAD OF CAMERA MATRICES ###\n",
    "            homography = np.array([[11.6261525276, 185.257281938, 818.145590521],\n",
    "                                   [-24.7005245641, 14.5276400234, 272.499203107],\n",
    "                                   [-0.197073111956, 0.178268418299, 1.0]])\n",
    "            self.projectedImageGridPoints = np.dot(np.linalg.inv(homography), np.concatenate([self.projectedImageGridPoints.astype(np.float32), np.ones([len(self.projectedImageGridPoints), 1], np.float32)], axis=1).T)\n",
    "            self.projectedImageGridPoints /= self.projectedImageGridPoints[-1, :]\n",
    "            self.projectedImageGridPoints[-1, :] = 0\n",
    "            self.projectedImageGridPoints = self.projectedImageGridPoints.T.astype(np.float32)\n",
    "        print(\"RANGE OF POINTS\", np.min(self.projectedImageGridPoints, axis=0), np.max(self.projectedImageGridPoints, axis=0))\n",
    "    \n",
    "    def setFrustumScaleDelta(self, scaleDelta) :\n",
    "        if scaleDelta < 0.0 :\n",
    "            self.cameraFrustum.setScale(np.max([0.01, scaleDelta+self.cameraFrustum.scale]))\n",
    "        else :\n",
    "            self.cameraFrustum.setScale(np.min([50.0, scaleDelta+self.cameraFrustum.scale]))\n",
    "            \n",
    "    def toggleShowFrustumBillboard(self) :\n",
    "        self.cameraFrustum.toggleShowFrustumBillboard()\n",
    "        \n",
    "    def setPointSize(self, pointSize) :\n",
    "        self.pointSize = np.float32(pointSize)\n",
    "#         self.setGeometryAndBuffers()\n",
    "\n",
    "    def placeObjectOnNextCostGridPointAtBestOrientation(self, doGoForward) :\n",
    "        if doGoForward :\n",
    "            self.gridPointToPlaceObjectAt = np.mod(self.gridPointToPlaceObjectAt+1, len(self.costOnGrid.gridPoints))\n",
    "        else :\n",
    "            self.gridPointToPlaceObjectAt = self.gridPointToPlaceObjectAt-1\n",
    "            if self.gridPointToPlaceObjectAt < 0 :\n",
    "                self.gridPointToPlaceObjectAt = len(self.costOnGrid.gridPoints) - 1\n",
    "                \n",
    "        objPos, bestMatchesCost, bestOrientationMatchCost, bestOrientationMatchFrameIdx, bestOrientationModelMat = self.costOnGrid.getCostsAtGridPoint(self.gridPointToPlaceObjectAt,\n",
    "                                                                                                                                                       self.filmedObjects[self.currentFilmedObject])\n",
    "        self.filmedObjects[self.currentFilmedObject].setObjectModelMat(bestOrientationModelMat)\n",
    "        \n",
    "    def setGeometryAndBuffers(self) :\n",
    "        if False and not self.initFailed :\n",
    "            ## PROJECTED IMAGE POINTS ##\n",
    "            self.gridIndices = np.arange(len(self.projectedImageGridPoints)).astype(np.int32)\n",
    "\n",
    "            self.gridIndexBuffer = glvbo.VBO(self.gridIndices, gl.GL_STATIC_DRAW, gl.GL_ELEMENT_ARRAY_BUFFER)\n",
    "            self.gridVerticesBuffer = glvbo.VBO(self.projectedImageGridPoints, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "            self.gridColorBuffer = glvbo.VBO(self.projectedImageGridColors, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        \n",
    "    def requestRender(self) :\n",
    "        if not self.initFailed :\n",
    "            self.currentFrame = np.mod(self.currentFrame+self.playbackFrameSkip, len(self.filmedFramesLocs))\n",
    "#             self.imagePlaneBillboard.setTexture(self.allFrames[self.currentFrame])\n",
    "            self.cameraFrustum.setImage(self.allFrames[self.currentFrame])\n",
    "        \n",
    "    def setShaders(self) :\n",
    "        self.colorNoShadeShadersProgram = compileShaders(VS_COLOR_NO_SHADE, FS_COLOR_NO_SHADE)\n",
    "        if self.colorNoShadeShadersProgram is None :\n",
    "            self.initDone = False\n",
    "            return\n",
    "        self.cameraFrustum.setShaders()\n",
    "        for filmedObject in self.filmedObjects :\n",
    "            filmedObject.setShaders()\n",
    "        \n",
    "        if self.modifiedScene is not None : \n",
    "            self.modifiedScene.setShaders()\n",
    "        if self.costOnGrid is not None : \n",
    "            self.costOnGrid.setShaders()\n",
    "            \n",
    "        self.sceneMesh.setShaders()\n",
    "        \n",
    "        self.initDone = True\n",
    "    \n",
    "    def isPlayerLookingAtCamera(self, projectionMat, viewMat) :\n",
    "        ## THIS WORKS BUT IT CAN START PLAYING EVEN WHEN NOT LOOKING AT THE CAMERA SINCE THE ONLY THING THAT IS IMPORTANT IS THAT THE NORMALS ARE SOMEWHAT PARALLEL AND THEY ARE CLOSE BY\n",
    "        camPos, camNorm = getWorldSpacePosAndNorm(self.modelMat)\n",
    "        viewPos, viewNorm = getWorldSpacePosAndNorm(np.linalg.pinv(viewMat), np.array([[0.0], [0.0], [-1.0], [1.0]]))\n",
    "#         print(\"README\", np.linalg.norm(camPos-viewPos), np.arccos(np.dot(camNorm, viewNorm))*180.0/np.pi, camNorm, viewNorm, np.dot(camNorm, viewNorm), np.arccos(np.dot(camNorm, viewNorm)), angle)\n",
    "        \n",
    "#         return np.linalg.norm(camPos-viewPos) < 3.0 and np.pi-np.arccos(np.dot(camNorm, viewNorm)) < 25.0*np.pi/180.0 ## I think is wrong because I was using the wrong transforamtion which assumed -1 zDir\n",
    "        return np.linalg.norm(camPos-viewPos) < 3.0 and np.arccos(np.clip(np.dot(camNorm, viewNorm), -1.0, 1.0)) < 25.0*np.pi/180.0\n",
    "    \n",
    "    def doRequestPlayVideo(self, doRequest) :\n",
    "        if doRequest :\n",
    "            if not self.playTimer.isActive() :\n",
    "                print(\"START PLAYING\"); sys.stdout.flush()\n",
    "                self.playTimer.start()\n",
    "        else :\n",
    "            if self.playTimer.isActive() :\n",
    "                print(\"STOP PLAYING\"); sys.stdout.flush()\n",
    "                self.playTimer.stop()\n",
    "        \n",
    "    def drawProjectedImageGridPoints(self, projectionMat, viewMat) :\n",
    "        if self.pointSize > 0.01 :\n",
    "            gl.glUseProgram(self.colorNoShadeShadersProgram)\n",
    "            gl.glPointSize(self.pointSize)\n",
    "\n",
    "            ## send mvp\n",
    "            gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.colorNoShadeShadersProgram, \"m_pvm\"), 1, gl.GL_FALSE, np.dot(projectionMat, viewMat).T)\n",
    "            ## send camera distance\n",
    "            gl.glUniform1f(gl.glGetUniformLocation(self.colorNoShadeShadersProgram, \"camera_dist\"), np.float32(1.0))\n",
    "    #             print(cameraDist)\n",
    "\n",
    "            ################ RENDER BODY ################\n",
    "\n",
    "            ## bind the index buffer\n",
    "            self.gridIndexBuffer.bind()\n",
    "\n",
    "            ## bind the VBO with vertex data\n",
    "            self.gridVerticesBuffer.bind()\n",
    "            gl.glEnableVertexAttribArray(0)\n",
    "            # tell OpenGL that the VBO contains an array of vertices\n",
    "            # these vertices contain 3 single precision coordinates\n",
    "            gl.glVertexAttribPointer(0, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "            ## bind the VBO with color data\n",
    "            self.gridColorBuffer.bind()\n",
    "            gl.glEnableVertexAttribArray(1)\n",
    "            gl.glVertexAttribPointer(1, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "            ## draw points from the VBO\n",
    "            gl.glDrawElements(gl.GL_POINTS, len(self.gridIndices), gl.GL_UNSIGNED_INT, None)\n",
    "\n",
    "            ## clean up\n",
    "            gl.glDisableVertexAttribArray(0)\n",
    "            gl.glDisableVertexAttribArray(1)\n",
    "\n",
    "            gl.glUseProgram(0)\n",
    "        \n",
    "    def draw(self, projectionMat, viewMat) :\n",
    "        if self.initDone and not self.initFailed :\n",
    "#             tmp = time.time()\n",
    "            self.doRequestPlayVideo(self.isPlayerLookingAtCamera(projectionMat, viewMat) and self.cameraFrustum.drawBillboard)\n",
    "#             print(\"requestePlayVideo\", time.time()-tmp)\n",
    "            \n",
    "#             tmp = time.time()\n",
    "            self.cameraFrustum.draw(projectionMat, viewMat)\n",
    "#             gl.glFinish()\n",
    "#             print(\"cameraFrustum.draw\", time.time()-tmp)\n",
    "                \n",
    "# #             tmp = time.time()\n",
    "#             if self.costOnGrid is not None :\n",
    "#                 self.costOnGrid.draw(projectionMat, viewMat)\n",
    "# #             gl.glFinish()\n",
    "# #             print(\"costOnGrid.draw\", time.time()-tmp)\n",
    "\n",
    "#             tmp = time.time()\n",
    "#             self.drawProjectedImageGridPoints(projectionMat, viewMat)\n",
    "            self.sceneMesh.draw(projectionMat, viewMat)\n",
    "#             gl.glFinish()\n",
    "#             print(\"drawProjectedImageGridPoints\", time.time()-tmp)\n",
    "                \n",
    "#             for filmedObject in self.filmedObjects :\n",
    "            if self.currentFilmedObject != -1 :\n",
    "#                 tmp = time.time()\n",
    "                self.filmedObjects[self.currentFilmedObject].draw(projectionMat, viewMat, doDrawMisc=False)\n",
    "#                 gl.glFinish()\n",
    "#                 print(\"filmedObject.draw\", time.time()-tmp)\n",
    "            \n",
    "            if self.modifiedScene is not None and self.doRenderModifiedScene :\n",
    "#                 tmp = time.time()\n",
    "                self.modifiedScene.draw(projectionMat, viewMat)\n",
    "#                 gl.glFinish()\n",
    "#                 print(\"modifiedScene.draw\", time.time()-tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GLScene() :\n",
    "    def __init__(self) :\n",
    "        self.lightDirection = np.array([[1, 1, 1, 0]], np.float32).T#QtGui.QVector4D(1.0, 1.0, 1.0, 0.0)\n",
    "        self.lightColor = np.array([1.0, 1.0, 1.0], np.float32)\n",
    "        self.lightPower = np.float32(1.0)\n",
    "        \n",
    "        self.projectionMat = np.eye(4, dtype=np.float32)\n",
    "        \n",
    "        ## set view matrix using the qt lookat function\n",
    "        self.viewMat = QtGui.QMatrix4x4()\n",
    "#         cameraPos = QtGui.QVector3D(0.0, 1.0, 6.0)\n",
    "        ## (cameraPos, cameraPos + direction, upVec) are in gl coords\n",
    "#         self.viewMat.lookAt(cameraPos, cameraPos+QtGui.QVector3D(0, 0, -1), QtGui.QVector3D(0, 1, 0))\n",
    "\n",
    "        cameraPos = QtGui.QVector3D(5.0, 6.0, 11.0)\n",
    "        self.viewMat.lookAt(cameraPos, QtGui.QVector3D(4, 0, 2), QtGui.QVector3D(0, 1, 0))\n",
    "        \n",
    "#         cameraPos = QtGui.QVector3D(0.0, 20.0, 0.0)\n",
    "#         self.viewMat.lookAt(cameraPos, QtGui.QVector3D(0, 0, 0), QtGui.QVector3D(1, 0, 0))\n",
    "        \n",
    "        \n",
    "        ## rotate gl coords to match my world coords\n",
    "        self.viewMat.rotate(-90, 1, 0, 0)\n",
    "        \n",
    "        self.viewMat = np.array(self.viewMat.data(), np.float32).reshape([4, 4]).T\n",
    "        self.width = 1280\n",
    "        self.height = 720\n",
    "        \n",
    "        \n",
    "        self.shaders_program = None\n",
    "        \n",
    "        self.doShowEdges = True\n",
    "        \n",
    "        self.axesWidget = AxesWidget()\n",
    "        self.meshes = []\n",
    "        self.filmedScenes = []\n",
    "        \n",
    "        self.currentObjectViewFrame = -1\n",
    "        self.doPlaybackObjectViews = False\n",
    "        self.doPlaybackObjectTrajectory = False\n",
    "        self.playbackLastTime = time.time()\n",
    "    \n",
    "    ## not sure this actually cleans up properly\n",
    "    def __del__(self) :\n",
    "        del self.meshes, self.filmedScenes, self.axesWidget, self.lightDirection, self.lightColor, self.lightPower\n",
    "        \n",
    "    def setShaderProgram(self, shaders_program) :\n",
    "        self.shaders_program = shaders_program\n",
    "        for i in xrange(len(self.meshes)) :\n",
    "            self.meshes[i].shaders_program = self.shaders_program\n",
    "        \n",
    "        if not self.axesWidget.initDone :\n",
    "            self.axesWidget.setShaders()\n",
    "        for i in xrange(len(self.filmedScenes)) :\n",
    "            if not self.filmedScenes[i].initDone :\n",
    "                self.filmedScenes[i].setShaders()\n",
    "        \n",
    "    def setFrustumScaleDelta(self, scaleDelta) :\n",
    "        for filmedScene in self.filmedScenes :\n",
    "            filmedScene.setFrustumScaleDelta(scaleDelta)\n",
    "            \n",
    "    def toggleShowFrustumBillboard(self) :\n",
    "        for filmedScene in self.filmedScenes :\n",
    "            filmedScene.toggleShowFrustumBillboard()\n",
    "        \n",
    "    def setPointSizeDelta(self, sizeDelta) :\n",
    "        for filmedScene in self.filmedScenes :\n",
    "            if sizeDelta < 0.0 :\n",
    "                filmedScene.setPointSize(np.max([0.01, sizeDelta+filmedScene.pointSize]))\n",
    "            else :\n",
    "                filmedScene.setPointSize(np.min([30.0, sizeDelta+filmedScene.pointSize]))\n",
    "        \n",
    "    def setCameraProjectionMat(self, cameraFOV, width, height, near=0.1, far=1000.0) :\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.projectionMat = QtGui.QMatrix4x4()\n",
    "        self.projectionMat.perspective(cameraFOV, width/float(height), near, far)\n",
    "        self.projectionMat = np.array(self.projectionMat.data(), np.float32).reshape([4, 4]).T\n",
    "        \n",
    "    def translateCamera(self, translation) :\n",
    "        viewPos, viewDir = getWorldSpacePosAndNorm(np.linalg.pinv(self.viewMat), np.array([[0.0], [0.0], [-1.0], [1.0]]))\n",
    "        viewPos, viewUp = getWorldSpacePosAndNorm(np.linalg.pinv(self.viewMat), np.array([[0.0], [1.0], [0.0], [1.0]]))\n",
    "        viewPos, viewRight = getWorldSpacePosAndNorm(np.linalg.pinv(self.viewMat), np.array([[1.0], [0.0], [0.0], [1.0]]))\n",
    "        \n",
    "        t = viewDir*translation[0] + viewRight*translation[1] + viewUp*translation[2]\n",
    "        tMat = np.array([[1, 0, 0, t[0]],\n",
    "                         [0, 1, 0, t[1]],\n",
    "                         [0, 0, 1, t[2]],\n",
    "                         [0, 0, 0, 1]], np.float32)\n",
    "        self.viewMat = np.dot(self.viewMat, np.linalg.pinv(tMat))\n",
    "\n",
    "    def rotateCamera(self, quaternion, centerPoint) :        \n",
    "        self.viewMat = np.linalg.inv(rotateAboutPoint(np.linalg.inv(self.viewMat), quaternion, centerPoint))\n",
    "        \n",
    "    def moveCameraInRange(self, x, y, rangeWidth = 1.0, rangeHeight = 1.0) :\n",
    "        \"\"\" x and y input arguments must be in range [-1, 1] \"\"\"\n",
    "        \n",
    "#         print(\"MOVING CAMERA\", x, y)\n",
    "        viewMat, projectionMat = cvCameraToOpenGL(self.filmedScenes[0].cameraExtrinsics, self.filmedScenes[0].cameraIntrinsics, self.filmedScenes[0].medianImage.shape[:2])\n",
    "        \n",
    "        self.projectionMat = projectionMat\n",
    "        \n",
    "        viewPos, viewUp = getWorldSpacePosAndNorm(np.linalg.pinv(viewMat), np.array([[0.0], [1.0], [0.0], [1.0]]))\n",
    "        viewPos, viewRight = getWorldSpacePosAndNorm(np.linalg.pinv(viewMat), np.array([[1.0], [0.0], [0.0], [1.0]]))\n",
    "        \n",
    "        t = viewRight*x*rangeWidth/2.0 + viewUp*y*rangeHeight/2.0\n",
    "        tMat = np.array([[1, 0, 0, t[0]],\n",
    "                         [0, 1, 0, t[1]],\n",
    "                         [0, 0, 1, t[2]],\n",
    "                         [0, 0, 0, 1]], np.float32)\n",
    "        self.viewMat = np.dot(viewMat, np.linalg.pinv(tMat))\n",
    "        \n",
    "        \n",
    "    ## this probably makes more sense in some other class but it's easier here for now\n",
    "    def goToCamera(self) :\n",
    "        if len(self.filmedScenes) > 0 :\n",
    "            print(\"PREVIOUS:\\n\", self.viewMat)\n",
    "            print(\"EXTRINSICS:\\n\", self.filmedScenes[0].cameraExtrinsics)\n",
    "            \n",
    "            self.viewMat = np.copy(self.filmedScenes[0].cameraExtrinsics)\n",
    "            ## flip z and y axis because of opencv vs opengl coord systems\n",
    "            self.viewMat[2, :] *= -1\n",
    "            self.viewMat[1, :] *= -1\n",
    "            print(\"VIEW:\\n\", self.viewMat)\n",
    "            \n",
    "            cameraIntrinsics = np.copy(self.filmedScenes[0].cameraIntrinsics)\n",
    "            ## changing signs for the same reason as above for the viewMat\n",
    "            cameraIntrinsics[:, 2] *= -1\n",
    "            cameraIntrinsics[:, 1] *= -1\n",
    "            near = 0.1\n",
    "            far = 100.0\n",
    "            projectionMat = np.zeros([4, 4])\n",
    "            projectionMat[:2, :-1] = cameraIntrinsics[:2, :]\n",
    "            projectionMat[-1, :-1] = cameraIntrinsics[-1, :]\n",
    "            projectionMat[2, 2] = near + far\n",
    "            projectionMat[2, 3] = near*far\n",
    "            \n",
    "            left = 0.0\n",
    "            right = float(self.filmedScenes[0].medianImage.shape[1])\n",
    "            bottom = float(self.filmedScenes[0].medianImage.shape[0])\n",
    "            top = 0.0\n",
    "            print(\"FSDFSAD\", left, right, bottom, top)\n",
    "            \n",
    "            projectionMat = np.dot(np.array([[2/(right-left), 0, 0, -(right+left)/(right-left)],\n",
    "                                             [0, 2/(top-bottom), 0, -(top+bottom)/(top-bottom)],\n",
    "                                             [0, 0, -2/(far-near), -(far+near)/(far-near)],\n",
    "                                             [0, 0, 0, 1]]), np.copy(projectionMat))\n",
    "            \n",
    "            print(\"PROJ:\\n\", self.projectionMat)\n",
    "            self.projectionMat = np.copy(projectionMat)\n",
    "            \n",
    "            \n",
    "            print(\"PROJ_NEW:\\n\", self.projectionMat)\n",
    "            \n",
    "            sys.stdout.flush()\n",
    "            ## returns new fov\n",
    "            return np.arctan2(1.0, projectionMat[1, 1])*2.0*180.0/np.pi\n",
    "            \n",
    "    ## this probably makes more sense in some other class but it's easier here for now\n",
    "    def playbackObjectAnimation(self) :\n",
    "        self.currentObjectViewFrame = np.mod(self.currentObjectViewFrame+1, len(self.filmedScenes[0].filmedObjects[self.filmedScenes[0].currentFilmedObject].cameraToObjectDirectionsObjSpace))\n",
    "#         self.currentObjectViewFrame = 191\n",
    "\n",
    "        if self.doPlaybackObjectViews :\n",
    "            self.playbackObjectViews()\n",
    "        elif self.doPlaybackObjectTrajectory :\n",
    "            self.filmedScenes[0].filmedObjects[self.filmedScenes[0].currentFilmedObject].setObjectOnTrajectory(self.currentObjectViewFrame)\n",
    "            \n",
    "            objPos = getWorldSpacePosAndNorm(self.filmedScenes[0].filmedObjects[self.filmedScenes[0].currentFilmedObject].modelMat, posOnly=True)\n",
    "            objDirPosInWorldSpace = np.dot(self.filmedScenes[0].filmedObjects[self.filmedScenes[0].currentFilmedObject].modelMat,\n",
    "                                           self.filmedScenes[0].filmedObjects[self.filmedScenes[0].currentFilmedObject].forwardDir).flatten()[:-1]\n",
    "            self.filmedScenes[0].modifiedScene.updateObjectMovementIndicators(objPos, (objDirPosInWorldSpace-objPos)/np.linalg.norm(objDirPosInWorldSpace-objPos))\n",
    "            \n",
    "            \n",
    "    def playbackObjectViews(self) :\n",
    "        ## find distance from obj to current camera\n",
    "        viewPos = getWorldSpacePosAndNorm(np.linalg.pinv(self.viewMat), posOnly=True)\n",
    "        objPos = getWorldSpacePosAndNorm(self.filmedScenes[0].filmedObjects[self.filmedScenes[0].currentFilmedObject].modelMat, posOnly=True)\n",
    "        viewToObjDir = objPos-viewPos\n",
    "        distanceToObj = np.linalg.norm(viewToObjDir)\n",
    "        viewToObjDir /= distanceToObj\n",
    "\n",
    "        ## desired direction in object space\n",
    "        desiredViewDir = self.filmedScenes[0].filmedObjects[self.filmedScenes[0].currentFilmedObject].cameraToObjectDirectionsObjSpace[self.currentObjectViewFrame, :]\n",
    "        ## direction into world space\n",
    "        ## from object to world space using modelMat\n",
    "        desiredViewDirPos = np.dot(self.filmedScenes[0].filmedObjects[self.filmedScenes[0].currentFilmedObject].modelMat, np.concatenate([np.zeros(3) - desiredViewDir, [1]]).reshape([4, 1])).flatten()\n",
    "        desiredViewDirPos = desiredViewDirPos[:-1]/desiredViewDirPos[-1]\n",
    "#         print(\"README\", np.linalg.norm(desiredViewDir))\n",
    "        desiredViewDir = objPos-desiredViewDirPos\n",
    "#         print(\"README2\", np.linalg.norm(desiredViewDir))\n",
    "        desiredViewDir /= np.linalg.norm(desiredViewDir)\n",
    "\n",
    "        camMat = np.eye(4, dtype=np.float32)\n",
    "        camMat[:-1, -1] = objPos-desiredViewDir*distanceToObj\n",
    "\n",
    "        ## rotate camera to give it the desired direction\n",
    "        viewPos, viewDir = getWorldSpacePosAndNorm(camMat)\n",
    "        axis = np.cross(desiredViewDir, viewDir)\n",
    "        axis /= np.linalg.norm(axis)\n",
    "        angle = np.arccos(np.clip(np.dot(desiredViewDir, viewDir), -1.0, 1.0))\n",
    "        camMat = rotateAboutPoint(camMat, angleAxisToQuaternion(angle, axis), viewPos)\n",
    "\n",
    "        ## now rotate along viewDir to make sure that the up vector is pointing up (i.e. camera is parallel to ground plane)\n",
    "        desiredPlaneNorm = np.array([0.0, 0.0, 1.0])\n",
    "        _, viewDir = getWorldSpacePosAndNorm(camMat)\n",
    "        _, viewUp = getWorldSpacePosAndNorm(camMat, np.array([[0.0], [-1.0], [0.0], [1.0]]))\n",
    "        ## project desiredPlaneNorm (i.e. norm of ground plane) onto camera image plane (described by the view direction or normal)\n",
    "        projNorm = desiredPlaneNorm - np.dot(desiredPlaneNorm, viewDir)*viewDir\n",
    "        projNorm /= np.linalg.norm(projNorm)\n",
    "\n",
    "        adjustAngle = np.arccos(np.clip(np.dot(projNorm, viewUp), -1, 1))\n",
    "        adjustAxis = np.cross(projNorm, viewUp)\n",
    "        adjustAxis /= np.linalg.norm(adjustAxis)\n",
    "        camMat = rotateAboutPoint(camMat, angleAxisToQuaternion(adjustAngle, adjustAxis), viewPos)\n",
    "\n",
    "        self.viewMat = np.linalg.inv(camMat)\n",
    "        self.viewMat[1:3] *= -1\n",
    "        \n",
    "#         print(self.currentObjectViewFrame)\n",
    "        \n",
    "    def draw(self) :\n",
    "        if self.doPlaybackObjectViews or self.doPlaybackObjectTrajectory :\n",
    "            if time.time() - self.playbackLastTime > 0.05 :\n",
    "                self.playbackLastTime = time.time()\n",
    "                self.playbackObjectAnimation()\n",
    "        if self.shaders_program is not None :\n",
    "            gl.glUseProgram(self.shaders_program)\n",
    "\n",
    "            ## scene specific parameters\n",
    "            gl.glUniform3fv(gl.glGetUniformLocation(self.shaders_program, \"l_color\"), 1, self.lightColor)\n",
    "            gl.glUniform1f(gl.glGetUniformLocation(self.shaders_program, \"l_power\"), self.lightPower)\n",
    "\n",
    "            if gl.glGetUniformLocation(self.shaders_program, \"l_dir\") != -1 :\n",
    "                lightDirection = np.dot(self.viewMat, self.lightDirection)\n",
    "                lightDirection /= np.float32(np.linalg.norm(lightDirection).flatten())\n",
    "                gl.glUniform3fv(gl.glGetUniformLocation(self.shaders_program, \"l_dir\"), 1, lightDirection.flatten()[:3])\n",
    "\n",
    "            if gl.glGetUniformLocation(self.shaders_program, \"l_pos_world\") != -1 :\n",
    "                ## send light position (i.e. camera position)\n",
    "                lightPos = getWorldSpacePosAndNorm(np.linalg.pinv(self.viewMat), posOnly=True)\n",
    "                gl.glUniform3fv(gl.glGetUniformLocation(self.shaders_program, \"l_pos_world\"), 1, lightPos.astype(np.float32))\n",
    "\n",
    "            if gl.glGetUniformLocation(self.shaders_program, \"show_edges\") != -1 :\n",
    "                gl.glUniform1i(gl.glGetUniformLocation(self.shaders_program, \"show_edges\"), self.doShowEdges)\n",
    "                \n",
    "            ## send viewlightDirection\n",
    "            gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.shaders_program, \"m_v\"), 1, gl.GL_FALSE, self.viewMat.T)\n",
    "            gl.glUseProgram(0)\n",
    "            \n",
    "            ## draw meshes\n",
    "            for i in xrange(len(self.meshes)) :\n",
    "                self.meshes[i].draw(self.projectionMat, self.viewMat)\n",
    "                \n",
    "            ## draw filmed scenes\n",
    "            for i in xrange(len(self.filmedScenes)) :\n",
    "#                 tmp = time.time()\n",
    "                self.filmedScenes[i].draw(self.projectionMat, self.viewMat)\n",
    "#                 print(\"all\", time.time()-tmp)\n",
    "#                 print(\"\\n\")\n",
    "                \n",
    "#             cameraPos = np.array([self.cameraPos.x(), self.cameraPos.y(), self.cameraPos.z()], np.float32)\n",
    "#             cameraDist = np.float32(self.cameraPos.length())\n",
    "            cameraPos = getWorldSpacePosAndNorm(np.linalg.pinv(self.viewMat), posOnly=True)\n",
    "            cameraDist = np.float32(np.linalg.norm(cameraPos))\n",
    "            self.axesWidget.draw(cameraDist, np.dot(self.projectionMat, self.viewMat))\n",
    "        \n",
    "    def loadSceneFromFile(self, sceneLoc) :\n",
    "        if sceneLoc.split(\".\")[-1] == \"npy\" :\n",
    "            if len(self.filmedScenes) == 1 :\n",
    "                del self.filmedScenes[0]\n",
    "            self.filmedScenes.append(GLFilmedScene(sceneLoc))\n",
    "        elif sceneLoc.split(\".\")[-1] == \"obj\" or sceneLoc.split(\".\")[-1] == \"ply\" :\n",
    "            self.addMeshesFromFile(sceneLoc)\n",
    "        \n",
    "    def addMeshesFromFile(self, fileLoc) :\n",
    "        meshAsset = pyassimp.load(fileLoc)\n",
    "        for mesh in meshAsset.meshes :\n",
    "            newMesh = GLMesh(mesh, self.shaders_program)\n",
    "            if not newMesh.isInvalidMesh :\n",
    "                self.meshes.append(newMesh)\n",
    "        \n",
    "                print(\"Loaded mesh:\", len(mesh.vertices), \"vertices,\", len(mesh.faces), \"faces\"); sys.stdout.flush()\n",
    "            else :\n",
    "                del newMesh\n",
    "        \n",
    "        pyassimp.release(meshAsset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GLWidget(QGLWidget):\n",
    "    # default window size\n",
    "    width, height = 600.0, 600.0\n",
    "    \n",
    "    def __init__(self, fmt, parent=None):\n",
    "        super(GLWidget, self).__init__(fmt, parent=parent)\n",
    "        \n",
    "        self.scene = GLScene()\n",
    "        \n",
    "        self.initDone = False\n",
    "        self.sceneChanged = False\n",
    "        self.shadersChanged = False\n",
    "        self.doShowEdges = True\n",
    "        \n",
    "        self.cameraHorizontalAngle = np.pi\n",
    "        self.cameraVerticalAngle = 0#-np.pi/6\n",
    "        self.cameraFOV = 45.0\n",
    "        self.cameraSpeed = 10.0\n",
    "        \n",
    "        self.indexBuffers = []\n",
    "        self.verticesBuffers = []\n",
    "        self.uvsBuffers = []\n",
    "        self.barycentricsBuffers = []\n",
    "        self.normalsBuffers = []\n",
    "        \n",
    "#         self.setScene(\"../data/suzanne.obj\")\n",
    "#         self.setScene(\"../data/havana/filmed_scene-havana.npy\")\n",
    "#         self.setScene(\"/media/ilisescu/Data1/PhD/data/theme_park_sunny/filmed_scene-theme_park_sunny.npy\")\n",
    "        self.setScene(\"../data/havana_short/filmed_scene-havana_short.npy\")\n",
    "        self.setShaders(VS_HEAD_LIGHT, FS_HEAD_LIGHT)\n",
    "#         self.setViewAndProjectionMats()\n",
    "        self.scene.setCameraProjectionMat(self.cameraFOV, self.width, self.height)\n",
    "        \n",
    "    def setCameraFOV(self, cameraFOV) :\n",
    "        self.cameraFOV = cameraFOV\n",
    "        self.scene.setCameraProjectionMat(self.cameraFOV, self.width, self.height)\n",
    "        \n",
    "    def setFrustumScaleDelta(self, scaleDelta) :\n",
    "        self.scene.setFrustumScaleDelta(scaleDelta)\n",
    "        \n",
    "    def setPointSizeDelta(self, sizeDelta) :\n",
    "        self.scene.setPointSizeDelta(sizeDelta)\n",
    "    \n",
    "    def setScene(self, sceneLoc) :\n",
    "        self.scene.loadSceneFromFile(sceneLoc)\n",
    "\n",
    "        self.sceneChanged = True\n",
    "        self.glInit()\n",
    "    \n",
    "    def setShaders(self, vs, fs) :\n",
    "        self.vs = vs\n",
    "        self.fs = fs\n",
    "        self.shadersChanged = True\n",
    "        self.glInit()\n",
    "        \n",
    "    def setShowEdges(self, doShowEdges) :\n",
    "        self.scene.doShowEdges = doShowEdges\n",
    "    \n",
    "    def cleanup(self) :\n",
    "        del self.scene\n",
    "\n",
    "    def initializeGL(self):\n",
    "        \"\"\"Initialize OpenGL, VBOs, upload data on the GPU, etc.\"\"\"\n",
    "        \n",
    "        self.initDone = True\n",
    "        \n",
    "        gl.glEnable(gl.GL_DEPTH_TEST)\n",
    "        gl.glDepthFunc(gl.GL_LESS)\n",
    "        gl.glEnable(gl.GL_CULL_FACE)\n",
    "        gl.glEnable(gl.GL_MULTISAMPLE)\n",
    "        gl.glEnable(gl.GL_BLEND)\n",
    "        gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n",
    "\n",
    "        # background color\n",
    "        gl.glClearColor(0.2, 0.2, 0.2, 0.2)\n",
    "\n",
    "        if self.shadersChanged :\n",
    "            self.shaders_program = compileShaders(self.vs, self.fs)\n",
    "            self.scene.setShaderProgram(self.shaders_program)\n",
    "            if self.shaders_program is None :\n",
    "                self.initDone = False\n",
    "                \n",
    "\n",
    "    def paintGL(self):\n",
    "        \"\"\"Paint the scene.\"\"\"\n",
    "        \n",
    "        if self.initDone :\n",
    "            # clear the buffer\n",
    "            gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n",
    "#             tmp = time.time()\n",
    "            self.scene.draw()\n",
    "#             print(\"all scene\", time.time()-tmp)\n",
    "#             print(\"\\n\")\n",
    "            \n",
    "            if False and self.scene.doPlaybackObjectViews :\n",
    "                imgBuffer = gl.glReadPixels(0, 0, self.width, self.height, gl.GL_RGB, gl.GL_UNSIGNED_BYTE)\n",
    "                global glImage\n",
    "                glImage = Image.frombytes(mode=\"RGB\", size=(self.width, self.height), data=imgBuffer)\n",
    "                glImage = glImage.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "                glImage.save(\"/home/ilisescu/PhD/animation_images/adjusted-rotation-adjust-scale-adjust/frame-{0:05}.png\".format(self.scene.currentObjectViewFrame))\n",
    "\n",
    "    def resizeGL(self, width, height):\n",
    "        \"\"\"Called upon window resizing: reinitialize the viewport.\"\"\"\n",
    "        # update the window size\n",
    "        self.width, self.height = width, height\n",
    "        self.scene.setCameraProjectionMat(self.cameraFOV, self.width, self.height)\n",
    "        \n",
    "        # paint within the whole window\n",
    "        gl.glViewport(0, 0, width, height)\n",
    "\n",
    "# define a Qt window with an OpenGL widget inside it\n",
    "class Window(QtGui.QWidget):\n",
    "    def __init__(self):\n",
    "        super(Window, self).__init__()\n",
    "        \n",
    "        self.createGUI()\n",
    "        \n",
    "        self.doShowEdges = True\n",
    "        self.maxDeltaTime = 0.0\n",
    "        \n",
    "        self.changingOrientation = False\n",
    "        self.prevPoint = None\n",
    "        self.mouseSpeed = 0.001\n",
    "        self.mouseDiffPos = QtCore.QPointF(0, 0)\n",
    "        self.doMoveForwards = 0.0\n",
    "        self.doMoveSideways = 0.0\n",
    "        self.doMoveUpwards = 0.0\n",
    "        self.doPivotHorizontally = 0.0\n",
    "        self.doPivotVertically = 0.0\n",
    "        self.doRoll = 0.0\n",
    "        self.doPlayControl = False\n",
    "        \n",
    "        self.doChangeFOV = False\n",
    "        self.doChangeFrustumScale = False\n",
    "        self.doChangePointSize = False\n",
    "        \n",
    "        self.playTimer = QtCore.QTimer(self)\n",
    "        self.playTimer.setInterval(1000/30)\n",
    "        self.playTimer.timeout.connect(self.requestRender)\n",
    "        self.lastRenderTime = time.time()\n",
    "        self.playTimer.start()\n",
    "        \n",
    "        self.setWindowTitle(\"3D Looping\")\n",
    "        self.resize(1850, 720)\n",
    "        self.glWidget.setMinimumSize(1280, 720)\n",
    "#         self.glWidget.setMinimumSize(self.glWidget.scene.filmedScenes[0].medianImage.shape[1], self.glWidget.scene.filmedScenes[0].medianImage.shape[0])\n",
    "#         self.glWidget.setFixedSize(self.glWidget.scene.filmedScenes[0].medianImage.shape[1], self.glWidget.scene.filmedScenes[0].medianImage.shape[0])\n",
    "        \n",
    "        self.setFocus()\n",
    "        \n",
    "    def requestRender(self) :\n",
    "        currentTime = time.time()\n",
    "        deltaTime = currentTime - self.lastRenderTime\n",
    "        \n",
    "        # self.faceDetectionWidget.trackInFrame()\n",
    "\n",
    "        if self.doPlayControl :\n",
    "            self.glWidget.scene.filmedScenes[0].modifiedScene.controlFilmedObject(self.doMoveForwards, self.doMoveSideways, deltaTime)\n",
    "        else :\n",
    "            if self.doMoveForwards != 0.0 or self.doMoveSideways != 0.0 :\n",
    "                self.glWidget.scene.translateCamera(np.array([self.doMoveForwards*deltaTime*self.glWidget.cameraSpeed,\n",
    "                                                              self.doMoveSideways*deltaTime*self.glWidget.cameraSpeed,\n",
    "                                                              0.0]))\n",
    "        \n",
    "        if self.doMoveUpwards :\n",
    "            self.glWidget.scene.translateCamera(np.array([0.0,\n",
    "                                                          0.0,\n",
    "                                                          self.doMoveUpwards*deltaTime*self.glWidget.cameraSpeed]))\n",
    "            \n",
    "        if self.doRoll != 0.0 :\n",
    "            angle = (self.doRoll*deltaTime*self.glWidget.cameraSpeed*5)*np.pi/180.0\n",
    "            cameraPos, axis = getWorldSpacePosAndNorm(np.linalg.pinv(self.glWidget.scene.viewMat))\n",
    "            self.glWidget.scene.rotateCamera(angleAxisToQuaternion(angle, axis), cameraPos)\n",
    "            \n",
    "        if self.doPivotHorizontally != 0.0 :\n",
    "            angle = (self.doPivotHorizontally*deltaTime*self.glWidget.cameraSpeed*5)*np.pi/180.0\n",
    "            axis = np.array([0, 0, 1], np.float32)\n",
    "            self.glWidget.scene.rotateCamera(angleAxisToQuaternion(angle, axis), np.zeros(3))\n",
    "            \n",
    "        if self.doPivotVertically != 0.0 :\n",
    "            angle = (self.doPivotVertically*deltaTime*self.glWidget.cameraSpeed*5)*np.pi/180.0\n",
    "            _, axis = getWorldSpacePosAndNorm(np.linalg.pinv(self.glWidget.scene.viewMat), np.array([[1.0], [0.0], [0.0], [1.0]]))\n",
    "            self.glWidget.scene.rotateCamera(angleAxisToQuaternion(angle, axis), np.zeros(3))\n",
    "        \n",
    "#         tmp = time.time()\n",
    "        self.glWidget.updateGL()\n",
    "#         print(\"updateGL\", time.time()-tmp)\n",
    "        \n",
    "#         tmp = time.time()\n",
    "        if True :\n",
    "            cameraPos = getWorldSpacePosAndNorm(np.linalg.pinv(self.glWidget.scene.viewMat), posOnly=True)\n",
    "            previouslyUsedFrame = self.glWidget.scene.filmedScenes[0].filmedObjects[self.glWidget.scene.filmedScenes[0].currentFilmedObject].previouslyUsedFrame\n",
    "            usedFrameIdx = self.glWidget.scene.filmedScenes[0].filmedObjects[self.glWidget.scene.filmedScenes[0].currentFilmedObject].frameToUseIdx\n",
    "            previousCost, usedFrameCost = viewToObjectDirAngleDistance(self.glWidget.scene.filmedScenes[0].filmedObjects[self.glWidget.scene.filmedScenes[0].currentFilmedObject],\n",
    "                                                                       self.glWidget.scene.filmedScenes[0].modifiedScene.cameraViewMat)[[previouslyUsedFrame, usedFrameIdx]]\n",
    "\n",
    "            camPos = getWorldSpacePosAndNorm(np.linalg.inv(self.glWidget.scene.filmedScenes[0].modifiedScene.cameraViewMat), posOnly=True)\n",
    "            objPos = getWorldSpacePosAndNorm(self.glWidget.scene.filmedScenes[0].filmedObjects[self.glWidget.scene.filmedScenes[0].currentFilmedObject].modelMat, posOnly=True)\n",
    "            cameraToObjDir = objPos-camPos\n",
    "            cameraToObjDir /= np.linalg.norm(cameraToObjDir)\n",
    "            ## in object space from world space\n",
    "            cameraPosObjSpace = np.dot(np.linalg.inv(self.glWidget.scene.filmedScenes[0].filmedObjects[self.glWidget.scene.filmedScenes[0].currentFilmedObject].modelMat),\n",
    "                                       np.concatenate([objPos-cameraToObjDir, [1]]).reshape([4, 1])).flatten()\n",
    "            cameraPosObjSpace = cameraPosObjSpace[:-1]/cameraPosObjSpace[-1]\n",
    "            cameraToObjDir = np.zeros(3)-cameraPosObjSpace\n",
    "            cameraToObjDir /= np.linalg.norm(cameraToObjDir)\n",
    "            thetaCam = np.arctan2(cameraToObjDir[1], cameraToObjDir[0])*180.0/np.pi ## theta is angle on xy plane (i.e. longitude)\n",
    "            phiCam = np.arccos(cameraToObjDir[2])*180.0/np.pi ## phi is vertical angle (i.e. latitude)\n",
    "\n",
    "            thetaObjPrev = np.arctan2(self.glWidget.scene.filmedScenes[0].filmedObjects[self.glWidget.scene.filmedScenes[0].currentFilmedObject].cameraToObjectDirectionsObjSpace[previouslyUsedFrame, 1],\n",
    "                                      self.glWidget.scene.filmedScenes[0].filmedObjects[self.glWidget.scene.filmedScenes[0].currentFilmedObject].cameraToObjectDirectionsObjSpace[previouslyUsedFrame, 0])*180.0/np.pi\n",
    "            phiObjPrev = np.arccos(self.glWidget.scene.filmedScenes[0].filmedObjects[self.glWidget.scene.filmedScenes[0].currentFilmedObject].cameraToObjectDirectionsObjSpace[previouslyUsedFrame, 2])*180.0/np.pi\n",
    "\n",
    "            thetaObjCurr = np.arctan2(self.glWidget.scene.filmedScenes[0].filmedObjects[self.glWidget.scene.filmedScenes[0].currentFilmedObject].cameraToObjectDirectionsObjSpace[usedFrameIdx, 1],\n",
    "                                      self.glWidget.scene.filmedScenes[0].filmedObjects[self.glWidget.scene.filmedScenes[0].currentFilmedObject].cameraToObjectDirectionsObjSpace[usedFrameIdx, 0])*180.0/np.pi\n",
    "            phiObjCurr = np.arccos(self.glWidget.scene.filmedScenes[0].filmedObjects[self.glWidget.scene.filmedScenes[0].currentFilmedObject].cameraToObjectDirectionsObjSpace[usedFrameIdx, 2])*180.0/np.pi\n",
    "    #         print(\"computations\", time.time()-tmp)\n",
    "    #         print(\"\\n\")\n",
    "\n",
    "            self.infoLabel.setText(\"{5} --- Rendering at {0} FPS, FOV: {1}; {2}; render time[ms]: {3}, using frame {4} [{6}; {7}({8})]\".format(int(1.0/(deltaTime)), self.glWidget.cameraFOV,\n",
    "                                                                                                                               cameraPos, (time.time()-currentTime)*1000.0, usedFrameIdx,\n",
    "                                                                                                                               [\" VIEW CONTROL\", \" OBJECT CONTROL\"][bool(self.doPlayControl)],\n",
    "                                                                                                                               usedFrameCost, previouslyUsedFrame, previousCost)+\n",
    "                                   \"\\ncamToObj({0}, {1}) --- prevObj({2}, {3}) --- currObj({4}, {5})\".format(thetaCam, phiCam, thetaObjPrev, phiObjPrev, thetaObjCurr, phiObjCurr)+\n",
    "                                   \"\\nMove: Arrows/WASD --- Rise: R/F --- Roll: Q/E --- Pivot H: Z/X --- Pivot V: PageUp/Down --- FOV: V --- Frustum: U --- Point: P GoToCam: C --- \"+\n",
    "                                   \"Show Frustum Billboard: Space ---\\nSpeed: M Wheel --- Playback Obj (Trajectory) Views: (Shift) K --- Toggle Camera/Object Control: Enter --- Toggle Show Modified Scene: M --- \" +\n",
    "                                   \"Place Object On Grid: (Shift) G --- Top Down View: T\")\n",
    "        self.lastRenderTime = np.copy(currentTime)\n",
    "        if self.maxDeltaTime < deltaTime :\n",
    "            self.maxDeltaTime = deltaTime\n",
    "            print(\"MAX DELTA\", self.maxDeltaTime); sys.stdout.flush()\n",
    "#         self.playTimer.stop()\n",
    "        \n",
    "    def mousePressed(self, event):\n",
    "        if event.button() == QtCore.Qt.LeftButton :\n",
    "            self.changingOrientation = True\n",
    "            self.prevPoint = event.posF()\n",
    "                \n",
    "    def mouseMoved(self, event):\n",
    "        if self.changingOrientation and self.prevPoint is not None :\n",
    "            try :\n",
    "                prevPos = np.array([self.prevPoint.x(), self.prevPoint.y(), 0.0])\n",
    "                currentPos = np.array([event.posF().x(), event.posF().y(), 0.0])\n",
    "                angle = (np.linalg.norm(prevPos-currentPos)*self.mouseSpeed*100)*np.pi/180.0\n",
    "                if angle > 0.0 :\n",
    "                    axis = prevPos-currentPos\n",
    "                    axis /= np.linalg.norm(axis)\n",
    "                    axis = -np.array([axis[1], axis[0], axis[2]])\n",
    "                    cameraPos, axis = getWorldSpacePosAndNorm(np.linalg.pinv(self.glWidget.scene.viewMat), np.array([[axis[0]], [axis[1]], [axis[2]], [1.0]]))\n",
    "                    self.glWidget.scene.rotateCamera(angleAxisToQuaternion(angle, axis), cameraPos)\n",
    "\n",
    "                self.prevPoint = event.posF()\n",
    "            except :\n",
    "                print(\"ROTATION\", axis, np.linalg.norm(prevPos-currentPos)*self.mouseSpeed*100)\n",
    "                print(self.glWidget.scene.viewMat)\n",
    "                print(\"ERROR:\", sys.exc_info()[0])\n",
    "                raise\n",
    "            \n",
    "    def mouseReleased(self, event):\n",
    "        if event.button() == QtCore.Qt.LeftButton :\n",
    "            self.changingOrientation = False\n",
    "            self.prevPoint = None\n",
    "            self.mouseDiffPos = QtCore.QPointF(0, 0)\n",
    "        \n",
    "    def wheelEvent(self, e) :\n",
    "        if self.doChangeFrustumScale :\n",
    "            self.glWidget.setFrustumScaleDelta(0.0001*e.delta())\n",
    "        elif self.doChangeFOV :\n",
    "            if e.delta() < 0.0 :\n",
    "                self.glWidget.setCameraFOV(np.max([10.0, 0.005*e.delta()+self.glWidget.cameraFOV]))\n",
    "            else :\n",
    "                self.glWidget.setCameraFOV(np.min([170.0, 0.005*e.delta()+self.glWidget.cameraFOV]))\n",
    "        elif self.doChangePointSize :\n",
    "            self.glWidget.setPointSizeDelta(0.005*e.delta())\n",
    "        else :\n",
    "            if e.delta() < 0.0 :\n",
    "                self.glWidget.cameraSpeed = np.max([0.1, 0.001*e.delta()+self.glWidget.cameraSpeed])\n",
    "            else :\n",
    "                self.glWidget.cameraSpeed = np.min([30.0, 0.001*e.delta()+self.glWidget.cameraSpeed])\n",
    "        \n",
    "    def eventFilter(self, obj, event) :\n",
    "        if obj == self.glWidget and event.type() == QtCore.QEvent.Type.MouseMove :\n",
    "            self.mouseMoved(event)\n",
    "            return True\n",
    "        elif obj == self.glWidget and event.type() == QtCore.QEvent.Type.MouseButtonPress :\n",
    "            self.mousePressed(event)\n",
    "            return True\n",
    "        elif obj == self.glWidget and event.type() == QtCore.QEvent.Type.MouseButtonRelease :\n",
    "            self.mouseReleased(event)\n",
    "            return True\n",
    "        return QtGui.QWidget.eventFilter(self, obj, event)\n",
    "    \n",
    "    def keyPressEvent(self, e) :\n",
    "        if e.key() == e.key() >= QtCore.Qt.Key_0 and e.key() <= QtCore.Qt.Key_9 :\n",
    "            pressedNum = np.mod(e.key()-int(QtCore.Qt.Key_0), int(QtCore.Qt.Key_9))\n",
    "            \n",
    "            objectChanged = self.glWidget.scene.filmedScenes[0].showFilmedObject(pressedNum)\n",
    "            if objectChanged :\n",
    "                self.glWidget.scene.currentObjectViewFrame = -1\n",
    "            \n",
    "        if e.key() == QtCore.Qt.Key_C :\n",
    "            newFOV = self.glWidget.scene.goToCamera()\n",
    "            if newFOV is not None :\n",
    "                self.glWidget.cameraFOV = np.copy(newFOV)\n",
    "                \n",
    "        if e.key() == QtCore.Qt.Key_G :\n",
    "            self.glWidget.scene.filmedScenes[0].placeObjectOnNextCostGridPointAtBestOrientation(not e.modifiers() & QtCore.Qt.Modifier.SHIFT)\n",
    "        \n",
    "        if e.key() == QtCore.Qt.Key_T :\n",
    "            self.glWidget.scene.viewMat = QtGui.QMatrix4x4()\n",
    "\n",
    "            cameraPos = QtGui.QVector3D(0.0, 15.0, 0.0)\n",
    "            self.glWidget.scene.viewMat.lookAt(cameraPos, QtGui.QVector3D(0, 0, 0), QtGui.QVector3D(1, 0, 0))\n",
    "            \n",
    "            self.glWidget.scene.viewMat.rotate(-90, 1, 0, 0)\n",
    "            self.glWidget.scene.viewMat.rotate(-90, 0, 0, 1)\n",
    "            self.glWidget.scene.viewMat.translate(-6, 0, 0)\n",
    "            self.glWidget.scene.viewMat.translate(0, 2, 0)\n",
    "            self.glWidget.scene.viewMat = np.array(self.glWidget.scene.viewMat.data(), np.float32).reshape([4, 4]).T\n",
    "            \n",
    "                \n",
    "        if e.key() == QtCore.Qt.Key_Return :\n",
    "            self.doPlayControl = not self.doPlayControl\n",
    "        if e.key() == QtCore.Qt.Key_M :\n",
    "            self.glWidget.scene.filmedScenes[0].doRenderModifiedScene = not self.glWidget.scene.filmedScenes[0].doRenderModifiedScene\n",
    "            \n",
    "        if e.key() == QtCore.Qt.Key_Space :\n",
    "            self.glWidget.scene.toggleShowFrustumBillboard()\n",
    "        if e.key() == QtCore.Qt.Key_K :\n",
    "            if e.modifiers() & QtCore.Qt.Modifier.SHIFT :\n",
    "                self.glWidget.scene.doPlaybackObjectTrajectory = not self.glWidget.scene.doPlaybackObjectTrajectory\n",
    "                self.glWidget.scene.doPlaybackObjectViews = False\n",
    "            else :\n",
    "                self.glWidget.scene.doPlaybackObjectViews = not self.glWidget.scene.doPlaybackObjectViews\n",
    "                self.glWidget.scene.doPlaybackObjectTrajectory = False\n",
    "                \n",
    "            if self.glWidget.scene.doPlaybackObjectViews or self.glWidget.scene.doPlaybackObjectTrajectory :\n",
    "                self.glWidget.scene.playbackLastTime = time.time()\n",
    "        \n",
    "        ## Move\n",
    "        if e.key() == QtCore.Qt.Key_W or e.key() == QtCore.Qt.Key_Up :\n",
    "            self.doMoveForwards += 1.0\n",
    "        if e.key() == QtCore.Qt.Key_S or e.key() == QtCore.Qt.Key_Down :\n",
    "            self.doMoveForwards -= 1.0\n",
    "        if e.key() == QtCore.Qt.Key_D or e.key() == QtCore.Qt.Key_Right :\n",
    "            self.doMoveSideways += 1.0\n",
    "        if e.key() == QtCore.Qt.Key_A or e.key() == QtCore.Qt.Key_Left :\n",
    "            self.doMoveSideways -= 1.0            \n",
    "        ## Rise\n",
    "        if e.key() == QtCore.Qt.Key_R :\n",
    "            self.doMoveUpwards += 1.0\n",
    "        if e.key() == QtCore.Qt.Key_F :\n",
    "            self.doMoveUpwards -= 1.0\n",
    "        ## Roll\n",
    "        if e.key() == QtCore.Qt.Key_Q :\n",
    "            self.doRoll -= 1.0\n",
    "        if e.key() == QtCore.Qt.Key_E :\n",
    "            self.doRoll += 1.0\n",
    "        ## Pivot\n",
    "        if e.key() == QtCore.Qt.Key_Z :\n",
    "            self.doPivotHorizontally += 1.0\n",
    "        if e.key() == QtCore.Qt.Key_X :\n",
    "            self.doPivotHorizontally -= 1.0\n",
    "        if e.key() == QtCore.Qt.Key_PageDown :\n",
    "            self.doPivotVertically -= 1.0\n",
    "        if e.key() == QtCore.Qt.Key_PageUp :\n",
    "            self.doPivotVertically += 1.0\n",
    "            \n",
    "        if e.key() == QtCore.Qt.Key_V :\n",
    "            self.doChangeFOV = True\n",
    "        if e.key() == QtCore.Qt.Key_U :\n",
    "            self.doChangeFrustumScale = True\n",
    "        if e.key() == QtCore.Qt.Key_P :\n",
    "            self.doChangePointSize = True\n",
    "    \n",
    "    def keyReleaseEvent(self, e) :\n",
    "        ## Move\n",
    "        if e.key() == QtCore.Qt.Key_W or e.key() == QtCore.Qt.Key_Up :\n",
    "            self.doMoveForwards -= 1.0\n",
    "        if e.key() == QtCore.Qt.Key_S or e.key() == QtCore.Qt.Key_Down :\n",
    "            self.doMoveForwards += 1.0\n",
    "        if e.key() == QtCore.Qt.Key_D or e.key() == QtCore.Qt.Key_Right :\n",
    "            self.doMoveSideways -= 1.0\n",
    "        if e.key() == QtCore.Qt.Key_A or e.key() == QtCore.Qt.Key_Left :\n",
    "            self.doMoveSideways += 1.0\n",
    "        ## Rise\n",
    "        if e.key() == QtCore.Qt.Key_R :\n",
    "            self.doMoveUpwards -= 1.0\n",
    "        if e.key() == QtCore.Qt.Key_F :\n",
    "            self.doMoveUpwards += 1.0\n",
    "        ## Roll\n",
    "        if e.key() == QtCore.Qt.Key_Q :\n",
    "            self.doRoll += 1.0\n",
    "        if e.key() == QtCore.Qt.Key_E :\n",
    "            self.doRoll -= 1.0\n",
    "        ## Pivot\n",
    "        if e.key() == QtCore.Qt.Key_Z :\n",
    "            self.doPivotHorizontally -= 1.0\n",
    "        if e.key() == QtCore.Qt.Key_X :\n",
    "            self.doPivotHorizontally += 1.0\n",
    "        if e.key() == QtCore.Qt.Key_PageDown :\n",
    "            self.doPivotVertically += 1.0\n",
    "        if e.key() == QtCore.Qt.Key_PageUp :\n",
    "            self.doPivotVertically -= 1.0\n",
    "            \n",
    "        if e.key() == QtCore.Qt.Key_V :\n",
    "            self.doChangeFOV = False\n",
    "        if e.key() == QtCore.Qt.Key_U :\n",
    "            self.doChangeFrustumScale = False\n",
    "        if e.key() == QtCore.Qt.Key_P :\n",
    "            self.doChangePointSize = False\n",
    "            \n",
    "    def closeEvent(self, event) :\n",
    "        self.playTimer.stop()\n",
    "        self.faceDetectionWidget.cleanup()\n",
    "        self.glWidget.cleanup()\n",
    "    \n",
    "    def changeScene(self) :\n",
    "        sceneLoc = QtGui.QFileDialog.getOpenFileName(self, \"Load Scene\", os.path.expanduser(\"~\")+\"/PhD/data/\", \"Filmed Scenes (filmed_scene-*.npy);;OBJ files (*.obj);;PLY files (*.ply)\")[0]\n",
    "        if sceneLoc != \"\" :\n",
    "            self.glWidget.setScene(sceneLoc)\n",
    "        self.setFocus()\n",
    "        \n",
    "    def useHeadLight(self) :\n",
    "        self.glWidget.setShaders(VS_HEAD_LIGHT, FS_HEAD_LIGHT)\n",
    "    \n",
    "    def useDirLight(self) :\n",
    "        self.glWidget.setShaders(VS_DIR_LIGHT, FS_DIR_LIGHT)\n",
    "        \n",
    "    def toggleEdges(self) :\n",
    "        self.doShowEdges = not self.doShowEdges\n",
    "        self.glWidget.setShowEdges(self.doShowEdges)\n",
    "        \n",
    "    def createGUI(self) :\n",
    "        \n",
    "        ## WIDGETS ##\n",
    "        self.faceDetectionWidget = FaceDetectionWidget(True)\n",
    "        \n",
    "        # initialize the GL widget\n",
    "        fmt = QGLFormat()\n",
    "        fmt.setSampleBuffers(True)\n",
    "        fmt.setSamples(8)\n",
    "        fmt.setAlpha(True)\n",
    "        self.glWidget = GLWidget(fmt=fmt, parent=self)\n",
    "        self.glWidget.setMinimumSize(self.glWidget.width, self.glWidget.height)\n",
    "        self.glWidget.setSizePolicy(QtGui.QSizePolicy.MinimumExpanding, QtGui.QSizePolicy.MinimumExpanding)\n",
    "        self.glWidget.installEventFilter(self)\n",
    "         \n",
    "        self.infoLabel = QtGui.QLabel(\"Info\")\n",
    "#         self.infoLabel.setAlignment(QtCore.Qt.AlignLeft | QtCore.Qt.AlignHCenter)\n",
    "        \n",
    "        self.changeSceneButton = QtGui.QPushButton(\"Change Scene\")\n",
    "        self.changeSceneButton.setSizePolicy(QtGui.QSizePolicy.MinimumExpanding, QtGui.QSizePolicy.Minimum)\n",
    "#         self.changeSceneButton.setEnabled(False)\n",
    "        self.useHeadLightButton = QtGui.QPushButton(\"Use Head Light\")\n",
    "        self.useHeadLightButton.setSizePolicy(QtGui.QSizePolicy.Minimum, QtGui.QSizePolicy.Minimum)\n",
    "        self.useHeadLightButton.setEnabled(False)\n",
    "        self.useDirLightButton = QtGui.QPushButton(\"Use Directional Light\")\n",
    "        self.useDirLightButton.setSizePolicy(QtGui.QSizePolicy.Minimum, QtGui.QSizePolicy.Minimum)\n",
    "        self.useDirLightButton.setEnabled(False)\n",
    "        self.toggleEdgesButton = QtGui.QPushButton(\"Toggle Edges\")\n",
    "        self.toggleEdgesButton.setSizePolicy(QtGui.QSizePolicy.Minimum, QtGui.QSizePolicy.Minimum)\n",
    "        self.toggleEdgesButton.setEnabled(False)\n",
    "        \n",
    "        \n",
    "        ## SIGNALS ##\n",
    "        \n",
    "        self.changeSceneButton.clicked.connect(self.changeScene)\n",
    "        self.useHeadLightButton.clicked.connect(self.useHeadLight)\n",
    "        self.useDirLightButton.clicked.connect(self.useDirLight)\n",
    "        self.toggleEdgesButton.clicked.connect(self.toggleEdges)\n",
    "        self.faceDetectionWidget.bboxMoved.connect(self.glWidget.scene.moveCameraInRange)\n",
    "        \n",
    "        ## LAYOUTS ##\n",
    "        \n",
    "        controlsLayout = QtGui.QGridLayout()\n",
    "        idx = 0\n",
    "        controlsLayout.addWidget(self.changeSceneButton, idx, 0, 1, 1, QtCore.Qt.AlignLeft)\n",
    "        controlsLayout.setColumnStretch(0, 10)\n",
    "        controlsLayout.addWidget(self.useHeadLightButton, idx, 1, 1, 1, QtCore.Qt.AlignLeft)\n",
    "        controlsLayout.addWidget(self.useDirLightButton, idx, 2, 1, 1, QtCore.Qt.AlignLeft)\n",
    "        controlsLayout.addWidget(self.toggleEdgesButton, idx, 3, 1, 1, QtCore.Qt.AlignLeft); idx+=1\n",
    "        \n",
    "        mainLayout = QtGui.QVBoxLayout()\n",
    "        mainLayout.addWidget(self.glWidget)\n",
    "        mainLayout.addWidget(self.infoLabel)\n",
    "        mainLayout.addLayout(controlsLayout)\n",
    "        mainLayout.addWidget(self.faceDetectionWidget)\n",
    "        \n",
    "        self.setLayout(mainLayout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_VELOCITY = 1.5 ## units/second\n",
    "MAX_ANGULAR_VELOCITY = np.pi/4.0 ## rad/second\n",
    "class GLModifiedScene() :\n",
    "    def __init__(self, bgImage, filmedObject, cameraExtrinsics, cameraIntrinsics) :\n",
    "        self.initDone = False\n",
    "        \n",
    "        self.velocity = 0.0\n",
    "        self.acceleration = 2.0\n",
    "        \n",
    "        self.angularVelocity = 0.0\n",
    "        self.angularAcceleration = np.pi*0.75\n",
    "        \n",
    "        self.bgImage = bgImage\n",
    "        self.filmedObject = filmedObject\n",
    "        self.viewport = np.array([0, 0, self.bgImage.shape[1], self.bgImage.shape[0]], np.float32)\n",
    "        self.cameraExtrinsics = np.copy(cameraExtrinsics)\n",
    "        self.cameraIntrinsics = np.copy(cameraIntrinsics)\n",
    "        \n",
    "        self.cameraViewMat, self.cameraProjectionMat = cvCameraToOpenGL(self.cameraExtrinsics, self.cameraIntrinsics, np.array(self.bgImage.shape[0:2]))\n",
    "        \n",
    "        \n",
    "        self.screenHeightRatio = 0.7\n",
    "        ## screen height in clip space is 2 so need to multiply this ratio by 2\n",
    "        self.renderBillboard = GLBillboard(self.bgImage, self.screenHeightRatio*2.0, np.eye(4, dtype=np.float32), False, None, False)\n",
    "        \n",
    "        self.trajectory = GLTrajectory(filmedObject.trajectoryPoints, cameraIntrinsics, cameraExtrinsics, filmedObject.filmedObjectData[DICT_REPRESENTATIVE_COLOR], False)\n",
    "        \n",
    "        ## eventually I can use these to control the car\n",
    "#         moveDirection = np.array([[-1.0, 0.0]], dtype=np.float32)\n",
    "#         position = np.array([[932.0, 538.0]], dtype=np.float32)\n",
    "        \n",
    "#         self.moveDirectionIndicatorCameraSpace = GLTrajectory(np.concatenate([position, position+moveDirection*100.0]), cameraIntrinsics, cameraExtrinsics, doDrawProjectedPoints=False, doSmoothing=False)\n",
    "#         self.moveDirectionIndicatorWorldSpace = GLTrajectory(np.concatenate([position, position+moveDirection*100.0]), cameraIntrinsics, cameraExtrinsics, doSmoothing=False)\n",
    "\n",
    "        objPos = getWorldSpacePosAndNorm(self.filmedObject.modelMat, posOnly=True)\n",
    "        objDirPosInWorldSpace = np.dot(self.filmedObject.modelMat, self.filmedObject.forwardDir).flatten()[:-1]\n",
    "        self.updateObjectMovementIndicators(objPos, (objDirPosInWorldSpace-objPos)/np.linalg.norm(objDirPosInWorldSpace-objPos))\n",
    "        \n",
    "    def __del__(self) :\n",
    "        del self.bgImage, self.renderBillboard, self.moveDirectionIndicatorCameraSpace, self.moveDirectionIndicatorWorldSpace\n",
    "        \n",
    "    def setShaders(self) :\n",
    "        self.renderBillboard.setShaders()\n",
    "        self.trajectory.setShaders()\n",
    "        self.moveDirectionIndicatorCameraSpace.setShaders()\n",
    "        self.moveDirectionIndicatorWorldSpace.setShaders()\n",
    "        self.initDone = True\n",
    "        \n",
    "    def updateObjectMovementIndicators(self, positionWorld, moveDirectionWorld) :\n",
    "        T = np.dot(self.cameraIntrinsics, self.cameraExtrinsics[:-1, [0, 1, 3]])\n",
    "        positionCamera = np.dot(T, np.concatenate([positionWorld[:-1], [1]]).reshape([3, 1])).flatten()\n",
    "        positionCamera = positionCamera[:-1]/positionCamera[-1]\n",
    "        moveDirectionPosCamera = np.dot(T, np.concatenate([(positionWorld+moveDirectionWorld)[:-1], [1]]).reshape([3, 1])).flatten()\n",
    "        moveDirectionPosCamera = moveDirectionPosCamera[:-1]/moveDirectionPosCamera[-1]\n",
    "        moveDirectionCamera = moveDirectionPosCamera-positionCamera\n",
    "        moveDirectionCamera /= np.linalg.norm(moveDirectionCamera)\n",
    "        \n",
    "#         print(positionCamera, moveDirectionPosCamera)\n",
    "            \n",
    "        self.moveDirectionIndicatorCameraSpace = GLTrajectory(np.concatenate([[positionCamera], [positionCamera+moveDirectionCamera*100.0]]), self.cameraIntrinsics, self.cameraExtrinsics,\n",
    "                                                              doDrawProjectedPoints=False, doSmoothing=False)\n",
    "        self.moveDirectionIndicatorWorldSpace = GLTrajectory(np.concatenate([[positionCamera], [positionCamera+moveDirectionCamera*100.0]]), self.cameraIntrinsics, self.cameraExtrinsics,\n",
    "                                                             doSmoothing=False)\n",
    "        if self.initDone :\n",
    "            self.moveDirectionIndicatorCameraSpace.setShaders()\n",
    "            self.moveDirectionIndicatorWorldSpace.setShaders()\n",
    "        \n",
    "        \n",
    "    def controlFilmedObject(self, doAccelerate, doTurn, deltaTime) :\n",
    "        ####################### change velocity based on acceleration #######################\n",
    "        if doAccelerate == 1.0 :\n",
    "            acceleration = self.acceleration\n",
    "            ## if I want to go forwards while going backwards, accelerate faster\n",
    "            if self.velocity < 0.0 :\n",
    "                acceleration = self.acceleration*2\n",
    "\n",
    "            self.velocity = np.min([MAX_VELOCITY, self.velocity + acceleration*deltaTime*doAccelerate])\n",
    "        elif doAccelerate == -1.0 :\n",
    "            acceleration = self.acceleration\n",
    "            ## if I want to go backwards while going forwards, accelerate faster\n",
    "            if self.velocity > 0.0 :\n",
    "                acceleration = self.acceleration*2\n",
    "            self.velocity = np.max([-MAX_VELOCITY, self.velocity + acceleration*deltaTime*doAccelerate])\n",
    "        else :\n",
    "            ## decrease velocity based on direction\n",
    "            if self.velocity < 0.0 :\n",
    "                self.velocity = np.min([0.0, self.velocity + self.acceleration*deltaTime])\n",
    "            else :\n",
    "                self.velocity = np.max([0.0, self.velocity - self.acceleration*deltaTime])\n",
    "\n",
    "        ####################### change angular velocity based on angular acceleration #######################\n",
    "        if doTurn == 1.0 :\n",
    "            self.angularVelocity = np.min([MAX_ANGULAR_VELOCITY, self.angularVelocity + self.angularAcceleration*deltaTime*doTurn])\n",
    "        elif doTurn == -1.0 :\n",
    "            self.angularVelocity = np.max([-MAX_ANGULAR_VELOCITY, self.angularVelocity + self.angularAcceleration*deltaTime*doTurn])\n",
    "        else :\n",
    "            ## decrease angular velocity based on direction\n",
    "            if self.angularVelocity < 0.0 :\n",
    "                self.angularVelocity = np.min([0.0, self.angularVelocity + self.angularAcceleration*deltaTime])\n",
    "            else :\n",
    "                self.angularVelocity = np.max([0.0, self.angularVelocity - self.angularAcceleration*deltaTime])\n",
    "        \n",
    "        \n",
    "        objPos = getWorldSpacePosAndNorm(self.filmedObject.modelMat, posOnly=True)\n",
    "        objDirPosInWorldSpace = np.dot(self.filmedObject.modelMat, self.filmedObject.forwardDir).flatten()[:-1]\n",
    "        \n",
    "        angle = self.angularVelocity*deltaTime*np.abs(self.velocity)/MAX_VELOCITY\n",
    "        desiredDirection = (objDirPosInWorldSpace-objPos)/np.linalg.norm(objDirPosInWorldSpace-objPos)\n",
    "        if angle != 0.0 :\n",
    "            if self.velocity > 0.0 :\n",
    "                turnAxis = np.array([0.0, 0.0, 1.0])\n",
    "            else :\n",
    "                turnAxis = np.array([0.0, 0.0, -1.0])\n",
    "            desiredDirection = np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(angle, turnAxis)), np.concatenate([desiredDirection, [1]]).reshape([4, 1])).flatten()\n",
    "            desiredDirection = desiredDirection[:-1]/desiredDirection[-1]\n",
    "            desiredDirection /= np.linalg.norm(desiredDirection)\n",
    "        \n",
    "        if self.velocity != 0.0 :\n",
    "            positionWorld = objPos+desiredDirection*self.velocity*deltaTime\n",
    "            self.filmedObject.setObjectPosAndDir(positionWorld, desiredDirection)\n",
    "            self.updateObjectMovementIndicators(positionWorld, desiredDirection)\n",
    "        \n",
    "    def draw(self, projectionMat, viewMat) :\n",
    "        if self.initDone :\n",
    "            top, left, width, height = gl.glGetIntegerv(gl.GL_VIEWPORT)\n",
    "            viewportAspectRatio = float(width)/float(height)\n",
    "            \n",
    "            isDepthTestOn = bool(gl.glGetBooleanv(gl.GL_DEPTH_TEST))\n",
    "            gl.glDisable(gl.GL_DEPTH_TEST)\n",
    "            \n",
    "            ## change modelMat to scale x axis (y axis is fine as it's 1) so that aspect ratio is correct, by removing the viewport aspect ratio\n",
    "            ## also move the correctly scaled billboard to sit in the top right corner\n",
    "            tMat = np.array([[1.0/viewportAspectRatio, 0, 0, 1.0-self.screenHeightRatio*self.renderBillboard.aspectRatio/viewportAspectRatio],\n",
    "                             [0, 1, 0, 1.0-self.screenHeightRatio],\n",
    "                             [0, 0, 1, 0],\n",
    "                             [0, 0, 0, 1]], np.float32)\n",
    "            self.renderBillboard.modelMat = tMat\n",
    "            self.renderBillboard.draw(np.eye(4, dtype=np.float32), np.eye(4, dtype=np.float32))\n",
    "            \n",
    "            ## align trajectory to billboard by setting modelMat of trajectory to pvm = m = tMat*scaleMat\n",
    "            self.trajectory.draw(np.dot(tMat, np.array([[self.renderBillboard.scale, 0, 0, 0],\n",
    "                                                        [0, -self.renderBillboard.scale, 0, 0],\n",
    "                                                        [0, 0, self.renderBillboard.scale, 0],\n",
    "                                                        [0, 0, 0, 1]], np.float32)))\n",
    "            \n",
    "            ## this takes a rendered GLFilmedObject after view and projection transformations and scales it and moves it to align with the renderBillboard so that if I render the GLFilmedObject using the original\n",
    "            ## camera matrices then I can safely visualize it on top of the static background image\n",
    "            alignToBillboardTMat = np.array([[(self.screenHeightRatio*self.bgImage.shape[1])/(self.bgImage.shape[0]*viewportAspectRatio), 0, 0, 1.0-self.screenHeightRatio*self.renderBillboard.aspectRatio/viewportAspectRatio],\n",
    "                                             [0, self.screenHeightRatio, 0, 1.0-self.screenHeightRatio],\n",
    "                                             [0, 0, self.screenHeightRatio, 0],\n",
    "                                             [0, 0, 0, 1]], np.float32)\n",
    "            self.filmedObject.draw(np.dot(alignToBillboardTMat, self.cameraProjectionMat), self.cameraViewMat, False, False, True, False)\n",
    "            \n",
    "            \n",
    "            ## render the indicators for where the object should be (both camera and world space)\n",
    "#             self.moveDirectionIndicatorCameraSpace.draw(np.dot(tMat, np.array([[self.renderBillboard.scale, 0, 0, 0],\n",
    "#                                                                                [0, -self.renderBillboard.scale, 0, 0],\n",
    "#                                                                                [0, 0, self.renderBillboard.scale, 0],\n",
    "#                                                                                [0, 0, 0, 1]], np.float32)))\n",
    "            \n",
    "#             self.moveDirectionIndicatorWorldSpace.draw(np.dot(projectionMat, viewMat))\n",
    "            \n",
    "            \n",
    "            if isDepthTestOn :\n",
    "                gl.glEnable(gl.GL_DEPTH_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GLColoredSphere() :\n",
    "    def __init__(self, modelMat=np.eye(4, dtype=np.float32), longitudeLinesColors=np.array([[255.0, 0, 0], [0, 255.0, 0], [0, 0, 255.0], [255.0, 0, 255.0]]), numLatitudeLines=11) :\n",
    "        self.initDone = False\n",
    "        \n",
    "        self.modelMat = modelMat.astype(np.float32)\n",
    "        self.longitudeLinesColors = longitudeLinesColors\n",
    "        self.numLongitudeLines = len(self.longitudeLinesColors)+1\n",
    "        self.numLatitudeLines = numLatitudeLines        \n",
    "        self.setGeometryAndBuffers()\n",
    "        \n",
    "    def __del__(self) :\n",
    "        del self.longitudeLinesColors, self.vertices, self.indices, self.colors\n",
    "        \n",
    "    def setShaders(self) :\n",
    "        self.shaders_program = compileShaders(VS_COLOR_NO_SHADE, FS_COLOR_NO_SHADE)\n",
    "        if self.shaders_program is None :\n",
    "            self.initDone = False\n",
    "            return\n",
    "        self.initDone = True\n",
    "        \n",
    "    def setGeometryAndBuffers(self) :\n",
    "        u, v = np.mgrid[0:2*np.pi:complex(0, self.numLongitudeLines), 0:np.pi:complex(0, self.numLatitudeLines)]\n",
    "        x=np.cos(u)*np.sin(v)\n",
    "        y=np.sin(u)*np.sin(v)\n",
    "        z=np.cos(v)\n",
    "        self.vertices = np.array([x.T.flatten(), y.T.flatten(), z.T.flatten()]).T\n",
    "        ## remove last vertex on each latitude line as it's a duplicate of the first one\n",
    "        self.vertices = np.delete(self.vertices, np.arange(self.numLongitudeLines, self.numLongitudeLines*self.numLatitudeLines+1, self.numLongitudeLines)-1, axis=0)\n",
    "        ## remove all vertices in the first and last tituted lines apart from one\n",
    "        self.vertices = (self.vertices[self.numLongitudeLines-2:-self.numLongitudeLines+2]).astype(np.float32)\n",
    "        ## build indices to triangulate the vertices of the sphere\n",
    "        ## triangles for top lid of the sphere\n",
    "        self.indices = np.array([np.array([0, i, j]) for i, j in zip(np.arange(1, self.numLongitudeLines),\n",
    "                                                                np.concatenate([np.arange(2, self.numLongitudeLines), [1]]))]).flatten()\n",
    "        ## triangles for each row apart from lids\n",
    "        firstRowTriangleIndices = np.concatenate([np.array([np.array([0, self.numLongitudeLines-1, 1, 1, self.numLongitudeLines-1, self.numLongitudeLines])+1+i for i in np.arange(0, self.numLongitudeLines-2)]).flatten(),\n",
    "                                                  np.array([self.numLongitudeLines-1, (self.numLongitudeLines-1)*2, 1, 1, (self.numLongitudeLines-1)*2, self.numLongitudeLines])])\n",
    "        self.indices = np.concatenate([self.indices,\n",
    "                                  np.array([firstRowTriangleIndices+j*(self.numLongitudeLines-1) for j in np.arange(0, self.numLatitudeLines-3)]).flatten()])\n",
    "        ## triangles for bottom lid\n",
    "        self.indices = np.concatenate([self.indices,\n",
    "                                       np.array([np.array([len(self.vertices)-1, j, i]) for i, j in zip(np.arange(len(self.vertices)-self.numLongitudeLines, len(self.vertices)-1),\n",
    "                                                                                                   np.concatenate([np.arange(len(self.vertices)-self.numLongitudeLines+1, len(self.vertices)-1),\n",
    "                                                                                                                   [len(self.vertices)-self.numLongitudeLines]]))]).flatten()]).astype(np.int32)\n",
    "        \n",
    "        \n",
    "        self.colors = np.concatenate([np.ones([1, 3]),\n",
    "                                      self.longitudeLinesColors[np.arange(len(self.longitudeLinesColors)).reshape([len(self.longitudeLinesColors), 1]).repeat(self.numLatitudeLines-2, axis=1).T.flatten(), :]/255.0,\n",
    "                                      np.ones([1, 3])]).astype(np.float32)\n",
    "        \n",
    "        self.indexBuffer = glvbo.VBO(self.indices, gl.GL_STATIC_DRAW, gl.GL_ELEMENT_ARRAY_BUFFER)\n",
    "        self.verticesBuffer = glvbo.VBO(self.vertices, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        self.colorBuffer = glvbo.VBO(self.colors, gl.GL_STATIC_DRAW, gl.GL_ARRAY_BUFFER)\n",
    "        \n",
    "    def draw(self, projectionMat, viewMat) :\n",
    "        if self.initDone :\n",
    "            gl.glUseProgram(self.shaders_program)\n",
    "            \n",
    "            ## send mvp\n",
    "            gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.shaders_program, \"m_pvm\"), 1, gl.GL_FALSE, np.dot(projectionMat, np.dot(viewMat, self.modelMat)).T)\n",
    "            ## send camera distance\n",
    "            gl.glUniform1f(gl.glGetUniformLocation(self.shaders_program, \"camera_dist\"), np.float32(1.0))\n",
    "#             print(cameraDist)\n",
    "\n",
    "            ################ RENDER BODY ################\n",
    "    \n",
    "            ## bind the index buffer\n",
    "            self.indexBuffer.bind()\n",
    "\n",
    "            ## bind the VBO with vertex data\n",
    "            self.verticesBuffer.bind()\n",
    "            gl.glEnableVertexAttribArray(0)\n",
    "            # tell OpenGL that the VBO contains an array of vertices\n",
    "            # these vertices contain 3 single precision coordinates\n",
    "            gl.glVertexAttribPointer(0, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "            \n",
    "            ## bind the VBO with color data\n",
    "            self.colorBuffer.bind()\n",
    "            gl.glEnableVertexAttribArray(1)\n",
    "            gl.glVertexAttribPointer(1, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n",
    "\n",
    "            ## draw points from the VBO\n",
    "            gl.glDrawElements(gl.GL_TRIANGLES, len(self.indices), gl.GL_UNSIGNED_INT, None)\n",
    "#             gl.glDrawElements(gl.GL_POINTS, len(self.indices), gl.GL_UNSIGNED_INT, None)\n",
    "\n",
    "            ## clean up\n",
    "            gl.glDisableVertexAttribArray(0)\n",
    "            gl.glDisableVertexAttribArray(1)\n",
    "\n",
    "            gl.glUseProgram(0)\n",
    "            \n",
    "\n",
    "class GLCostOnGrid() :\n",
    "    def __init__(self, filmedObject, numAngleDivisions=16, worldGroundPlanePoints=None, gridSpace=np.array([-5, 4], float), gridSpacing=float(1.0)) :\n",
    "        self.initDone = False\n",
    "        \n",
    "        self.coloredSpheres = []\n",
    "        self.cameraViewMat, _ = cvCameraToOpenGL(filmedObject.cameraExtrinsics, filmedObject.cameraIntrinsics, np.array([100.0, 100.0]))\n",
    "        \n",
    "        self.showCostOnGrid(filmedObject, numAngleDivisions, worldGroundPlanePoints, gridSpace, gridSpacing)\n",
    "        \n",
    "    def __del__(self) :\n",
    "        del self.numAngleDivisions, self.worldGroundPlanePoints, self.gridSpacing, self.coloredSpheres, self.gridPoints, self.angles\n",
    "        \n",
    "    def showCostOnGrid(self, filmedObject, numAngleDivisions, worldGroundPlanePoints, gridSpace, gridSpacing) :\n",
    "        tmp = time.time()\n",
    "        if len(self.coloredSpheres) > 0 :\n",
    "            self.initDone = False\n",
    "            del self.coloredSpheres\n",
    "            self.coloredSpheres = []\n",
    "            \n",
    "        self.numAngleDivisions = numAngleDivisions\n",
    "        self.gridSpace = gridSpace\n",
    "        self.gridSpacing = gridSpacing\n",
    "        self.worldGroundPlanePoints = np.copy(worldGroundPlanePoints)\n",
    "        if worldGroundPlanePoints is None :\n",
    "            self.gridPoints = np.mgrid[self.gridSpace[0]:self.gridSpace[1]:self.gridSpacing, self.gridSpace[0]:self.gridSpace[1]:self.gridSpacing]\n",
    "            self.gridPoints = self.gridPoints.reshape([2, self.gridPoints.shape[1]*self.gridPoints.shape[2]]).T\n",
    "        else :\n",
    "            self.gridPoints = getGridPointsInPolygon2D(self.worldGroundPlanePoints[:, :-1], self.gridSpacing)\n",
    "            \n",
    "        self.angles = np.arange(0, np.pi*2, np.pi/self.numAngleDivisions*2)\n",
    "        allPositions, allBestMatchesCost = self.computeCostOnGrid(filmedObject)\n",
    "        \n",
    "        for position, bestMatchesCost in zip(allPositions, allBestMatchesCost) :\n",
    "            modelMat = np.array([[0.1, 0, 0, 0],\n",
    "                                 [0, 0.1, 0, 0],\n",
    "                                 [0, 0, 0.1, 0],\n",
    "                                 [0, 0, 0, 1]], dtype=np.float32)\n",
    "            modelMat[:-1, -1] = position\n",
    "            self.coloredSpheres.append(GLColoredSphere(modelMat, cm.jet(bestMatchesCost, bytes=True)[:, :-1].astype(np.float32)))\n",
    "            \n",
    "        print(\"DONE in\", time.time()-tmp)\n",
    "    \n",
    "    def computeCostOnGrid(self, filmedObject) :\n",
    "        allPositions = []\n",
    "        allBestMatchesCost = []\n",
    "        for i, loc in enumerate(self.gridPoints) :\n",
    "            \n",
    "            objPos, bestMatchesCost, bestOrientationMatchCost, bestOrientationMatchFrameIdx, bestOrientationModelMat = self.getCostsAtGridPoint(i, filmedObject)\n",
    "#             print(objPos, bestMatchesCost)\n",
    "            allPositions.append(objPos)\n",
    "            allBestMatchesCost.append(bestMatchesCost)\n",
    "\n",
    "        allBestMatchesCost = np.array(allBestMatchesCost)\n",
    "        allBestMatchesCost = np.log(allBestMatchesCost)/np.max(np.log(allBestMatchesCost))\n",
    "        \n",
    "        return allPositions, allBestMatchesCost\n",
    "        \n",
    "    def getCostsAtGridPoint(self, idx, filmedObject) :\n",
    "        \"\"\" Returns position and costs of visualizing a filmedObject at a certain location on a grid and a number of different orientations \"\"\"\n",
    "        \n",
    "        bestMatchesCost = []\n",
    "        bestOrientationModelMat = np.eye(4, dtype=np.float32)\n",
    "        bestOrientationMatchCost = 1e20\n",
    "        bestOrientationMatchFrameIdx = 0\n",
    "        for angle in self.angles :\n",
    "            modelMat, orientationDirection, bestMatchFrameIdx, bestMatchCost = self.getCostAtGridPointAndAngle(idx, angle, filmedObject)\n",
    "            bestMatchesCost.append(bestMatchCost)\n",
    "            \n",
    "            if bestMatchCost < bestOrientationMatchCost :\n",
    "                bestOrientationMatchCost = bestMatchCost\n",
    "                bestOrientationModelMat = np.copy(modelMat).astype(np.float32)\n",
    "                bestOrientationMatchFrameIdx = bestMatchFrameIdx\n",
    "            \n",
    "        return modelMat[:-1, -1].flatten(), np.array(bestMatchesCost).flatten(), bestOrientationMatchCost, bestOrientationMatchFrameIdx, bestOrientationModelMat\n",
    "            \n",
    "    def getCostAtGridPointAndAngle(self, idx, angle, filmedObject) :\n",
    "        \"\"\" Returns modelMat, orientation direction based on angle, index of best frame and best cost of visualizing a filmedObject at a certain location on a grid at given orientation \"\"\"\n",
    "        \n",
    "        T = np.dot(filmedObject.cameraIntrinsics, filmedObject.cameraExtrinsics[:-1, [0, 1, 3]])\n",
    "        \n",
    "        objPos = np.array([self.gridPoints[idx, 0], self.gridPoints[idx, 1], 0.0])\n",
    "        modelMat = quaternionTo4x4Rotation(angleAxisToQuaternion(angle, np.array([0.0, 0.0, -1.0])))\n",
    "        modelMat[:-1, -1] = objPos\n",
    "        \n",
    "        ## find object location and direction in camera space\n",
    "        objectPosWorld = np.dot(modelMat, np.array([[0.0], [0.0], [0.0], [1.0]])).flatten()\n",
    "        objectPosWorld = objectPosWorld[:-1]/objectPosWorld[-1]\n",
    "        objectPosCamera = np.dot(T, np.concatenate([objectPosWorld[:-1], [1.0]])).flatten()\n",
    "        objectPosCamera = objectPosCamera[:-1]/objectPosCamera[-1]\n",
    "\n",
    "        objectDirPosWorld = np.dot(modelMat, filmedObject.forwardDir).flatten()\n",
    "        objectDirPosWorld = objectDirPosWorld[:-1]/objectDirPosWorld[-1]\n",
    "        objectDirPosCamera = np.dot(T, np.concatenate([objectDirPosWorld[:-1], [1.0]])).flatten()\n",
    "        objectDirPosCamera = objectDirPosCamera[:-1]/objectDirPosCamera[-1]\n",
    "        \n",
    "#         distances = viewToObjectDirAngleDistance(filmedObject, filmedObject.cameraExtrinsics, modelMat)\n",
    "        distances = viewToObjectDirAngleDistance(filmedObject, self.cameraViewMat, modelMat)\n",
    "        return modelMat, [objectPosCamera, objectDirPosCamera], int(np.argmin(distances).flatten()), float(np.min(distances).flatten())\n",
    "        \n",
    "    def setShaders(self) :\n",
    "        for i in xrange(len(self.coloredSpheres)) :\n",
    "            self.coloredSpheres[i].setShaders()\n",
    "        self.initDone = True\n",
    "        \n",
    "    def draw(self, projectionMat, viewMat) :\n",
    "        if self.initDone :\n",
    "            for i in xrange(len(self.coloredSpheres)) :\n",
    "                self.coloredSpheres[i].draw(projectionMat, viewMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FaceDetectionWidget(QtGui.QWidget) :\n",
    "    bboxMoved = QtCore.Signal(float, float)\n",
    "    \n",
    "    def __init__(self, doShowCapturedImage) :\n",
    "        super(FaceDetectionWidget, self).__init__()\n",
    "        \n",
    "        self.doShowCapturedImage = doShowCapturedImage\n",
    "        self.imageHeight = 80.0\n",
    "        self.cropTo = np.array([80, 90])\n",
    "        self.isTrackerRunning = False\n",
    "        self.readyToInit = False\n",
    "        self.numFramesFaceDetected = 0\n",
    "        self.desiredTrackFPS = 20\n",
    "        self.bbox = np.array([0, 0, 0, 0], float) ## (x, y, w, h)\n",
    "        self.trackLastTime = time.time()\n",
    "        \n",
    "        self.createGUI()\n",
    "        \n",
    "        self.vc = cv2.VideoCapture(0)\n",
    "        self.faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "        \n",
    "    def cleanup(self) :\n",
    "        self.vc.release()        \n",
    "        \n",
    "    def trackInFrame(self) :\n",
    "        if time.time() - self.trackLastTime > 1.0/self.desiredTrackFPS :\n",
    "            self.trackLastTime = time.time()\n",
    "            rval, frame = self.vc.read()\n",
    "            doRestartInit = False\n",
    "            if rval :\n",
    "                gray = cv2.flip(cv2.cvtColor(cv2.resize(frame, (int(self.imageHeight/frame.shape[0]*frame.shape[1]), int(self.imageHeight))), cv2.COLOR_BGR2GRAY), 1)\n",
    "                cropBy = (np.array(gray.shape)-self.cropTo)/2\n",
    "                gray = gray[cropBy[0]:cropBy[0]+self.cropTo[0], cropBy[1]:cropBy[1]+self.cropTo[1]]\n",
    "                if self.doShowCapturedImage :\n",
    "                    self.imageLabel.setImage(gray.reshape([gray.shape[0], gray.shape[1], 1]).repeat(3, axis=-1))\n",
    "\n",
    "                if not self.isTrackerRunning :\n",
    "                    if self.readyToInit :\n",
    "                        ## init CMT tracker\n",
    "\n",
    "                        self.tracker = CMT.CMT()\n",
    "                        self.tracker.estimate_scale = True\n",
    "                        self.tracker.estimate_rotation = False\n",
    "\n",
    "                        self.tracker.initialise(gray, (self.bbox[0], self.bbox[1]), \n",
    "                                                      (self.bbox[0]+self.bbox[2], self.bbox[1]+self.bbox[3]), \n",
    "                                                      (self.bbox[0]+self.bbox[2], self.bbox[1]), \n",
    "                                                      (self.bbox[0], self.bbox[1]+self.bbox[3]))\n",
    "                        self.imageLabel.setBBox(self.bbox, [0, 255, 0, 255])\n",
    "                        self.isTrackerRunning = True\n",
    "                    else :\n",
    "                        ## track using face detector\n",
    "                        faces = self.faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(int(self.cropTo[0]*0.4), int(self.cropTo[0]*0.4)), flags=cv2.cv.CV_HAAR_SCALE_IMAGE)\n",
    "                        if len(faces) > 0 :\n",
    "                            self.numFramesFaceDetected += 1\n",
    "                            if self.doShowCapturedImage :\n",
    "                                ## show found bbox\n",
    "                                self.imageLabel.setBBox(np.array(faces[0], float), [255, 255, 0, 255])\n",
    "                            else :\n",
    "                                self.imageLabel.setBBox(None, None)\n",
    "\n",
    "                            if self.numFramesFaceDetected == 1 :\n",
    "                                ## set self.bbox\n",
    "                                self.bbox = np.array(faces[0], float)\n",
    "                            else :\n",
    "                                bboxDist = np.sqrt(np.sum((np.array(faces[0], float)-self.bbox)**2))\n",
    "                                ## if the bbox hasn't changed too much, the new bbox is the average of the previous and the new\n",
    "                                if bboxDist < 10.0 :\n",
    "                                    self.bbox = np.average(np.vstack([self.bbox.reshape([1, 4]), np.array(faces[0], float).reshape([1, 4])]), axis=0)\n",
    "\n",
    "                                if self.numFramesFaceDetected == 30 :\n",
    "                                    self.readyToInit = True\n",
    "                        else :\n",
    "                            ## if face hasn't been found, need to restart initialization\n",
    "                            doRestartInit = True\n",
    "                else :\n",
    "                    self.tracker.process_frame(gray)\n",
    "                    # Draw updated estimate\n",
    "                    if self.tracker.has_result:\n",
    "                        ## update bbox\n",
    "                        self.bbox = np.array([self.tracker.tl[0], self.tracker.tl[1], self.tracker.br[0]-self.tracker.tl[0], self.tracker.br[1]-self.tracker.tl[1]], float)\n",
    "    #                     self.bbox = np.array([-30, -30, 60, 60], float)\n",
    "                        self.imageLabel.setBBox(self.bbox, [0, 255, 0, 255])\n",
    "\n",
    "                        centerPoint = np.array([gray.shape[1]/2.0, gray.shape[0]/2.0])\n",
    "                        boxCenter = self.bbox[0:2]+self.bbox[2:]/2.0\n",
    "                        moveTo = (boxCenter-centerPoint)/centerPoint\n",
    "                        self.bboxMoved.emit(moveTo[0], -moveTo[1]) ## need a - for the y coord because right now I'm using opencv image coords and I want to use opengl ones\n",
    "    #                     print(moveTo)\n",
    "            else :\n",
    "                ## if frame is not available from webcam, need to restart initialization\n",
    "                doRestartInit = True\n",
    "\n",
    "            if doRestartInit :\n",
    "                self.imageLabel.setBBox(None, None)\n",
    "                self.numFramesFaceDetected = 0\n",
    "                self.isTrackerRunning = False\n",
    "                self.readyToInit = False\n",
    "\n",
    "    def createGUI(self) :\n",
    "        \n",
    "        self.imageLabel = ImageLabel(\"Video Capture\")\n",
    "        self.imageLabel.setFixedSize(self.imageHeight, self.imageHeight)\n",
    "        \n",
    "        mainLayout = QtGui.QVBoxLayout()\n",
    "        mainLayout.addWidget(self.imageLabel)\n",
    "        \n",
    "        self.setLayout(mainLayout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING /home/ilisescu/PhD/data/havana_short/downsampledSet-4x.npy\n",
      "LOADED green_car1\n",
      "[ 12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29\n",
      "  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155\n",
      " 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173\n",
      " 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191\n",
      " 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263\n",
      " 264 265 266 267 268 269 270 271 272 273 274 275] 264 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilisescu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:116: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "/home/ilisescu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:387: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE in 26.1069400311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX DELTA 0.111188173294\n",
      "START PLAYING\n",
      "STOP PLAYING\n",
      "START PLAYING\n",
      "STOP PLAYING\n",
      "PREVIOUS:\n",
      " [[  9.82782737e-01  -1.47040063e-01   1.11666259e-01  -5.25276669e+01]\n",
      " [ -4.32004793e-02   4.04876416e-01   9.13349067e-01  -1.45534169e+01]\n",
      " [ -1.79546034e-01  -9.02440740e-01   3.91555459e-01  -7.99248097e+01]\n",
      " [  5.61731360e-07  -3.55456762e-07   9.42939505e-09   9.99986717e-01]]\n",
      "EXTRINSICS:\n",
      " [[  8.53921474e-01   5.20377864e-01  -4.99958923e-03   4.33377562e+00]\n",
      " [  2.22200702e-01  -3.73277150e-01  -9.00716946e-01  -5.48714971e+00]\n",
      " [ -4.70579393e-01   7.68030630e-01  -4.34377700e-01   4.71429587e+01]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n",
      "VIEW:\n",
      " [[  8.53921474e-01   5.20377864e-01  -4.99958923e-03   4.33377562e+00]\n",
      " [ -2.22200702e-01   3.73277150e-01   9.00716946e-01   5.48714971e+00]\n",
      " [  4.70579393e-01  -7.68030630e-01   4.34377700e-01  -4.71429587e+01]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n",
      "FSDFSAD 0.0 1746.0 982.0 0.0\n",
      "PROJ:\n",
      " [[ 0.95089376  0.          0.          0.        ]\n",
      " [ 0.          2.41421366  0.          0.        ]\n",
      " [ 0.          0.         -1.00020003 -0.20002   ]\n",
      " [ 0.          0.         -1.          0.        ]]\n",
      "PROJ_NEW:\n",
      " [[  8.05269187e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   1.43177189e+00  -1.11022302e-16   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00  -1.00200200e+00  -2.00200200e-01]\n",
      " [  0.00000000e+00   0.00000000e+00  -1.00000000e+00   0.00000000e+00]]\n",
      "START PLAYING\n",
      "PREVIOUS:\n",
      " [[  8.53921438e-01   5.20377889e-01  -4.99958645e-03   4.33377567e+00]\n",
      " [ -2.22200904e-01   3.73277197e-01   9.00716961e-01   5.48714972e+00]\n",
      " [  4.70580888e-01  -7.68030609e-01   4.34377670e-01  -4.85486735e+01]\n",
      " [ -2.98023225e-08   1.32406652e-16  -9.99200722e-16   9.99999998e-01]]\n",
      "EXTRINSICS:\n",
      " [[  8.53921474e-01   5.20377864e-01  -4.99958923e-03   4.33377562e+00]\n",
      " [  2.22200702e-01  -3.73277150e-01  -9.00716946e-01  -5.48714971e+00]\n",
      " [ -4.70579393e-01   7.68030630e-01  -4.34377700e-01   4.71429587e+01]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n",
      "VIEW:\n",
      " [[  8.53921474e-01   5.20377864e-01  -4.99958923e-03   4.33377562e+00]\n",
      " [ -2.22200702e-01   3.73277150e-01   9.00716946e-01   5.48714971e+00]\n",
      " [  4.70579393e-01  -7.68030630e-01   4.34377700e-01  -4.71429587e+01]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n",
      "FSDFSAD 0.0 1746.0 982.0 0.0\n",
      "PROJ:\n",
      " [[  8.05269187e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   1.43177189e+00  -1.11022302e-16   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00  -1.00200200e+00  -2.00200200e-01]\n",
      " [  0.00000000e+00   0.00000000e+00  -1.00000000e+00   0.00000000e+00]]\n",
      "PROJ_NEW:\n",
      " [[  8.05269187e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   1.43177189e+00  -1.11022302e-16   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00  -1.00200200e+00  -2.00200200e-01]\n",
      " [  0.00000000e+00   0.00000000e+00  -1.00000000e+00   0.00000000e+00]]\n",
      "STOP PLAYING\n",
      "START PLAYING\n",
      "STOP PLAYING\n",
      "START PLAYING\n",
      "STOP PLAYING\n"
     ]
    }
   ],
   "source": [
    "window = Window()\n",
    "window.show()\n",
    "app.exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getGridPairIndices(width, height) :\n",
    "## deal with pixels that have East and South neighbours i.e. all of them apart from last column and last row\n",
    "    pairIdxs = np.zeros(((width*height-(width+height-1))*2, 2), dtype=int)\n",
    "## each column contains idxs [0, h-2]\n",
    "    idxs = np.arange(0, height-1, dtype=int).reshape((height-1, 1)).repeat(width-1, axis=-1)\n",
    "## each column contains idxs [0, h-2]+h*i where i is the column index \n",
    "## (i.e. now I have indices of all nodes in the grid apart from last col and row)\n",
    "    idxs += (np.arange(0, width-1)*height).reshape((1, width-1)).repeat(height-1, axis=0)\n",
    "    # figure(); imshow(idxs)\n",
    "## now flatten idxs and repeat once so that I have the idx for each node that has E and S neighbours twice\n",
    "    idxs = np.ndarray.flatten(idxs.T).repeat(2)\n",
    "## idxs for each \"left\" node (that is connected to the edge) are the ones just computed\n",
    "    pairIdxs[:, 0] = idxs\n",
    "## idxs for each \"right\" node are to the E and S so need to sum \"left\" idx to height and to 1\n",
    "# print np.ndarray.flatten(np.array([[patchSize[0]], [1]]).repeat(np.prod(patchSize)-(np.sum(patchSize)-1), axis=-1).T)\n",
    "    pairIdxs[:, 1] = idxs + np.ndarray.flatten(np.array([[height], [1]]).repeat(width*height-(width+height-1), axis=-1).T)\n",
    "    \n",
    "## deal with pixels that have only East neighbours\n",
    "## get \"left\" nodes\n",
    "    leftNodes = np.arange(height-1, width*height-1, height)\n",
    "## now connect \"left\" nodes to the nodes to their East (i.e. sum to height) and add them to the list of pair indices\n",
    "    pairIdxs = np.concatenate((pairIdxs, np.array([leftNodes, leftNodes+height]).T), axis=0)\n",
    "    \n",
    "## deal with pixels that have only South neighbours\n",
    "## get \"top\" nodes\n",
    "    topNodes = np.arange(width*height-height, width*height-1)\n",
    "## now connect \"to\" nodes to the nodes to their South (i.e. sum to 1) and add them to the list of pair indices\n",
    "    pairIdxs = np.concatenate((pairIdxs, np.array([topNodes, topNodes+1]).T), axis=0)\n",
    "    \n",
    "    return pairIdxs\n",
    "\n",
    "def backgroundCut(bgImage, image, k1=30.0/255.0, k2=60.0/255.0, K=5.0/255.0, sigmaZ=10.0/255.0) :\n",
    "    \"\"\" Given an image and a static background bgImage, it computes fg/bg segmentation\n",
    "    \n",
    "    based on BGcut [Sun et al. ECCV2006] with modifications seen in Video Synposis [Pritch et al. PAMI2008]\"\"\"\n",
    "    ## as seen in Sun's background cut (with the mods made in pritch synopsis paper)\n",
    "#     figure(\"bgImage\"); imshow(bgImage); figure(\"image\"); imshow(image)\n",
    "    \n",
    "    if np.all(bgImage.shape != image.shape) :\n",
    "        raise Exception(\"The two specified patches have different shape so graph cannot be built\")\n",
    "    \n",
    "    height, width, channels = bgImage.shape\n",
    "    maxCost = 10000000.0#np.sys.float_info.max\n",
    "    \n",
    "    bgPixels = bgImage.reshape([height*width, channels], order='F')/255.0\n",
    "    imagePixels = image.reshape([height*width, channels], order='F')/255.0\n",
    "    \n",
    "    s = time.time()\n",
    "    ## build graph\n",
    "    numLabels = 2\n",
    "    numNodes = height*width\n",
    "    gm = opengm.gm(np.ones(numNodes,dtype=opengm.label_type)*numLabels)\n",
    "    \n",
    "    \n",
    "    ############################### COMPUTE UNARIES ###############################\n",
    "    unaries = np.zeros((numNodes,numLabels))\n",
    "    \n",
    "    dr = np.sqrt(np.sum((imagePixels-bgPixels)**2.0, axis=-1))\n",
    "    \n",
    "    unaries[dr<=k1, 1] = (k1-dr)[dr<=k1]\n",
    "    unaries[dr>k2, 0] = maxCost\n",
    "    unaries[np.all(np.array([dr>k1, k2>dr]), axis=0), 0] = (dr-k1)[np.all(np.array([dr>k1, k2>dr]), axis=0)]\n",
    "        \n",
    "    # add functions\n",
    "    fids = gm.addFunctions(unaries)\n",
    "    # add first order factors\n",
    "    gm.addFactors(fids, np.arange(0, numNodes, 1))\n",
    "    \n",
    "    \n",
    "    ############################### COMPUTE PAIRWISE ###############################\n",
    "    pairIndices = getGridPairIndices(width, height)\n",
    "    \n",
    "    pairwise = np.zeros(len(pairIndices))\n",
    "    \n",
    "    zrs = np.max([np.sqrt(np.sum((imagePixels[pairIndices[:, 0], :]-bgPixels[pairIndices[:, 0], :])**2.0, axis=-1)),\n",
    "                  np.sqrt(np.sum((imagePixels[pairIndices[:, 1], :]-bgPixels[pairIndices[:, 1], :])**2.0, axis=-1))], axis=0)\n",
    "    \n",
    "    imPixelsDiff = np.sqrt(np.sum((imagePixels[pairIndices[:, 0], :]-imagePixels[pairIndices[:, 1], :])**2.0, axis=-1))\n",
    "    bgPixelsDiff = np.sqrt(np.sum((bgPixels[pairIndices[:, 0], :]-bgPixels[pairIndices[:, 1], :])**2.0, axis=-1))\n",
    "    drs = imPixelsDiff/(1+((bgPixelsDiff/K)**2.0)*np.exp(-(zrs**2)/sigmaZ))\n",
    "    beta = 2.0/np.mean(imPixelsDiff)\n",
    "    pairwise = np.exp(-beta*drs)\n",
    "    \n",
    "    ## visualize\n",
    "    if False :\n",
    "        contrastMap = np.zeros(len(bgPixels))\n",
    "        for i in np.arange((width-1)*(height-1)*2) :\n",
    "            contrastMap[pairIndices[i, 0]] += drs[i]\n",
    "        figure(); imshow(np.reshape(np.sqrt(np.copy(contrastMap)), [height, width], 'F'))\n",
    "    \n",
    "    # add functions\n",
    "    fids = gm.addFunctions(np.array([[0.0, 1.0],[1.0, 0.0]]).reshape((1, 2, 2)).repeat(len(pairwise), axis=0)*\n",
    "                           pairwise.reshape((len(pairwise), 1, 1)).repeat(2, axis=1).repeat(2, axis=2))\n",
    "    \n",
    "    # add second order factors\n",
    "    gm.addFactors(fids, pairIndices)\n",
    "    \n",
    "    print(gm)\n",
    "    \n",
    "    \n",
    "    graphCut = opengm.inference.GraphCut(gm=gm)\n",
    "    graphCut.infer()    \n",
    "    labels = np.array(graphCut.arg(), dtype=int)\n",
    "    reshapedLabels = np.reshape(np.copy(labels), [height, width], 'F')\n",
    "    \n",
    "    return reshapedLabels\n",
    "\n",
    "def backgroundCut3D(bgImage, images, k1=30.0/255.0, k2=60.0/255.0, K=5.0/255.0, sigmaZ=10.0/255.0) :\n",
    "    \"\"\" Given a stack of temporally sequential images and a static background bgImage, it computes temporally consistent fg/bg segmentation\n",
    "    \n",
    "    based on BGcut [Sun et al. ECCV2006] with modifications seen in Video Synposis [Pritch et al. PAMI2008]\"\"\"\n",
    "    ## as seen in Sun's background cut (with the mods made in pritch synopsis paper)\n",
    "#     figure(\"bgImage\"); imshow(bgImage); figure(\"image\"); imshow(image)\n",
    "    \n",
    "    if np.all(bgImage.shape != images.shape[:-1]) :\n",
    "        raise Exception(\"The two specified patches have different shape so graph cannot be built\")\n",
    "    \n",
    "    height, width, channels, numImages = images.shape\n",
    "    maxCost = 10000000.0#np.sys.float_info.max\n",
    "    \n",
    "    bgPixels = bgImage.reshape([height*width, channels], order='F')/255.0\n",
    "    \n",
    "    s = time.time()\n",
    "    ## build graph\n",
    "    numLabels = 2\n",
    "    gm = opengm.gm(np.ones(height*width*numImages,dtype=opengm.label_type)*numLabels)\n",
    "    \n",
    "    for i in np.arange(numImages) :\n",
    "        imagePixels1 = images[:, :, :, i].reshape([height*width, channels], order='F')/255.0\n",
    "\n",
    "\n",
    "        ############################### COMPUTE UNARIES ###############################\n",
    "        unaries = np.zeros((height*width,numLabels))\n",
    "\n",
    "        dr = np.sqrt(np.sum((imagePixels1-bgPixels)**2.0, axis=-1))\n",
    "\n",
    "        unaries[dr<=k1, 1] = (k1-dr)[dr<=k1]\n",
    "        unaries[dr>k2, 0] = maxCost\n",
    "        unaries[np.all(np.array([dr>k1, k2>dr]), axis=0), 0] = (dr-k1)[np.all(np.array([dr>k1, k2>dr]), axis=0)]\n",
    "\n",
    "        # add functions\n",
    "        fids = gm.addFunctions(unaries)\n",
    "        # add first order factors\n",
    "        gm.addFactors(fids, np.arange(i*height*width, (i+1)*height*width, 1))\n",
    "\n",
    "\n",
    "        ############################### COMPUTE PAIRWISE ###############################\n",
    "        for j in np.arange(2) :\n",
    "            if j == 0 or (i > 0 and j ==1) :\n",
    "                pairIndices = getGridPairIndices(width, height)\n",
    "\n",
    "                imagePixels2 = imagePixels1\n",
    "                if i > 0 and j == 1 :\n",
    "                    ## in this case compute pairwise between temporally neighbouring pixels in current image and previous one\n",
    "                    pairIndices = np.concatenate([[np.arange(width*height)], [np.arange(width*height)]]).T\n",
    "                    imagePixels2 = images[:, :, :, i-1].reshape([height*width, channels], order='F')/255.0\n",
    "\n",
    "                pairwise = np.zeros(len(pairIndices))\n",
    "\n",
    "                zrs = np.max([np.sqrt(np.sum((imagePixels2[pairIndices[:, 0], :]-bgPixels[pairIndices[:, 0], :])**2.0, axis=-1)),\n",
    "                              np.sqrt(np.sum((imagePixels1[pairIndices[:, 1], :]-bgPixels[pairIndices[:, 1], :])**2.0, axis=-1))], axis=0)\n",
    "\n",
    "                imPixelsDiff = np.sqrt(np.sum((imagePixels2[pairIndices[:, 0], :]-imagePixels1[pairIndices[:, 1], :])**2.0, axis=-1))\n",
    "                bgPixelsDiff = np.sqrt(np.sum((bgPixels[pairIndices[:, 0], :]-bgPixels[pairIndices[:, 1], :])**2.0, axis=-1))\n",
    "                drs = imPixelsDiff/(1+((bgPixelsDiff/K)**2.0)*np.exp(-(zrs**2)/sigmaZ))\n",
    "                beta = 2.0/np.mean(imPixelsDiff)\n",
    "                pairwise = np.exp(-beta*drs)\n",
    "\n",
    "                ## visualize\n",
    "                if False :\n",
    "                    contrastMap = np.zeros(len(bgPixels))\n",
    "                    for i in np.arange((width-1)*(height-1)*2) :\n",
    "                        contrastMap[pairIndices[i, 0]] += drs[i]\n",
    "                    figure(); imshow(np.reshape(np.sqrt(np.copy(contrastMap)), [height, width], 'F'))\n",
    "\n",
    "                # add functions\n",
    "                fids = gm.addFunctions(np.array([[0.0, 1.0],[1.0, 0.0]]).reshape((1, 2, 2)).repeat(len(pairwise), axis=0)*\n",
    "                                       pairwise.reshape((len(pairwise), 1, 1)).repeat(2, axis=1).repeat(2, axis=2))\n",
    "\n",
    "                if j == 0 :\n",
    "                    ## in this case compute pairwise between neighbouring pixels in the current image\n",
    "                    # add second order factors\n",
    "                    gm.addFactors(fids, pairIndices+(i*height*width))\n",
    "                elif i > 0 and j == 1 :\n",
    "                    ## in this case compute pairwise between temporally neighbouring pixels in current image and previous one\n",
    "                    pairIndices[:, 0] += ((i-1)*height*width)\n",
    "                    pairIndices[:, 1] += (i*height*width)\n",
    "                    gm.addFactors(fids, pairIndices)\n",
    "    \n",
    "    print(gm)\n",
    "    \n",
    "    \n",
    "    graphCut = opengm.inference.GraphCut(gm=gm)\n",
    "    graphCut.infer()    \n",
    "    labels = np.array(graphCut.arg(), dtype=int)\n",
    "    reshapedLabels = np.reshape(np.copy(labels), [height, width, numImages], 'F')\n",
    "    \n",
    "    return reshapedLabels\n",
    "    \n",
    "# resizeMultiplier = 1.0\n",
    "\n",
    "# fgMask = backgroundCut(cv2.resize(bgImage, (0, 0), fx=resizeMultiplier, fy=resizeMultiplier, interpolation=cv2.INTER_AREA),\n",
    "#                        cv2.resize(im, (0, 0), fx=resizeMultiplier, fy=resizeMultiplier, interpolation=cv2.INTER_AREA))\n",
    "\n",
    "# fgMask2 = backgroundCut3D(cv2.resize(bgImage, (0, 0), fx=resizeMultiplier, fy=resizeMultiplier, interpolation=cv2.INTER_AREA),\n",
    "#                           cv2.resize(im, (0, 0), fx=resizeMultiplier, fy=resizeMultiplier, interpolation=cv2.INTER_AREA).reshape([im.shape[0], im.shape[1], im.shape[2], 1]))\n",
    "\n",
    "# # fgMask = cv2.morphologyEx(fgMask.astype(float), cv2.MORPH_OPEN, np.ones((5,5),np.uint8), iterations=1)\n",
    "# # fgMask = cv2.morphologyEx(fgMask.astype(float), cv2.MORPH_CLOSE, np.ones((5,5),np.uint8), iterations=2)*255\n",
    "# figure(); imshow(cv2.resize(fgMask.astype(np.uint8).reshape([fgMask.shape[0], fgMask.shape[1], 1]), (bgImage.shape[1], bgImage.shape[0]), interpolation=cv2.INTER_CUBIC))\n",
    "\n",
    "# for i in xrange(fgMask2.shape[-1]) :\n",
    "#     figure(); imshow(cv2.resize(fgMask2[:, :, i].astype(np.uint8).reshape([fgMask2[:, :, i].shape[0], \n",
    "#                                                                            fgMask2[:, :, i].shape[1], 1]), (bgImage.shape[1], bgImage.shape[0]), interpolation=cv2.INTER_CUBIC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def smoothLabels(bgImage, image, segmentation, prevLabels, k1=30.0/255.0, k2=60.0/255.0, K=5.0/255.0, sigmaZ=10.0/255.0) :\n",
    "    ## as seen in Sun's background cut (with the mods made in pritch synopsis paper)\n",
    "#     figure(\"bgImage\"); imshow(bgImage); figure(\"image\"); imshow(image)\n",
    "    \n",
    "    if np.all(bgImage.shape != image.shape) :\n",
    "        raise Exception(\"The two specified patches have different shape so graph cannot be built\")\n",
    "    \n",
    "    height, width, channels = bgImage.shape\n",
    "    maxCost = 10000000.0#np.sys.float_info.max\n",
    "    \n",
    "    bgPixels = bgImage.reshape([height*width, channels], order='F')/255.0\n",
    "    imagePixels = image.reshape([height*width, channels], order='F')/255.0\n",
    "    \n",
    "    labelIds = np.sort(list(set(prevLabels.flatten())))\n",
    "#     print(len(labelIds))\n",
    "    \n",
    "#     print(len(list(set(prevLabels.flatten()))))\n",
    "#     figure(); imshow(prevLabels)\n",
    "    \n",
    "    s = time.time()\n",
    "    ## build graph\n",
    "    numLabels = len(labelIds)\n",
    "    numNodes = height*width\n",
    "    gm = opengm.gm(np.ones(numNodes,dtype=opengm.label_type)*numLabels)\n",
    "    ## num of labels should be the number of different blobs and I should combine that cost with either the original unaries or with the segmentation I had before or a combination of the two\n",
    "    ## then the pairwise should probaly be the same as before as that reduces the cost of cutting around edges of the foreground objects but probably a measure simply based on gradients would \n",
    "    ## do too as the unaries should constrain the cuts to be around the foreground object...\n",
    "    \n",
    "    ############################### COMPUTE UNARIES ###############################\n",
    "    unaries = np.zeros((numNodes,numLabels))\n",
    "    \n",
    "#     dr = np.sqrt(np.sum((imagePixels-bgPixels)**2.0, axis=-1))\n",
    "    \n",
    "#     unaries[dr<=k1, 1] = (k1-dr)[dr<=k1]\n",
    "#     unaries[dr>k2, 0] = maxCost\n",
    "#     unaries[np.all(np.array([dr>k1, k2>dr]), axis=0), 0] = (dr-k1)[np.all(np.array([dr>k1, k2>dr]), axis=0)]\n",
    "\n",
    "    ## unaries for the background\n",
    "    unaries[:, 0] = segmentation.reshape([height*width], order='F')*numLabels\n",
    "#     figure(); imshow(unaries[:, 0].reshape([height, width], order='F'))\n",
    "    for i in np.arange(1, numLabels) :\n",
    "        unaries[:, i] = prevLabels.reshape([height*width], order='F') != labelIds[i]\n",
    "#         figure(); imshow(unaries[:, i].reshape([height, width], order='F'))\n",
    "        \n",
    "    \n",
    "    # add functions\n",
    "    fids = gm.addFunctions(unaries)\n",
    "    # add first order factors\n",
    "    gm.addFactors(fids, np.arange(0, numNodes, 1))\n",
    "    \n",
    "    \n",
    "    ############################### COMPUTE PAIRWISE ###############################\n",
    "    pairIndices = getGridPairIndices(width, height)\n",
    "    \n",
    "    pairwise = np.zeros(len(pairIndices))\n",
    "    \n",
    "    zrs = np.max([np.sqrt(np.sum((imagePixels[pairIndices[:, 0], :]-bgPixels[pairIndices[:, 0], :])**2.0, axis=-1)),\n",
    "                  np.sqrt(np.sum((imagePixels[pairIndices[:, 1], :]-bgPixels[pairIndices[:, 1], :])**2.0, axis=-1))], axis=0)\n",
    "    \n",
    "    imPixelsDiff = np.sqrt(np.sum((imagePixels[pairIndices[:, 0], :]-imagePixels[pairIndices[:, 1], :])**2.0, axis=-1))\n",
    "    bgPixelsDiff = np.sqrt(np.sum((bgPixels[pairIndices[:, 0], :]-bgPixels[pairIndices[:, 1], :])**2.0, axis=-1))\n",
    "    drs = imPixelsDiff/(1+((bgPixelsDiff/K)**2.0)*np.exp(-(zrs**2)/sigmaZ))\n",
    "    beta = 2.0/np.mean(imPixelsDiff)\n",
    "    pairwise = np.exp(-beta*drs)\n",
    "    \n",
    "    ## visualize\n",
    "    if False :\n",
    "        contrastMap = np.zeros(len(bgPixels))\n",
    "        for i in np.arange((width-1)*(height-1)*2) :\n",
    "            contrastMap[pairIndices[i, 0]] += pairwise[i]\n",
    "        figure(); imshow(np.reshape(np.sqrt(np.copy(contrastMap)), [height, width], 'F'))\n",
    "    \n",
    "    # add functions\n",
    "    maxPairwiseAtOnce = 100000\n",
    "    \n",
    "    for i in np.arange(0, len(pairwise), maxPairwiseAtOnce) :\n",
    "#         print((1.0-np.eye(numLabels)).reshape((1, numLabels, numLabels)).repeat(len(pairwise[i:i+maxPairwiseAtOnce]), axis=0).shape)\n",
    "        fids = gm.addFunctions((1.0-np.eye(numLabels)).reshape((1, numLabels, numLabels)).repeat(len(pairwise[i:i+maxPairwiseAtOnce]), axis=0)*\n",
    "                               pairwise[i:i+maxPairwiseAtOnce].reshape((len(pairwise[i:i+maxPairwiseAtOnce]), 1, 1)).repeat(numLabels, axis=1).repeat(numLabels, axis=2))\n",
    "    \n",
    "        # add second order factors\n",
    "        gm.addFactors(fids, pairIndices[i:i+maxPairwiseAtOnce, :])\n",
    "    \n",
    "#     print(gm)\n",
    "    \n",
    "    \n",
    "    graphCut = opengm.inference.TrwsExternal(gm=gm)\n",
    "    graphCut.infer()\n",
    "    labels = np.array(graphCut.arg(), dtype=int)\n",
    "    \n",
    "    ## set labels back to original labels\n",
    "    tmp = np.zeros_like(labels)\n",
    "    for i in np.arange(1, numLabels) :\n",
    "        tmp[labels == i] = labelIds[i]\n",
    "    \n",
    "    reshapedLabels = np.reshape(np.copy(tmp), [height, width], 'F')\n",
    "    \n",
    "    return reshapedLabels\n",
    "\n",
    "# newLabels = smoothLabels(bgImage[375:540, 1035:1275, :], ims[375:540, 1035:1275, :, 10], fgMasks[375:540, 1035:1275, 10], masksLabels[375:540, 1035:1275, 0])\n",
    "# newLabels = smoothLabels(bgImage[265:540, 965:1275, :], ims[265:540, 965:1275, :, 10], fgMasks[265:540, 965:1275, 10], masksLabels[265:540, 965:1275, 0])\n",
    "# newLabels = smoothLabels(bgImage, ims[:, :, :, 10], fgMasks[:, :, 10], masksLabels[:, :, 0])\n",
    "        \n",
    "def readNukeTrack(trackLocation) :\n",
    "    \"\"\"returns trajectoryPoints, sortedFrameKeys\"\"\"\n",
    "    f = open(trackLocation, 'r')\n",
    "    lines = f.readlines()\n",
    "    try :\n",
    "        vals = [np.array(i.split(\" \")).astype(float) for i in lines]\n",
    "    except ValueError :\n",
    "        return np.empty([0], dtype=int), np.empty([0, 2], dtype=float)\n",
    "    if np.array(vals).shape[1] != 3 :\n",
    "        return np.empty([0], dtype=int), np.empty([0, 2], dtype=float)\n",
    "\n",
    "    vals = [(int(i[-1]), i[0:2]) for i in vals]\n",
    "    tmp = dict(vals)\n",
    "    sortedFrameKeys = np.sort(tmp.keys())\n",
    "    trajectoryPoints = np.array([tmp[key] for key in sortedFrameKeys])\n",
    "    \n",
    "    return trajectoryPoints, sortedFrameKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING SCENE: /home/ilisescu/PhD/data/smooth_abbey_road/filmed_scene-smooth_abbey_road.npy\n",
      "LOADING OBJECT: /home/ilisescu/PhD/data/smooth_abbey_road/filmed_object-black_pickup1.npy\n",
      "435 561\n",
      "129 (312, 640, 127)\n",
      "0 1 (312, 640, 3, 3)\n",
      "-number of variables :599040\n",
      "-number of function(type-0)2193624\n",
      "-number of function(type-1)0\n",
      "-number of function(type-2)0\n",
      "-number of function(type-3)0\n",
      "-number of function(type-4)0\n",
      "-number of function(type-5)0\n",
      "-number of function(type-6)0\n",
      "-number of function(type-7)0\n",
      "-number of factors :2193624\n",
      "-max. factor order :2\n",
      "1 2 (312, 640, 3, 3)\n",
      "-number of variables :599040\n",
      "-number of function(type-0)2193624\n",
      "-number of function(type-1)0\n",
      "-number of function(type-2)0\n",
      "-number of function(type-3)0\n",
      "-number of function(type-4)0\n",
      "-number of function(type-5)0\n",
      "-number of function(type-6)0\n",
      "-number of function(type-7)0\n",
      "-number of factors :2193624\n",
      "-max. factor order :2\n",
      "2 3 (312, 640, 3, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-306-eeea4cb71255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m## compute mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mfgMasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaskIdx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackgroundCut3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbgImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumNeighboringFrames\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mfgMasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaskIdx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphologyEx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgMasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaskIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMORPH_CLOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-426f70f42dc6>\u001b[0m in \u001b[0;36mbackgroundCut3D\u001b[0;34m(bgImage, images, k1, k2, K, sigmaZ)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;31m# add functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 fids = gm.addFunctions(np.array([[0.0, 1.0],[1.0, 0.0]]).reshape((1, 2, 2)).repeat(len(pairwise), axis=0)*\n\u001b[0;32m--> 178\u001b[0;31m                                        pairwise.reshape((len(pairwise), 1, 1)).repeat(2, axis=1).repeat(2, axis=2))\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilisescu/anaconda2/lib/python2.7/site-packages/opengm/opengmcore/gm_injector.py\u001b[0m in \u001b[0;36maddFunctions\u001b[0;34m(self, functions)\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_addUnaryFunctions_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_addFunctions_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_addFunctions_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "close(\"all\")\n",
    "# filmedDatasetLoc = \"/home/ilisescu/PhD/data/havana/filmed_dataset-havana.npy\"\n",
    "# filmedDatasetLoc = \"/home/ilisescu/PhD/data/havana_short/filmed_dataset-havana_short.npy\"\n",
    "# filmedDatasetLoc = \"/home/ilisescu/PhD/data/abbey_road/filmed_dataset-abbey_road.npy\"\n",
    "# filmedDatasetLoc = \"/home/ilisescu/PhD/data/jackson/filmed_dataset-jackson.npy\"\n",
    "filmedDatasetLoc = \"/home/ilisescu/PhD/data/smooth_abbey_road/filmed_dataset-smooth_abbey_road.npy\"\n",
    "filmedDatasetData = np.load(filmedDatasetLoc).item()\n",
    "dataLoc = filmedDatasetData[DICT_FILMED_DATASET_BASE_LOC]+os.sep\n",
    "filmedScenesLocs = np.sort(glob.glob(dataLoc+\"filmed_scene-*.npy\"))\n",
    "filmedObjectsLocs = np.sort(glob.glob(dataLoc+\"filmed_object-*.npy\"))\n",
    "print(\"LOADING SCENE:\", filmedScenesLocs[0])\n",
    "print(\"LOADING OBJECT:\", filmedObjectsLocs[0])\n",
    "filmedSceneData = np.load(filmedScenesLocs[0]).item()\n",
    "filmedObjectData = np.load(filmedObjectsLocs[0]).item()\n",
    "_, usedFramesKeys = readNukeTrack(filmedObjectData[DICT_TRACK_LOCATION])\n",
    "print (np.min(usedFramesKeys), np.max(usedFramesKeys))\n",
    "\n",
    "resizeMultiplier = 1.0\n",
    "\n",
    "bgImage = cv2.resize(np.array(Image.open(dataLoc+\"median.png\")), (0, 0), fx=resizeMultiplier, fy=resizeMultiplier, interpolation=cv2.INTER_AREA)[:, :, 0:3]\n",
    "figure(); imshow(bgImage)\n",
    "\n",
    "numNeighboringFrames = 2 ## add numNeighboringFrames/2 before and numNeighboringFrames/2 after\n",
    "frameLocs = np.sort(glob.glob(dataLoc+\"frame-*.png\"))[np.min(usedFramesKeys)-(numNeighboringFrames/2):np.max(usedFramesKeys)+(numNeighboringFrames/2)+1]\n",
    "\n",
    "if True and os.path.isfile(dataLoc+\"segmentation-{0}to{1}.npy\".format(np.min(usedFramesKeys)+1, np.max(usedFramesKeys)+1)) :\n",
    "    ## fgMasks gets loaded later when removing blobs\n",
    "#     fgMasks = np.load(dataLoc+\"segmentation-2311to2590.npy\").astype(np.uint8)\n",
    "    fgMasks = np.load(dataLoc+\"segmentation-{0}to{1}.npy\".format(np.min(usedFramesKeys)+1, np.max(usedFramesKeys)+1)).astype(np.uint8)\n",
    "    pass\n",
    "else :\n",
    "    fgMasks = np.zeros([bgImage.shape[0], bgImage.shape[1], len(frameLocs)-numNeighboringFrames], dtype=np.uint8)\n",
    "    print(len(frameLocs), fgMasks.shape)\n",
    "    for maskIdx, frameIdx in enumerate(np.arange(numNeighboringFrames/2, len(frameLocs)-numNeighboringFrames/2)) :\n",
    "    # for maskIdx, frameIdx in enumerate(np.arange(numNeighboringFrames/2, 10-numNeighboringFrames/2)) :\n",
    "        ims = np.zeros([bgImage.shape[0], bgImage.shape[1], bgImage.shape[2], numNeighboringFrames+1], dtype=np.uint8)\n",
    "        print(maskIdx, frameIdx, ims.shape)\n",
    "\n",
    "        ## load the images\n",
    "        for idx, i in enumerate(np.arange(frameIdx-numNeighboringFrames/2, frameIdx+1+numNeighboringFrames/2)) :\n",
    "            im = np.array(Image.open(frameLocs[i]))\n",
    "            ims[:, :, :, idx] = cv2.resize(im, (0, 0), fx=resizeMultiplier, fy=resizeMultiplier, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        ## compute mask\n",
    "        fgMasks[:, :, maskIdx] = backgroundCut3D(bgImage, ims)[:, :, numNeighboringFrames/2]\n",
    "        fgMasks[:, :, maskIdx] = cv2.morphologyEx(fgMasks[:, :, maskIdx].astype(float), cv2.MORPH_CLOSE, np.ones((5,5),np.uint8), iterations=2)\n",
    "        sys.stdout.flush()\n",
    "    #         figure(); imshow(im)\n",
    "    #         diff = np.sqrt(np.sum((im/255.0-bgImage/255.0)**2, axis=-1))\n",
    "    #         figure(); imshow(diff)\n",
    "    np.save(dataLoc+\"segmentation-{0}to{1}.npy\".format(np.min(usedFramesKeys)+1, np.max(usedFramesKeys)+1), fgMasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## remove blobs smaller than threshold\n",
    "blobMinArea= 35\n",
    "# fgMasks = np.load(dataLoc+\"segmentation-2311to2590.npy\").astype(np.uint8)\n",
    "for i in np.arange(fgMasks.shape[-1]) :\n",
    "    labelling = measure.label(fgMasks[:, :, i])\n",
    "    for region in measure.regionprops(labelling) :\n",
    "        if len(np.argwhere(labelling == region[\"label\"])) < blobMinArea :\n",
    "            fgMasks[labelling == region[\"label\"], i] = 0\n",
    "    #         print(region[\"label\"],region[\"area\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure()\n",
    "img = None\n",
    "for i in xrange(fgMasks.shape[-1]):\n",
    "    if img is None:\n",
    "        img = mpl.pylab.imshow(fgMasks[:, :, i])\n",
    "    else:\n",
    "        img.set_data(fgMasks[:, :, i])\n",
    "    mpl.pylab.pause(0.01)\n",
    "    mpl.pylab.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1]]\n",
      "newly separated blobs []\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([3, 5]), 2]]\n",
      "newly separated blobs []\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([3, 5]), 2]]\n",
      "newly separated blobs [3]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([3, 5]), 2]]\n",
      "newly separated blobs [3]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([3, 5]), 3]]\n",
      "newly separated blobs [3]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([3, 5]), 3]]\n",
      "newly separated blobs [3]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([3, 5]), 3]]\n",
      "newly separated blobs [3]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([3, 5]), 3]]\n",
      "newly separated blobs [3]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1]]\n",
      "newly separated blobs []\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1]]\n",
      "newly separated blobs []\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1]]\n",
      "newly separated blobs []\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1]]\n",
      "newly separated blobs []\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 5]), 3]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([4, 8]), 8], [array([1, 2]), 1], [array([4, 5]), 3]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([4, 8]), 8], [array([1, 2]), 1], [array([4, 5]), 3]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([4, 8]), 8], [array([1, 2]), 1], [array([4, 5]), 3]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([4, 8]), 8], [array([1, 2]), 1], [array([4, 5]), 3]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([4, 8]), 8], [array([1, 2]), 1], [array([4, 5]), 3]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([4, 8]), 8], [array([1, 2]), 1], [array([4, 5]), 3]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 5]), 3], [array([4, 6, 8]), 6]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 5]), 3], [array([4, 6, 8]), 6]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 5]), 3], [array([4, 6, 8]), 6]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 5]), 3], [array([4, 6, 8]), 6]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 5, 6, 8]), 3]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 5, 6, 8]), 3]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 5, 6, 8]), 3]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 5, 6, 8]), 3]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 5, 6, 8]), 3]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 6, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 6, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 6, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 6, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 6, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 6, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 6, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 6, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 6, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 6, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 6, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 6, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 6, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 6, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 2]), 1], [array([4, 6, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 4, 6, 8]), 3], [array([4, 5]), 4], [array([4, 5]), 5]]\n",
      "newly separated blobs [1, 4, 5, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 4, 6, 8]), 3], [array([4, 5]), 4], [array([4, 5]), 5]]\n",
      "newly separated blobs [1, 4, 5, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 4, 6, 8]), 3], [array([4, 5]), 4], [array([4, 5]), 5]]\n",
      "newly separated blobs [1, 4, 5, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([4, 5]), 3], [array([1, 4, 8]), 4], [array([4, 5]), 5]]\n",
      "newly separated blobs [1, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([4, 5]), 3], [array([4, 8]), 4], [array([4, 5]), 5]]\n",
      "newly separated blobs [4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([4, 5]), 3], [array([4, 8]), 4], [array([4, 5]), 5]]\n",
      "newly separated blobs [4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([3, 4, 5]), 2], [array([4, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([3, 4, 5]), 2], [array([4, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([3, 4, 5]), 2], [array([4, 8]), 3], [array([4, 5]), 4]]\n",
      "newly separated blobs [4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 2], [array([4, 5]), 3]]\n",
      "newly separated blobs [4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 2], [array([4, 5]), 3]]\n",
      "newly separated blobs [4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 2]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 2]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 2]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 2]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 2]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 2]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 2]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 2]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 2]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 2]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 2]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 5]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 5]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 5]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 6]]\n",
      "newly separated blobs [4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 6]]\n",
      "newly separated blobs [4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5]), 1], [array([4, 8]), 6]]\n",
      "newly separated blobs [4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 8]), 1]]\n",
      "newly separated blobs [1, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 7, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1, 10, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1, 10, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 7, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 7, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 7, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 7, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 7, 8]), 1]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 4, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 2]]\n",
      "newly separated blobs [1]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 3]]\n",
      "newly separated blobs [1]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 3]]\n",
      "newly separated blobs [1]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 3]]\n",
      "newly separated blobs [1]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 4]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 4]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 4]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 4]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 4]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7, 8]), 4]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 10], [array([1, 3, 5, 7, 8]), 4]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 10], [array([ 1, 16]), 3], [array([1, 3, 5, 7, 8]), 4]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 10], [array([ 1, 16]), 3], [array([1, 3, 5, 7, 8]), 4]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 9], [array([ 1, 16]), 2], [array([1, 3, 5, 7, 8]), 3]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 9], [array([ 1, 16]), 2], [array([1, 3, 5, 7, 8]), 3], [array([1, 5]), 5]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 9], [array([ 1, 16]), 2], [array([1, 3, 5, 7, 8]), 3], [array([1, 5]), 5]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 9], [array([ 1, 16]), 2], [array([1, 3, 5, 7, 8]), 3], [array([1, 5]), 5]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 10], [array([ 1, 16]), 3], [array([1, 3, 5, 7, 8]), 4], [array([1, 5]), 6]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 10], [array([ 1, 16]), 3], [array([1, 3, 5, 7, 8]), 4], [array([1, 5]), 6]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 10], [array([ 1, 16]), 3], [array([1, 3, 5, 7, 8]), 4], [array([1, 5]), 6]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 10], [array([ 1, 16]), 3], [array([1, 3, 5, 7, 8]), 4]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 11], [array([ 1, 16]), 3], [array([1, 3, 5, 7, 8]), 4]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 11], [array([ 1, 16]), 3], [array([1, 3, 5, 7, 8]), 4]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 11], [array([ 1, 16]), 3], [array([1, 3, 5, 7, 8]), 4]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 11], [array([ 1, 16]), 3], [array([1, 3, 5, 7, 8]), 4]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 10], [array([ 1, 16]), 3], [array([1, 3, 5, 7, 8]), 4], [array([1, 5]), 6]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 10], [array([ 1, 16]), 3], [array([1, 3, 5, 7, 8]), 4], [array([1, 5]), 6]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 10], [array([ 1, 16]), 3], [array([1, 3, 5, 7, 8]), 4], [array([1, 5]), 6]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 10], [array([ 1, 16]), 3], [array([1, 3, 5, 7, 8]), 4], [array([1, 5]), 6]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 10], [array([ 1, 16]), 3], [array([1, 3, 5, 7, 8]), 4], [array([1, 5]), 6]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 8], [array([ 1,  3,  5,  7,  8, 16]), 3], [array([1, 5]), 5], [array([10, 15]), 6]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 8], [array([ 1,  3,  5,  7,  8, 16]), 3], [array([1, 5]), 5], [array([10, 15]), 6]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7,  8, 16]), 3], [array([1, 5]), 5], [array([10, 15]), 6], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7,  8, 16]), 3], [array([1, 5]), 5], [array([10, 15]), 6], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7, 16]), 3], [array([1, 5]), 5], [array([10, 15]), 6], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7, 16]), 3], [array([1, 5]), 5], [array([10, 15]), 6], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7, 16]), 3], [array([1, 5]), 5], [array([10, 15]), 6], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7, 16]), 3], [array([ 4, 10, 15]), 5], [array([ 6,  9, 14]), 6]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7, 16]), 3], [array([10, 15]), 5], [array([ 6,  9, 14]), 6]]\n",
      "newly separated blobs []\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7, 16]), 3], [array([ 4, 10, 15]), 5], [array([ 6,  9, 14]), 6]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7, 16]), 3], [array([ 4,  6,  9, 14]), 4], [array([1, 5]), 5], [array([ 4, 10, 15]), 6]]\n",
      "newly separated blobs [1, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7, 16]), 3], [array([ 4,  6,  9, 14]), 4], [array([ 4, 10, 15]), 5]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7, 16]), 3], [array([ 4,  6,  9, 14]), 4], [array([ 4, 10, 15]), 5]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7, 16]), 2], [array([ 4,  6,  9, 14]), 3], [array([ 4, 10, 15]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7, 16]), 2], [array([ 4,  6,  9, 14]), 3], [array([ 4, 10, 15]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7, 16]), 2], [array([ 4,  6,  9, 14]), 3], [array([ 4, 10, 15]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7, 16]), 2], [array([ 4,  6,  9, 14]), 3], [array([ 4, 10, 15]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([ 1,  3,  5,  7, 16]), 2], [array([ 4,  6,  9, 14]), 3], [array([ 4, 10, 15]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4,  6,  9, 14]), 3], [array([ 4, 10, 15]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4,  6,  9, 14]), 3], [array([ 4, 10, 15]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4,  6,  9, 14]), 3], [array([ 4, 10, 15]), 4]]\n",
      "newly separated blobs [4, 15]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4,  6,  9, 14]), 3], [array([ 4, 10, 15]), 4]]\n",
      "newly separated blobs [4, 15]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4,  6,  9, 14]), 3], [array([ 4, 10, 15]), 4]]\n",
      "newly separated blobs [4, 15]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4,  6,  9, 14]), 3], [array([ 4, 10, 15]), 4]]\n",
      "newly separated blobs [4, 15]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4,  6,  9, 14]), 3], [array([ 4, 10, 15]), 4]]\n",
      "newly separated blobs [4, 15]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4,  6,  9, 14]), 3], [array([ 4, 10, 15]), 4]]\n",
      "newly separated blobs [4, 15]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4, 10, 15]), 4], [array([ 4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [4, 15]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4, 10, 15]), 4], [array([ 4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [4, 15]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4, 10, 15]), 4], [array([ 4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [4, 15]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4, 10, 15]), 4], [array([ 4,  6,  9, 14]), 5]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4, 10, 15]), 4], [array([ 4,  6,  9, 14]), 5]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4, 10, 15]), 4], [array([ 4,  6,  9, 14]), 5]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4, 10, 15]), 4], [array([ 4,  6,  9, 14]), 5]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4, 10, 15]), 3], [array([ 4,  6,  9, 14]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4, 10, 15]), 3], [array([ 4,  6,  9, 14]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4, 10, 15]), 3], [array([ 4,  6,  9, 14]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 5, 7]), 2], [array([ 4,  6,  9, 14]), 4], [array([ 4, 10, 15]), 5]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([1, 3, 5]), 4], [array([ 4,  6,  9, 14]), 5], [array([ 4, 10, 15]), 6]]\n",
      "newly separated blobs [1, 3, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([1, 3, 5]), 4], [array([ 4,  6,  9, 14]), 5], [array([ 4, 10, 15]), 6]]\n",
      "newly separated blobs [1, 3, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([1, 3, 5]), 4], [array([ 4, 10, 15]), 5], [array([ 4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([1, 3, 5]), 4], [array([ 4, 10, 15]), 5], [array([ 4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([1, 3, 5]), 4], [array([ 4, 10, 15]), 5], [array([ 4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([1, 3, 5]), 3], [array([ 4, 10, 15]), 4], [array([ 4,  6,  9, 14]), 5]]\n",
      "newly separated blobs [1, 3, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 3], [array([1, 3, 5]), 4], [array([ 4, 10, 15]), 5], [array([ 4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 3], [array([1, 3, 5]), 4], [array([ 4, 10, 15]), 5], [array([ 4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 3], [array([1, 3, 5]), 4], [array([ 4, 10, 15]), 5], [array([ 4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 3], [array([1, 3, 5]), 4], [array([ 4, 10, 15]), 5], [array([ 4,  6,  9, 14]), 6], [array([1, 5]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 3], [array([3, 5]), 4], [array([ 4, 10, 15]), 5], [array([ 4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 3], [array([ 4, 10, 15]), 4], [array([3, 5]), 5], [array([ 4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 3], [array([ 4, 10, 15]), 4], [array([3, 5]), 5], [array([ 4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 3], [array([ 4, 10, 15]), 4], [array([3, 5]), 5], [array([ 4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 3], [array([ 4, 10, 15]), 4], [array([3, 5]), 5], [array([ 4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 3], [array([ 4, 10, 15]), 4], [array([3, 5]), 5], [array([ 4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 8], [array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 5]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 8], [array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 5]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 8], [array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 5]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 8], [array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 5]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 8], [array([ 4, 10, 15]), 2], [array([1, 3, 7]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 5]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 8], [array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 5]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 8], [array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 5]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 8], [array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 5]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 9], [array([1, 3, 7]), 3], [array([ 4, 10, 15]), 4], [array([3, 5]), 5], [array([ 4,  6, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 9], [array([ 4, 10, 15]), 3], [array([1, 3, 7]), 4], [array([3, 5]), 5], [array([ 4,  6, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 9], [array([ 4, 10, 15]), 3], [array([1, 3, 7]), 4], [array([3, 5]), 5], [array([ 4,  6, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 8], [array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 6]]\n",
      "newly separated blobs [14, 3, 4, 5, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 8], [array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 6]]\n",
      "newly separated blobs [14, 3, 4, 5, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 8], [array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 6]]\n",
      "newly separated blobs [14, 3, 4, 5, 6]\n",
      "old blobs merged to new blob [X, Y] [[array([ 9, 14]), 9], [array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 5], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 5], [array([ 6,  9, 14]), 7], [array([1, 4]), 8]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 5], [array([ 6,  9, 14]), 7], [array([1, 4]), 8]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 5], [array([ 6,  9, 14]), 7], [array([1, 4]), 8]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 5], [array([ 6,  9, 14]), 7], [array([1, 4]), 8]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 4,  6, 14]), 5], [array([ 6,  9, 14]), 7], [array([1, 4]), 8]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 1,  4,  6, 14]), 5], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 1,  4,  6, 14]), 5], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 1,  4,  6, 14]), 5], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 1,  4,  6, 14]), 6], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10, 15]), 3], [array([3, 5]), 4], [array([ 1,  4,  6, 14]), 6], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5, 6, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10]), 3], [array([3, 5]), 4], [array([ 1,  4, 14]), 6], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10]), 3], [array([3, 5]), 4], [array([ 1,  4, 14]), 6], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10]), 3], [array([3, 5]), 4], [array([ 1,  4, 14]), 6], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10]), 3], [array([3, 5]), 4], [array([ 1,  4, 14]), 6], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10]), 3], [array([3, 5]), 4], [array([ 1,  4, 14]), 6], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10]), 3], [array([3, 5]), 4], [array([ 1,  4, 14]), 6], [array([ 6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5, 14]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10]), 3], [array([3, 5]), 4], [array([ 1,  4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4, 10]), 3], [array([3, 5]), 4], [array([ 1,  4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([3, 5]), 3], [array([ 4, 10]), 4], [array([ 1,  4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([3, 5]), 3], [array([ 4, 10]), 4], [array([ 1,  4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([3, 5]), 3], [array([ 4, 10]), 4], [array([ 1,  4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([3, 5]), 3], [array([ 4, 10]), 4], [array([ 1,  4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([3, 5]), 3], [array([ 1,  4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([3, 5]), 3], [array([ 1,  4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([3, 5]), 3], [array([ 1,  4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([3, 5]), 3], [array([ 1,  4,  6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([3, 5]), 3], [array([ 1,  4,  6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([3, 5]), 3], [array([ 1,  4,  6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([3, 5]), 3], [array([ 1,  4,  6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([3, 5]), 3], [array([ 1,  4,  6,  9, 14]), 7]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 1,  4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 1,  4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 1,  4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 1,  4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 1,  4,  6,  9, 14]), 6]]\n",
      "newly separated blobs [1, 3, 4, 5]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 1,  4,  6,  9, 14]), 5]]\n",
      "newly separated blobs [1, 3, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 1,  4,  6,  9, 14]), 5]]\n",
      "newly separated blobs [1, 3, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 1,  4,  6,  9, 14]), 5]]\n",
      "newly separated blobs [1, 3, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 1,  4,  6,  9, 14]), 4]]\n",
      "newly separated blobs [1, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 1,  4,  6,  9, 14]), 4]]\n",
      "newly separated blobs [1, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 1,  4,  6,  9, 14]), 4]]\n",
      "newly separated blobs [1, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4,  6,  9, 14]), 4]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4,  6,  9, 14]), 5]]\n",
      "newly separated blobs [4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4,  6,  9, 14]), 5]]\n",
      "newly separated blobs [1, 4]\n",
      "old blobs merged to new blob [X, Y] [[array([1, 3, 7]), 2], [array([ 4,  6,  9, 14]), 5]]\n",
      "newly separated blobs [1, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fae8c1fe910>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## this would happen after I computed the temporally consistent masks and used close on them\n",
    "# fgMasksSubset = fgMasks[:, :, 0:]\n",
    "# imsSubset = ims[:, :, :, 0:]\n",
    "startFrame = 0\n",
    "# fgMasks = fgMasks.astype(int)\n",
    "masksLabels = np.zeros_like(fgMasks).astype(np.uint16)\n",
    "masksLabels[:, :, startFrame] = measure.label(fgMasks[:, :, startFrame].astype(bool))\n",
    "for i in np.arange(startFrame+1, fgMasks.shape[-1]) :\n",
    "# for i in np.arange(startFrame+1, startFrame+5) :\n",
    "    currentImage = np.array(Image.open(frameLocs[i+numNeighboringFrames/2]))\n",
    "    currentImage = cv2.resize(currentImage, (0, 0), fx=resizeMultiplier, fy=resizeMultiplier, interpolation=cv2.INTER_AREA)\n",
    "    ## do the labelling for each frame i and i-1\n",
    "    labels, maxLabel = measure.label(fgMasks[:, :, i-1:i+1].astype(bool), return_num=True)\n",
    "    ## match the labels between i-1 and the original i-1 labels and store mapping\n",
    "    ## if the newLabel happens more than once in the second column, it means two blobs have merged as two old labels have been mapped to a single new one\n",
    "#     figure(); imshow(np.copy(masksLabels[:, :, i-1]))\n",
    "#     figure(); imshow(np.copy(labels[:, :, 0]))\n",
    "    labelsMap = np.array(list(set([(oldLabel, newLabel) for oldLabel, newLabel in zip(masksLabels[fgMasks[:, :, i-1] != 0, i-1], labels[fgMasks[:, :, i-1] != 0, 0])])))\n",
    "    oldToNewLabelsMap = labelsMap[np.argsort(labelsMap[:, 0]).flatten(), :]\n",
    "    newToOldLabelsMap = labelsMap[np.argsort(labelsMap[:, 1]).flatten(), :][:, ::-1]\n",
    "    \n",
    "#     print(maxLabel, len(list(set(labels[fgMasks[:, :, i-1] != 0, 0]))))\n",
    "    \n",
    "    mappingNewToOldLabels = np.zeros([maxLabel+1, 2], labelsMap.dtype)\n",
    "    mappingNewToOldLabels[:, 0] = np.arange(maxLabel+1)\n",
    "    \n",
    "    \n",
    "    ## find blobs that are in frame i but not in i-1 and assign them new ids starting from the max of masksLabels so that every new blob gets recorded\n",
    "    newBlobIdsOnlyInCurrent = np.setdiff1d(list(set(labels[fgMasks[:, :, i] != 0, 1])), list(set(labels[fgMasks[:, :, i-1] != 0, 0])))\n",
    "    mappingNewToOldLabels[newBlobIdsOnlyInCurrent, 1] = np.arange(np.max(masksLabels)+1, np.max(masksLabels)+len(newBlobIdsOnlyInCurrent)+1)\n",
    "    \n",
    "    ## find blobs that are in frame i-1 but not in i and set them to the background id (i.e. 0)\n",
    "    newBlobIdsOnlyInPrevious = np.setdiff1d(list(set(labels[fgMasks[:, :, i-1] != 0, 0])), list(set(labels[fgMasks[:, :, i] != 0, 1])))\n",
    "    mappingNewToOldLabels[newBlobIdsOnlyInPrevious, 1] = 0\n",
    "    \n",
    "    ## new ids of blobs that used to be separated and are now merged: assign them to max_label_so_far+1\n",
    "    newMergedBlobFromMultipleOldOnes = np.sort(oldToNewLabelsMap[:, 1])\n",
    "    newMergedBlobFromMultipleOldOnes = list(set(newMergedBlobFromMultipleOldOnes[np.argwhere(newMergedBlobFromMultipleOldOnes[:-1]-newMergedBlobFromMultipleOldOnes[1:] == 0).flatten()]))\n",
    "    mappingNewToOldLabels[newMergedBlobFromMultipleOldOnes, 1] = np.max(mappingNewToOldLabels)+1\n",
    "    \n",
    "    listOfMergedOldBlobs = [oldToNewLabelsMap[np.argwhere(oldToNewLabelsMap[:, 1] == blobId).flatten(), 0] for blobId in newMergedBlobFromMultipleOldOnes]\n",
    "    print(\"old blobs merged to new blob [X, Y]\", [[tmp[0], tmp[1]] for tmp in zip(listOfMergedOldBlobs, newMergedBlobFromMultipleOldOnes)])\n",
    "    \n",
    "    \n",
    "    ## new ids of blobs that used to be merged and are now separated\n",
    "    newSeparateBlobsFromOneMergedOld = np.sort(newToOldLabelsMap[:, 1])\n",
    "    newSeparateBlobsFromOneMergedOld = list(set(newSeparateBlobsFromOneMergedOld[np.argwhere(newSeparateBlobsFromOneMergedOld[:-1]-newSeparateBlobsFromOneMergedOld[1:] == 0).flatten()]))\n",
    "    print(\"newly separated blobs\", newSeparateBlobsFromOneMergedOld)\n",
    "    \n",
    "#     print(newBlobIdsOnlyInCurrent, newBlobIdsOnlyInPrevious, newMergedBlobFromMultipleOldOnes, newSeparateBlobsFromOneMergedOld)\n",
    "    \n",
    "    \n",
    "#     print(mappingNewToOldLabels)\n",
    "    \n",
    "    ## assign the remaining blob ids to corresponding old labels\n",
    "    unchangedNewBlobIdToOldId = np.array(list(set([(pair[0], pair[1]) for pair in newToOldLabelsMap if pair[0] not in newMergedBlobFromMultipleOldOnes])))\n",
    "    mappingNewToOldLabels[unchangedNewBlobIdToOldId[:, 0], 1] = unchangedNewBlobIdToOldId[:, 1]\n",
    "    \n",
    "#     print(mappingNewToOldLabels)\n",
    "    masksLabels[fgMasks[:, :, i] != 0, i] = mappingNewToOldLabels[labels[fgMasks[:, :, i] != 0, 1], 1]\n",
    "    \n",
    "#     figure(); imshow(masksLabels[:, :, i])\n",
    "    \n",
    "    ################################## USE SMOOTH LABELS TO ENSURE MERGED BLOBS GET IDS FROM PREVIOUS LABELING ##################################\n",
    "    ## for every blob that came from merging old blobs do the \n",
    "    blobProperties = measure.regionprops(labels[:, :, 1])\n",
    "    bboxBorder = 20\n",
    "    for blob in blobProperties :\n",
    "        if blob[\"label\"] in newMergedBlobFromMultipleOldOnes :\n",
    "            ## enlarging the bbox and checking forout of bounds coords\n",
    "            bbox = np.min(np.vstack([[np.array(blob[\"bbox\"])+np.array([-bboxBorder, -bboxBorder, bboxBorder, bboxBorder])],\n",
    "                                     np.array([[labels.shape[0], labels.shape[1], labels.shape[0], labels.shape[1]]])]), axis=0)\n",
    "            minRow, minCol, maxRow, maxCol = np.max(np.vstack([[bbox], np.zeros([1, 4], int)]), axis=0)\n",
    "            \n",
    "            masksLabels[minRow:maxRow, minCol:maxCol, i] = smoothLabels(bgImage[minRow:maxRow, minCol:maxCol, :], currentImage[minRow:maxRow, minCol:maxCol, :],\n",
    "                                                                        labels[minRow:maxRow, minCol:maxCol, 1], masksLabels[minRow:maxRow, minCol:maxCol, i-1])\n",
    "            \n",
    "#             print(blob[\"label\"], np.argwhere(masksLabels[:, :, i] == 1))\n",
    "    \n",
    "    ## then do something\n",
    "#     figure(); imshow(masksLabels[:, :, i])\n",
    "#     print(newBlobsFromMerge)\n",
    "\n",
    "    \n",
    "########## CHECK THAT WHAT IS PRINTED MAKE SENSE ##########\n",
    "## to check if \"old blobs merged to new blob\" is correct, check if the blobs in X used to be separate in figure a and are now merged in blob Y figure b\n",
    "## to check if \"newly separated blobs\" is correct, check if the printed blob is merged in figure a and is now separate in figure b\n",
    "figure(\"a\"); imshow(masksLabels[:, :, -2])\n",
    "figure(\"b\"); imshow(labels[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fae872cdf10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure(\"a\"); imshow(masksLabels[:, :, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure()\n",
    "img = None\n",
    "for i in xrange(fgMasks.shape[-1]):\n",
    "    if img is None:\n",
    "        img = mpl.pylab.imshow(masksLabels[:, :, i])\n",
    "    else:\n",
    "        img.set_data(masksLabels[:, :, i])\n",
    "    mpl.pylab.pause(0.01)\n",
    "    mpl.pylab.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blobIdToShow = 1 #35 # 42\n",
    "imgsToShow = np.array(masksLabels == blobIdToShow, dtype=masksLabels.dtype)\n",
    "figure()\n",
    "img = None\n",
    "for i in np.arange(np.min(np.argwhere(imgsToShow == 1)[:, -1]), np.max(np.argwhere(imgsToShow == 1)[:, -1])+1):\n",
    "    if img is None:\n",
    "        img = mpl.pylab.imshow(imgsToShow[:, :, i])\n",
    "    else:\n",
    "        img.set_data(imgsToShow[:, :, i])\n",
    "    mpl.pylab.pause(0.01)\n",
    "    mpl.pylab.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## here doing the same as findContours but using skimage instead of opencv\n",
    "# from skimage import measure\n",
    "# tmp = measure.find_contours(undistortedFgMask/255.0, 0.99)\n",
    "# for i in xrange(len(tmp)) :\n",
    "#     tmp[i] = tmp[i][:, ::-1].reshape([tmp[i].shape[0], 1, 2]).astype(np.int32)\n",
    "    \n",
    "# tmp2 = np.ones_like(undistortedIm).astype(np.uint8)*255\n",
    "\n",
    "# for idx, cnt in enumerate(tmp) :\n",
    "#     cv2.drawContours(tmp2, [cnt], 0, (idx, idx, idx), 1)\n",
    "# figure(); imshow(tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilisescu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:117: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "## overrride so I only use one object but I should find which contour belongs to each object automatically evenutally like they find actors in video synopsis\n",
    "contourIdxs = [18, 18, 15, 16, 16, 19, 17, 17, 15, 15, 17, 17, 17, 19, 20]\n",
    "worldFootprints = {}\n",
    "worldContours = {}\n",
    "\n",
    "for frameIdx in np.arange(20, 250) : #np.arange(masksLabels.shape[-1]) :\n",
    "    \n",
    "    ################################ RETRIEVE THE FRAME AND ITS SEGMENTATION AND UNDISTORT ################################\n",
    "    currentImage = np.array(Image.open(frameLocs[frameIdx+numNeighboringFrames/2]))\n",
    "    currentMaskLabels = cv2.resize(masksLabels[:, :, frameIdx].astype(float).reshape([masksLabels.shape[0], masksLabels.shape[1], 1]),\n",
    "                                   (np.round(bgImage.shape[1]/resizeMultiplier).astype(int), np.round(bgImage.shape[0]/resizeMultiplier).astype(int)), interpolation=cv2.INTER_CUBIC).astype(float)\n",
    "#     undistortedIm, cameraIntrinsics, distortionCoeff, map1, map2 = undistortImage(filmedSceneData[DICT_DISTORTION_PARAMETER], filmedSceneData[DICT_DISTORTION_RATIO], im, filmedSceneData[DICT_CAMERA_INTRINSICS])\n",
    "    \n",
    "    for blobId in [42] : #list(set(currentMaskLabels[currentMaskLabels != 0])) :\n",
    "        if blobId not in worldFootprints :\n",
    "            worldFootprints[blobId] = {}\n",
    "        if blobId not in worldContours :\n",
    "            worldContours[blobId] = {}\n",
    "        \n",
    "        ## REMOVE THIS IF STATEMENT ONCE I DO THIS FOR ALL BLOBIDS IN THE CURRENT MASK LABELS \n",
    "        if blobId in currentMaskLabels.flatten() :\n",
    "            \n",
    "            ################################ GET FOREGROUND MASK FOR CURRENT BLOB ID ################################\n",
    "            fgMask = np.array(currentMaskLabels == blobId, dtype=np.uint8)*255\n",
    "\n",
    "            undistortedFgMask, cameraIntrinsics, distortionCoeff, map1, map2 = undistortImage(filmedSceneData[DICT_DISTORTION_PARAMETER], filmedSceneData[DICT_DISTORTION_RATIO], fgMask, filmedSceneData[DICT_CAMERA_INTRINSICS])\n",
    "            undistortedFgMask[undistortedFgMask >= 128] = 255\n",
    "            undistortedFgMask[undistortedFgMask < 128] = 0\n",
    "            \n",
    "#             figure(); imshow(undistortedFgMask)\n",
    "            \n",
    "#         gridPoints = np.indices(undistortedFgMask.shape[0:2][::-1]).reshape([2, np.prod(undistortedFgMask.shape[0:2])]).T\n",
    "#         inverseT = np.linalg.inv(np.dot(cameraIntrinsics, filmedSceneData[DICT_CAMERA_EXTRINSICS][:-1, [0, 1, 3]]))\n",
    "#         worldFgPoints = np.dot(inverseT, np.concatenate([gridPoints[undistortedFgMask[gridPoints[:, 1], gridPoints[:, 0]] > 0],\n",
    "#                                                          np.ones([len(gridPoints[undistortedFgMask[gridPoints[:, 1], gridPoints[:, 0]] > 0]), 1], float)], axis=1).T)\n",
    "#         worldFgPoints /= worldFgPoints[-1, :]\n",
    "#         worldFgPoints[-1, :] = 0\n",
    "#         worldFgPoints = worldFgPoints.T\n",
    "#         # print(gridPoints.shape, worldFgPoints.shape)\n",
    "#         figure(); scatter(worldFgPoints[:, 0], worldFgPoints[:, 1])\n",
    "#         scatter(np.linalg.inv(filmedSceneData[DICT_CAMERA_EXTRINSICS])[0, -1], np.linalg.inv(filmedSceneData[DICT_CAMERA_EXTRINSICS])[1, -1], color=\"red\")\n",
    "\n",
    "#         ############################### FIND CONNECTED COMPONENTS ################################\n",
    "#         contours, hierarchy = cv2.findContours(np.copy(undistortedFgMask).astype(np.uint8),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "#         renderedContours = np.ones_like(undistortedIm).astype(np.uint8)*255\n",
    "\n",
    "#         for idx, cnt in enumerate(contours) :\n",
    "#             cv2.drawContours(renderedContours, [cnt], 0, (idx, idx, idx), 1)\n",
    "#         figure(); imshow(undistortedIm)\n",
    "#         figure(); imshow(renderedContours)\n",
    "\n",
    "            ############################### FIND CONTOURS ################################\n",
    "            contours, hierarchy = cv2.findContours(np.copy(undistortedFgMask).astype(np.uint8),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "#         ################################ FIND WHICH POINTS IN EACH CONTOUR ARE ON THE GROUND PLANE AND WHICH ARE NOT ################################\n",
    "\n",
    "#         ## project contour of blob onto the ground plane and check intersection of line to camera with it\n",
    "#         inverseT = np.linalg.inv(np.dot(cameraIntrinsics, filmedSceneData[DICT_CAMERA_EXTRINSICS][:-1, [0, 1, 3]]))\n",
    "#         ## I should do this nex bit for each frame of each contour/object but I don't have that working at the minute\n",
    "#         contourIdx = contourIdxs[frameIdx]\n",
    "#         if False :\n",
    "#             ## use the renderedContours but then I lose the ordering\n",
    "#             gridPoints = np.indices(renderedContours.shape[0:2][::-1]).reshape([2, np.prod(renderedContours.shape[0:2])]).T\n",
    "#             worldContourPoints = np.dot(inverseT, np.concatenate([gridPoints[renderedContours[gridPoints[:, 1], gridPoints[:, 0], 0] == contourIdx],\n",
    "#                                                                   np.ones([len(gridPoints[renderedContours[gridPoints[:, 1], gridPoints[:, 0], 0] == contourIdx]), 1], float)], axis=1).T)\n",
    "#         else :\n",
    "#             ## use the contours found by findContours: if the approximation is simple, then I can simply draw lines between the points, otherwise, each point in contours[idx] is a pixel\n",
    "#             ## might as well use simple approximation since findContours works on a binary mask so the contour is always pixellated and made up of lines AND it makes everything faster\n",
    "#             worldContourPoints = np.dot(inverseT, np.concatenate([contours[contourIdx][:, 0, :],\n",
    "#                                                                   np.ones([len(contours[contourIdx]), 1], float)], axis=1).T)\n",
    "\n",
    "\n",
    "            ################################ PROJECT ALL CONTOURS FOUND FROM THE FOREGROUND MASK ONTO THE GROUND PLANE ################################\n",
    "            ## project contour of blob onto the ground plane and check intersection of line to camera with it\n",
    "            inverseT = np.linalg.inv(np.dot(cameraIntrinsics, filmedSceneData[DICT_CAMERA_EXTRINSICS][:-1, [0, 1, 3]]))\n",
    "            ## each blob might have more than one contour\n",
    "            worldContourPoints = []\n",
    "            for contour in contours :\n",
    "                worldContourPoints.append(np.dot(inverseT, np.concatenate([contour[:, 0, :], np.ones([len(contour), 1], float)], axis=1).T))\n",
    "                \n",
    "                worldContourPoints[-1] /= worldContourPoints[-1][-1, :]\n",
    "                worldContourPoints[-1][-1, :] = 0\n",
    "                worldContourPoints[-1] = worldContourPoints[-1].T\n",
    "#             print(len(worldContourPoints), worldContourPoints[0].shape)\n",
    "#             figure(); plot(worldContourPoints[0][:, 0], worldContourPoints[0][:, 1])\n",
    "            \n",
    "            worldCameraPos = np.linalg.inv(filmedSceneData[DICT_CAMERA_EXTRINSICS])[:-1, -1]\n",
    "\n",
    "            ################################ FIND WHICH POINTS IN EACH CONTOUR ARE ON THE GROUND PLANE AND WHICH ARE NOT ################################\n",
    "            worldAllContourPoints = np.vstack(worldContourPoints)\n",
    "            cameraAllContourPoints = np.vstack(contours)[:, 0, :].astype(float)\n",
    "            if len(worldAllContourPoints) != len(cameraAllContourPoints) :\n",
    "                raise Exception(\"Something's wrong\")\n",
    "            isPointFootprint = np.ones(len(worldAllContourPoints), dtype=bool)\n",
    "            \n",
    "            if True :\n",
    "                for idx, point in enumerate(cameraAllContourPoints) :\n",
    "                    bottomPoint = np.array([point[0], undistortedFgMask.shape[0]])\n",
    "                    pointToBottom = bottomPoint - point\n",
    "                    pointToBottom /= np.linalg.norm(pointToBottom)\n",
    "                    doBreak = False\n",
    "                    for contourIdx in np.arange(len(contours)) :\n",
    "                        for segment in np.concatenate([[np.arange(0, len(contours[contourIdx]))], [np.mod(np.arange(0, len(contours[contourIdx]))+1, len(contours[contourIdx]))]]).T :\n",
    "                            if idx not in segment :\n",
    "                                try :\n",
    "                                    intersectionPoint = line2lineIntersection(np.concatenate([point, bottomPoint]), np.concatenate([contours[contourIdx][segment[0], 0, :].astype(float), \n",
    "                                                                                                                                    contours[contourIdx][segment[1], 0, :].astype(float)]))\n",
    "                                except Exception as e:\n",
    "#                                     print(e, bottomPoint, point, contours[contourIdx][segment[0], 0, :].astype(float), contours[contourIdx][segment[1], 0, :].astype(float))\n",
    "                                    pass\n",
    "\n",
    "                                if isABetweenBandC(intersectionPoint, contours[contourIdx][segment[0], 0, :].astype(float), contours[contourIdx][segment[1], 0, :].astype(float)) :\n",
    "                                    pointToIntersection = intersectionPoint - point\n",
    "                                    pointToIntersection /= np.linalg.norm(pointToIntersection)\n",
    "                                    if not np.linalg.norm(pointToBottom + pointToIntersection) < 1e-10 :\n",
    "                                        isPointFootprint[idx] = False\n",
    "#                                         print(idx, bottomPoint, point, contours[contourIdx][segment[0], 0, :].astype(float), contours[contourIdx][segment[1], 0, :].astype(float), segment, intersectionPoint)\n",
    "                                        ## finding one segment the ray intersects is enough to know this is not a footprint point so need to break out \n",
    "                                        ## of both this loop and the outer one looping through the multiple found contours\n",
    "                                        doBreak = True\n",
    "                                        break\n",
    "                        if doBreak :\n",
    "                            break\n",
    "            else :\n",
    "                for idx, point in enumerate(worldAllContourPoints[:, :-1]) :\n",
    "                    pointToCamera = worldCameraPos[:-1] - point\n",
    "                    pointToCamera /= np.linalg.norm(pointToCamera)\n",
    "                    doBreak = False\n",
    "                    for contourIdx in np.arange(len(worldContourPoints)) :\n",
    "                        for segment in np.concatenate([[np.arange(0, len(worldContourPoints[contourIdx]))], [np.mod(np.arange(0, len(worldContourPoints[contourIdx]))+1, len(worldContourPoints[contourIdx]))]]).T :\n",
    "                            if idx not in segment :\n",
    "                                try :\n",
    "                                    intersectionPoint = line2lineIntersection(np.concatenate([point, worldCameraPos[:-1]]), np.concatenate([worldContourPoints[contourIdx][segment[0], :-1], \n",
    "                                                                                                                                            worldContourPoints[contourIdx][segment[1], :-1]]))\n",
    "                                except Exception as e:\n",
    "                                    print(e)\n",
    "                                    pass\n",
    "\n",
    "                                if isABetweenBandC(intersectionPoint, worldContourPoints[contourIdx][segment[0], :-1], worldContourPoints[contourIdx][segment[1], :-1]) :\n",
    "                                    pointToIntersection = intersectionPoint - point\n",
    "                                    pointToIntersection /= np.linalg.norm(pointToIntersection)\n",
    "                                    if not np.linalg.norm(pointToCamera + pointToIntersection) < 1e-10 :\n",
    "                                        isPointFootprint[idx] = False\n",
    "                                        ## finding one segment the ray intersects is enough to know this is not a footprint point so need to break out \n",
    "                                        ## of both this loop and the outer one looping through the multiple found contours\n",
    "                                        doBreak = True\n",
    "                                        break\n",
    "                        if doBreak :\n",
    "                            break\n",
    "                        \n",
    "#             figure(); scatter(worldAllContourPoints[:, 0], worldAllContourPoints[:, 1], color=\"red\")\n",
    "#             scatter(worldAllContourPoints[isPointFootprint, 0], worldAllContourPoints[isPointFootprint, 1], color=\"blue\")\n",
    "            \n",
    "#         figure(); scatter(worldContourPoints[np.negative(isPointFootprint), 0], worldContourPoints[np.negative(isPointFootprint), 1], color=\"blue\")\n",
    "#         scatter(worldContourPoints[isPointFootprint, 0], worldContourPoints[isPointFootprint, 1], color=\"green\")\n",
    "#         scatter(worldCameraPos[0], worldCameraPos[1], color=\"red\")\n",
    "\n",
    "            ################################ SAVE THE PROJECTED FOOTPRINT AND BLOB CONTOURS FOR CURRENT BLOB ID AT THE CURRENT FRAME ################################\n",
    "            worldFootprints[blobId][frameIdx] = worldAllContourPoints[isPointFootprint, :]\n",
    "            worldContours[blobId][frameIdx] = worldAllContourPoints\n",
    "#         figure(); imshow(renderedContours)\n",
    "#         xlim([0, renderedContours.shape[1]])\n",
    "#         ylim([renderedContours.shape[0], 0])\n",
    "#         plot(contours[contourIdx][isPointFootprint, 0, 0], contours[contourIdx][isPointFootprint, 0, 1], color=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "(0, 1) 6.91413879395e-06\n",
      "(1, 2) 0.0269269943237\n",
      "(2, 3) 0.0579619407654\n",
      "(3, 4) 0.0931560993195\n",
      "(4, 5) 0.17937207222\n",
      "(5, 6) 0.202177047729\n",
      "(6, 7) 0.186733007431\n",
      "(7, 8) 0.199249982834\n",
      "(8, 9) 0.307285070419\n",
      "(9, 10) 0.301449775696\n",
      "(10, 11) 0.244371891022\n",
      "(11, 12) 0.292034864426\n",
      "(12, 13) 0.256741046906\n",
      "(13, 14) 0.332991123199\n",
      "(14, 15) 0.372936964035\n",
      "(15, 16) 0.484366178513\n",
      "(16, 17) 0.397279977798\n",
      "(17, 18) 0.4767100811\n",
      "(18, 19) 0.432455778122\n",
      "(19, 20) 0.527922868729\n",
      "(20, 21) 0.43282699585\n",
      "(21, 22) 0.569586992264\n",
      "(22, 23) 0.578860044479\n",
      "(23, 24) 0.889394044876\n",
      "(24, 25) 0.675477981567\n",
      "(25, 26) 0.69267988205\n",
      "(26, 27) 0.781049966812\n",
      "(27, 28) 0.764395952225\n",
      "(28, 29) 0.861645936966\n",
      "(29, 30) 0.884134054184\n",
      "(30, 31) 1.09363102913\n",
      "(31, 32) 0.830734014511\n",
      "(32, 33) 0.824951887131\n",
      "(33, 34) 1.00805997849\n",
      "(34, 35) 1.38619399071\n",
      "(35, 36) 1.30983805656\n",
      "(36, 37) 1.11487817764\n",
      "(37, 38) 1.0311768055\n",
      "(38, 39) 1.0367770195\n",
      "(39, 40) 0.96626996994\n",
      "(40, 41) 1.1354701519\n",
      "(41, 42) 1.04766106606\n",
      "(42, 43) 1.17779898643\n",
      "(43, 44) 3.8848798275\n",
      "(44, 45) 2.6132080555\n",
      "(45, 46) 1.08424806595\n",
      "(46, 47) 1.20937490463\n",
      "(47, 48) 1.21425390244\n",
      "(48, 49) 1.37681102753\n",
      "(49, 50) 1.27342700958\n",
      "(50, 51) 1.47594499588\n",
      "(51, 52) 2.54749488831\n",
      "(52, 53) 1.53316116333\n",
      "(53, 54) 2.84695291519\n",
      "(54, 55) 1.93569612503\n",
      "(55, 56) 1.34290218353\n",
      "(56, 57) 1.82871413231\n",
      "(57, 58) 2.09973502159\n",
      "(58, 59) 1.82191801071\n",
      "(59, 60) 2.46384000778\n",
      "(60, 61) 1.50612282753\n",
      "(61, 62) 1.64256906509\n",
      "(62, 63) 1.41143584251\n",
      "(63, 64) 1.56768393517\n",
      "(64, 65) 2.03958201408\n",
      "(65, 66) 1.76339697838\n",
      "(66, 67) 1.73216891289\n",
      "(67, 68) 1.78972315788\n",
      "(68, 69) 1.87551593781\n",
      "(69, 70) 1.77401709557\n",
      "(70, 71) 1.84873890877\n",
      "(71, 72) 1.97011590004\n",
      "(72, 73) 1.85373306274\n",
      "(73, 74) 1.92787504196\n",
      "(74, 75) 2.02306699753\n",
      "(75, 76) 2.0761039257\n",
      "(76, 77) 1.94666314125\n",
      "(77, 78) 2.59475398064\n",
      "(78, 79) 2.29243898392\n",
      "(79, 80) 2.0191860199\n",
      "(80, 81) 1.90851712227\n",
      "(81, 82) 1.9282579422\n",
      "(82, 83) 1.94271802902\n",
      "(83, 84) 2.29255700111\n",
      "(84, 85) 2.76552796364\n",
      "(85, 86) 2.45658993721\n",
      "(86, 87) 2.23018598557\n",
      "(87, 88) 2.40099096298\n",
      "(88, 89) 2.43439006805\n",
      "(89, 90) 2.31248903275\n",
      "(90, 91) 2.22578501701\n",
      "(91, 92) 2.48208498955\n",
      "(92, 93) 2.36283421516\n",
      "(93, 94) 2.31506514549\n",
      "(94, 95) 2.52331113815\n",
      "(95, 96) 2.53175210953\n",
      "(96, 97) 2.21325802803\n",
      "(97, 98) 2.48583006859\n",
      "(98, 99) 2.59602093697\n",
      "(99, 100) 2.77368998528\n",
      "(100, 101) 2.97331190109\n",
      "(101, 102) 3.81637501717\n",
      "(102, 103) 2.71864008904\n",
      "(103, 104) 2.37054896355\n",
      "(104, 105) 2.46596097946\n",
      "(105, 106) 2.84498882294\n",
      "(106, 107) 2.57536220551\n",
      "(107, 108) 2.48599910736\n",
      "(108, 109) 2.53757214546\n",
      "(109, 110) 2.58049416542\n",
      "(110, 111) 2.77091598511\n",
      "(111, 112) 2.62905597687\n",
      "(112, 113) 2.6830830574\n",
      "(113, 114) 2.63434505463\n",
      "(114, 115) 2.57123780251\n",
      "(115, 116) 2.62068891525\n",
      "(116, 117) 2.9479701519\n",
      "(117, 118) 3.04504394531\n",
      "(118, 119) 2.6721470356\n",
      "(119, 120) 2.56842899323\n",
      "(120, 121) 3.86002206802\n",
      "(121, 122) 2.95464515686\n",
      "(122, 123) 2.94090008736\n",
      "(123, 124) 3.12517499924\n",
      "(124, 125) 2.47938704491\n",
      "(125, 126) 2.78858208656\n",
      "(126, 127) 2.42272210121\n",
      "(127, 128) 2.91064691544\n",
      "(128, 129) 3.37654614449\n",
      "(129, 130) 2.87512016296\n",
      "(130, 131) 3.09338283539\n",
      "(131, 132) 3.02538919449\n",
      "(132, 133) 3.11288404465\n",
      "(133, 134) 3.32593202591\n",
      "(134, 135) 3.93850302696\n",
      "(135, 136) 3.98300004005\n",
      "(136, 137) 3.63565206528\n",
      "(137, 138) 3.49502110481\n",
      "(138, 139) 4.03870105743\n",
      "(139, 140) 3.37149000168\n",
      "(140, 141) 3.9212141037\n",
      "(141, 142) 3.31925582886\n",
      "(142, 143) 3.55444002151\n",
      "(143, 144) 4.19203996658\n",
      "(144, 145) 3.8878929615\n",
      "(145, 146) 3.8262488842\n",
      "(146, 147) 3.869587183\n",
      "(147, 148) 3.68365097046\n",
      "(148, 149) 3.5644159317\n",
      "(149, 150) 3.42591905594\n",
      "(150, 151) 4.76963019371\n",
      "(151, 152) 3.50842809677\n",
      "(152, 153) 4.17126393318\n",
      "(153, 154) 4.03632187843\n",
      "(154, 155) 3.78553104401\n",
      "(155, 156) 7.46021389961\n",
      "(156, 157) 4.35162496567\n",
      "(157, 158) 4.21078896523\n",
      "(158, 159) 4.5474691391\n",
      "(159, 160) 3.55888986588\n",
      "(160, 161) 4.63826203346\n",
      "(161, 162) 3.99454498291\n",
      "(162, 163) 4.90023112297\n",
      "(163, 164) 10.8300180435\n",
      "(164, 165) 8.18312692642\n",
      "(165, 166) 4.8903222084\n",
      "(166, 167) 4.58505606651\n",
      "(167, 168) 4.29720401764\n",
      "(168, 169) 4.73210310936\n",
      "(169, 170) 4.29442596436\n",
      "(170, 171) 4.24864888191\n",
      "(171, 172) 5.29026389122\n",
      "(172, 173) 4.53738117218\n",
      "(173, 174) 4.37830114365\n",
      "(174, 175) 4.18874692917\n",
      "(175, 176) 4.66610312462\n",
      "(176, 177) 7.06379103661\n",
      "(177, 178) 5.02847695351\n",
      "(178, 179) 5.11736989021\n",
      "(179, 180) 5.27918314934\n",
      "(180, 181) 4.73634409904\n",
      "(181, 182) 4.29315400124\n",
      "(182, 183) 5.34927296638\n",
      "(183, 184) 5.19555306435\n",
      "(184, 185) 5.08396291733\n",
      "(185, 186) 6.63167905807\n",
      "(186, 187) 4.6827609539\n",
      "(187, 188) 4.71307492256\n",
      "(188, 189) 5.0329618454\n",
      "(189, 190) 4.74845695496\n",
      "(190, 191) 5.24160194397\n",
      "(191, 192) 4.8824930191\n",
      "(192, 193) 4.71970009804\n",
      "(193, 194) 5.07165598869\n",
      "(194, 195) 5.05924987793\n",
      "(195, 196) 5.74610185623\n",
      "(196, 197) 5.32016301155\n",
      "(197, 198) 5.18670010567\n",
      "(198, 199) 5.39843583107\n",
      "(199, 200) 5.23065304756\n",
      "(200, 201) 7.06234502792\n",
      "(201, 202) 5.16000795364\n",
      "(202, 203) 5.4440600872\n",
      "(203, 204) 6.04540205002\n",
      "(204, 205) 5.69069099426\n",
      "(205, 206) 5.17309808731\n",
      "(206, 207) 4.83077287674\n",
      "(207, 208) 6.00138902664\n",
      "(208, 209) 6.59191298485\n",
      "(209, 210) 5.18122696877\n",
      "(210, 211) 5.75205397606\n",
      "(211, 212) 5.52414083481\n",
      "(212, 213) 6.15597009659\n",
      "(213, 214) 6.74068593979\n",
      "(214, 215) 6.60552597046\n",
      "(215, 216) 6.56890892982\n",
      "(216, 217) 6.22186899185\n",
      "(217, 218) 6.35056900978\n",
      "(218, 219) 5.95889687538\n",
      "(219, 220) 6.49181103706\n",
      "(220, 221) 6.73443388939\n",
      "(221, 222) 7.30688500404\n",
      "(222, 223) 6.28377389908\n",
      "(223, 224) 7.06029486656\n",
      "(224, 225) 5.55416703224\n",
      "(225, 226) 8.35199189186\n",
      "(226, 227) 7.8279042244\n",
      "(227, 228) 6.36942195892\n",
      "(228, 229) 6.30836701393\n"
     ]
    }
   ],
   "source": [
    "for blobId in np.sort(worldFootprints.keys()) :\n",
    "    frameIds = np.sort(worldFootprints[blobId].keys())\n",
    "    numFootprints = len(frameIds)\n",
    "    print(numFootprints)\n",
    "    ## find transformation T of each frame's footprint points to the next frame\n",
    "    Ts = []\n",
    "    ## find transformation T of each frame's footprint points to the last frame\n",
    "    TsToLast = []\n",
    "    for pointsPair in zip(np.arange(0, numFootprints-1), np.arange(1, numFootprints)) :\n",
    "        ## transformation from current frame to next\n",
    "        Ts.append(icp(worldFootprints[blobId][frameIds[pointsPair[0]]][:, :-1].T, worldFootprints[blobId][frameIds[pointsPair[1]]][:, :-1].T))\n",
    "        ## for the current frame just use the found T\n",
    "        TsToLast.append(np.array(Ts[-1][1]))\n",
    "        ## now update the previous frames' TsToLast\n",
    "        startTime = time.time()\n",
    "        for i in np.arange(0, len(TsToLast)-1) :\n",
    "            ## get T to the current frame's footprint\n",
    "            TsToLast[i] = np.dot(TsToLast[-1], TsToLast[i])\n",
    "\n",
    "            ## transform the footprint to the current frame's footprint\n",
    "            tmpFootprint = np.dot(TsToLast[i], np.vstack([worldFootprints[blobId][frameIds[i]][:, :-1].T, np.ones([1, len(worldFootprints[blobId][frameIds[i]])])]))\n",
    "            tmpFootprint = tmpFootprint[:-1, :]/tmpFootprint[-1, :]\n",
    "\n",
    "            ## refine transformation using icp\n",
    "            TsToLast[i] = np.dot(np.array(icp(tmpFootprint, worldFootprints[blobId][frameIds[pointsPair[1]]][:, :-1].T)[1]), TsToLast[i])\n",
    "            \n",
    "        print(pointsPair, time.time()-startTime)\n",
    "        sys.stdout.flush()\n",
    "#             print(i)\n",
    "\n",
    "Ts = [np.array(t[1]) for t in Ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.save(dataLoc+\"Ts-blob42-2311to2590.npy\", [np.array(t[1]) for t in Ts])\n",
    "# np.save(dataLoc+\"TsToLast-blob42-2311to2590.npy\", TsToLast)\n",
    "# np.save(dataLoc+\"worldFootprints-blob42-2311to2590.npy\", worldFootprints)\n",
    "# np.save(dataLoc+\"worldContours-blob42-2311to2590.npy\", worldContours)\n",
    "# Ts = np.load(dataLoc+\"Ts-blob42-2311to2590.npy\")\n",
    "# TsToLast = np.load(dataLoc+\"TsToLast-blob42-2311to2590.npy\")\n",
    "# worldFootprints = np.load(dataLoc+\"worldFootprints-blob42-2311to2590.npy\").item()\n",
    "# worldContours = np.load(dataLoc+\"worldContours-blob42-2311to2590.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228 (2, 69)\n",
      "227 (2, 80)\n",
      "226 (2, 75)\n",
      "225 (2, 82)\n",
      "224 (2, 85)\n",
      "223 (2, 86)\n",
      "222 (2, 88)\n",
      "221 (2, 82)\n",
      "220 (2, 87)\n",
      "219 (2, 82)\n",
      "218 (2, 82)\n",
      "217 (2, 83)\n",
      "216 (2, 85)\n",
      "215 (2, 85)\n",
      "214 (2, 94)\n",
      "213 (2, 85)\n",
      "212 (2, 82)\n",
      "211 (2, 82)\n",
      "210 (2, 73)\n",
      "209 (2, 75)\n",
      "208 (2, 74)\n",
      "207 (2, 73)\n",
      "206 (2, 74)\n",
      "205 (2, 78)\n",
      "204 (2, 70)\n",
      "203 (2, 80)\n",
      "202 (2, 66)\n",
      "201 (2, 66)\n",
      "200 (2, 65)\n",
      "199 (2, 65)\n",
      "198 (2, 64)\n",
      "197 (2, 68)\n",
      "196 (2, 60)\n",
      "195 (2, 74)\n",
      "194 (2, 72)\n",
      "193 (2, 69)\n",
      "192 (2, 65)\n",
      "191 (2, 71)\n",
      "190 (2, 70)\n",
      "189 (2, 70)\n",
      "188 (2, 59)\n",
      "187 (2, 57)\n",
      "186 (2, 58)\n",
      "185 (2, 60)\n",
      "184 (2, 59)\n",
      "183 (2, 65)\n",
      "182 (2, 58)\n",
      "181 (2, 62)\n",
      "180 (2, 71)\n",
      "179 (2, 60)\n",
      "178 (2, 66)\n",
      "177 (2, 63)\n",
      "176 (2, 54)\n",
      "175 (2, 62)\n",
      "174 (2, 55)\n",
      "173 (2, 47)\n",
      "172 (2, 55)\n",
      "171 (2, 50)\n",
      "170 (2, 57)\n",
      "169 (2, 45)\n",
      "168 (2, 50)\n",
      "167 (2, 51)\n",
      "166 (2, 49)\n",
      "165 (2, 52)\n",
      "164 (2, 28)\n",
      "163 (2, 49)\n",
      "162 (2, 39)\n",
      "161 (2, 43)\n",
      "160 (2, 44)\n",
      "159 (2, 50)\n",
      "158 (2, 54)\n",
      "157 (2, 64)\n",
      "156 (2, 44)\n",
      "155 (2, 41)\n",
      "154 (2, 40)\n",
      "153 (2, 47)\n",
      "152 (2, 48)\n",
      "151 (2, 49)\n",
      "150 (2, 48)\n",
      "149 (2, 46)\n",
      "148 (2, 46)\n",
      "147 (2, 41)\n",
      "146 (2, 38)\n",
      "145 (2, 42)\n",
      "144 (2, 45)\n",
      "143 (2, 41)\n",
      "142 (2, 36)\n",
      "141 (2, 40)\n",
      "140 (2, 37)\n",
      "139 (2, 41)\n",
      "138 (2, 37)\n",
      "137 (2, 34)\n",
      "136 (2, 39)\n",
      "135 (2, 35)\n",
      "134 (2, 39)\n",
      "133 (2, 31)\n",
      "132 (2, 32)\n",
      "131 (2, 30)\n",
      "130 (2, 26)\n",
      "129 (2, 30)\n",
      "128 (2, 30)\n",
      "127 (2, 35)\n",
      "126 (2, 29)\n",
      "125 (2, 28)\n",
      "124 (2, 27)\n",
      "123 (2, 26)\n",
      "122 (2, 19)\n",
      "121 (2, 25)\n",
      "120 (2, 30)\n",
      "119 (2, 30)\n",
      "118 (2, 34)\n",
      "117 (2, 38)\n",
      "116 (2, 30)\n",
      "115 (2, 33)\n",
      "114 (2, 38)\n",
      "113 (2, 42)\n",
      "112 (2, 42)\n",
      "111 (2, 42)\n",
      "110 (2, 40)\n",
      "109 (2, 38)\n",
      "108 (2, 29)\n",
      "107 (2, 21)\n",
      "106 (2, 27)\n",
      "105 (2, 28)\n",
      "104 (2, 31)\n",
      "103 (2, 30)\n",
      "102 (2, 33)\n",
      "101 (2, 35)\n",
      "100 (2, 31)\n",
      "99 (2, 25)\n",
      "98 (2, 23)\n",
      "97 (2, 26)\n",
      "96 (2, 35)\n",
      "95 (2, 33)\n",
      "94 (2, 33)\n",
      "93 (2, 14)\n",
      "92 (2, 21)\n",
      "91 (2, 27)\n",
      "90 (2, 28)\n",
      "89 (2, 40)\n",
      "88 (2, 35)\n",
      "87 (2, 30)\n",
      "86 (2, 37)\n",
      "85 (2, 23)\n",
      "84 (2, 30)\n",
      "83 (2, 21)\n",
      "82 (2, 22)\n",
      "81 (2, 24)\n",
      "80 (2, 27)\n",
      "79 (2, 32)\n",
      "78 (2, 35)\n",
      "77 (2, 42)\n",
      "76 (2, 34)\n",
      "75 (2, 35)\n",
      "74 (2, 31)\n",
      "73 (2, 29)\n",
      "72 (2, 27)\n",
      "71 (2, 25)\n",
      "70 (2, 29)\n",
      "69 (2, 27)\n",
      "68 (2, 36)\n",
      "67 (2, 38)\n",
      "66 (2, 31)\n",
      "65 (2, 38)\n",
      "64 (2, 37)\n",
      "63 (2, 38)\n",
      "62 (2, 40)\n",
      "61 (2, 48)\n",
      "60 (2, 44)\n",
      "59 (2, 48)\n",
      "58 (2, 36)\n",
      "57 (2, 19)\n",
      "56 (2, 44)\n",
      "55 (2, 41)\n",
      "54 (2, 19)\n",
      "53 (2, 39)\n",
      "52 (2, 38)\n",
      "51 (2, 18)\n",
      "50 (2, 41)\n",
      "49 (2, 41)\n",
      "48 (2, 31)\n",
      "47 (2, 38)\n",
      "46 (2, 34)\n",
      "45 (2, 38)\n",
      "44 (2, 19)\n",
      "43 (2, 45)\n",
      "42 (2, 49)\n",
      "41 (2, 42)\n",
      "40 (2, 41)\n",
      "39 (2, 51)\n",
      "38 (2, 50)\n",
      "37 (2, 45)\n",
      "36 (2, 51)\n",
      "35 (2, 23)\n",
      "34 (2, 40)\n",
      "33 (2, 47)\n",
      "32 (2, 45)\n",
      "31 (2, 50)\n",
      "30 (2, 22)\n",
      "29 (2, 40)\n",
      "28 (2, 35)\n",
      "27 (2, 41)\n",
      "26 (2, 39)\n",
      "25 (2, 44)\n",
      "24 (2, 41)\n",
      "23 (2, 43)\n",
      "22 (2, 37)\n",
      "21 (2, 39)\n",
      "20 (2, 39)\n",
      "19 (2, 33)\n",
      "18 (2, 38)\n",
      "17 (2, 32)\n",
      "16 (2, 41)\n",
      "15 (2, 37)\n",
      "14 (2, 33)\n",
      "13 (2, 30)\n",
      "12 (2, 30)\n",
      "11 (2, 37)\n",
      "10 (2, 43)\n",
      "9 (2, 40)\n",
      "8 (2, 40)\n",
      "7 (2, 42)\n",
      "6 (2, 40)\n",
      "5 (2, 19)\n",
      "4 (2, 38)\n",
      "3 (2, 47)\n",
      "2 (2, 42)\n",
      "1 (2, 44)\n",
      "0 (2, 36)\n",
      "228 (2, 69)\n",
      "227 (2, 80)\n",
      "226 (2, 75)\n",
      "225 (2, 82)\n",
      "224 (2, 85)\n",
      "223 (2, 86)\n",
      "222 (2, 88)\n",
      "221 (2, 82)\n",
      "220 (2, 87)\n",
      "219 (2, 82)\n",
      "218 (2, 82)\n",
      "217 (2, 83)\n",
      "216 (2, 85)\n",
      "215 (2, 85)\n",
      "214 (2, 94)\n",
      "213 (2, 85)\n",
      "212 (2, 82)\n",
      "211 (2, 82)\n",
      "210 (2, 73)\n",
      "209 (2, 75)\n",
      "208 (2, 74)\n",
      "207 (2, 73)\n",
      "206 (2, 74)\n",
      "205 (2, 78)\n",
      "204 (2, 70)\n",
      "203 (2, 80)\n",
      "202 (2, 66)\n",
      "201 (2, 66)\n",
      "200 (2, 65)\n",
      "199 (2, 65)\n",
      "198 (2, 64)\n",
      "197 (2, 68)\n",
      "196 (2, 60)\n",
      "195 (2, 74)\n",
      "194 (2, 72)\n",
      "193 (2, 69)\n",
      "192 (2, 65)\n",
      "191 (2, 71)\n",
      "190 (2, 70)\n",
      "189 (2, 70)\n",
      "188 (2, 59)\n",
      "187 (2, 57)\n",
      "186 (2, 58)\n",
      "185 (2, 60)\n",
      "184 (2, 59)\n",
      "183 (2, 65)\n",
      "182 (2, 58)\n",
      "181 (2, 62)\n",
      "180 (2, 71)\n",
      "179 (2, 60)\n",
      "178 (2, 66)\n",
      "177 (2, 63)\n",
      "176 (2, 54)\n",
      "175 (2, 62)\n",
      "174 (2, 55)\n",
      "173 (2, 47)\n",
      "172 (2, 55)\n",
      "171 (2, 50)\n",
      "170 (2, 57)\n",
      "169 (2, 45)\n",
      "168 (2, 50)\n",
      "167 (2, 51)\n",
      "166 (2, 49)\n",
      "165 (2, 52)\n",
      "164 (2, 28)\n",
      "163 (2, 49)\n",
      "162 (2, 39)\n",
      "161 (2, 43)\n",
      "160 (2, 44)\n",
      "159 (2, 50)\n",
      "158 (2, 54)\n",
      "157 (2, 64)\n",
      "156 (2, 44)\n",
      "155 (2, 41)\n",
      "154 (2, 40)\n",
      "153 (2, 47)\n",
      "152 (2, 48)\n",
      "151 (2, 49)\n",
      "150 (2, 48)\n",
      "149 (2, 46)\n",
      "148 (2, 46)\n",
      "147 (2, 41)\n",
      "146 (2, 38)\n",
      "145 (2, 42)\n",
      "144 (2, 45)\n",
      "143 (2, 41)\n",
      "142 (2, 36)\n",
      "141 (2, 40)\n",
      "140 (2, 37)\n",
      "139 (2, 41)\n",
      "138 (2, 37)\n",
      "137 (2, 34)\n",
      "136 (2, 39)\n",
      "135 (2, 35)\n",
      "134 (2, 39)\n",
      "133 (2, 31)\n",
      "132 (2, 32)\n",
      "131 (2, 30)\n",
      "130 (2, 26)\n",
      "129 (2, 30)\n",
      "128 (2, 30)\n",
      "127 (2, 35)\n",
      "126 (2, 29)\n",
      "125 (2, 28)\n",
      "124 (2, 27)\n",
      "123 (2, 26)\n",
      "122 (2, 19)\n",
      "121 (2, 25)\n",
      "120 (2, 30)\n",
      "119 (2, 30)\n",
      "118 (2, 34)\n",
      "117 (2, 38)\n",
      "116 (2, 30)\n",
      "115 (2, 33)\n",
      "114 (2, 38)\n",
      "113 (2, 42)\n",
      "112 (2, 42)\n",
      "111 (2, 42)\n",
      "110 (2, 40)\n",
      "109 (2, 38)\n",
      "108 (2, 29)\n",
      "107 (2, 21)\n",
      "106 (2, 27)\n",
      "105 (2, 28)\n",
      "104 (2, 31)\n",
      "103 (2, 30)\n",
      "102 (2, 33)\n",
      "101 (2, 35)\n",
      "100 (2, 31)\n",
      "99 (2, 25)\n",
      "98 (2, 23)\n",
      "97 (2, 26)\n",
      "96 (2, 35)\n",
      "95 (2, 33)\n",
      "94 (2, 33)\n",
      "93 (2, 14)\n",
      "92 (2, 21)\n",
      "91 (2, 27)\n",
      "90 (2, 28)\n",
      "89 (2, 40)\n",
      "88 (2, 35)\n",
      "87 (2, 30)\n",
      "86 (2, 37)\n",
      "85 (2, 23)\n",
      "84 (2, 30)\n",
      "83 (2, 21)\n",
      "82 (2, 22)\n",
      "81 (2, 24)\n",
      "80 (2, 27)\n",
      "79 (2, 32)\n",
      "78 (2, 35)\n",
      "77 (2, 42)\n",
      "76 (2, 34)\n",
      "75 (2, 35)\n",
      "74 (2, 31)\n",
      "73 (2, 29)\n",
      "72 (2, 27)\n",
      "71 (2, 25)\n",
      "70 (2, 29)\n",
      "69 (2, 27)\n",
      "68 (2, 36)\n",
      "67 (2, 38)\n",
      "66 (2, 31)\n",
      "65 (2, 38)\n",
      "64 (2, 37)\n",
      "63 (2, 38)\n",
      "62 (2, 40)\n",
      "61 (2, 48)\n",
      "60 (2, 44)\n",
      "59 (2, 48)\n",
      "58 (2, 36)\n",
      "57 (2, 19)\n",
      "56 (2, 44)\n",
      "55 (2, 41)\n",
      "54 (2, 19)\n",
      "53 (2, 39)\n",
      "52 (2, 38)\n",
      "51 (2, 18)\n",
      "50 (2, 41)\n",
      "49 (2, 41)\n",
      "48 (2, 31)\n",
      "47 (2, 38)\n",
      "46 (2, 34)\n",
      "45 (2, 38)\n",
      "44 (2, 19)\n",
      "43 (2, 45)\n",
      "42 (2, 49)\n",
      "41 (2, 42)\n",
      "40 (2, 41)\n",
      "39 (2, 51)\n",
      "38 (2, 50)\n",
      "37 (2, 45)\n",
      "36 (2, 51)\n",
      "35 (2, 23)\n",
      "34 (2, 40)\n",
      "33 (2, 47)\n",
      "32 (2, 45)\n",
      "31 (2, 50)\n",
      "30 (2, 22)\n",
      "29 (2, 40)\n",
      "28 (2, 35)\n",
      "27 (2, 41)\n",
      "26 (2, 39)\n",
      "25 (2, 44)\n",
      "24 (2, 41)\n",
      "23 (2, 43)\n",
      "22 (2, 37)\n",
      "21 (2, 39)\n",
      "20 (2, 39)\n",
      "19 (2, 33)\n",
      "18 (2, 38)\n",
      "17 (2, 32)\n",
      "16 (2, 41)\n",
      "15 (2, 37)\n",
      "14 (2, 33)\n",
      "13 (2, 30)\n",
      "12 (2, 30)\n",
      "11 (2, 37)\n",
      "10 (2, 43)\n",
      "9 (2, 40)\n",
      "8 (2, 40)\n",
      "7 (2, 42)\n",
      "6 (2, 40)\n",
      "5 (2, 19)\n",
      "4 (2, 38)\n",
      "3 (2, 47)\n",
      "2 (2, 42)\n",
      "1 (2, 44)\n",
      "0 (2, 36)\n",
      "228 (2, 69)\n",
      "227 (2, 80)\n",
      "226 (2, 75)\n",
      "225 (2, 82)\n",
      "224 (2, 85)\n",
      "223 (2, 86)\n",
      "222 (2, 88)\n",
      "221 (2, 82)\n",
      "220 (2, 87)\n",
      "219 (2, 82)\n",
      "218 (2, 82)\n",
      "217 (2, 83)\n",
      "216 (2, 85)\n",
      "215 (2, 85)\n",
      "214 (2, 94)\n",
      "213 (2, 85)\n",
      "212 (2, 82)\n",
      "211 (2, 82)\n",
      "210 (2, 73)\n",
      "209 (2, 75)\n",
      "208 (2, 74)\n",
      "207 (2, 73)\n",
      "206 (2, 74)\n",
      "205 (2, 78)\n",
      "204 (2, 70)\n",
      "203 (2, 80)\n",
      "202 (2, 66)\n",
      "201 (2, 66)\n",
      "200 (2, 65)\n",
      "199 (2, 65)\n",
      "198 (2, 64)\n",
      "197 (2, 68)\n",
      "196 (2, 60)\n",
      "195 (2, 74)\n",
      "194 (2, 72)\n",
      "193 (2, 69)\n",
      "192 (2, 65)\n",
      "191 (2, 71)\n",
      "190 (2, 70)\n",
      "189 (2, 70)\n",
      "188 (2, 59)\n",
      "187 (2, 57)\n",
      "186 (2, 58)\n",
      "185 (2, 60)\n",
      "184 (2, 59)\n",
      "183 (2, 65)\n",
      "182 (2, 58)\n",
      "181 (2, 62)\n",
      "180 (2, 71)\n",
      "179 (2, 60)\n",
      "178 (2, 66)\n",
      "177 (2, 63)\n",
      "176 (2, 54)\n",
      "175 (2, 62)\n",
      "174 (2, 55)\n",
      "173 (2, 47)\n",
      "172 (2, 55)\n",
      "171 (2, 50)\n",
      "170 (2, 57)\n",
      "169 (2, 45)\n",
      "168 (2, 50)\n",
      "167 (2, 51)\n",
      "166 (2, 49)\n",
      "165 (2, 52)\n",
      "164 (2, 28)\n",
      "163 (2, 49)\n",
      "162 (2, 39)\n",
      "161 (2, 43)\n",
      "160 (2, 44)\n",
      "159 (2, 50)\n",
      "158 (2, 54)\n",
      "157 (2, 64)\n",
      "156 (2, 44)\n",
      "155 (2, 41)\n",
      "154 (2, 40)\n",
      "153 (2, 47)\n",
      "152 (2, 48)\n",
      "151 (2, 49)\n",
      "150 (2, 48)\n",
      "149 (2, 46)\n",
      "148 (2, 46)\n",
      "147 (2, 41)\n",
      "146 (2, 38)\n",
      "145 (2, 42)\n",
      "144 (2, 45)\n",
      "143 (2, 41)\n",
      "142 (2, 36)\n",
      "141 (2, 40)\n",
      "140 (2, 37)\n",
      "139 (2, 41)\n",
      "138 (2, 37)\n",
      "137 (2, 34)\n",
      "136 (2, 39)\n",
      "135 (2, 35)\n",
      "134 (2, 39)\n",
      "133 (2, 31)\n",
      "132 (2, 32)\n",
      "131 (2, 30)\n",
      "130 (2, 26)\n",
      "129 (2, 30)\n",
      "128 (2, 30)\n",
      "127 (2, 35)\n",
      "126 (2, 29)\n",
      "125 (2, 28)\n",
      "124 (2, 27)\n",
      "123 (2, 26)\n",
      "122 (2, 19)\n",
      "121 (2, 25)\n",
      "120 (2, 30)\n",
      "119 (2, 30)\n",
      "118 (2, 34)\n",
      "117 (2, 38)\n",
      "116 (2, 30)\n",
      "115 (2, 33)\n",
      "114 (2, 38)\n",
      "113 (2, 42)\n",
      "112 (2, 42)\n",
      "111 (2, 42)\n",
      "110 (2, 40)\n",
      "109 (2, 38)\n",
      "108 (2, 29)\n",
      "107 (2, 21)\n",
      "106 (2, 27)\n",
      "105 (2, 28)\n",
      "104 (2, 31)\n",
      "103 (2, 30)\n",
      "102 (2, 33)\n",
      "101 (2, 35)\n",
      "100 (2, 31)\n",
      "99 (2, 25)\n",
      "98 (2, 23)\n",
      "97 (2, 26)\n",
      "96 (2, 35)\n",
      "95 (2, 33)\n",
      "94 (2, 33)\n",
      "93 (2, 14)\n",
      "92 (2, 21)\n",
      "91 (2, 27)\n",
      "90 (2, 28)\n",
      "89 (2, 40)\n",
      "88 (2, 35)\n",
      "87 (2, 30)\n",
      "86 (2, 37)\n",
      "85 (2, 23)\n",
      "84 (2, 30)\n",
      "83 (2, 21)\n",
      "82 (2, 22)\n",
      "81 (2, 24)\n",
      "80 (2, 27)\n",
      "79 (2, 32)\n",
      "78 (2, 35)\n",
      "77 (2, 42)\n",
      "76 (2, 34)\n",
      "75 (2, 35)\n",
      "74 (2, 31)\n",
      "73 (2, 29)\n",
      "72 (2, 27)\n",
      "71 (2, 25)\n",
      "70 (2, 29)\n",
      "69 (2, 27)\n",
      "68 (2, 36)\n",
      "67 (2, 38)\n",
      "66 (2, 31)\n",
      "65 (2, 38)\n",
      "64 (2, 37)\n",
      "63 (2, 38)\n",
      "62 (2, 40)\n",
      "61 (2, 48)\n",
      "60 (2, 44)\n",
      "59 (2, 48)\n",
      "58 (2, 36)\n",
      "57 (2, 19)\n",
      "56 (2, 44)\n",
      "55 (2, 41)\n",
      "54 (2, 19)\n",
      "53 (2, 39)\n",
      "52 (2, 38)\n",
      "51 (2, 18)\n",
      "50 (2, 41)\n",
      "49 (2, 41)\n",
      "48 (2, 31)\n",
      "47 (2, 38)\n",
      "46 (2, 34)\n",
      "45 (2, 38)\n",
      "44 (2, 19)\n",
      "43 (2, 45)\n",
      "42 (2, 49)\n",
      "41 (2, 42)\n",
      "40 (2, 41)\n",
      "39 (2, 51)\n",
      "38 (2, 50)\n",
      "37 (2, 45)\n",
      "36 (2, 51)\n",
      "35 (2, 23)\n",
      "34 (2, 40)\n",
      "33 (2, 47)\n",
      "32 (2, 45)\n",
      "31 (2, 50)\n",
      "30 (2, 22)\n",
      "29 (2, 40)\n",
      "28 (2, 35)\n",
      "27 (2, 41)\n",
      "26 (2, 39)\n",
      "25 (2, 44)\n",
      "24 (2, 41)\n",
      "23 (2, 43)\n",
      "22 (2, 37)\n",
      "21 (2, 39)\n",
      "20 (2, 39)\n",
      "19 (2, 33)\n",
      "18 (2, 38)\n",
      "17 (2, 32)\n",
      "16 (2, 41)\n",
      "15 (2, 37)\n",
      "14 (2, 33)\n",
      "13 (2, 30)\n",
      "12 (2, 30)\n",
      "11 (2, 37)\n",
      "10 (2, 43)\n",
      "9 (2, 40)\n",
      "8 (2, 40)\n",
      "7 (2, 42)\n",
      "6 (2, 40)\n",
      "5 (2, 19)\n",
      "4 (2, 38)\n",
      "3 (2, 47)\n",
      "2 (2, 42)\n",
      "1 (2, 44)\n",
      "0 (2, 36)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-5, -7)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numFootprintsToShow = len(Ts)\n",
    "### SHOW THE ALIGNED FOOTPRINTS ###\n",
    "figure()\n",
    "cols = [\"red\", \"green\", \"blue\", \"cyan\", \"magenta\"]\n",
    "blobId = 42\n",
    "frameIds = np.sort(worldFootprints[blobId].keys())\n",
    "cameraPos = np.linalg.inv(filmedSceneData[DICT_CAMERA_EXTRINSICS])[:-1, -1]\n",
    "for i in np.arange(numFootprintsToShow)[::25] :\n",
    "    plot(worldContours[blobId][frameIds[i]][:, 0], worldContours[blobId][frameIds[i]][:, 1], color=cols[np.mod(i, len(cols))])\n",
    "    scatter(worldFootprints[blobId][frameIds[i]][:, 0], worldFootprints[blobId][frameIds[i]][:, 1], color=cols[np.mod(i, len(cols))])\n",
    "    for j in np.arange(len(worldFootprints[blobId][frameIds[i]])) :\n",
    "        plot([worldFootprints[blobId][frameIds[i]][j, 0], cameraPos[0]], [worldFootprints[blobId][frameIds[i]][j, 1], cameraPos[1]])\n",
    "scatter(cameraPos[0], cameraPos[1])\n",
    "# xlim([-1, 1])\n",
    "# ylim([-3.7, -1.7])\n",
    "\n",
    "### TRANSFORMS ACCUMULATED OVER TIME ###\n",
    "figure()\n",
    "plot(worldContours[blobId][frameIds[numFootprintsToShow]][:, 0], worldContours[blobId][frameIds[numFootprintsToShow]][:, 1], color=cols[np.mod(numFootprintsToShow, len(cols))])\n",
    "scatter(worldFootprints[blobId][frameIds[numFootprintsToShow]][:, 0], worldFootprints[blobId][frameIds[numFootprintsToShow]][:, 1], color=cols[np.mod(numFootprintsToShow, len(cols))])\n",
    "currentTransform = np.eye(3)\n",
    "for i in np.arange(numFootprintsToShow)[::-1] :\n",
    "#     currentTransform = np.dot(currentTransform, np.array(Ts[i][1]))\n",
    "    currentTransform = np.dot(currentTransform, np.array(Ts[i]))\n",
    "    transformedFootprint = np.dot(currentTransform, np.vstack([worldFootprints[blobId][frameIds[i]][:, :-1].T, np.ones([1, len(worldFootprints[blobId][frameIds[i]])])]))\n",
    "    transformedFootprint = transformedFootprint[:-1, :]/transformedFootprint[-1, :]\n",
    "    \n",
    "    transformedContours = np.dot(currentTransform, np.vstack([worldContours[blobId][frameIds[i]][:, :-1].T, np.ones([1, len(worldContours[blobId][frameIds[i]])])]))\n",
    "    transformedContours = transformedContours[:-1, :]/transformedContours[-1, :]\n",
    "    plot(transformedContours[0, :], transformedContours[1, :], color=cols[np.mod(i, len(cols))])\n",
    "    scatter(transformedFootprint[0, :], transformedFootprint[1, :], color=cols[np.mod(i, len(cols))])\n",
    "    \n",
    "    print(i, transformedFootprint.shape)\n",
    "    \n",
    "# xlim([-1, 1])\n",
    "# ylim([-3.7, -1.7])\n",
    "xlim([-1, 1])\n",
    "ylim([-5, -7])\n",
    "\n",
    "### ACCUMULATED TRANSFORMS ARE REFINED USING ICP AGAIN ###\n",
    "figure()\n",
    "plot(worldContours[blobId][frameIds[numFootprintsToShow]][:, 0], worldContours[blobId][frameIds[numFootprintsToShow]][:, 1], color=cols[np.mod(numFootprintsToShow, len(cols))])\n",
    "scatter(worldFootprints[blobId][frameIds[numFootprintsToShow]][:, 0], worldFootprints[blobId][frameIds[numFootprintsToShow]][:, 1], color=cols[np.mod(numFootprintsToShow, len(cols))])\n",
    "currentTransform = np.eye(3)\n",
    "for i in np.arange(numFootprintsToShow)[::-1] :\n",
    "    currentTransform = TsToLast[i]\n",
    "    transformedFootprint = np.dot(currentTransform, np.vstack([worldFootprints[blobId][frameIds[i]][:, :-1].T, np.ones([1, len(worldFootprints[blobId][frameIds[i]])])]))\n",
    "    transformedFootprint = transformedFootprint[:-1, :]/transformedFootprint[-1, :]\n",
    "    \n",
    "    transformedContours = np.dot(currentTransform, np.vstack([worldContours[blobId][frameIds[i]][:, :-1].T, np.ones([1, len(worldContours[blobId][frameIds[i]])])]))\n",
    "    transformedContours = transformedContours[:-1, :]/transformedContours[-1, :]\n",
    "    plot(transformedContours[0, :], transformedContours[1, :], color=cols[np.mod(i, len(cols))])\n",
    "    scatter(transformedFootprint[0, :], transformedFootprint[1, :], color=cols[np.mod(i, len(cols))])\n",
    "    \n",
    "    print(i, transformedFootprint.shape)\n",
    "    \n",
    "# xlim([-1, 1])\n",
    "# ylim([-3.7, -1.7])\n",
    "xlim([-1, 1])\n",
    "ylim([-5, -7])\n",
    "\n",
    "### (JUST FOOTPRINT POINTS) ACCUMULATED TRANSFORMS ARE REFINED USING ICP AGAIN ###\n",
    "figure()\n",
    "plot(worldContours[blobId][frameIds[numFootprintsToShow]][:, 0], worldContours[blobId][frameIds[numFootprintsToShow]][:, 1], color=cols[np.mod(numFootprintsToShow, len(cols))])\n",
    "scatter(worldFootprints[blobId][frameIds[numFootprintsToShow]][:, 0], worldFootprints[blobId][frameIds[numFootprintsToShow]][:, 1], color=cols[np.mod(numFootprintsToShow, len(cols))])\n",
    "currentTransform = np.eye(3)\n",
    "for i in np.arange(numFootprintsToShow)[::-1] :\n",
    "    currentTransform = TsToLast[i]\n",
    "    transformedFootprint = np.dot(currentTransform, np.vstack([worldFootprints[blobId][frameIds[i]][:, :-1].T, np.ones([1, len(worldFootprints[blobId][frameIds[i]])])]))\n",
    "    transformedFootprint = transformedFootprint[:-1, :]/transformedFootprint[-1, :]\n",
    "    plot(transformedFootprint[0, :], transformedFootprint[1, :], color=cols[np.mod(i, len(cols))])\n",
    "    \n",
    "    print(i, transformedFootprint.shape)\n",
    "    \n",
    "# xlim([-1, 1])\n",
    "# ylim([-3.7, -1.7])\n",
    "xlim([-1, 1])\n",
    "ylim([-5, -7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10399\n",
      "6847 3552\n",
      "2037 8362\n",
      "5960 4439\n",
      "2587 7812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-5, -7)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignedFootprintsAllPoints = np.empty([0, 2])\n",
    "for i in np.arange(len(TsToLast)) :\n",
    "    transformedFootprint = np.dot(TsToLast[i], np.vstack([worldFootprints[blobId][frameIds[i]][:, :-1].T, np.ones([1, len(worldFootprints[blobId][frameIds[i]])])]))\n",
    "    transformedFootprint = transformedFootprint[:-1, :]/transformedFootprint[-1, :]\n",
    "    alignedFootprintsAllPoints = np.concatenate([alignedFootprintsAllPoints, transformedFootprint.T], axis=0)\n",
    "\n",
    "alignedFootprintsAllPoints = np.concatenate([alignedFootprintsAllPoints, worldFootprints[blobId][frameIds[-1]][:, :-1]], axis=0)\n",
    "\n",
    "## fit shape using lines\n",
    "figure();\n",
    "scatter(alignedFootprintsAllPoints[:, 0], alignedFootprintsAllPoints[:, 1], color=\"green\")\n",
    "currentInliers = []\n",
    "for i in xrange(5) :\n",
    "    currentPointsMask = np.ones(len(alignedFootprintsAllPoints), bool)\n",
    "    currentPointsMask[currentInliers] = False\n",
    "    currentOutliers = np.arange(len(alignedFootprintsAllPoints), dtype=int)\n",
    "    currentOutliers = currentOutliers[currentPointsMask]\n",
    "    print(len(currentInliers), len(currentOutliers))\n",
    "    fittedModel = linear_model.RANSACRegressor(linear_model.LinearRegression())\n",
    "    fittedModel.fit(alignedFootprintsAllPoints[currentPointsMask, 0][:, np.newaxis], alignedFootprintsAllPoints[currentPointsMask, 1])\n",
    "    \n",
    "    lineX = np.arange(-1, 2)\n",
    "    lineY = fittedModel.predict(lineX[:, np.newaxis])\n",
    "    \n",
    "    currentInliers = currentOutliers[fittedModel.inlier_mask_]\n",
    "    plot(lineX, lineY)\n",
    "# scatter(alignedFootprintsAllPoints[fittedModel.inlier_mask_, 0], alignedFootprintsAllPoints[fittedModel.inlier_mask_, 1], color=\"green\")\n",
    "# scatter(alignedFootprintsAllPoints[np.logical_not(fittedModel.inlier_mask_), 0], alignedFootprintsAllPoints[np.logical_not(fittedModel.inlier_mask_), 1], color=\"red\")\n",
    "xlim([-1, 1])\n",
    "ylim([-5, -7])\n",
    "\n",
    "# inlier_mask = model_ransac.inlier_mask_\n",
    "# outlier_mask = np.logical_not(inlier_mask)\n",
    "\n",
    "# Predict data of estimated models\n",
    "# line_X = np.arange(-5, 5)\n",
    "# line_y = model.predict(line_X[:, np.newaxis])\n",
    "# line_y_ransac = model_ransac.predict(line_X[:, np.newaxis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## compute distances from each point to each of the others (consider regularly sampling the footprintPointsBBox to reduce amount of calculations)\n",
    "footprintPointsBBox = np.vstack([[np.min(alignedFootprintsAllPoints, axis=0)], [np.min(alignedFootprintsAllPoints[:, 0]), np.max(alignedFootprintsAllPoints[:, 1])],\n",
    "                                 [np.max(alignedFootprintsAllPoints, axis=0)], [np.max(alignedFootprintsAllPoints[:, 0]), np.min(alignedFootprintsAllPoints[:, 1])]])\n",
    "footprintPointsBBoxWidth = np.max(footprintPointsBBox[:, 0]) - np.min(footprintPointsBBox[:, 0])\n",
    "footprintPointsBBoxHeight = np.max(footprintPointsBBox[:, 1]) - np.min(footprintPointsBBox[:, 1])\n",
    "\n",
    "footprintPointsDistMat = ssd(alignedFootprintsAllPoints)\n",
    "footprintPointsDistMat[footprintPointsDistMat>0] = np.sqrt(footprintPointsDistMat[footprintPointsDistMat>0])\n",
    "## sum of distances to every other point for each point\n",
    "footprintPointsAllDistsSum = np.sum(footprintPointsDistMat, axis=0)\n",
    "## number of points within a certain threshold\n",
    "areaFraction = 100\n",
    "thresh = np.sqrt(footprintPointsBBoxWidth*footprintPointsBBoxHeight/(areaFraction*np.pi)) ## thresh is radius of circle having a fraction of the area of the footprintPointsBBox\n",
    "footprintPointsNumCloseNeighs = np.sum((footprintPointsDistMat < thresh).astype(float), axis=0)/np.sum((footprintPointsDistMat < thresh*2).astype(float), axis=0)\n",
    "\n",
    "# figure(); imshow(footprintPointsDistMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc9292c9890>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## found here http://stackoverflow.com/questions/6652671/efficient-method-of-calculating-density-of-irregularly-spaced-points\n",
    "def grid_density_gaussian_filter(x0, y0, x1, y1, w, h, data):\n",
    "    kx = (w - 1) / (x1 - x0)\n",
    "    ky = (h - 1) / (y1 - y0)\n",
    "    r = 20\n",
    "    border = r\n",
    "    imgw = (w + 2 * border)\n",
    "    imgh = (h + 2 * border)\n",
    "    img = np.zeros((imgh,imgw))\n",
    "    for x, y in data:\n",
    "        ix = int((x - x0) * kx) + border\n",
    "        iy = int((y - y0) * ky) + border\n",
    "        if 0 <= ix < imgw and 0 <= iy < imgh:\n",
    "            img[iy][ix] += 1\n",
    "    return spimg.gaussian_filter(img, (r,r))  ## gaussian convolution\n",
    "\n",
    "x0, y0, x1, y1 = np.min(alignedFootprintsAllPoints[:, 0]), np.min(alignedFootprintsAllPoints[:, 1]), np.max(alignedFootprintsAllPoints[:, 0]), np.max(alignedFootprintsAllPoints[:, 1])\n",
    "densityImg = grid_density_gaussian_filter(x0, y0, x1, y1, 512, np.round(512*(y1-y0)/(x1-x0)).astype(int), alignedFootprintsAllPoints)\n",
    "kx = (densityImg.shape[1] - 1) / (x1 - x0)\n",
    "ky = (densityImg.shape[0] - 1) / (y1 - y0)\n",
    "figure(); imshow(densityImg)\n",
    "# scatter((alignedFootprintsAllPoints[:, 0] - x0) * kx, (alignedFootprintsAllPoints[:, 1] - y0) * ky, marker=\"o\", facecolors='none', s=80, edgecolors=[0, 0, 0, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc9290b0e90>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonMaxSuppressedImg = np.zeros_like(densityImg)\n",
    "\n",
    "for x in np.arange(1, densityImg.shape[1]-1) :\n",
    "    for y in np.arange(1, densityImg.shape[0]-1) :\n",
    "        pixelIdx = np.array([x, y], int)\n",
    "\n",
    "        dirs = np.array([[1, 0], [1, 1], [0, 1], [-1, 1]], int)\n",
    "        perpendicularDirsIdxs = np.array([2, 3, 0, 1], int)\n",
    "        gradients = (densityImg[pixelIdx[1]+dirs[:, 1], pixelIdx[0]+dirs[:, 0]]-densityImg[pixelIdx[1]-dirs[:, 1], pixelIdx[0]-dirs[:, 0]])/np.linalg.norm((pixelIdx+dirs)-(pixelIdx-dirs), axis=1)\n",
    "        maxGradientDirIdx = np.argmax(np.abs(gradients))\n",
    "        # figure(); imshow(densityImg); scatter(x, y)\n",
    "        # plot([pixelIdx[0]-dirs[maxGradientDirIdx, 0], pixelIdx[0]+dirs[maxGradientDirIdx, 0]], [pixelIdx[1]-dirs[maxGradientDirIdx, 1], pixelIdx[1]+dirs[maxGradientDirIdx, 1]])\n",
    "        negativePerpendicularPixelIdx = pixelIdx-dirs[perpendicularDirsIdxs[maxGradientDirIdx], :]\n",
    "        positivePerpendicularPixelIdx = pixelIdx+dirs[perpendicularDirsIdxs[maxGradientDirIdx], :]\n",
    "\n",
    "        if (densityImg[pixelIdx[1], pixelIdx[0]] - densityImg[negativePerpendicularPixelIdx[1], negativePerpendicularPixelIdx[0]] > 1e-10 and\n",
    "            densityImg[pixelIdx[1], pixelIdx[0]] - densityImg[positivePerpendicularPixelIdx[1], positivePerpendicularPixelIdx[0]] > 1e-10) :\n",
    "            nonMaxSuppressedImg[y, x] = 1\n",
    "            \n",
    "figure(); imshow(nonMaxSuppressedImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc92908d5d0>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densitiesAtFootprintPoints = densityImg[np.round((alignedFootprintsAllPoints[:, 1] - y0) * ky).astype(int), np.round((alignedFootprintsAllPoints[:, 0] - x0) * kx).astype(int)]\n",
    "allDistsSumsOverDensities = footprintPointsAllDistsSum*np.sum(densitiesAtFootprintPoints)/densitiesAtFootprintPoints\n",
    "\n",
    "def discretizeDataValuesToImage(x0, y0, x1, y1, w, h, data, dataValues):\n",
    "    kx = (w - 1) / (x1 - x0)\n",
    "    ky = (h - 1) / (y1 - y0)\n",
    "    r = 20\n",
    "    border = r\n",
    "    imgw = (w + 2 * border)\n",
    "    imgh = (h + 2 * border)\n",
    "    img = np.zeros((imgh,imgw))\n",
    "    for pointIdx, (x, y) in enumerate(data):\n",
    "        ix = int((x - x0) * kx) + border\n",
    "        iy = int((y - y0) * ky) + border\n",
    "        if 0 <= ix < imgw and 0 <= iy < imgh:\n",
    "            img[iy][ix] += dataValues[pointIdx]\n",
    "    return spimg.gaussian_filter(img, (r,r))\n",
    "\n",
    "accumulatedDistsSumsOverDensitiesImg = discretizeDataValuesToImage(x0, y0, x1, y1, densityImg.shape[1], densityImg.shape[0], alignedFootprintsAllPoints, allDistsSumsOverDensities)\n",
    "accumulatedDistsSumsOverDensities = accumulatedDistsSumsOverDensitiesImg[np.round((alignedFootprintsAllPoints[:, 1] - y0) * ky).astype(int), np.round((alignedFootprintsAllPoints[:, 0] - x0) * kx).astype(int)]\n",
    "figure(); imshow(accumulatedDistsSumsOverDensitiesImg)\n",
    "xlim([0, accumulatedDistsSumsOverDensitiesImg.shape[1]]); ylim([0, accumulatedDistsSumsOverDensitiesImg.shape[0]])\n",
    "plot((footprintPointsBBox[[0, 1, 2, 3, 0], 0] - x0) * kx, (footprintPointsBBox[[0, 1, 2, 3, 0], 1] - y0) * ky, c=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nnInterp(point, neighs, neighVals, p=6.0) :\n",
    "    ## can't seem to find where I got this from\n",
    "    return np.sum(neighVals/(np.sum((neighs-point)**2, axis=1)**(p/2.0)))/np.sum(1.0/(np.sum((neighs-point)**2, axis=1)**(p/2.0)))\n",
    "\n",
    "## do the same non max suppression thing but straight onto the footprint points\n",
    "def getInterpolatedValuesAtPoints(points, allPoints, allPointsVals, numNeighs=4) :\n",
    "    distancesToAllPoints = ssd2(points, allPoints)\n",
    "    closestNeighs = np.argsort(distancesToAllPoints, axis=1)[:, :numNeighs]\n",
    "    valsAtPoints = np.zeros(len(points))\n",
    "    for i in np.arange(len(valsAtPoints)) :\n",
    "        valsAtPoints[i] = nnInterp(points[i, :], allPoints[closestNeighs[i, :], :], allPointsVals[closestNeighs[i, :]])\n",
    "    return valsAtPoints\n",
    "\n",
    "isLocalMax = np.zeros(len(alignedFootprintsAllPoints), dtype=bool)\n",
    "numNeighs = 4\n",
    "\n",
    "dirs = np.array([[1, 0], [1, 1], [0, 1], [-1, 1]], float)\n",
    "dirs /= np.linalg.norm(dirs, axis=1)[:, np.newaxis]\n",
    "perpendicularDirsIdxs = np.array([2, 3, 0, 1], int)\n",
    "h = 0.05 ## maybe set this based on the footprintBBox\n",
    "\n",
    "# pointsVals = allDistsSumsOverDensities/np.max(allDistsSumsOverDensities)\n",
    "pointsVals = densitiesAtFootprintPoints/np.max(densitiesAtFootprintPoints)\n",
    "\n",
    "for pointIdx in np.arange(len(alignedFootprintsAllPoints)) :\n",
    "    point = alignedFootprintsAllPoints[pointIdx, :]\n",
    "    pointsOnPositiveDirs = point+dirs*h*0.5\n",
    "    pointsOnNegativeDirs = point-dirs*h*0.5\n",
    "    valsAtPointsOnPositiveDirs = getInterpolatedValuesAtPoints(pointsOnPositiveDirs, alignedFootprintsAllPoints, pointsVals, numNeighs)\n",
    "    valsAtPointsOnNegativeDirs = getInterpolatedValuesAtPoints(pointsOnNegativeDirs, alignedFootprintsAllPoints, pointsVals, numNeighs)\n",
    "    gradients = (valsAtPointsOnPositiveDirs-valsAtPointsOnNegativeDirs)/h\n",
    "    maxGradientDirIdx = np.argmax(np.abs(gradients))\n",
    "\n",
    "    if (pointsVals[pointIdx]-valsAtPointsOnPositiveDirs[perpendicularDirsIdxs[maxGradientDirIdx]] > 1e-10 and\n",
    "        pointsVals[pointIdx]-valsAtPointsOnNegativeDirs[perpendicularDirsIdxs[maxGradientDirIdx]] > 1e-10) :\n",
    "        isLocalMax[pointIdx] = True\n",
    "\n",
    "# figure(); scatter(alignedFootprintsAllPoints[:, 0], alignedFootprintsAllPoints[:, 1], c=cm.jet(np.log(allDistsSumsOverDensities)/np.max(np.log(allDistsSumsOverDensities)), alpha=1),\n",
    "#                   marker=\"o\", facecolors='none', s=80, edgecolors=[0, 0, 0, 0.2])\n",
    "# scatter(alignedFootprintsAllPoints[pointIdx, 0], alignedFootprintsAllPoints[pointIdx, 1])\n",
    "# plot([pointsOnNegativeDirs[maxGradientDirIdx, 0], pointsOnPositiveDirs[maxGradientDirIdx, 0]], [pointsOnNegativeDirs[maxGradientDirIdx, 1], pointsOnPositiveDirs[maxGradientDirIdx, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alignedFootprintsAllPoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-0a4869e8d8a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mombb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mcalipersOMBB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malignedFootprintsAllPoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'alignedFootprintsAllPoints' is not defined"
     ]
    }
   ],
   "source": [
    "## from here http://math.stackexchange.com/questions/180418/calculate-rotation-matrix-to-align-vector-a-to-vector-b-in-3d\n",
    "## but it doesn't seem to work for some reason\n",
    "def rotateVectorOntoVector3D(a, b) :\n",
    "    \"\"\" DOES NOT WORK: returns rotation matrix that rotates vector a onto vector b \"\"\"\n",
    "    v = np.cross(a, b)\n",
    "    v1, v2, v3 = v/np.linalg.norm(v)\n",
    "    s = np.linalg.norm(v)\n",
    "    c = np.dot(a, b)\n",
    "    vx = np.array([[0.0, -v3, v2],\n",
    "                   [v3, 0.0, -v1],\n",
    "                   [-v2, v1, 0.0]])\n",
    "    if s != 0.0 :\n",
    "        return np.eye(3) + vx + (vx**2)/(1+c)\n",
    "    else :\n",
    "        return np.eye(3)\n",
    "    \n",
    "def calipersOMBB(points) :\n",
    "    \"\"\" computes minimum area oriented bounding box given a set of points using the calipers algorithm \"\"\"\n",
    "    \n",
    "    convexHull = cv2.convexHull(points.astype(np.float32))[:, 0, :]\n",
    "#     figure(); scatter(points[:, 0], points[:, 1]); plot(convexHull[np.mod(arange(len(convexHull)+1), len(convexHull)), 0], convexHull[np.mod(arange(len(convexHull)+1), len(convexHull)), 1])\n",
    "#     scatter(convexHull[0, 0],convexHull[0, 1], color=\"red\")\n",
    "#     xlim([-1, 1])\n",
    "#     ylim([-6.5, -4.5])\n",
    "    \n",
    "    minArea = 10000000000.0\n",
    "    ombb = np.zeros([4, 2])\n",
    "    for i in np.arange(len(convexHull))[0:] :\n",
    "        j = np.mod(i+1, len(convexHull))\n",
    "        \n",
    "        segmentDir = convexHull[j, :] - convexHull[i, :]\n",
    "        segmentDir /= np.linalg.norm(segmentDir)\n",
    "        \n",
    "        crossProduct = np.cross(np.array([1.0, 0.0, 0.0]), np.concatenate([segmentDir, [0]]))\n",
    "        dotProduct = np.dot(segmentDir, np.array([1.0, 0.0]))\n",
    "        #I know the last component of both vectors is 0 so the rotation matrix will be all zeros there\n",
    "        T = quaternionTo4x4Rotation(angleAxisToQuaternion(np.arccos(dotProduct), crossProduct/np.linalg.norm(crossProduct)))[:-2, :-2]\n",
    "        \n",
    "        transformedPoints = np.dot(T, points.T-convexHull[i, :][:, np.newaxis]).T + convexHull[i, :]\n",
    "        \n",
    "        [x0, y0], [x1, y1] = np.min(transformedPoints, axis=0), np.max(transformedPoints, axis=0)\n",
    "        \n",
    "        transformedBBox = np.array([[x0, y0], [x0, y1], [x1, y1], [x1, y0]])\n",
    "        bbox = np.dot(np.linalg.inv(T), transformedBBox.T-convexHull[i, :][:, np.newaxis]).T + convexHull[i, :]\n",
    "        \n",
    "        bboxArea = (x1-x0)*(y1-y0)\n",
    "        if bboxArea < minArea :\n",
    "            minArea = np.copy(bboxArea)\n",
    "            ombb = np.copy(bbox)\n",
    "            \n",
    "#         transformedHull = np.dot(T, convexHull.T-convexHull[i, :][:, np.newaxis]).T + convexHull[i, :]\n",
    "#         scatter(transformedPoints[:, 0], transformedPoints[:, 1], color=\"cyan\")\n",
    "#         plot(transformedHull[np.mod(arange(len(convexHull)+1), len(convexHull)), 0], transformedHull[np.mod(arange(len(convexHull)+1), len(convexHull)), 1], color=\"magenta\")\n",
    "#         scatter(transformedHull[np.mod(arange(len(convexHull)+1), len(convexHull)), 0], transformedHull[np.mod(arange(len(convexHull)+1), len(convexHull)), 1], color=\"magenta\")\n",
    "#         plot(transformedBBox[np.mod(arange(len(transformedBBox)+1), len(transformedBBox)), 0], transformedBBox[np.mod(arange(len(transformedBBox)+1), len(transformedBBox)), 1], color=\"magenta\")\n",
    "#         scatter(convexHull[i, 0], convexHull[i, 1], color=\"green\"); plot([convexHull[i, 0], convexHull[i, 0]+segmentDir[0]], [convexHull[i, 1], convexHull[i, 1]+segmentDir[1]], color=\"green\")\n",
    "#         plot([convexHull[i, 0], convexHull[i, 0]+1], [convexHull[i, 1], convexHull[i, 1]], color=\"green\")\n",
    "#         plot(bbox[np.mod(arange(len(bbox)+1), len(bbox)), 0], bbox[np.mod(arange(len(bbox)+1), len(bbox)), 1], color=\"red\")\n",
    "#     plot(ombb[np.mod(arange(len(ombb)+1), len(ombb)), 0], ombb[np.mod(arange(len(ombb)+1), len(ombb)), 1], color=\"green\")\n",
    "    return ombb\n",
    "    \n",
    "calipersOMBB(alignedFootprintsAllPoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.79764389992\n"
     ]
    }
   ],
   "source": [
    "def sampleOBB(obb, numSubdivs) :\n",
    "    return np.vstack([v1+np.arange(0.0, (numSubdivs+1.0)/numSubdivs, 1.0/numSubdivs)[:, np.newaxis]*(v2-v1)[np.newaxis, :] for v1, v2 in zip(obb, obb[np.mod(np.arange(1, len(obb)+1), len(obb)), :])])\n",
    "\n",
    "def getOBBVerticesPerpendicularDirs(obb) :\n",
    "    return np.vstack([((v2-v1)/np.linalg.norm(v2-v1))[newaxis, :] for v1, v2 in zip(obb, obb[np.arange(len(obb))-1, :])])\n",
    "\n",
    "def updateOBBScale(obb, dirs, amounts) :\n",
    "    \"\"\" scales the obb by moving the i'th segment (comprised of the i'th and i+1'th vertices in obb) by the i'th dir times the i'th amount \"\"\"\n",
    "    return np.vstack([obb[idx, :]+dirs[idx, :]*amounts[idx]+dirs[idx-1, :]*amounts[idx-1] for idx in np.arange(len(dirs))])\n",
    "\n",
    "def functionToMinimize(p, src, dst, dirs, weights, allPoints) :\n",
    "    ps = p.repeat(len(src)/len(p))[:, np.newaxis]\n",
    "    updatedSrc = src+dirs*ps\n",
    "    \n",
    "    return np.sum(np.sum((updatedSrc-dst)**2, axis=1)*weights)\n",
    "\n",
    "doUseNNInterp = False\n",
    "currentOBB = calipersOMBB(alignedFootprintsAllPoints)\n",
    "p = np.zeros(len(currentOBB))\n",
    "numSubdivs = 10\n",
    "numNeighs = 4\n",
    "\n",
    "if doUseNNInterp : \n",
    "#     pointsVals = allDistsSumsOverDensities/np.max(allDistsSumsOverDensities)\n",
    "    pointsVals = densitiesAtFootprintPoints/np.max(densitiesAtFootprintPoints)\n",
    "#     pointsVals = accumulatedDistsSumsOverDensities/np.max(accumulatedDistsSumsOverDensities)\n",
    "else : \n",
    "    pointsVals = allDistsSumsOverDensities/np.max(allDistsSumsOverDensities)\n",
    "    \n",
    "    ## ACCUMULATE THE POINTS VALUES OVER A GRID (basically getting what I have in accumulatedDistsSumsOverDensities if I use pointsVals = allDistsSumsOverDensities) AND USE TO FIND BEST NEIGHBOURS\n",
    "    ## get grid bounds\n",
    "    gridX0, gridY0, gridX1, gridY1 = np.min(currentOBB[:, 0]), np.min(currentOBB[:, 1]), np.max(currentOBB[:, 0]), np.max(currentOBB[:, 1])\n",
    "    gridWidth, gridHeight = (gridX1-gridX0, gridY1-gridY0)\n",
    "    ## extend by a factor\n",
    "    extendFactor = 0.1\n",
    "    gridExtend = np.array([gridWidth, gridHeight])*extendFactor\n",
    "    gridX0, gridY0 = np.array([gridX0, gridY0])-gridExtend\n",
    "    gridX1, gridY1 = np.array([gridX1, gridY1])+gridExtend\n",
    "    discreteGridWidth = 512\n",
    "    ## accumulate the pointsVals over discrete grid \n",
    "    accumulatedPointsValsDiscreteGrid = discretizeDataValuesToImage(gridX0, gridY0, gridX1, gridY1, discreteGridWidth, np.ceil(discreteGridWidth*gridHeight/gridWidth).astype(int), \n",
    "                                                                    alignedFootprintsAllPoints, pointsVals)\n",
    "    gridScaleX = (accumulatedPointsValsDiscreteGrid.shape[1] - 1) / (gridX1 - gridX0)\n",
    "    gridScaleY = (accumulatedPointsValsDiscreteGrid.shape[0] - 1) / (gridY1 - gridY0)\n",
    "    pointsValsFromGrid = accumulatedPointsValsDiscreteGrid[np.round((alignedFootprintsAllPoints[:, 1] - gridY0) * gridScaleY).astype(int), np.round((alignedFootprintsAllPoints[:, 0] - gridX0) * gridScaleX).astype(int)]\n",
    "    pointsValsFromGrid = pointsValsFromGrid/np.max(pointsValsFromGrid)\n",
    "\n",
    "\n",
    "figure() \n",
    "doShowIterEvolution = True\n",
    "if doShowIterEvolution :\n",
    "    ion()\n",
    "\n",
    "startTime = time.time()\n",
    "numIters = 10\n",
    "for iterNum in np.arange(numIters) :\n",
    "    if doShowIterEvolution or iterNum == numIters-1 :\n",
    "        cla()\n",
    "        if doUseNNInterp :\n",
    "            scatter(alignedFootprintsAllPoints[:, 0], alignedFootprintsAllPoints[:, 1], c=cm.jet(np.log(1+pointsVals)/np.max(np.log(1+pointsVals)), alpha=1),\n",
    "                    marker=\"o\", s=60, edgecolors=[0, 0, 0, 0.2])\n",
    "        else :\n",
    "            scatter(alignedFootprintsAllPoints[:, 0], alignedFootprintsAllPoints[:, 1], c=cm.jet(np.log(1+pointsValsFromGrid)/np.max(np.log(1+pointsValsFromGrid)), alpha=1),\n",
    "                    marker=\"o\", s=60, edgecolors=[0, 0, 0, 0.2])\n",
    "            \n",
    "        xlim([-1, 1])\n",
    "        ylim([-6.5, -4.5])\n",
    "    \n",
    "    \n",
    "    ## sample the current OBB\n",
    "    sampledCurrentOBB = sampleOBB(currentOBB, numSubdivs)\n",
    "    vertexMoveDir = getOBBVerticesPerpendicularDirs(currentOBB)\n",
    "    pointsMoveDir = np.vstack([moveDir[np.newaxis, :].repeat(numSubdivs+1, axis=0) for moveDir in vertexMoveDir])\n",
    "    ## length of subdivision for the segment the point belongs to\n",
    "    pointsSubdivisionLength = np.concatenate([np.linalg.norm(v2-v1).repeat(numSubdivs+1)/numSubdivs for v1, v2 in zip(currentOBB, currentOBB[np.mod(np.arange(1, len(currentOBB)+1), len(currentOBB)), :])])\n",
    "    \n",
    "    ## find best neighbours in +- moveDir\n",
    "    ## do this by discretizing the +- dir and find best value (not the fastests of things but it should do for now) --> one speed up would be use the point density image (seeing how I'm discretizing anyways) and do NNinterp\n",
    "    discreteRatio = 0.05\n",
    "    bestNeighbours = np.zeros_like(sampledCurrentOBB)\n",
    "    bestNeighsValues = np.zeros(len(sampledCurrentOBB))\n",
    "    \n",
    "    ## only look inside obb if it's the first iteration because I know I start with an OMBB\n",
    "    neighboursRange = np.arange(0.0, 1.0+discreteRatio, discreteRatio) if iterNum == 0 else np.arange(-1.0, 1.0+discreteRatio, discreteRatio)\n",
    "    for pointIdx in np.arange(len(sampledCurrentOBB)) :\n",
    "        closeNeighbours = (neighboursRange*pointsSubdivisionLength[pointIdx]*pointsMoveDir[pointIdx, :][:, np.newaxis]).T+sampledCurrentOBB[pointIdx, :][np.newaxis, :]\n",
    "        if doUseNNInterp :\n",
    "            ## use nnInterp\n",
    "            valuesAtNeighbours = getInterpolatedValuesAtPoints(closeNeighbours, alignedFootprintsAllPoints, pointsVals, numNeighs)\n",
    "        else :\n",
    "            ## use discrete grid\n",
    "            ## THIS COULD PROBABLY BE VECTORIZED MORE BUT IT'S ALREADY 10x faster than nnInterp and it doesn't suffer from the problem discussed in the 14/02/17 journal entry\n",
    "            closeNeighboursGridSpace = (closeNeighbours-np.array([[gridX0, gridY0]]))*np.array([[gridScaleX, gridScaleY]])\n",
    "            valuesAtNeighbours = []\n",
    "            for closeNeighbour in closeNeighboursGridSpace :\n",
    "                nearestNeighbours = np.concatenate([np.floor(closeNeighbour), np.ceil(closeNeighbour)])[[0, 1, 0, 3, 2, 3, 2, 1]].reshape([4, 2]).astype(int)\n",
    "                distsToNNs = np.linalg.norm(nearestNeighbours-closeNeighbour, axis=1)\n",
    "                weights = distsToNNs/np.sum(distsToNNs)\n",
    "                valuesAtNeighbours.append(np.sum(accumulatedPointsValsDiscreteGrid[nearestNeighbours[:, 1], nearestNeighbours[:, 0]]*weights))\n",
    "            valuesAtNeighbours = np.array(valuesAtNeighbours)\n",
    "            \n",
    "        bestNeighbourIdx = np.argmax(valuesAtNeighbours).flatten().astype(int)\n",
    "        bestNeighbours[pointIdx, :] = closeNeighbours[bestNeighbourIdx, :]\n",
    "        bestNeighsValues[pointIdx] = valuesAtNeighbours[bestNeighbourIdx]\n",
    "        \n",
    "    bestNeighsValues /= np.sum(bestNeighsValues)\n",
    "    \n",
    "    optResult = minimize(functionToMinimize, np.zeros_like(p), args=(sampledCurrentOBB, bestNeighbours, pointsMoveDir, bestNeighsValues, alignedFootprintsAllPoints), method='BFGS') #, method='Newton-CG')#, jac=jac, hess=hess)\n",
    "    p = optResult.x\n",
    "    currentOBB = updateOBBScale(currentOBB, vertexMoveDir, p)\n",
    "    \n",
    "    if doShowIterEvolution or iterNum == numIters-1 :\n",
    "        plot(currentOBB[np.mod(arange(len(currentOBB)+1), len(currentOBB)), 0], currentOBB[np.mod(arange(len(currentOBB)+1), len(currentOBB)), 1], color=\"green\")\n",
    "        scatter(sampledCurrentOBB[:, 0], sampledCurrentOBB[:, 1], color=\"green\")\n",
    "        scatter(bestNeighbours[:, 0], bestNeighbours[:, 1], c=cm.jet(bestNeighsValues/np.max(bestNeighsValues), alpha=1))\n",
    "        show()\n",
    "        pause(0.05)\n",
    "        \n",
    "print(time.time()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 320.  156.]\n"
     ]
    }
   ],
   "source": [
    "print(filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS][:-1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING /home/ilisescu/PhD/data/smooth_abbey_road/downsampledSet-4x.npy\n",
      "LOADED black_pickup1\n",
      "[435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452\n",
      " 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470\n",
      " 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488\n",
      " 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506\n",
      " 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524\n",
      " 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542\n",
      " 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560\n",
      " 561] 127 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilisescu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:146: RuntimeWarning: divide by zero encountered in log\n",
      "/home/ilisescu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:146: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE in 9.49459886551\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "def distortPoints(undistortedPoints, distortionCoeff, undistortedIntrinsics, distortedIntrinsics) :\n",
    "    \"\"\" distorts points in an undistorted image space to the original image space as if they are \n",
    "    seen again through the distorting lens\n",
    "    \n",
    "    - as seen here: http://stackoverflow.com/a/35016615\"\"\"\n",
    "    ## not sure what this does but it doesn't work without it\n",
    "    tmp = cv2.undistortPoints(undistortedPoints.reshape([1, len(undistortedPoints), 2]),\n",
    "                              undistortedIntrinsics, np.zeros(5))\n",
    "    distortedPoints = cv2.projectPoints(np.concatenate([tmp, np.ones([1, tmp.shape[1], 1])], axis=-1), (0, 0, 0),\n",
    "                                        (0, 0, 0), distortedIntrinsics, distortionCoeff)[0][:, 0, :]\n",
    "    return distortedPoints\n",
    "\n",
    "def patchImageIdxsFromCenterAndSize(patchCenter, patchHalfSize, imageShape) :\n",
    "    \"\"\"patchCenter is (x, y) and patchHalfSize is (width, height)\n",
    "    returns [minRow, minCol, maxRow, maxCol]\"\"\"\n",
    "    ## enlarge patch and make sure it's within bounds\n",
    "    patchMinCorner = np.floor(np.max([np.zeros(2), patchCenter-patchHalfSize], axis=0)).astype(int)\n",
    "    patchMaxCorner = np.ceil(np.min([np.array(imageShape[::-1]),\n",
    "                                     patchCenter+patchHalfSize+1], axis=0)).astype(int)\n",
    "    return np.concatenate([patchMinCorner[::-1], patchMaxCorner[::-1]])\n",
    "\n",
    "\n",
    "########################## INIT AND GET FILMED SCENE AND OBJECT DATA AND STUFF ##########################\n",
    "\n",
    "boundingVolumeVertexDrawIndices = [0, 1, 2, 3, 0, 4, 5, 6, 7, 4, 0, 1, 5, 6, 2, 3, 7]\n",
    "filmedScene = GLFilmedScene(filmedScenesLocs[0])\n",
    "filmedObject = filmedScene.filmedObjects[0]\n",
    "filmedObject.footprintScale = filmedObject.filmedObjectData[DICT_OBJECT_WIDTH] #0.25\n",
    "filmedObject.footprintAspectRatio = filmedObject.filmedObjectData[DICT_OBJECT_LENGTH]/filmedObject.filmedObjectData[DICT_OBJECT_WIDTH]#2.35\n",
    "filmedObject.setGeometryAndBuffers()\n",
    "filmedObjectHeight = filmedObject.filmedObjectData[DICT_OBJECT_HEIGHT] ##0.18 ## this would have to be eventually found at the same time as the footprint box\n",
    "viewMat, projectionMat = cvCameraToOpenGL(filmedScene.cameraExtrinsics, filmedScene.cameraIntrinsics,\n",
    "                                          filmedScene.medianImage.shape[:-1])\n",
    "\n",
    "\n",
    "########################## GET TRAJECTORY OF CURRENT OBJECT ##########################\n",
    "## here I'm using code from GLFilmedObject\n",
    "if False :\n",
    "    ## hacks done for blue_car1\n",
    "    # trajectoryPoints, trajectoryPointsFrameIds = readNukeTrack(filmedObject.filmedObjectData[DICT_TRACK_LOCATION])\n",
    "    trajectoryPoints, trajectoryPointsFrameIds = readNukeTrack(\"/home/ilisescu/PhD/data/havana/{0}-track_longer.txt\".format(\"blue_car1\"))\n",
    "    trajectoryPoints = trajectoryPoints + filmedScene.cameraIntrinsics[:2, -1] - filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS][:2, -1]\n",
    "else :\n",
    "    trajectoryPoints, trajectoryPointsFrameIds = readNukeTrack(filmedObject.filmedObjectData[DICT_TRACK_LOCATION])\n",
    "    trajectoryPoints = getUndistortedTrajectoryPoints(filmedObjectData, getDistortionCoeffFromParamAndRatio(filmedSceneData[DICT_DISTORTION_PARAMETER], filmedSceneData[DICT_DISTORTION_RATIO]),\n",
    "                                                      filmedScene.cameraIntrinsics)\n",
    "\n",
    "trajectory = GLTrajectory(trajectoryPoints, filmedScene.cameraIntrinsics, filmedScene.cameraExtrinsics, \n",
    "                          filmedObject.filmedObjectData[DICT_REPRESENTATIVE_COLOR], doSmoothing = False)\n",
    "\n",
    "\n",
    "filmedObjectTransform = filmedObject.modelMat\n",
    "distanceTransforms = np.zeros([int(filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS][1, -1]*2), int(filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS][0, -1]*2), len(trajectoryPointsFrameIds)], dtype=np.float32)\n",
    "patchesImageIdxs = np.zeros([4, len(trajectoryPointsFrameIds)], dtype=np.int32)\n",
    "for currentFrameIdx in [100] : #np.arange(len(trajectoryPointsFrameIds)) :\n",
    "    \n",
    "    ########################## SET OBJECT ONTO TRAJECTORY AND RENDER ITS BOUNDING VOLUME ##########################\n",
    "\n",
    "    ## I'm basically using utilities from GLFilmedObject but using a different trajectory \n",
    "    ## (because the trajectory saved for filmed objects are clamped to make sure the object is always fully visible)\n",
    "    positionWorld = trajectory.worldTrajectoryPoints[currentFrameIdx, :]\n",
    "    directionWorld = trajectory.worldTrajectoryDirections[currentFrameIdx, :]\n",
    "\n",
    "    objPos, objFDir = getWorldSpacePosAndNorm(filmedObjectTransform, filmedObject.forwardDir)\n",
    "    adjustAngle = np.arccos(np.clip(np.dot(objFDir, directionWorld), -1, 1))\n",
    "    if np.abs(adjustAngle) > 1e-06 :\n",
    "    #             print(adjustAngle, np.cross(directionWorld, objFDir))\n",
    "        adjustAxis = np.cross(directionWorld, objFDir)\n",
    "        adjustAxis /= np.linalg.norm(adjustAxis)\n",
    "        filmedObjectTransform = np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(adjustAngle, adjustAxis)), filmedObjectTransform)\n",
    "    filmedObjectTransform[:-1, -1] = positionWorld\n",
    "\n",
    "    worldFootprintVertices = np.dot(filmedObjectTransform, np.hstack([filmedObject.footprintVertices[[0, 1, 4, 5], :],\n",
    "                                                                      np.ones([4, 1])]).T)\n",
    "    worldFootprintVertices = worldFootprintVertices[:-1, :]/worldFootprintVertices[-1, :]\n",
    "    worldFootprintVertices = worldFootprintVertices.T\n",
    "    worldBoundingVolumeVertices = np.vstack([worldFootprintVertices,\n",
    "                                             worldFootprintVertices+np.array([[0, 0, 1.0]])*filmedObjectHeight])\n",
    "\n",
    "    cameraBoundingVolumeVertices = worldToScreenSpace(viewMat, projectionMat, worldBoundingVolumeVertices,\n",
    "                                                      filmedScene.medianImage.shape[1], filmedScene.medianImage.shape[0])\n",
    "\n",
    "    # T = np.dot(filmedScene.cameraIntrinsics, filmedScene.cameraExtrinsics[:-1, [0, 1, 3]])\n",
    "    # cameraFootprintVertices = np.dot(T, np.vstack([worldFootprintVertices[:-1, :],\n",
    "    #                                                np.ones([1, len(worldFootprintVertices.T)])]))\n",
    "    # cameraFootprintVertices = cameraFootprintVertices[:-1, :]/cameraFootprintVertices[-1, :]\n",
    "\n",
    "\n",
    "\n",
    "    # currentFrameImg, _, _, _, _ = undistortImage(filmedScene.filmedSceneData[DICT_DISTORTION_PARAMETER],\n",
    "    #                                              filmedScene.filmedSceneData[DICT_DISTORTION_RATIO],\n",
    "    #                                              np.array(Image.open(dataLoc+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[currentFrameIdx]+1))),\n",
    "    #                                              filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS])\n",
    "    # figure(); imshow(currentFrameImg); xlim([0, currentFrameImg.shape[1]]); ylim([currentFrameImg.shape[0], 0])\n",
    "    # plot(trajectoryPoints[:, 0], trajectoryPoints[:, 1],\n",
    "    #      c=tuple(filmedObject.filmedObjectData[DICT_REPRESENTATIVE_COLOR]/255.0))\n",
    "    # plot(cameraBoundingVolumeVertices[boundingVolumeVertexDrawIndices, 0],\n",
    "    #      cameraBoundingVolumeVertices[boundingVolumeVertexDrawIndices, 1], c=\"green\")\n",
    "    # scatter(trajectoryPoints[[50, 30], 0], trajectoryPoints[[50, 30], 1])\n",
    "\n",
    "\n",
    "    ########################## DISTORT THE cameraBoundingVolumeVertices SO THAT I CAN WORK IN THE ORIGINAL IMAGE SPACE ##########################\n",
    "\n",
    "    currentFrameImg = np.array(Image.open(dataLoc+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[currentFrameIdx]+1)))\n",
    "    # cameraBoundingVolumeVertices = cv2.undistortPoints(cameraBoundingVolumeVertices.reshape((1, len(cameraBoundingVolumeVertices), 2)),\n",
    "    #                                                    filmedScene.cameraIntrinsics, -filmedScene.distortionCoeff,\n",
    "    #                                                    P=filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS])[0, :, :]\n",
    "    # cameraTrajectoryPoints = cv2.undistortPoints(trajectoryPoints.reshape((1, len(trajectoryPoints), 2)),\n",
    "    #                                              filmedScene.cameraIntrinsics, -filmedScene.distortionCoeff,\n",
    "    #                                              P=filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS])[0, :, :]\n",
    "    cameraBoundingVolumeVertices = distortPoints(cameraBoundingVolumeVertices, filmedScene.distortionCoeff,\n",
    "                                                 filmedScene.cameraIntrinsics, \n",
    "                                                 filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS])\n",
    "    cameraTrajectoryPoints = distortPoints(trajectoryPoints, filmedScene.distortionCoeff, filmedScene.cameraIntrinsics, \n",
    "                                           filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS])\n",
    "\n",
    "    tmpImg = np.copy(currentFrameImg)\n",
    "    cv2.polylines(tmpImg, [cameraBoundingVolumeVertices[boundingVolumeVertexDrawIndices, :].astype(np.int32).reshape((-1,1,2))], False, (0, 0, 255))\n",
    "    Image.fromarray(tmpImg.astype(np.uint8)).save('/home/ilisescu/PhD/data/havana/segmentation_shapePrior_input/frame-{0:05}.png'.format(trajectoryPointsFrameIds[currentFrameIdx]+1))\n",
    "#     figure(); imshow(currentFrameImg); xlim([0, currentFrameImg.shape[1]]); ylim([currentFrameImg.shape[0], 0])\n",
    "#     plot(cameraTrajectoryPoints[:, 0], cameraTrajectoryPoints[:, 1],\n",
    "#          c=tuple(filmedObject.filmedObjectData[DICT_REPRESENTATIVE_COLOR]/255.0))\n",
    "#     plot(cameraBoundingVolumeVertices[boundingVolumeVertexDrawIndices, 0],\n",
    "#          cameraBoundingVolumeVertices[boundingVolumeVertexDrawIndicboundingVolumeVertexDrawIndiceses, 1], c=\"green\")\n",
    "#     scatter(cameraTrajectoryPoints[[50, 30], 0], cameraTrajectoryPoints[[50, 30], 1])\n",
    "\n",
    "\n",
    "    ########################## FIND CONVEX HULL OF PROJECTED BOUNDING VOLUME AND COMPUTE DIST TRANSFORM ##########################\n",
    "\n",
    "    hullIdxs = ConvexHull(cameraBoundingVolumeVertices).vertices\n",
    "    cameraConvexHull = cameraBoundingVolumeVertices[hullIdxs, :]\n",
    "#     plot(cameraConvexHull[:, 0], cameraConvexHull[:, 1], c=\"red\")\n",
    "\n",
    "    volumeConvexHullImg = np.ones(currentFrameImg.shape[0:-1])\n",
    "    cv2.polylines(volumeConvexHullImg, [cameraConvexHull.astype(np.int32).reshape((-1,1,2))], True, (0))\n",
    "    distanceTransformImg = spimg.morphology.distance_transform_edt(volumeConvexHullImg)\n",
    "#     convexFillImg = np.ones_like(distanceTransformImg)\n",
    "#     cv2.fillConvexPoly(convexFillImg, cameraConvexHull.astype(np.int32), (0))\n",
    "#     distanceTransformImg *= convexFillImg*2-1\n",
    "#     cv2.fillConvexPoly(distanceTransformImg, cameraConvexHull.astype(np.int32), (0))\n",
    "\n",
    "    ## the patch will be of size 1+patchHalfSize*2 (unless image borders are hit of course) and centered on patchCenter\n",
    "    patchSize = np.ceil(np.max(cameraConvexHull, axis=0))-np.floor(np.min(cameraConvexHull, axis=0))\n",
    "    patchCenter = np.round(np.floor(np.min(cameraConvexHull, axis=0))+patchSize/2.0)\n",
    "    enlargePercentage = 1.0\n",
    "    patchHalfSize = np.ceil((patchSize + patchSize*enlargePercentage)/2.0)\n",
    "\n",
    "    patchImageIdxs = patchImageIdxsFromCenterAndSize(patchCenter, patchHalfSize, currentFrameImg.shape[0:2])\n",
    "    figure(); imshow(currentFrameImg[patchImageIdxs[0]:patchImageIdxs[2], patchImageIdxs[1]:patchImageIdxs[3]])\n",
    "    plot(cameraBoundingVolumeVertices[boundingVolumeVertexDrawIndices, 0]-patchImageIdxs[1],\n",
    "         cameraBoundingVolumeVertices[boundingVolumeVertexDrawIndices, 1]-patchImageIdxs[0], c=\"green\")\n",
    "#     figure(); imshow(distanceTransformImg[patchImageIdxs[0]:patchImageIdxs[2], patchImageIdxs[1]:patchImageIdxs[3]])\n",
    "#     plot(cameraBoundingVolumeVertices[boundingVolumeVertexDrawIndices, 0]-patchImageIdxs[1],\n",
    "#          cameraBoundingVolumeVertices[boundingVolumeVertexDrawIndices, 1]-patchImageIdxs[0], c=\"green\")\n",
    "    \n",
    "    patchesImageIdxs[:, currentFrameIdx] = patchImageIdxs\n",
    "    distanceTransforms[:, :, currentFrameIdx] = distanceTransformImg\n",
    "    print(currentFrameIdx)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1087"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usedFramesKeys[220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efd38eefa50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# figure(); imshow(currentFrameImg, interpolation='none'); plot(cameraBoundingVolumeVertices[boundingVolumeVertexDrawIndices, 0], cameraBoundingVolumeVertices[boundingVolumeVertexDrawIndices, 1])\n",
    "figure(); imshow(distanceTransformImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508075688772"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.sqrt(np.sum((np.zeros(3)-np.ones(1))**2.0))\n",
    "np.sqrt(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def backgroundCut3DShapePrior(bgImage, images, shapePriors, extraPriors, shapePriorWeight=0.5, k1=30.0/255.0, k2=60.0/255.0, K=5.0/255.0, sigmaZ=10.0/255.0) :\n",
    "    \"\"\" Given a stack of temporally sequential images, a static background bgImage and a stack of shapePriors under the form of unsigned distance functions,\n",
    "    it computes temporally consistent fg/bg segmentation enforcing cuts to be close to shape boundaries by adding extra pairwise term as seen in Equation (1) in\n",
    "    Interactive GC segmentation [Freedman and Zhang. CVPR2005]\n",
    "    \n",
    "    based on BGcut [Sun et al. ECCV2006] with modifications seen in Video Synposis [Pritch et al. PAMI2008]\"\"\"\n",
    "    ## as seen in Sun's background cut (with the mods made in pritch synopsis paper)\n",
    "#     figure(\"bgImage\"); imshow(bgImage); figure(\"image\"); imshow(image)\n",
    "    \n",
    "    if np.all(bgImage.shape != images.shape[:-1]) :\n",
    "        raise Exception(\"The two specified patches have different shape so graph cannot be built\")\n",
    "    \n",
    "    height, width, channels, numImages = images.shape\n",
    "    maxCost = 10000000.0#np.sys.float_info.max\n",
    "    \n",
    "    bgPixels = bgImage.reshape([height*width, channels], order='F')/255.0\n",
    "    \n",
    "    s = time.time()\n",
    "    ## build graph\n",
    "    numLabels = 2\n",
    "    gm = opengm.gm(np.ones(height*width*numImages,dtype=opengm.label_type)*numLabels)\n",
    "    \n",
    "    for i in np.arange(numImages) :\n",
    "        imagePixels1 = images[:, :, :, i].reshape([height*width, channels], order='F')/255.0\n",
    "        shapePrior1 = shapePriors[:, :, i].reshape([height*width], order='F')\n",
    "        extraPrior1 = extraPriors[:, :, i].reshape([height*width], order='F')\n",
    "\n",
    "\n",
    "        ############################### COMPUTE UNARIES ###############################\n",
    "        unaries = np.zeros((height*width,numLabels))\n",
    "\n",
    "        dr = np.sqrt(np.sum((imagePixels1-bgPixels)**2.0, axis=-1))\n",
    "        ## shapePriors has max = 1.0 while absolute difference between pixels is sqrt(3) so scale it by that much\n",
    "        ## small value in dr means BG while small value in shapePriors means FG so take 1-shapePriors\n",
    "#         dr = (1.0-shapePriorWeight)*dr + shapePriorWeight*np.sqrt(3)*(1.0-shapePriors.reshape([height*width], order=\"F\"))\n",
    "        figure(\"dr\"); imshow(dr.reshape([height, width], order=\"F\"))\n",
    "\n",
    "        unaries[dr<=k1, 1] = (k1-dr)[dr<=k1]\n",
    "        unaries[dr>k2, 0] = dr[dr>k2]#maxCost\n",
    "        unaries[np.all(np.array([dr>k1, k2>dr]), axis=0), 0] = (dr-k1)[np.all(np.array([dr>k1, k2>dr]), axis=0)]\n",
    "        figure(\"drFGThresh\"); imshow(np.copy((dr<=k1).reshape([height, width], order=\"F\")))\n",
    "        figure(\"bgUnaryBefore\"); imshow(np.copy(unaries.reshape([height, width, numLabels], order=\"F\")[:, :, 0]))\n",
    "        figure(\"fgUnaryBefore\"); imshow(np.copy(unaries.reshape([height, width, numLabels], order=\"F\")[:, :, 1]))\n",
    "        \n",
    "        alpha = 0.75\n",
    "        unaries[:, 0] = unaries[:, 0]*alpha+(1.0-extraPrior1)*(1.0-alpha)\n",
    "        unaries[:, 1] = unaries[:, 1]*alpha+extraPrior1*(1.0-alpha)\n",
    "        \n",
    "        \n",
    "#         unaries[:, 0] = 0.0\n",
    "#         unaries[:, 1] = 0.0\n",
    "#         tmp = np.zeros([height, width])\n",
    "#         tmp[118:140, 130:190] = maxCost\n",
    "#         unaries[:, 0] = tmp.reshape([width*height], order='F')\n",
    "#         tmp = np.ones([height, width])*maxCost\n",
    "#         tmp[20:height-20, 20:width-20] = 0.0\n",
    "#         unaries[:, 1] = tmp.reshape([width*height], order='F')\n",
    "#         unaries[127*250+50, 1] = maxCost\n",
    "#         unaries[127*250, 0] = maxCost\n",
    "#         unaries *= (1.0-shapePriorWeight)\n",
    "        \n",
    "#         unaries += shapePriorWeight*np.concatenate([1.0-shapePriors[:, :, i].reshape([height*width], order=\"F\")[:, np.newaxis],\n",
    "#                                                     shapePriors[:, :, i].reshape([height*width], order=\"F\")[:, np.newaxis]], axis=-1)\n",
    "\n",
    "        # add functions\n",
    "        fids = gm.addFunctions(unaries)\n",
    "        # add first order factors\n",
    "        gm.addFactors(fids, np.arange(i*height*width, (i+1)*height*width, 1))\n",
    "        figure(\"bgUnaries\"); imshow(unaries.reshape([height, width, numLabels], order=\"F\")[:, :, 0])\n",
    "        figure(\"fgUnaries\"); imshow(unaries.reshape([height, width, numLabels], order=\"F\")[:, :, 1])\n",
    "\n",
    "\n",
    "        ############################### COMPUTE PAIRWISE ###############################\n",
    "        for j in np.arange(2) :\n",
    "            if j == 0 or (i > 0 and j ==1) :\n",
    "                pairIndices = getGridPairIndices(width, height)\n",
    "\n",
    "                imagePixels2 = imagePixels1\n",
    "                shapePrior2 = shapePrior1\n",
    "                if i > 0 and j == 1 :\n",
    "                    ## in this case compute pairwise between temporally neighbouring pixels in current image and previous one\n",
    "                    pairIndices = np.concatenate([[np.arange(width*height)], [np.arange(width*height)]]).T\n",
    "                    imagePixels2 = images[:, :, :, i-1].reshape([height*width, channels], order='F')/255.0\n",
    "                    shapePrior2 = shapePriors[:, :, i-1].reshape([height*width], order='F')\n",
    "\n",
    "                pairwise = np.zeros(len(pairIndices))\n",
    "\n",
    "                ### not sure why I use pairIndices[:, 0] on the second image and pairIndices[:, 1] on the first image and not the other way around but I don't think it makes any difference\n",
    "                zrs = np.max([np.sqrt(np.sum((imagePixels2[pairIndices[:, 0], :]-bgPixels[pairIndices[:, 0], :])**2.0, axis=-1)),\n",
    "                              np.sqrt(np.sum((imagePixels1[pairIndices[:, 1], :]-bgPixels[pairIndices[:, 1], :])**2.0, axis=-1))], axis=0)\n",
    "\n",
    "                imPixelsDiff = np.sqrt(np.sum((imagePixels2[pairIndices[:, 0], :]-imagePixels1[pairIndices[:, 1], :])**2.0, axis=-1))\n",
    "                bgPixelsDiff = np.sqrt(np.sum((bgPixels[pairIndices[:, 0], :]-bgPixels[pairIndices[:, 1], :])**2.0, axis=-1))\n",
    "                drs = imPixelsDiff/(1+((bgPixelsDiff/K)**2.0)*np.exp(-(zrs**2)/sigmaZ))\n",
    "                beta = 2.0/np.mean(imPixelsDiff)\n",
    "                pairwise = (1.0-shapePriorWeight)*np.exp(-beta*drs)\n",
    "\n",
    "                ## visualize\n",
    "                if False :\n",
    "                    contrastMap = np.zeros(len(bgPixels))\n",
    "                    for pairIndicesIdx in np.arange((width-1)*(height-1)*2) :\n",
    "                        contrastMap[pairIndices[pairIndicesIdx, 0]] += drs[pairIndicesIdx]\n",
    "                    figure(); imshow(np.reshape(np.sqrt(np.copy(contrastMap)), [height, width], 'F'))\n",
    "\n",
    "                ## not sure it makes sense to compute the shape prior thing for the temporal neighbours but let's see\n",
    "                if j == 0 : #or True :\n",
    "#                     print(\"DOING THA SHIT\", i, j)\n",
    "                    ## here I get the distance transform at p and at q and divide by two rather than getting the distance transform at (p+q)/2 which is how they write it down in the paper\n",
    "                    ## not sure it's the same thing but i think it is\n",
    "                    shapePairwise = (shapePrior2[pairIndices[:, 0]]+shapePrior1[pairIndices[:, 1]])/2.0\n",
    "                    \n",
    "                    print(i, j, np.min(pairwise), np.max(pairwise), np.min(shapePairwise), np.max(shapePairwise))\n",
    "#                     print(len(pairIndices), np.max(shapePriorWeight*shapePairwise), np.max(pairwise))\n",
    "                    pairwise += (shapePriorWeight*shapePairwise)\n",
    "    \n",
    "                    \n",
    "#                     pairwise = shapePairwise\n",
    "#                     print(pairwise.shape)\n",
    "                    \n",
    "                    contrastMap = np.zeros(len(bgPixels))\n",
    "                    for pairIndicesIdx in np.arange((width-1)*(height-1)*2) :\n",
    "                        contrastMap[pairIndices[pairIndicesIdx, 0]] += pairwise[pairIndicesIdx]\n",
    "                    figure(\"pairwise\"); imshow(np.reshape(np.sqrt(np.copy(contrastMap)), [height, width], 'F'))\n",
    "                \n",
    "                ## add functions\n",
    "                fids = gm.addFunctions(np.array([[0.0, 1.0],[1.0, 0.0]]).reshape((1, 2, 2)).repeat(len(pairwise), axis=0)*\n",
    "                                       pairwise.reshape((len(pairwise), 1, 1)).repeat(2, axis=1).repeat(2, axis=2))\n",
    "\n",
    "                if j == 0 :\n",
    "                    ## in this case compute pairwise between neighbouring pixels in the current image\n",
    "                    # add second order factors\n",
    "                    gm.addFactors(fids, pairIndices+(i*height*width))\n",
    "                elif i > 0 and j == 1 :\n",
    "                    ## in this case compute pairwise between temporally neighbouring pixels in current image and previous one\n",
    "                    # add second order factors\n",
    "                    pairIndices[:, 0] += ((i-1)*height*width)\n",
    "                    pairIndices[:, 1] += (i*height*width)\n",
    "                    gm.addFactors(fids, pairIndices)\n",
    "    \n",
    "#     print(gm)\n",
    "    \n",
    "    \n",
    "    graphCut = opengm.inference.GraphCut(gm=gm)\n",
    "    graphCut.infer()    \n",
    "    labels = np.array(graphCut.arg(), dtype=int)\n",
    "    print(\"COST\", gm.evaluate(labels))\n",
    "    reshapedLabels = np.reshape(np.copy(labels), [height, width, numImages], 'F')\n",
    "    figure(\"reshapedLabels\"); imshow(reshapedLabels[:, :, 0])\n",
    "    \n",
    "    return reshapedLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1.38571583559e-22 0.5 0.0 0.99624\n",
      "COST 732.21588805\n",
      "100 0 [100] 0.631079912186\n",
      "535\n"
     ]
    }
   ],
   "source": [
    "# figure(); imshow(distanceTransforms[patchesImageIdxs[0, 0]:patchesImageIdxs[2, 0],\n",
    "#                                     patchesImageIdxs[1, 0]:patchesImageIdxs[3, 0], 0])\n",
    "close(\"all\")\n",
    "numNeighboringFrames = 1\n",
    "shapePriorWeight = 0.5\n",
    "currentFgMasks = np.zeros([bgImage.shape[0], bgImage.shape[1], len(trajectoryPoints)], dtype=np.uint8)\n",
    "for currentFrameIdx in [100] :# np.arange(len(trajectoryPoints)) :\n",
    "    startTime = time.time()\n",
    "    imgsIdxs = np.arange(np.max([0, currentFrameIdx-numNeighboringFrames/2]),\n",
    "                         np.min([len(trajectoryPoints), currentFrameIdx+1+numNeighboringFrames/2]))\n",
    "    currentFrameImgsIdx = int(np.argwhere(imgsIdxs == currentFrameIdx).flatten())\n",
    "    \n",
    "    commonPatchImageIdxs = np.concatenate([np.min(patchesImageIdxs[0:2, imgsIdxs], axis=1),\n",
    "                                           np.max(patchesImageIdxs[2:, imgsIdxs], axis=1)])\n",
    "    \n",
    "    ims = np.zeros([commonPatchImageIdxs[2]-commonPatchImageIdxs[0],\n",
    "                    commonPatchImageIdxs[3]-commonPatchImageIdxs[1], bgImage.shape[2], len(imgsIdxs)], dtype=np.uint8)\n",
    "    ## load the images\n",
    "    for idx, i in enumerate(imgsIdxs) :\n",
    "        ims[:, :, :, idx] = np.array(Image.open(dataLoc+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[i]+1)))[commonPatchImageIdxs[0]:commonPatchImageIdxs[2],\n",
    "                                                                                                                   commonPatchImageIdxs[1]:commonPatchImageIdxs[3], :]\n",
    "    distanceTransformsPatches = distanceTransforms[commonPatchImageIdxs[0]:commonPatchImageIdxs[2],\n",
    "                                                   commonPatchImageIdxs[1]:commonPatchImageIdxs[3], imgsIdxs]#.flatten()\n",
    "#     distanceTransformsPatches[distanceTransformsPatches >= 15] = 15\n",
    "#     distanceTransformsPatches = distanceTransformsPatches**5\n",
    "#     distanceTransformsPatches = distanceTransformsPatches.reshape(np.array(ims.shape)[[0, 1, 3]])\n",
    "    distanceTransformsPatches /= np.max(distanceTransformsPatches.reshape([np.prod(distanceTransformsPatches.shape[0:2]), len(imgsIdxs)]), axis=0)[np.newaxis, np.newaxis, :]\n",
    "#     figure(); imshow(distanceTransformsPatches[:, :, 0])\n",
    "\n",
    "    convexFillImg = np.ones_like(distanceTransformImg)\n",
    "    cv2.fillConvexPoly(convexFillImg, cameraConvexHull.astype(np.int32), (0))\n",
    "    currentFgMasks[commonPatchImageIdxs[0]:commonPatchImageIdxs[2],\n",
    "                   commonPatchImageIdxs[1]:commonPatchImageIdxs[3],\n",
    "                   currentFrameIdx] = backgroundCut3DShapePrior(bgImage[commonPatchImageIdxs[0]:commonPatchImageIdxs[2], commonPatchImageIdxs[1]:commonPatchImageIdxs[3], :],\n",
    "                                                                ims, distanceTransformsPatches, convexFillImg[commonPatchImageIdxs[0]:commonPatchImageIdxs[2],\n",
    "                                                                                                              commonPatchImageIdxs[1]:commonPatchImageIdxs[3]][:, :, np.newaxis],\n",
    "                                                                shapePriorWeight=shapePriorWeight, k1=60.0/255.0, k2=110.0/255.0)[:, :, currentFrameImgsIdx]\n",
    "    \n",
    "    print(currentFrameIdx, currentFrameImgsIdx, imgsIdxs, time.time()-startTime)\n",
    "#     ## compute mask\n",
    "#     fgMasks[:, :, maskIdx] = backgroundCut3D(bgImage, ims)[:, :, numNeighboringFrames/2]\n",
    "#     fgMasks[:, :, maskIdx] = cv2.morphologyEx(fgMasks[:, :, maskIdx].astype(float), cv2.MORPH_CLOSE, np.ones((5,5),np.uint8), iterations=2)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# figure(); imshow(distanceTransforms[:, :, 220])\n",
    "figure(\"currentMask\"); imshow(currentFgMasks[:, :, 100])\n",
    "# figure(\"originalImage\"); imshow(np.array(Image.open(dataLoc+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[220]+1))))\n",
    "# figure(\"shapePrior\"); imshow(distanceTransformsPatches[:, :, 0])\n",
    "print(trajectoryPointsFrameIds[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ported from matlab https://uk.mathworks.com/matlabcentral/fileexchange/58843-scalable-lucas-kanade-optical-flow?focused=6751540&tab=function\n",
    "def makeColorwheel() :\n",
    "    RY = 15\n",
    "    YG = 6\n",
    "    GC = 4\n",
    "    CB = 11\n",
    "    BM = 13\n",
    "    MR = 6\n",
    "\n",
    "    ncols = RY + YG + GC + CB + BM + MR\n",
    "\n",
    "    colorwheel = np.zeros([ncols, 3]) # r g b\n",
    "\n",
    "    col = -1;\n",
    "    #RY\n",
    "    colorwheel[:RY, 0] = 255.0\n",
    "    colorwheel[:RY, 1] = np.floor(255.0*np.arange(RY)/float(RY))\n",
    "    col = col+RY\n",
    "\n",
    "    #YG\n",
    "    colorwheel[col+np.arange(1, YG+1), 0] = 255.0 - np.floor(255.0*np.arange(YG)/float(YG))\n",
    "    colorwheel[col+np.arange(1, YG+1), 1] = 255.0\n",
    "    col = col+YG\n",
    "\n",
    "    #GC\n",
    "    colorwheel[col+np.arange(1, GC+1), 1] = 255.0\n",
    "    colorwheel[col+np.arange(1, GC+1), 2] = np.floor(255.0*np.arange(GC)/float(GC))\n",
    "    col = col+GC\n",
    "\n",
    "    #CB\n",
    "    colorwheel[col+np.arange(1, CB+1), 1] = 255.0 - np.floor(255.0*np.arange(CB)/float(CB))\n",
    "    colorwheel[col+np.arange(1, CB+1), 2] = 255.0\n",
    "    col = col+CB\n",
    "\n",
    "    #BM\n",
    "    colorwheel[col+np.arange(1, BM+1), 2] = 255.0\n",
    "    colorwheel[col+np.arange(1, BM+1), 0] = np.floor(255.0*np.arange(BM)/float(BM))\n",
    "    col = col+BM\n",
    "\n",
    "    #MR\n",
    "    colorwheel[col+np.arange(1, MR+1), 2] = 255.0 - np.floor(255.0*np.arange(MR)/float(MR))\n",
    "    colorwheel[col+np.arange(1, MR+1), 0] = 255.0\n",
    "    \n",
    "    return colorwheel\n",
    "\n",
    "def computeColor(us, vs, maxFlow=-1, doReturnMaxRadius = False, verbose=False) :\n",
    "    nanIdx = np.any(np.vstack([np.isnan(us)[np.newaxis, :], np.isnan(vs)[np.newaxis, :]]), axis=0)\n",
    "    u = np.copy(us)\n",
    "    v = np.copy(vs)\n",
    "    u[nanIdx] = 0\n",
    "    v[nanIdx] = 0\n",
    "                        \n",
    "    \n",
    "    ## normalize u an v first to max radius\n",
    "    maxu = np.max(u)\n",
    "    maxv = np.max(v)\n",
    "    minu = np.min(u)\n",
    "    minv = np.min(v)\n",
    "    rad = np.sqrt(u**2+v**2)\n",
    "    if maxFlow > 0 :\n",
    "        maxrad = maxFlow\n",
    "    else :\n",
    "        maxrad = np.max(rad)\n",
    "\n",
    "    if verbose :\n",
    "        print(\"max flow: {0:04f} flow range: u = {1:03f} .. {2:03f}; v = {3:03f} .. {4:03f}\".format(maxrad, minu, maxu, minv, maxv))\n",
    "\n",
    "    u /= maxrad\n",
    "    v /= maxrad\n",
    "    \n",
    "    colorwheel = makeColorwheel()\n",
    "    ncols = len(colorwheel)\n",
    "\n",
    "    rad = np.sqrt(u**2+v**2)         \n",
    "\n",
    "    a = np.arctan2(-v, -u)/np.pi\n",
    "\n",
    "    fk = (a+1) /2 * (ncols-1)  # -1~1 maped to 0~ncols-1\n",
    "\n",
    "    k0 = np.floor(fk).astype(int)          # 0, 1, ..., ncols-1\n",
    "\n",
    "    k1 = k0+1\n",
    "    k1[k1==ncols] = 1;\n",
    "\n",
    "    f = fk - k0;\n",
    "\n",
    "    colors = np.zeros([len(u), colorwheel.shape[1]])\n",
    "    for i in np.arange(colorwheel.shape[1]) :\n",
    "        tmp = colorwheel[:, i]\n",
    "        col0 = tmp[k0]/255.0\n",
    "        col1 = tmp[k1]/255.0\n",
    "        col = (1-f)*col0 + f*col1\n",
    "\n",
    "        idx = rad <= 1\n",
    "        col[idx] = 1-rad[idx]*(1-col[idx])    # increase saturation with radius\n",
    "\n",
    "        col[~idx] = col[~idx]*0.75             # out of range\n",
    "\n",
    "        colors[:, i] = np.uint8(floor(255*col*(1-nanIdx.astype(int))))\n",
    "        \n",
    "    if doReturnMaxRadius :\n",
    "        return colors, maxrad\n",
    "    else :\n",
    "        return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trajectory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-eec4c37f749a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mcurrentFrameIdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m220\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mpreviousWorldBvVertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreviousObjectT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaceFilmedObjectBoundingVolume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrajectory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworldTrajectoryPoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrentFrameIdx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworldTrajectoryDirections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrentFrameIdx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilmedObject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m previousCameraBvVertices = distortPoints(worldToScreenSpace(viewMat, projectionMat, previousWorldBvVertices, filmedScene.medianImage.shape[1], filmedScene.medianImage.shape[0]),\n\u001b[1;32m     50\u001b[0m                                          filmedScene.distortionCoeff, filmedScene.cameraIntrinsics, filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trajectory' is not defined"
     ]
    }
   ],
   "source": [
    "def placeFilmedObjectBoundingVolume(positionWorld, directionWorld, filmedObject) :\n",
    "    \"\"\"places bounding volume of filmedObject at positionWorld facing directionWorld based on filmedObject.forwardDir which needs to be a column vector in homogeneous coordinates\"\"\"\n",
    "    objPos, objFDir = getWorldSpacePosAndNorm(np.eye(4), filmedObject.forwardDir)\n",
    "    adjustAngle = np.arccos(np.clip(np.dot(objFDir, directionWorld), -1, 1))\n",
    "    if np.abs(adjustAngle) > 1e-06 :\n",
    "    #             print(adjustAngle, np.cross(directionWorld, objFDir))\n",
    "        adjustAxis = np.cross(directionWorld, objFDir)\n",
    "        adjustAxis /= np.linalg.norm(adjustAxis)\n",
    "        filmedObjectTransform = quaternionTo4x4Rotation(angleAxisToQuaternion(adjustAngle, adjustAxis))\n",
    "    filmedObjectTransform[:-1, -1] = positionWorld\n",
    "\n",
    "    worldFootprintVertices = np.dot(filmedObjectTransform, np.hstack([filmedObject.footprintVertices[[0, 1, 4, 5], :],\n",
    "                                                                      np.ones([4, 1])]).T)\n",
    "    worldFootprintVertices = worldFootprintVertices[:-1, :]/worldFootprintVertices[-1, :]\n",
    "    worldFootprintVertices = worldFootprintVertices.T\n",
    "    worldBoundingVolumeVertices = np.vstack([worldFootprintVertices,\n",
    "                                             worldFootprintVertices+np.array([[0, 0, 1.0]])*filmedObject.filmedObjectData[DICT_OBJECT_HEIGHT]])\n",
    "    \n",
    "    return worldBoundingVolumeVertices, filmedObjectTransform\n",
    "\n",
    "def fastPoissonDiskSample(minCoords, maxCoords, r, k=30) :\n",
    "    if len(minCoords) != 2 or len(maxCoords) != 2 :\n",
    "        raise Exception(\"Poission Sampling only for 2D coords\")\n",
    "    \n",
    "    print(minCoords, maxCoords, r)\n",
    "        \n",
    "    samples = minCoords[np.newaxis, :]+np.random.rand(1, len(minCoords))*(maxCoords-minCoords)[np.newaxis, :]\n",
    "    activeList = [0]\n",
    "    while len(activeList) > 0 :\n",
    "        idx = np.random.choice(np.arange(len(activeList)))\n",
    "        xi = samples[activeList[idx], :]\n",
    "        del activeList[idx]\n",
    "        \n",
    "        ## find points between r and 2r as shown here http://stackoverflow.com/a/35066007\n",
    "        ## not sure this correctly samples the 2D annulus but oh well\n",
    "        rs = np.sqrt(np.random.rand(k)*(r**2))+r\n",
    "        thetas = np.random.random(k)*2.0*np.pi\n",
    "        newSamples = xi[np.newaxis, :] + np.vstack([[rs*np.cos(thetas)], [rs*np.sin(thetas)]]).T\n",
    "        for sample in newSamples :\n",
    "            if np.all(sample <= maxCoords) and np.all(sample >= minCoords) :\n",
    "                if np.all(np.linalg.norm(samples-sample[np.newaxis, :], axis=1) >= r) :\n",
    "                    samples = np.vstack([samples, sample])\n",
    "                    activeList.append(len(samples)-1)\n",
    "    \n",
    "    return samples\n",
    "\n",
    "currentFrameIdx = 220\n",
    "previousWorldBvVertices, previousObjectT = placeFilmedObjectBoundingVolume(trajectory.worldTrajectoryPoints[currentFrameIdx-1, :], trajectory.worldTrajectoryDirections[currentFrameIdx-1, :], filmedObject)\n",
    "previousCameraBvVertices = distortPoints(worldToScreenSpace(viewMat, projectionMat, previousWorldBvVertices, filmedScene.medianImage.shape[1], filmedScene.medianImage.shape[0]),\n",
    "                                         filmedScene.distortionCoeff, filmedScene.cameraIntrinsics, filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS])\n",
    "currentWorldBvVertices, currentObjectT = placeFilmedObjectBoundingVolume(trajectory.worldTrajectoryPoints[currentFrameIdx, :], trajectory.worldTrajectoryDirections[currentFrameIdx, :], filmedObject)\n",
    "currentCameraBvVertices = distortPoints(worldToScreenSpace(viewMat, projectionMat, currentWorldBvVertices, filmedScene.medianImage.shape[1], filmedScene.medianImage.shape[0]),\n",
    "                                        filmedScene.distortionCoeff, filmedScene.cameraIntrinsics, filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS])\n",
    "\n",
    "## FIGURE OUT HOW THE BOUNDING VOLUME HAS MOVED\n",
    "currentImage = np.array(Image.open(dataLoc+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[currentFrameIdx]+1)))\n",
    "figure(); imshow(currentImage)\n",
    "visibleFacesIndices = np.array([[7, 6, 5, 4], [3, 2, 6, 7], [2, 1, 5, 6]]) ## these indices are CCW and should be found automatically somehow checking the face visibility\n",
    "plot(currentCameraBvVertices[visibleFacesIndices.T.flatten(), 0], currentCameraBvVertices[visibleFacesIndices.T.flatten(), 1])\n",
    "plot(previousCameraBvVertices[visibleFacesIndices.T.flatten(), 0], previousCameraBvVertices[visibleFacesIndices.T.flatten(), 1])\n",
    "\n",
    "previousCameraShapeSamples = np.empty([0, 2])\n",
    "currentCameraShapeSamples = np.empty([0, 2])\n",
    "for faceIndices in visibleFacesIndices :\n",
    "    currentObjectBvVertices = np.dot(np.linalg.inv(currentObjectT), np.vstack([currentWorldBvVertices[faceIndices, :].T, np.ones([1, len(faceIndices)])]))\n",
    "    currentObjectBvVertices = currentObjectBvVertices.T[:, :-1]/currentObjectBvVertices.T[:, -1][:, np.newaxis]\n",
    "    ## find on which axis, each vertex has the same value and then disregard that axis when computing the sampling which can only work in 2D\n",
    "    ## (I could do this by projecting the vertices on the plane represented by the normal of the face but CBA and this should do it)\n",
    "    dimensionsToUse = ~np.all(np.abs(currentObjectBvVertices - currentObjectBvVertices[0, :][np.newaxis, :]) < 1e-10, axis=0)\n",
    "    \n",
    "    minVertexCoords = np.min(currentObjectBvVertices[:, dimensionsToUse], axis=0)\n",
    "    maxVertexCoords = np.max(currentObjectBvVertices[:, dimensionsToUse], axis=0)\n",
    "    faceSamples2D = fastPoissonDiskSample(minVertexCoords, maxVertexCoords, np.min(maxVertexCoords-minVertexCoords)*0.05)\n",
    "    objectFaceSamples = np.zeros([len(faceSamples2D), 3])\n",
    "    objectFaceSamples[:, dimensionsToUse] = faceSamples2D\n",
    "    objectFaceSamples[:, ~dimensionsToUse] = currentObjectBvVertices[0, ~dimensionsToUse]\n",
    "    \n",
    "    previousWorldFaceSamples = np.dot(previousObjectT, np.vstack([objectFaceSamples.T, np.ones([1, len(objectFaceSamples)])]))\n",
    "    previousWorldFaceSamples = previousWorldFaceSamples.T[:, :-1]/previousWorldFaceSamples.T[:, -1][:, np.newaxis]\n",
    "    previousCameraFaceSamples = distortPoints(worldToScreenSpace(viewMat, projectionMat, previousWorldFaceSamples, filmedScene.medianImage.shape[1], filmedScene.medianImage.shape[0]),\n",
    "                                              filmedScene.distortionCoeff, filmedScene.cameraIntrinsics, filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS])\n",
    "    previousCameraShapeSamples = np.vstack([previousCameraShapeSamples, previousCameraFaceSamples])\n",
    "    \n",
    "    currentWorldFaceSamples = np.dot(currentObjectT, np.vstack([objectFaceSamples.T, np.ones([1, len(objectFaceSamples)])]))\n",
    "    currentWorldFaceSamples = currentWorldFaceSamples.T[:, :-1]/currentWorldFaceSamples.T[:, -1][:, np.newaxis]\n",
    "    currentCameraFaceSamples = distortPoints(worldToScreenSpace(viewMat, projectionMat, currentWorldFaceSamples, filmedScene.medianImage.shape[1], filmedScene.medianImage.shape[0]),\n",
    "                                             filmedScene.distortionCoeff, filmedScene.cameraIntrinsics, filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS])\n",
    "    currentCameraShapeSamples = np.vstack([currentCameraShapeSamples, currentCameraFaceSamples])\n",
    "    \n",
    "\n",
    "colors = np.zeros([len(previousCameraShapeSamples), 4])\n",
    "colors[:, -1] = 1.0\n",
    "samplesMoveDirs = currentCameraShapeSamples-previousCameraShapeSamples\n",
    "# colors[:, 0:2] = (samplesMoveDirs-np.min(samplesMoveDirs))/(np.max(samplesMoveDirs)-np.min(samplesMoveDirs))\n",
    "colors[:, :-1] = computeColor(samplesMoveDirs[:, 0], samplesMoveDirs[:, 1])/255.0\n",
    "scatter(currentCameraShapeSamples[:, 0], currentCameraShapeSamples[:, 1], color=colors)\n",
    "idxToShow = -35\n",
    "plot([currentCameraShapeSamples[idxToShow, 0], previousCameraShapeSamples[idxToShow, 0]], [currentCameraShapeSamples[idxToShow, 1], previousCameraShapeSamples[idxToShow, 1]])\n",
    "xlim([0, currentImage.shape[1]])\n",
    "ylim([currentImage.shape[0], 0])\n",
    "\n",
    "## show previous image\n",
    "previousImage = np.array(Image.open(dataLoc+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[currentFrameIdx-1]+1)))\n",
    "figure(); imshow(previousImage)\n",
    "## show current image\n",
    "figure(); imshow(currentImage)\n",
    "## get pixels from previous image and move them and compare to currentImage\n",
    "modifiedImage = np.ones_like(currentImage)*255\n",
    "figure(); imshow(modifiedImage)\n",
    "for samplePoint, moveDir in zip(currentCameraShapeSamples, samplesMoveDirs) :\n",
    "    previousColor = cv2.getRectSubPix(previousImage, (1, 1), tuple(samplePoint-moveDir)).flatten().astype(float)/255.0\n",
    "    currentColor = cv2.getRectSubPix(currentImage, (1, 1), tuple(samplePoint)).flatten().astype(float)/255.0\n",
    "    colorDiff = np.sqrt(np.sum((previousColor-currentColor)**2))/np.sqrt(3)\n",
    "#     colorDiff = np.log(colorDiff+1)\n",
    "    scatter(samplePoint[0], samplePoint[1], color=cm.jet(colorDiff))\n",
    "xlim([0, modifiedImage.shape[1]])\n",
    "ylim([modifiedImage.shape[0], 0])\n",
    "\n",
    "denseFlow = cv2.calcOpticalFlowFarneback(cv2.cvtColor(previousImage,cv2.COLOR_RGB2GRAY), cv2.cvtColor(currentImage,cv2.COLOR_RGB2GRAY), 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "denseFlowImg = computeColor(denseFlow[:, :, 0].flatten(), denseFlow[:, :, 1].flatten(), 7.0).reshape([denseFlow.shape[0], denseFlow.shape[1], 3]).astype(np.uint8)\n",
    "figure(); imshow(denseFlowImg)\n",
    "currentPointsFromFlow = cv2.calcOpticalFlowPyrLK(previousImage, currentImage, previousCameraShapeSamples.astype(np.float32))[0]\n",
    "colors = np.zeros([len(previousCameraShapeSamples), 4])\n",
    "colors[:, -1] = 1.0\n",
    "flowMoveDir = currentPointsFromFlow-previousCameraShapeSamples\n",
    "colors[:, :-1] = computeColor(flowMoveDir[:, 0], flowMoveDir[:, 1], 7.0)/255.0\n",
    "figure(); imshow(currentImage)\n",
    "# scatter(currentPointsFromFlow[:, 0], currentPointsFromFlow[:, 1], color=colors)\n",
    "scatter(currentCameraShapeSamples[:, 0], currentCameraShapeSamples[:, 1], color=colors)\n",
    "xlim([0, currentImage.shape[1]])\n",
    "ylim([currentImage.shape[0], 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max flow: 7.006701 flow range: u = -6.165441 .. -2.308926; v = 1.291844 .. 4.788867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(312, 0)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = np.zeros([len(previousCameraShapeSamples), 4])\n",
    "colors[:, -1] = 1.0\n",
    "samplesMoveDirs = currentCameraShapeSamples-previousCameraShapeSamples\n",
    "# colors[:, 0:2] = (samplesMoveDirs-np.min(samplesMoveDirs))/(np.max(samplesMoveDirs)-np.min(samplesMoveDirs))\n",
    "colors[:, :-1] = computeColor(samplesMoveDirs[:, 0], samplesMoveDirs[:, 1])/255.0\n",
    "imshow(np.zeros_like(currentImage))\n",
    "scatter(currentCameraShapeSamples[:, 0], currentCameraShapeSamples[:, 1], color=colors)\n",
    "idxToShow = -35\n",
    "plot([currentCameraShapeSamples[idxToShow, 0], previousCameraShapeSamples[idxToShow, 0]], [currentCameraShapeSamples[idxToShow, 1], previousCameraShapeSamples[idxToShow, 1]])\n",
    "xlim([0, currentImage.shape[1]])\n",
    "ylim([currentImage.shape[0], 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max flow: 7.006701 flow range: u = -6.165441 .. -2.308926; v = 1.291844 .. 4.788867\n"
     ]
    }
   ],
   "source": [
    "tmpDict = dict([(tuple(np.round(shapeSample)), sampleMoveDir) for shapeSample, sampleMoveDir in zip(currentCameraShapeSamples, samplesMoveDirs)])\n",
    "sampleKeys = tmpDict.keys()\n",
    "tmp = np.zeros_like(currentImage)\n",
    "colors = computeColor(np.array([tmpDict[sampleKey] for sampleKey in sampleKeys])[:, 0], np.array([tmpDict[sampleKey] for sampleKey in sampleKeys])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f924eeabb50>"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[np.array(sampleKeys).astype(int)[:, 1], np.array(sampleKeys).astype(int)[:, 0]] = colors\n",
    "figure(); imshow(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flowForRemap = cv2.calcOpticalFlowFarneback(cv2.cvtColor(currentImage,cv2.COLOR_RGB2GRAY), cv2.cvtColor(previousImage,cv2.COLOR_RGB2GRAY), 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "flowMap = np.zeros(flowForRemap.shape, dtype=np.float32)\n",
    "for y in np.arange(flowMap.shape[0]) :\n",
    "    for x in np.arange(flowMap.shape[1]) : \n",
    "        flowMap[y, x] = np.array([x+flowForRemap[y, x, 0], y+flowForRemap[y, x, 1]])\n",
    "tmp = cv2.remap(previousImage, flowMap, None, cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, 0)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modifiedImage = np.ones_like(currentImage)*255\n",
    "figure(); imshow(modifiedImage)\n",
    "for samplePoint, moveDir in zip(currentCameraShapeSamples, samplesMoveDirs) :\n",
    "    previousColor = cv2.getRectSubPix(tmp, (1, 1), tuple(samplePoint)).flatten().astype(float)/255.0\n",
    "    currentColor = cv2.getRectSubPix(currentImage, (1, 1), tuple(samplePoint)).flatten().astype(float)/255.0\n",
    "    colorDiff = np.sqrt(np.sum((previousColor-currentColor)**2))/np.sqrt(3)\n",
    "#     colorDiff = np.log(colorDiff+1)\n",
    "    scatter(samplePoint[0], samplePoint[1], color=cm.jet(colorDiff))\n",
    "xlim([0, modifiedImage.shape[1]])\n",
    "ylim([modifiedImage.shape[0], 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these should be the same (direction through pixel the world origin projects to, direction from camera center to world origin) [-0.59543952  0.78852191 -0.15389923] [-0.59543952  0.78852191 -0.15389923]\n"
     ]
    }
   ],
   "source": [
    "def rayQuadIntersection(quad, rayOrigin, rayDirs) :\n",
    "    ## as seen here http://stackoverflow.com/a/21114992\n",
    "    ## find two vectors on the plane defined by quad and find the plane's normal direction\n",
    "    planeV1 = quad[1, :]-quad[0, :]\n",
    "    planeV2 = quad[3, :]-quad[0, :]\n",
    "    planeNormal = np.cross(planeV1, planeV2)\n",
    "    planeNormal /= np.linalg.norm(planeNormal)\n",
    "    \n",
    "    ## check if plane and rays are parallel\n",
    "    planeRayDots = np.dot(planeNormal[np.newaxis, :], rayDirs.T).flatten()\n",
    "    validRays = abs(planeRayDots) > 1e-10\n",
    "    \n",
    "    if len(np.argwhere(validRays)) == 0 :\n",
    "        return np.empty([0, 3]), validRays\n",
    "    else :\n",
    "        ts = -np.dot(planeNormal, rayOrigin-quad[0, :])/planeRayDots[validRays]\n",
    "        \n",
    "        intersectionPoints = rayOrigin[np.newaxis, :] + (rayDirs[validRays, :]*ts[validRays, np.newaxis])\n",
    "        \n",
    "        ## project intersectionPoints onto planeV1 and planeV2 (usually, projection is done using normalized planeV1 and planeV2 but I'm following above links' instructions and the check for points being\n",
    "        ## inside below only works if I do the projection like this)\n",
    "        pointsDiff = intersectionPoints-quad[0, :][np.newaxis, :]\n",
    "        us = np.dot(pointsDiff, planeV1[:, np.newaxis])\n",
    "        vs = np.dot(pointsDiff, planeV2[:, np.newaxis])\n",
    "        \n",
    "        pointsInsideQuad = np.all(np.hstack([us >= 0, us <= np.dot(planeV1, planeV1), vs >= 0, vs <= np.dot(planeV2, planeV2)]), axis=1)\n",
    "        \n",
    "        validRays[validRays] = pointsInsideQuad\n",
    "        \n",
    "        return intersectionPoints[pointsInsideQuad, :], validRays\n",
    "    \n",
    "def getCameraPixelRays(pixelsCoords, imageSize, viewMat, projectionMat) :\n",
    "    \"\"\"returns rayOrigin (i.e. camera center location) and directions of rays through each pixel coordinate in the Nx2 pixelCoords\"\"\"\n",
    "#     print(pixelsCoords)\n",
    "    clipPixels = (pixelsCoords+0.5)/imageSize.astype(float).reshape([1, 2])*np.array([[2.0, -2.0]]) + np.array([[-1.0, 1.0]])\n",
    "    \n",
    "    cameraPixels = np.dot(np.linalg.inv(projectionMat), np.vstack([clipPixels.T, np.zeros([1, len(pixelsCoords)]), np.ones([1, len(pixelsCoords)])]))\n",
    "    cameraPixels = cameraPixels[:-1, :]/cameraPixels[-1, :]\n",
    "\n",
    "    worldPixels = np.dot(np.linalg.inv(viewMat), np.vstack([cameraPixels, np.ones([1, len(pixelsCoords)])]))\n",
    "    worldPixels = worldPixels[:-1, :]/worldPixels[-1, :]\n",
    "    \n",
    "    rayOrigin = getWorldSpacePosAndNorm(np.linalg.inv(viewMat), posOnly=True) ## == worldCamCenter\n",
    "    \n",
    "    rayDirs = worldPixels.T-rayOrigin[np.newaxis, :]\n",
    "    rayDirs /= np.linalg.norm(rayDirs, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    return rayOrigin, rayDirs\n",
    "\n",
    "rayOrigin, rayDirs = getCameraPixelRays((worldToScreenSpace(viewMat, projectionMat, np.zeros(3), filmedScene.medianImage.shape[1], filmedScene.medianImage.shape[0])-0.5).reshape([1, 2]),\n",
    "                                        np.array(filmedScene.medianImage.shape[0:2])[::-1], viewMat, projectionMat)\n",
    "print(\"these should be the same (direction through pixel the world origin projects to, direction from camera center to world origin)\", rayDirs[0, :], (-rayOrigin)/np.linalg.norm(-rayOrigin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.6576178074\n"
     ]
    }
   ],
   "source": [
    "## figure out the size of the canonical box and make the vertices array\n",
    "currentWorldBvVertices, currentObjectT = placeFilmedObjectBoundingVolume(trajectory.worldTrajectoryPoints[100, :], trajectory.worldTrajectoryDirections[100, :], filmedObject)\n",
    "currentCameraBvVertices = distortPoints(worldToScreenSpace(viewMat, projectionMat, currentWorldBvVertices, filmedScene.medianImage.shape[1], filmedScene.medianImage.shape[0]),\n",
    "                                        filmedScene.distortionCoeff, filmedScene.cameraIntrinsics, filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS])\n",
    "\n",
    "## these indices are CCW for each face quad (the faces are ordered like this (given forwardDir): right, front, left, back, top, bottom)\n",
    "boxFaceIndices = np.array([[7, 4, 0, 3], [2, 6, 7, 3], [1, 5, 6, 2], [4, 5, 1, 0], [6, 5, 4, 7], [0, 1, 2, 3]])\n",
    "colors = [\"r\", \"g\", \"b\", \"y\", \"m\", \"c\"]\n",
    "figure(\"exampleFrame\"); imshow(np.array(Image.open(dataLoc+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[100]+1))))\n",
    "for faceIdx, faceIndices in enumerate(boxFaceIndices) :\n",
    "    plot(currentCameraBvVertices[faceIndices, 0], currentCameraBvVertices[faceIndices, 1], c=colors[faceIdx], linewidth=3)\n",
    "    plot(currentCameraBvVertices[faceIndices[[0, 2]], 0], currentCameraBvVertices[faceIndices[[0, 2]], 1], c=colors[faceIdx])\n",
    "\n",
    "canonicalSpaceMinSize = 200\n",
    "faceToUseIdx = 4\n",
    "faceIndicesToUse = boxFaceIndices[faceToUseIdx, :]\n",
    "## find the index of the face that's closest to [0, 0] (i.e. take one with min norm) and roll the indices so that that is the first one in the sequence of vertices (because the canonical box starts at [0, 0])\n",
    "## not sure this reasoning is the best but it's a way to make sure the way the image is in the canonical space is the right way up\n",
    "faceIndicesToUse = np.roll(faceIndicesToUse, -np.argmin(np.linalg.norm(currentCameraBvVertices[faceIndicesToUse], axis=1)))\n",
    "\n",
    "## build canonical space while ensuring the min size is the same as canonicalSpaceMinSize and the aspect ratio is the same as the face\n",
    "faceSize = np.array([np.linalg.norm(currentWorldBvVertices[faceIndicesToUse[1], :]-currentWorldBvVertices[faceIndicesToUse[2], :]),  # H\n",
    "                     np.linalg.norm(currentWorldBvVertices[faceIndicesToUse[0], :]-currentWorldBvVertices[faceIndicesToUse[1], :])])  # W\n",
    "canonicalSpaceSize = np.array([200, 200], dtype=float) # [W, H]\n",
    "canonicalSpaceSize[np.argmax(faceSize)] *= faceSize[np.argmax(faceSize)]/faceSize[np.argmin(faceSize)]\n",
    "canonicalBox = np.array([[0, 0], [0, canonicalSpaceSize[1]], canonicalSpaceSize, [canonicalSpaceSize[0], 0]], dtype=float)\n",
    "\n",
    "                                                                                                                    ##   0        1       2       3       4        5\n",
    "warpedColorsDir = filmedScene.filmedSceneData[DICT_FILMED_SCENE_BASE_LOC]+os.sep+\"{0}_{1}-face_warpedColors/\".format(filmedObject.filmedObjectData[DICT_FILMED_OBJECT_NAME],\n",
    "                                                                                                                     [\"right\", \"front\", \"left\", \"back\", \"top\", \"bottom\"][faceToUseIdx])\n",
    "if not os.path.isdir(warpedColorsDir) :\n",
    "    os.makedirs(warpedColorsDir)\n",
    "    \n",
    "cvFlowDir = filmedScene.filmedSceneData[DICT_FILMED_SCENE_BASE_LOC]+os.sep+\"{0}_{1}-face_warpedCVFlow/\".format(filmedObject.filmedObjectData[DICT_FILMED_OBJECT_NAME],\n",
    "                                                                                                               [\"right\", \"front\", \"left\", \"back\", \"top\", \"bottom\"][faceToUseIdx])\n",
    "if not os.path.isdir(cvFlowDir) :\n",
    "    os.makedirs(cvFlowDir)\n",
    "    \n",
    "boxFlowDir = filmedScene.filmedSceneData[DICT_FILMED_SCENE_BASE_LOC]+os.sep+\"{0}_{1}-face_warpedBoxFlow/\".format(filmedObject.filmedObjectData[DICT_FILMED_OBJECT_NAME],\n",
    "                                                                                                                 [\"right\", \"front\", \"left\", \"back\", \"top\", \"bottom\"][faceToUseIdx])\n",
    "if not os.path.isdir(boxFlowDir) :\n",
    "    os.makedirs(boxFlowDir)\n",
    "    \n",
    "cvFlowRemapDiffDir = filmedScene.filmedSceneData[DICT_FILMED_SCENE_BASE_LOC]+os.sep+\"{0}_{1}-face_warpedCVFlowRemapDiff/\".format(filmedObject.filmedObjectData[DICT_FILMED_OBJECT_NAME],\n",
    "                                                                                                                                 [\"right\", \"front\", \"left\", \"back\", \"top\", \"bottom\"][faceToUseIdx])\n",
    "if not os.path.isdir(cvFlowRemapDiffDir) :\n",
    "    os.makedirs(cvFlowRemapDiffDir)\n",
    "    \n",
    "boxFlowRemapDiffDir = filmedScene.filmedSceneData[DICT_FILMED_SCENE_BASE_LOC]+os.sep+\"{0}_{1}-face_warpedBoxFlowRemapDiff/\".format(filmedObject.filmedObjectData[DICT_FILMED_OBJECT_NAME],\n",
    "                                                                                                                                  [\"right\", \"front\", \"left\", \"back\", \"top\", \"bottom\"][faceToUseIdx])\n",
    "if not os.path.isdir(boxFlowRemapDiffDir) :\n",
    "    os.makedirs(boxFlowRemapDiffDir)\n",
    "    \n",
    "maxFlowRadius = 10.0\n",
    "\n",
    "doShow = False\n",
    "\n",
    "if doShow :\n",
    "    frameIndicesToProcess = [-16]\n",
    "else :\n",
    "    frameIndicesToProcess = np.arange(1, len(trajectoryPoints))\n",
    "\n",
    "startTime = time.time()\n",
    "for currentFrameIdx in frameIndicesToProcess :\n",
    "    previousImage = np.array(Image.open(dataLoc+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[currentFrameIdx-1]+1))) \n",
    "    currentImage = np.array(Image.open(dataLoc+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[currentFrameIdx]+1)))\n",
    "    \n",
    "    previousWorldBvVertices, previousObjectT = placeFilmedObjectBoundingVolume(trajectory.worldTrajectoryPoints[currentFrameIdx-1, :], trajectory.worldTrajectoryDirections[currentFrameIdx-1, :], filmedObject)\n",
    "    previousCameraBvVertices = distortPoints(worldToScreenSpace(viewMat, projectionMat, previousWorldBvVertices, filmedScene.medianImage.shape[1], filmedScene.medianImage.shape[0]),\n",
    "                                             filmedScene.distortionCoeff, filmedScene.cameraIntrinsics, filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS])\n",
    "    \n",
    "    currentWorldBvVertices, currentObjectT = placeFilmedObjectBoundingVolume(trajectory.worldTrajectoryPoints[currentFrameIdx, :], trajectory.worldTrajectoryDirections[currentFrameIdx, :], filmedObject)\n",
    "    currentCameraBvVertices = distortPoints(worldToScreenSpace(viewMat, projectionMat, currentWorldBvVertices, filmedScene.medianImage.shape[1], filmedScene.medianImage.shape[0]),\n",
    "                                            filmedScene.distortionCoeff, filmedScene.cameraIntrinsics, filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS])\n",
    "\n",
    "    M = cv2.findHomography(currentCameraBvVertices[faceIndicesToUse, :], canonicalBox)[0]\n",
    "    \n",
    "    ######################## WARP COLORS ########################\n",
    "    warpedImage = cv2.warpPerspective(currentImage, M, tuple(np.ceil(canonicalSpaceSize).astype(int)), borderValue=[0, 0, 0, 0])\n",
    "    if doShow :\n",
    "        figure(\"warped colors\"); imshow(warpedImage)\n",
    "    else :\n",
    "        Image.fromarray(warpedImage).save(warpedColorsDir+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[currentFrameIdx]+1))\n",
    "    \n",
    "    \n",
    "    ######################## WARP BOX FLOW ########################\n",
    "    ## find pixels the face rasterizes to\n",
    "    facePixelsImg = np.zeros(currentImage.shape[0:2])\n",
    "    cv2.fillConvexPoly(facePixelsImg, np.round(currentCameraBvVertices[faceIndicesToUse, :]).astype(int), (1))\n",
    "    if doShow :\n",
    "        figure(\"pixels on current face\"); imshow(facePixelsImg); plot(currentCameraBvVertices[faceIndicesToUse[[0, 1, 2, 3, 0]], 0], currentCameraBvVertices[faceIndicesToUse[[0, 1, 2, 3, 0]], 1], c=\"y\")\n",
    "\n",
    "    ## undistort the image space coords as they are in the original image's distorted space\n",
    "    facePixelsCoords = np.argwhere(facePixelsImg==1).astype(float)[:, ::-1]\n",
    "    if len(facePixelsCoords) > 0 :\n",
    "        facePixelsCoords = cv2.undistortPoints(facePixelsCoords.reshape((1, len(facePixelsCoords), 2)), filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS],\n",
    "                                               filmedScene.distortionCoeff, P=filmedScene.cameraIntrinsics)[0, :, :]\n",
    "\n",
    "        ## get rays through raster pixels and find their world location by intersecting these rays with the quad\n",
    "        rayOrigin, rayDirs = getCameraPixelRays(facePixelsCoords, np.array(filmedScene.medianImage.shape[0:2])[::-1], viewMat, projectionMat)\n",
    "        currentWorldFacePoints, _ = rayQuadIntersection(currentWorldBvVertices[faceIndicesToUse, :], rayOrigin, rayDirs)\n",
    "\n",
    "        if len(currentWorldFacePoints) > 0 :\n",
    "            currentCameraFacePoints = distortPoints(worldToScreenSpace(viewMat, projectionMat, currentWorldFacePoints, filmedScene.medianImage.shape[1], filmedScene.medianImage.shape[0]),\n",
    "                                                    filmedScene.distortionCoeff, filmedScene.cameraIntrinsics, filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS])\n",
    "            patchBoundaries = np.vstack([[np.max([np.zeros(2), np.floor(np.min(currentCameraBvVertices, axis=0)-0.1*np.array(currentImage.shape[0:2])[::-1])], axis=0)],\n",
    "                                         [np.min([np.array(currentImage.shape[0:2])[::-1], np.ceil(np.max(currentCameraBvVertices, axis=0)+0.1*np.array(currentImage.shape[0:2])[::-1])], axis=0)]]).astype(int)\n",
    "#             patchBoundaries = np.array([[0, 0], [1280, 720]])\n",
    "            if doShow :\n",
    "                print(patchBoundaries)\n",
    "\n",
    "\n",
    "            previousWorldFacePoints = np.dot(np.dot(previousObjectT, np.linalg.inv(currentObjectT)), np.vstack([currentWorldFacePoints.T, np.ones([1, len(currentWorldFacePoints)])]))\n",
    "            previousWorldFacePoints = previousWorldFacePoints.T[:, :-1]/previousWorldFacePoints.T[:, -1][:, np.newaxis]\n",
    "            previousCameraFacePoints = distortPoints(worldToScreenSpace(viewMat, projectionMat, previousWorldFacePoints, filmedScene.medianImage.shape[1], filmedScene.medianImage.shape[0]),\n",
    "                                                     filmedScene.distortionCoeff, filmedScene.cameraIntrinsics, filmedScene.filmedSceneData[DICT_CAMERA_INTRINSICS])\n",
    "\n",
    "            boxFlowImage = np.ones_like(currentImage)*255\n",
    "            samplesMoveDirs = currentCameraFacePoints-previousCameraFacePoints\n",
    "            ## need to substract 0.5 because getCameraPixelRays gets the ray through the center of the pixel so when I project these points back into image space they are at the center\n",
    "            \n",
    "            boxFlowImage[np.round(currentCameraFacePoints[:, 1]-0.5).astype(int),\n",
    "                         np.round(currentCameraFacePoints[:, 0]-0.5).astype(int), :], maxRadius = computeColor(samplesMoveDirs[:, 0], samplesMoveDirs[:, 1], doReturnMaxRadius=True)#, maxFlow=maxFlowRadius)\n",
    "            if doShow :\n",
    "                figure(\"box flow\"); imshow(boxFlowImage)\n",
    "            \n",
    "            warpedImage = cv2.warpPerspective(boxFlowImage, M, tuple(np.ceil(canonicalSpaceSize).astype(int)), borderValue=[0, 0, 0, 0])\n",
    "            \n",
    "            if doShow :\n",
    "                figure(\"warped box flow\"); imshow(warpedImage)\n",
    "            else :\n",
    "                Image.fromarray(warpedImage).save(boxFlowDir+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[currentFrameIdx]+1))\n",
    "            \n",
    "            \n",
    "            ######################## WARP REAL DENSE FLOW ########################\n",
    "            denseFlow = cv2.calcOpticalFlowFarneback(cv2.cvtColor(previousImage[patchBoundaries[0, 1]:patchBoundaries[1, 1], patchBoundaries[0, 0]:patchBoundaries[1, 0], :],cv2.COLOR_RGB2GRAY),\n",
    "                                                     cv2.cvtColor(currentImage[patchBoundaries[0, 1]:patchBoundaries[1, 1], patchBoundaries[0, 0]:patchBoundaries[1, 0], :],cv2.COLOR_RGB2GRAY), 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            denseFlowImage = np.ones_like(currentImage)*255\n",
    "            denseFlowImage[patchBoundaries[0, 1]:patchBoundaries[1, 1], patchBoundaries[0, 0]:patchBoundaries[1, 0], :] = computeColor(denseFlow[:, :, 0].flatten(), denseFlow[:, :, 1].flatten(),\n",
    "                                                                                                                                       maxFlow=maxRadius).reshape([denseFlow.shape[0],\n",
    "                                                                                                                                                                   denseFlow.shape[1], 3]).astype(np.uint8)\n",
    "            warpedImage = cv2.warpPerspective(denseFlowImage, M, tuple(np.ceil(canonicalSpaceSize).astype(int)), borderValue=[0, 0, 0, 0])\n",
    "            \n",
    "            if doShow :\n",
    "                figure(\"dense flow\"); imshow(denseFlowImage)\n",
    "                figure(\"warped dense flow\"); imshow(warpedImage)\n",
    "            else :\n",
    "                Image.fromarray(warpedImage).save(cvFlowDir+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[currentFrameIdx]+1))\n",
    "            \n",
    "            \n",
    "            ######################## WARP DIFF BETWEEN REMAPPED PREVIOUS IMAGE AND CURRENT USING REAL DENSE FLOW ########################\n",
    "#             flowForRemap = cv2.calcOpticalFlowFarneback(cv2.cvtColor(currentImage[patchBoundaries[0, 1]:patchBoundaries[1, 1], patchBoundaries[0, 0]:patchBoundaries[1, 0], :],cv2.COLOR_RGB2GRAY),\n",
    "#                                                         cv2.cvtColor(previousImage[patchBoundaries[0, 1]:patchBoundaries[1, 1], patchBoundaries[0, 0]:patchBoundaries[1, 0], :],cv2.COLOR_RGB2GRAY), \n",
    "#                                                         0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "            flowMap = np.zeros([currentImage.shape[0], currentImage.shape[1], 2], dtype=np.float32)\n",
    "            xs, ys = np.meshgrid(np.arange(patchBoundaries[0, 0], patchBoundaries[1, 0]), np.arange(patchBoundaries[0, 1], patchBoundaries[1, 1]))\n",
    "            flowMap[ys.flatten(), xs.flatten(), :] = np.hstack([(xs.flatten()-denseFlow[:, :, 0].flatten())[:, np.newaxis],\n",
    "                                                                (ys.flatten()-denseFlow[:, :, 1].flatten())[:, np.newaxis]])\n",
    "            remappedPreviousDiffToCurrent = np.sqrt(np.sum((cv2.remap(previousImage, flowMap, None, cv2.INTER_AREA)/255.0-currentImage/255.0)**2, axis=-1))\n",
    "            \n",
    "            warpedImage = cv2.warpPerspective(cm.jet(remappedPreviousDiffToCurrent/np.sqrt(3), bytes=True)[:, :, 0:3], M, tuple(np.ceil(canonicalSpaceSize).astype(int)), borderValue=[0, 0, 0, 0])\n",
    "            if doShow :\n",
    "                figure(\"diff between current and previous remapped using real dense flow\"); imshow(cm.jet(remappedPreviousDiffToCurrent/np.sqrt(3))[:, :, 0:3])\n",
    "                figure(); imshow(warpedImage)\n",
    "                figure(); imshow(cv2.remap(previousImage, flowMap, None, cv2.INTER_AREA))\n",
    "            else :\n",
    "                Image.fromarray(warpedImage).save(cvFlowRemapDiffDir+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[currentFrameIdx]+1))\n",
    "            \n",
    "            \n",
    "            ######################## WARP DIFF BETWEEN REMAPPED PREVIOUS IMAGE AND CURRENT USING BOX FLOW ########################\n",
    "            flowMap = np.zeros([currentImage.shape[0], currentImage.shape[1], 2], dtype=np.float32)\n",
    "            xs = np.round(currentCameraFacePoints[:, 0]-0.5).astype(int).flatten()\n",
    "            ys = np.round(currentCameraFacePoints[:, 1]-0.5).astype(int).flatten()\n",
    "            flowMap[ys, xs, :] = np.hstack([(xs-samplesMoveDirs[:, 0])[:, np.newaxis], (ys-samplesMoveDirs[:, 1])[:, np.newaxis]])\n",
    "            remappedPreviousDiffToCurrent = np.sqrt(np.sum((cv2.remap(previousImage, flowMap, None, cv2.INTER_AREA)/255.0-currentImage/255.0)**2, axis=-1))\n",
    "            \n",
    "            warpedImage = cv2.warpPerspective(cm.jet(remappedPreviousDiffToCurrent/np.sqrt(3), bytes=True)[:, :, 0:3], M, tuple(np.ceil(canonicalSpaceSize).astype(int)), borderValue=[0, 0, 0, 0])\n",
    "            if doShow :\n",
    "                figure(\"diff between current and previous remapped using box flow\"); imshow(cm.jet(remappedPreviousDiffToCurrent/np.sqrt(3))[:, :, 0:3])\n",
    "                figure(\"warped diff between current and previous remapped using box flow\"); imshow(warpedImage)\n",
    "                figure(\"previous remapped using box flow\"); imshow(cv2.remap(previousImage, flowMap, None, cv2.INTER_AREA))\n",
    "            else :\n",
    "                Image.fromarray(warpedImage).save(boxFlowRemapDiffDir+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[currentFrameIdx]+1))\n",
    "                \n",
    "print(time.time()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227, 439, 2)\n"
     ]
    }
   ],
   "source": [
    "# figure(); imshow(previousImage)\n",
    "close(\"all\")\n",
    "print(flowForRemap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseDir = \"/home/ilisescu/PhD/data/havana_short/green_car1_top-face_warpedCVFlowRemapDiff/\"\n",
    "frameLocs = np.sort(glob.glob(baseDir+\"frame-*.png\"))\n",
    "\n",
    "allFrames = np.zeros(np.concatenate([np.array(Image.open(frameLocs[0])).shape, [len(frameLocs)]]), np.uint8)\n",
    "for frameIdx, frameLoc in enumerate(frameLocs) :\n",
    "    allFrames[:, :, :, frameIdx] = np.array(Image.open(frameLoc))\n",
    "    \n",
    "Image.fromarray(np.median(allFrames, axis=-1).astype(np.uint8)).save(baseDir+\"median.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7ad028db50>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure(); imshow(np.median(allFrames, axis=-1).astype(np.uint8))\n",
    "# print(np.median(allFrames, axis=-1).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/ilisescu/PhD/data/havana_short/green_car1_top-face_warpedCVFlow/frame-00241.png'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvFlowDir+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[-36]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ims = np.zeros([bgImage.shape[0], bgImage.shape[1], bgImage.shape[2], len(imgsIdxs)], dtype=np.uint8)\n",
    "# for idx, i in enumerate(imgsIdxs) :\n",
    "#     ims[:, :, :, idx] = np.array(Image.open(dataLoc+\"frame-{0:05}.png\".format(trajectoryPointsFrameIds[i]+1)))\n",
    "# tmp = backgroundCut3D(bgImage, ims)[:, :, currentFrameImgsIdx]\n",
    "# figure(); imshow(tmp)\n",
    "# figure()\n",
    "# img = None\n",
    "# for i in xrange(currentFgMasks.shape[-1]):\n",
    "#     if img is None:\n",
    "#         img = mpl.pylab.imshow(currentFgMasks[:, :, i])\n",
    "#     else:\n",
    "#         img.set_data(currentFgMasks[:, :, i])\n",
    "#     mpl.pylab.pause(0.01)\n",
    "#     mpl.pylab.draw()\n",
    "\n",
    "extraInfo = \"\" #\"_tighterbox\"\n",
    "saveLoc = dataLoc+\"segmentation{2}_{0}neighs_shapePrior_{1}\".format(numNeighboringFrames, shapePriorWeight, extraInfo)+os.sep\n",
    "if not os.path.isdir(saveLoc):\n",
    "    os.makedirs(saveLoc)\n",
    "figure()\n",
    "colors = cm.jet(np.arange(4)/3.0)\n",
    "# create a patch (proxy artist) for every color \n",
    "patches = [ matplotlib.patches.Patch(color=tuple(colors[i]), label=[\"old FG\", \"BG\", \"old+new FG\", \"new FG\"][i]) for i in range(4) ]\n",
    "plt.legend(handles=patches, bbox_to_anchor=(0, 1), loc=2, borderaxespad=0.)\n",
    "img = None\n",
    "for i in xrange(currentFgMasks.shape[-1]):\n",
    "    if i+4 < fgMasks.shape[-1] :\n",
    "        imToShow = currentFgMasks[:, :, i]*2.0-fgMasks[:, :, i]#+4] the + 4 was for blue_car1 for which I had 4 extra frames at the beginning that i had segemnted before\n",
    "        if img is None:\n",
    "            img = mpl.pylab.imshow(imToShow, interpolation='none')\n",
    "        else:\n",
    "            img.set_data(imToShow)\n",
    "        mpl.pylab.pause(0.01)\n",
    "        mpl.pylab.draw()\n",
    "        savefig(saveLoc + 'figure-{0:05}.png'.format(trajectoryPointsFrameIds[i]+1), bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efd042fa110>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imToShow = currentFgMasks[:, :, 12]*2.0-fgMasks[:, :, 12]#+4] the + 4 was for blue_car1 for which I had 4 extra frames at the beginning that i had segemnted before\n",
    "figure(figsize=(8, 5), dpi=200); \n",
    "imshow(imToShow, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc8c77a2810>"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure(); imshow(ims[:, :, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efd0440c090>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure(); imshow(currentFgMasks[:, :, 12])\n",
    "figure(); imshow(fgMasks[:, :, 12])#+4] the + 4 was for blue_car1 for which I had 4 extra frames at the beginning that i had segemnted before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc8cc088d90>"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure(); imshow(currentFgMasks[:, :, currentFrameIdx])\n",
    "# figure(); imshow(fgMasks[:, :, currentFrameIdx+4])\n",
    "# figure(); imshow(distanceTransforms[commonPatchImageIdxs[0]:commonPatchImageIdxs[2], commonPatchImageIdxs[1]:commonPatchImageIdxs[3], imgsIdxs[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29172, 2)\n"
     ]
    }
   ],
   "source": [
    "figure()\n",
    "# xs, ys = np.meshgrid(np.arange(x0-0.5, x1+0.5+0.01, 0.01), np.arange(y0-0.5, y1+0.5+0.01, 0.01))\n",
    "# gridPoints = np.hstack([xs.flatten()[:, np.newaxis], ys.flatten()[:, np.newaxis]])\n",
    "# valuesAtGrid = getInterpolatedValuesAtPoints(gridPoints, alignedFootprintsAllPoints, pointsVals, numNeighs)\n",
    "scatter(gridPoints[:, 0], gridPoints[:, 1], c=cm.jet(valuesAtGrid/np.max(valuesAtGrid), alpha=1), edgecolors='none')\n",
    "print(gridPoints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff31e9d8850>"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distancesToAllPoints = np.sqrt(ssd2(sampleOBB(currentOBB, numSubdivs), alignedFootprintsAllPoints))\n",
    "medianValue = np.median(alignedFootprintsAllPoints, axis=0)\n",
    "thresh = np.median(np.sqrt(np.sum((alignedFootprintsAllPoints-medianValue)**2, axis=1))) ## median absolute deviation\n",
    "thresh = np.median(pointsSubdivisionLength)\n",
    "pointsWithinThresh = np.any(np.vstack([d <= thresh for d in distancesToAllPoints]), axis=0)\n",
    "scatter(alignedFootprintsAllPoints[pointsWithinThresh, 0], alignedFootprintsAllPoints[pointsWithinThresh, 1], color=\"yellow\")\n",
    "# scatter(sampleOBB(currentOBB, numSubdivs)[:, 0], sampleOBB(currentOBB, numSubdivs)[:, 1], color=\"magenta\")\n",
    "# print(distancesToAllPoints.shape)\n",
    "# print(np.median(distancesToAllPoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff321dbad50>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure(); scatter(alignedFootprintsAllPoints[:, 0], alignedFootprintsAllPoints[:, 1], c=cm.jet(np.log(1+pointsVals)/np.max(np.log(1+pointsVals)), alpha=1),\n",
    "                  marker=\"o\", facecolors='none', s=60, edgecolors=[0, 0, 0, 0.2])\n",
    "scatter(alignedFootprintsAllPoints[isLocalMax, 0], alignedFootprintsAllPoints[isLocalMax, 1], c=\"cyan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff31d9319d0>"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "scatter(alignedFootprintsAllPoints[:, 0], alignedFootprintsAllPoints[:, 1], c=cm.jet(densitiesAtFootprintPoints/np.max(densitiesAtFootprintPoints), alpha=1),\n",
    "        marker=\"o\", facecolors='none', s=60, edgecolors=[0, 0, 0, 0.2])\n",
    "figure()\n",
    "scatter(alignedFootprintsAllPoints[:, 0], alignedFootprintsAllPoints[:, 1], c=cm.jet(accumulatedDistsSumsOverDensities/np.max(accumulatedDistsSumsOverDensities), alpha=1),\n",
    "        marker=\"o\", facecolors='none', s=60, edgecolors=[0, 0, 0, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [1 2]\n",
      " [2 3]\n",
      " [3 0]]\n",
      "-number of variables :4\n",
      "-number of function(type-0)4\n",
      "-number of function(type-1)0\n",
      "-number of function(type-2)0\n",
      "-number of function(type-3)0\n",
      "-number of function(type-4)0\n",
      "-number of function(type-5)0\n",
      "-number of function(type-6)0\n",
      "-number of function(type-7)0\n",
      "-number of factors :4\n",
      "-max. factor order :1\n"
     ]
    }
   ],
   "source": [
    "## trying a dynamic programming based fitting of a footprint box\n",
    "\n",
    "## the unary is based on allDistsSumsOverDensities, interpolated based on nearest neighbours\n",
    "## the pairwise makes sure that the box stays a box (i.e. cross product between ((i-1)-i)x((i+1)-i) is positive and is a right angle, assuming I order the vertices of the ox clockwise)\n",
    "## I discretize the directions in which each vertex can move and compute the unary by moving the vertex in each direction by a certain stepSize (can fix it for now but can also set a decreasing one, or smth else(2nd deriv?))\n",
    "\n",
    "x0, y0, x1, y1 = np.min(alignedFootprintsAllPoints[:, 0]), np.min(alignedFootprintsAllPoints[:, 1]), np.max(alignedFootprintsAllPoints[:, 0]), np.max(alignedFootprintsAllPoints[:, 1])\n",
    "stepSize = np.sqrt((x1-x0)**2+(y1-y0)**2)*0.1\n",
    "numDirections = 16\n",
    "numNeighs = 4\n",
    "\n",
    "displacementVecs = []\n",
    "for angle in np.arange(0, 2*np.pi, np.pi*2/numDirections) :\n",
    "    displacementVecs.append(np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(angle, np.array([0.0, 0.0, 1.0])))[:2, :2], np.array([1.0, 0.0])))\n",
    "displacementVecs = np.array(displacementVecs)\n",
    "displacementVecs = displacementVecs/np.linalg.norm(displacementVecs, axis=1)[:, np.newaxis]\n",
    "\n",
    "totalUnaryCost = allDistsSumsOverDensities/np.sum(allDistsSumsOverDensities)\n",
    "totalUnaryCost = np.exp(-totalUnaryCost/0.001)\n",
    "\n",
    "currentFootprintBox = np.array([[x0, y0], [x0, y1], [x1, y1], [x1, y0]])\n",
    "for iterNum in np.arange(1) :\n",
    "    maxCost = 10000000.0#np.sys.float_info.max\n",
    "    \n",
    "    s = time.time()\n",
    "    ## build graph\n",
    "    numLabels = numDirections\n",
    "    numNodes = len(currentFootprintBox)\n",
    "    gm = opengm.gm(np.ones(numNodes,dtype=opengm.label_type)*numLabels)\n",
    "    \n",
    "    \n",
    "    ############################### COMPUTE UNARIES ###############################\n",
    "    unaries = np.zeros((numNodes,numLabels))\n",
    "    \n",
    "    for nodeIdx in np.arange(numNodes) :\n",
    "        displacedPoints = currentFootprintBox[nodeIdx, :]+displacementVecs*stepSize\n",
    "        distancesToAllPoints = ssd2(displacedPoints, alignedFootprintsAllPoints)\n",
    "        closestNeighs = np.argsort(distancesToAllPoints, axis=1)[:, :numNeighs]\n",
    "        \n",
    "        for labelIdx in np.arange(numLabels) :\n",
    "            unaries[nodeIdx, labelIdx] = nnInterp(displacedPoints[labelIdx, :], alignedFootprintsAllPoints[closestNeighs[labelIdx, :], :], totalUnaryCost[closestNeighs[labelIdx, :]])\n",
    "        \n",
    "    # add functions\n",
    "    fids = gm.addFunctions(unaries)\n",
    "    # add first order factors\n",
    "    gm.addFactors(fids, np.arange(0, numNodes, 1))\n",
    "    \n",
    "    \n",
    "    ############################### COMPUTE PAIRWISE ###############################\n",
    "    pairIndices = np.vstack([[np.arange(numNodes)], [np.mod(np.arange(1, numNodes+1), numNodes)]]).T\n",
    "    print(pairIndices)\n",
    "    ###################################### I DON'T KNOW IF I CAN DO WHAT I WAS PLANNING HERE -- SEE JOURNAL 10/02/17 ######################################\n",
    "#     pairIndices = getGridPairIndices(width, height)\n",
    "    \n",
    "#     pairwise = np.zeros(len(pairIndices))\n",
    "    \n",
    "#     zrs = np.max([np.sqrt(np.sum((imagePixels[pairIndices[:, 0], :]-bgPixels[pairIndices[:, 0], :])**2.0, axis=-1)),\n",
    "#                   np.sqrt(np.sum((imagePixels[pairIndices[:, 1], :]-bgPixels[pairIndices[:, 1], :])**2.0, axis=-1))], axis=0)\n",
    "    \n",
    "#     imPixelsDiff = np.sqrt(np.sum((imagePixels[pairIndices[:, 0], :]-imagePixels[pairIndices[:, 1], :])**2.0, axis=-1))\n",
    "#     bgPixelsDiff = np.sqrt(np.sum((bgPixels[pairIndices[:, 0], :]-bgPixels[pairIndices[:, 1], :])**2.0, axis=-1))\n",
    "#     drs = imPixelsDiff/(1+((bgPixelsDiff/K)**2.0)*np.exp(-(zrs**2)/sigmaZ))\n",
    "#     beta = 2.0/np.mean(imPixelsDiff)\n",
    "#     pairwise = np.exp(-beta*drs)\n",
    "    \n",
    "#     ## visualize\n",
    "#     if False :\n",
    "#         contrastMap = np.zeros(len(bgPixels))\n",
    "#         for i in np.arange((width-1)*(height-1)*2) :\n",
    "#             contrastMap[pairIndices[i, 0]] += drs[i]\n",
    "#         figure(); imshow(np.reshape(np.sqrt(np.copy(contrastMap)), [height, width], 'F'))\n",
    "    \n",
    "#     # add functions\n",
    "#     fids = gm.addFunctions(np.array([[0.0, 1.0],[1.0, 0.0]]).reshape((1, 2, 2)).repeat(len(pairwise), axis=0)*\n",
    "#                            pairwise.reshape((len(pairwise), 1, 1)).repeat(2, axis=1).repeat(2, axis=2))\n",
    "    \n",
    "#     # add second order factors\n",
    "#     gm.addFactors(fids, pairIndices)\n",
    "    \n",
    "    print(gm)\n",
    "    \n",
    "    \n",
    "#     dynProg = opengm.inference.DynamicProgramming(gm=gm)\n",
    "#     dynProg.infer()    \n",
    "#     labels = np.array(dynProg.arg(), dtype=int)\n",
    "#     reshapedLabels = np.reshape(np.copy(labels), [height, width], 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff3230e02d0>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure();\n",
    "# scatter(alignedFootprintsAllPoints[:, 0], alignedFootprintsAllPoints[:, 1], c=cm.jet(footprintPointsAllDistsSum/np.max(footprintPointsAllDistsSum), alpha=1))\n",
    "# scatter(alignedFootprintsAllPoints[:, 0], alignedFootprintsAllPoints[:, 1], c=cm.jet(footprintPointsNumCloseNeighs/np.max(footprintPointsNumCloseNeighs), alpha=1))\n",
    "scatter(alignedFootprintsAllPoints[:, 0], alignedFootprintsAllPoints[:, 1], c=cm.jet(np.log(allDistsSumsOverDensities)/np.max(np.log(allDistsSumsOverDensities)), alpha=1))\n",
    "# gca().add_artist(pyplot.Circle(tuple(alignedFootprintsAllPoints[np.argmax(footprintPointsNumCloseNeighs), :]), thresh, color='r'))\n",
    "plot(footprintPointsBBox[[0, 1, 2, 3, 0], 0], footprintPointsBBox[[0, 1, 2, 3, 0], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7cf793e390>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatter(np.mean(alignedFootprintsAllPoints, axis=0)[0], np.mean(alignedFootprintsAllPoints, axis=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n"
     ]
    }
   ],
   "source": [
    "## get manual footprint bbox just to test and see how this all looks\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.scatter(alignedFootprintsAllPoints[:, 0], alignedFootprintsAllPoints[:, 1], color=\"green\")\n",
    "# xlim([-1, 1])\n",
    "# ylim([-5, -7])\n",
    "\n",
    "# # ax.imshow(medianImage)\n",
    "\n",
    "# clickedPoints = np.empty([0, 2])\n",
    "\n",
    "# def onclick(event):\n",
    "# #     print('button=%d, x=%d, y=%d, xdata=%f, ydata=%f' %\n",
    "# #           (event.button, event.x, event.y, event.xdata, event.ydata))\n",
    "#     global clickedPoints\n",
    "#     if event.xdata is not None and event.ydata is not None :\n",
    "#         clickedPoints = np.concatenate([clickedPoints, np.array([[event.xdata, event.ydata]])])\n",
    "#         cla()\n",
    "#         gca().scatter(alignedFootprintsAllPoints[:, 0], alignedFootprintsAllPoints[:, 1], color=\"green\")\n",
    "#         xlim([-1, 1])\n",
    "#         ylim([-5, -7])\n",
    "#         gca().plot(clickedPoints[:, 0], clickedPoints[:, 1])\n",
    "#         show()\n",
    "#         print(clickedPoints); sys.stdout.flush()\n",
    "\n",
    "# cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "## box of footprint for last frame\n",
    "manualFootprintBox = np.array([[-0.18951613, -5.96354167, 0.0],\n",
    "                               [ 0.11693548, -5.94270833, 0.0],\n",
    "                               [ 0.06451613, -5.34375   , 0.0],\n",
    "                               [-0.25806452, -5.36643836, 0.0]])\n",
    "longEdgeLength = np.linalg.norm(manualFootprintBBox[1, :]-manualFootprintBBox[2, :])\n",
    "boxCenter = line2lineIntersection(np.concatenate(manualFootprintBBox[[0, 2], :-1]), np.concatenate(manualFootprintBBox[[1, 3], :-1]))\n",
    "trajectory = []\n",
    "for i in np.arange(len(TsToLast)) :\n",
    "    transformedBoxCenter = np.dot(np.linalg.inv(TsToLast[i]), np.concatenate([boxCenter, [1]])[:, np.newaxis])\n",
    "    transformedBoxCenter = transformedBoxCenter[:-1, :]/transformedBoxCenter[-1, :]\n",
    "    trajectory.append(transformedBoxCenter.flatten())\n",
    "trajectory.append(boxCenter)\n",
    "trajectory = np.array(trajectory)\n",
    "directions = trajectory[1:, :]-trajectory[:-1, :]\n",
    "directions = (directions.T/np.linalg.norm(directions, axis=1)).T\n",
    "directions = np.vstack([directions, directions[-1:, :]])\n",
    "directionsAngles = (np.arcsin(np.cross(directions, np.array([[1.0, 0.0]]), axis=1))+np.pi/2)/np.pi\n",
    "directionsAngles = np.concatenate([directionsAngles, directionsAngles[-1:]])\n",
    "# figure(); scatter(trajectory[:, 0], trajectory[:, 1], c=cm.jet(directionsAngles, alpha=1))\n",
    "\n",
    "locSaveVis = \"/media/ilisescu/Data1/PhD/data/havana/3dLoppingVis/\"\n",
    "if not os.path.exists(locSaveVis) :\n",
    "    os.makedirs(locSaveVis)\n",
    "\n",
    "maxLabel = np.max(masksLabels)\n",
    "## remember to use the camera intrinsics after undistortion as the world footprints are defined in that frame of reference\n",
    "worldToCameraT = np.dot(cameraIntrinsics, filmedSceneData[DICT_CAMERA_EXTRINSICS][:-1, [0, 1, 3]])\n",
    "for frameIdx in np.arange(numNeighboringFrames/2, len(frameLocs)-numNeighboringFrames/2)[240:] :\n",
    "    frameIm = np.array(Image.open(frameLocs[frameIdx]))    \n",
    "    \n",
    "    footprintBoxIm = np.zeros([int(cameraIntrinsics[1, -1]*2), int(cameraIntrinsics[0, -1]*2), 4], frameIm.dtype)\n",
    "    for blobId in np.sort(worldFootprints.keys()) :\n",
    "        if frameIdx-numNeighboringFrames/2 in worldFootprints[blobId] :\n",
    "            tIdx = np.int(np.argwhere(np.sort(worldFootprints[blobId].keys())==frameIdx-numNeighboringFrames/2).flatten())\n",
    "            if tIdx < len(TsToLast) :\n",
    "                worldFootprintBox = np.dot(np.linalg.inv(TsToLast[tIdx]), np.concatenate([manualFootprintBox[:, :-1], np.ones([len(manualFootprintBox), 1], float)], axis=1).T)\n",
    "                worldFootprintBox = (worldFootprintBox[:-1, :]/worldFootprintBox[-1, :]).T\n",
    "                worldFootprintBox = np.concatenate([worldFootprintBox, np.ones([len(worldFootprintBox), 1], float)], axis=1)\n",
    "            else :\n",
    "                worldFootprintBox = np.copy(manualFootprintBox)\n",
    "                \n",
    "            cameraFootprintBox = np.dot(worldToCameraT, np.concatenate([worldFootprintBox[:, :-1], np.ones([len(worldFootprintBox), 1], float)], axis=1).T)\n",
    "            cameraFootprintBox = cameraFootprintBox[:-1, :]/cameraFootprintBox[-1, :]\n",
    "            cv2.polylines(footprintBoxIm, [cameraFootprintBox[:, [0, 1, 2, 3, 0]].T.astype(np.int32)], False, np.array([255, 0, 0, 255]), thickness=3)\n",
    "            \n",
    "            cameraFootprintBoxDirection = np.dot(worldToCameraT, np.concatenate([np.vstack([[trajectory[tIdx, :]], [trajectory[tIdx, :]+directions[tIdx, :]*longEdgeLength/2]]), np.ones([2, 1], float)], axis=1).T)\n",
    "            cameraFootprintBoxDirection = cameraFootprintBoxDirection[:-1, :]/cameraFootprintBoxDirection[-1, :]\n",
    "            cv2.polylines(footprintBoxIm, [cameraFootprintBoxDirection.T.astype(np.int32)], False, np.array(cm.jet(directionsAngles[tIdx], alpha=1, bytes=True), dtype=int), thickness=3)\n",
    "    \n",
    "    undistortedFrameIm = undistortImage(filmedSceneData[DICT_DISTORTION_PARAMETER], filmedSceneData[DICT_DISTORTION_RATIO], frameIm, filmedSceneData[DICT_CAMERA_INTRINSICS])[0]\n",
    "#     figure(); imshow(undistortedFrameIm)\n",
    "#     figure(); imshow(footprintsIm)\n",
    "#     figure(); imshow(footprintBoxIm)\n",
    "#     print(frameIdx)\n",
    "    Image.fromarray(footprintBoxIm).save(locSaveVis+\"footprintBox-frame-{0:05}.png\".format(frameIdx+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.arange(numNeighboringFrames/2, len(frameLocs)-numNeighboringFrames/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n"
     ]
    }
   ],
   "source": [
    "locSaveVis = \"/media/ilisescu/Data1/PhD/data/havana/3dLoppingVis/\"\n",
    "if not os.path.exists(locSaveVis) :\n",
    "    os.makedirs(locSaveVis)\n",
    "\n",
    "maxLabel = np.max(masksLabels)\n",
    "## remember to use the camera intrinsics after undistortion as the world footprints are defined in that frame of reference\n",
    "worldToCameraT = np.dot(cameraIntrinsics, filmedSceneData[DICT_CAMERA_EXTRINSICS][:-1, [0, 1, 3]])\n",
    "for frameIdx in np.arange(numNeighboringFrames/2, len(frameLocs)-numNeighboringFrames/2) :\n",
    "    frameIm = np.array(Image.open(frameLocs[frameIdx]))\n",
    "#     figure(); imshow(frameIm)\n",
    "    \n",
    "    fgMaskIm = mpl.cm.jet(fgMasks[:, :, frameIdx-numNeighboringFrames/2].astype(float), bytes=True)\n",
    "#     figure(); imshow(fgMaskIm)\n",
    "    \n",
    "    maskLabelIm = mpl.cm.Set1(masksLabels[:, :, frameIdx-numNeighboringFrames/2].astype(float)/maxLabel, bytes=True)\n",
    "    maskLabelIm[masksLabels[:, :, frameIdx-numNeighboringFrames/2] == 0, :] = np.array([0, 0, 0, 255])\n",
    "#     figure(); imshow(maskLabelIm)\n",
    "    \n",
    "    bboxesIm = np.zeros_like(maskLabelIm)\n",
    "    presentBlobIds = []\n",
    "    for region in measure.regionprops(masksLabels[:, :, frameIdx-numNeighboringFrames/2]) :\n",
    "        bbox = np.array(region[\"bbox\"])\n",
    "        presentBlobIds.append(region[\"label\"])\n",
    "        cv2.rectangle(bboxesIm, tuple(bbox[0:2][::-1]), tuple(bbox[2:][::-1]-1), np.array([255, 0, 0, 255]), thickness=2)\n",
    "#     figure(); imshow(bboxesIm)\n",
    "    \n",
    "    \n",
    "    maskLabelsContoursIm = np.zeros_like(maskLabelIm)\n",
    "    colorsPerBlob = mpl.cm.Set1(np.array(presentBlobIds, float)/maxLabel, bytes=True)\n",
    "    for colorIdx, blobId in enumerate(presentBlobIds) :\n",
    "        contours, hierarchy = cv2.findContours((masksLabels[:, :, frameIdx-numNeighboringFrames/2] == blobId).astype(np.uint8)*255,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for idx, cnt in enumerate(contours) :\n",
    "            cv2.drawContours(maskLabelsContoursIm, [cnt], 0, tuple(colorsPerBlob[colorIdx, :].astype(int)), 1)\n",
    "    \n",
    "#     figure(); imshow(maskLabelsContoursIm)\n",
    "    \n",
    "    footprintsIm = np.zeros([int(cameraIntrinsics[1, -1]*2), int(cameraIntrinsics[0, -1]*2), 4], maskLabelIm.dtype)\n",
    "    for blobId in np.sort(worldFootprints.keys()) :\n",
    "        if frameIdx-numNeighboringFrames/2 in worldFootprints[blobId] :\n",
    "#             print(worldFootprints[blobId][frameIdx-numNeighboringFrames/2].shape)\n",
    "            cameraFootprint = np.dot(worldToCameraT, np.concatenate([worldFootprints[blobId][frameIdx-numNeighboringFrames/2][:, :-1], \n",
    "                                                                     np.ones([len(worldFootprints[blobId][frameIdx-numNeighboringFrames/2]), 1], float)], axis=1).T)\n",
    "            cameraFootprint = cameraFootprint[:-1, :]/cameraFootprint[-1, :]\n",
    "#             print(cameraFootprint.T.shape, cameraFootprint.dtype)\n",
    "            cv2.polylines(footprintsIm, [cameraFootprint.T.astype(np.int32)], False, np.array([255, 0, 0, 255]))\n",
    "    \n",
    "    undistortedMaskLabelIm = undistortImage(filmedSceneData[DICT_DISTORTION_PARAMETER], filmedSceneData[DICT_DISTORTION_RATIO], maskLabelIm, filmedSceneData[DICT_CAMERA_INTRINSICS])[0]\n",
    "    undistortedFrameIm = undistortImage(filmedSceneData[DICT_DISTORTION_PARAMETER], filmedSceneData[DICT_DISTORTION_RATIO], frameIm, filmedSceneData[DICT_CAMERA_INTRINSICS])[0]\n",
    "#     figure(); imshow(undistortedMaskLabelIm)\n",
    "#     figure(); imshow(undistortedFrameIm)\n",
    "#     figure(); imshow(footprintsIm)\n",
    "    print(frameIdx)\n",
    "    \n",
    "    Image.fromarray(frameIm).save(locSaveVis+\"frame-{0:05}.png\".format(frameIdx+1))\n",
    "    Image.fromarray(fgMaskIm).save(locSaveVis+\"fgMask-frame-{0:05}.png\".format(frameIdx+1))\n",
    "    Image.fromarray(maskLabelIm).save(locSaveVis+\"maskLabel-frame-{0:05}.png\".format(frameIdx+1))\n",
    "    Image.fromarray(bboxesIm).save(locSaveVis+\"bboxes-frame-{0:05}.png\".format(frameIdx+1))\n",
    "    Image.fromarray(maskLabelsContoursIm).save(locSaveVis+\"maskLabelsContours-frame-{0:05}.png\".format(frameIdx+1))\n",
    "    Image.fromarray(undistortedMaskLabelIm).save(locSaveVis+\"undistortedMaskLabel-frame-{0:05}.png\".format(frameIdx+1))\n",
    "    Image.fromarray(undistortedFrameIm).save(locSaveVis+\"undistortedFrame-frame-{0:05}.png\".format(frameIdx+1))\n",
    "    Image.fromarray(footprintsIm).save(locSaveVis+\"footprints-frame-{0:05}.png\".format(frameIdx+1))\n",
    "    \n",
    "    \n",
    "# print(len(frameLocs))\n",
    "# print(fgMasks.shape)\n",
    "# print(numNeighboringFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/backend_bases.py:2437: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented\n",
      "  warnings.warn(str, mplDeprecation)\n"
     ]
    },
    {
     "ename": "TclError",
     "evalue": "can't invoke \"update\" command: application has been destroyed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-454d5ee19dae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mpause\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/backends/backend_tkagg.pyc\u001b[0m in \u001b[0;36mstart_event_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_event_loop_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0mstart_event_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_event_loop_default\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36mstart_event_loop_default\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   2443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_looping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2444\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_looping\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtimestep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2445\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2446\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2447\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/backends/backend_tkagg.pyc\u001b[0m in \u001b[0;36mflush_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflush_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_master\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/lib-tk/Tkinter.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;34m\"\"\"Enter event loop until all pending events have been processed by Tcl.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'update'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_idletasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \"\"\"Enter event loop until all idle callbacks have been called. This\n",
      "\u001b[0;31mTclError\u001b[0m: can't invoke \"update\" command: application has been destroyed"
     ]
    }
   ],
   "source": [
    "# figure(); imshow(fgMasks[:, :, 0:3])\n",
    "labels = measure.label(fgMasks[:, :, :5].astype(bool))\n",
    "\n",
    "figure()\n",
    "img = None\n",
    "for i in xrange(labels.shape[-1]):\n",
    "    if img is None:\n",
    "        img = mpl.pylab.imshow(labels[:, :, i])\n",
    "    else:\n",
    "        img.set_data(labels[:, :, i])\n",
    "    mpl.pylab.pause(1.0)\n",
    "    mpl.pylab.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8a58c09350>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(masksLabels[:, :, -2] == 51)\n",
    "figure(); imshow(masksLabels[:, :, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "figure()\n",
    "img = None\n",
    "for i in xrange(masksLabels.shape[-1]):\n",
    "    if img is None:\n",
    "        img = mpl.pylab.imshow(masksLabels[:, :, i])\n",
    "    else:\n",
    "        img.set_data(masksLabels[:, :, i])\n",
    "    mpl.pylab.pause(1.0)\n",
    "    mpl.pylab.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8a5ab1ce90>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure(); imshow(newLabels)\n",
    "figure(); imshow(masksLabels[265:540, 965:1275, 0])\n",
    "# figure(); imshow(masksLabels[375:540, 1035:1275, 0])\n",
    "figure(); imshow(labels[265:540, 965:1275, 1])\n",
    "# figure(); imshow(labels[375:540, 1035:1275, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filmedSceneLoc = \"/home/ilisescu/PhD/data/havana/filmed_scene-havana.npy\"\n",
    "# filmedSceneData = np.load(filmedSceneLoc).item()\n",
    "# cameraIntrinsics = filmedSceneData[DICT_CAMERA_INTRINSICS]\n",
    "# cameraExtrinsics = filmedSceneData[DICT_CAMERA_EXTRINSICS]\n",
    "\n",
    "# cameraGroundPoints = filmedSceneData[DICT_GROUND_MESH_POINTS]\n",
    "# worldGroundPoints = np.dot(np.linalg.inv(np.dot(cameraIntrinsics, cameraExtrinsics[:-1, [0, 1, 3]])), np.concatenate([cameraGroundPoints, np.ones([len(cameraGroundPoints), 1])], axis=1).T)\n",
    "# worldGroundPoints = np.vstack([worldGroundPoints[:-1, :]/worldGroundPoints[-1, :], np.zeros([1, len(cameraGroundPoints)])]).T\n",
    "# ## now triangulate the points \n",
    "# triangles = np.array(triangulate2DPolygon(worldGroundPoints[:, :-1], False))\n",
    "# gridPoints, validPoints, triangles = getGridPointsInPolygon2D(worldGroundPoints[:, :-1], 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# figure()\n",
    "# scatter(gridPoints[:, 0], gridPoints[:, 1])\n",
    "# scatter(gridPoints[validPoints, 0], gridPoints[validPoints, 1], c=\"r\")\n",
    "# for triangle in triangles :\n",
    "#     plot(triangle[[0, 1, 2, 0], 0], triangle[[0, 1, 2, 0], 1], c=\"m\")\n",
    "# # plot(worldGroundPoints[:, 0], worldGroundPoints[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# while True:\n",
    "#     # Capture frame-by-frame\n",
    "#     ret, frame = video_capture.read()\n",
    "\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     faces = faceCascade.detectMultiScale(\n",
    "#         gray,\n",
    "#         scaleFactor=1.1,\n",
    "#         minNeighbors=5,\n",
    "#         minSize=(30, 30),\n",
    "#         flags=cv2.cv.CV_HAAR_SCALE_IMAGE\n",
    "#     )\n",
    "\n",
    "#     # Draw a rectangle around the faces\n",
    "#     for (x, y, w, h) in faces:\n",
    "#         cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "#     # Display the resulting frame\n",
    "#     cv2.imshow('Video', frame)\n",
    "\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # When everything is done, release the capture\n",
    "# video_capture.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc 0 of 100\n",
      "loc 1 of 100\n",
      "loc 2 of 100\n",
      "loc 3 of 100\n",
      "loc 4 of 100\n",
      "loc 5 of 100\n",
      "loc 6 of 100\n",
      "loc 7 of 100\n",
      "loc 8 of 100\n",
      "loc 9 of 100\n",
      "loc 10 of 100\n",
      "loc 11 of 100\n",
      "loc 12 of 100\n",
      "loc 13 of 100\n",
      "loc 14 of 100\n",
      "loc 15 of 100\n",
      "loc 16 of 100\n",
      "loc 17 of 100\n",
      "loc 18 of 100\n",
      "loc 19 of 100\n",
      "loc 20 of 100\n",
      "loc 21 of 100\n",
      "loc 22 of 100\n",
      "loc 23 of 100\n",
      "loc 24 of 100\n",
      "loc 25 of 100\n",
      "loc 26 of 100\n",
      "loc 27 of 100\n",
      "loc 28 of 100\n",
      "loc 29 of 100\n",
      "loc 30 of 100\n",
      "loc 31 of 100\n",
      "loc 32 of 100\n",
      "loc 33 of 100\n",
      "loc 34 of 100\n",
      "loc 35 of 100\n",
      "loc 36 of 100\n",
      "loc 37 of 100\n",
      "loc 38 of 100\n",
      "loc 39 of 100\n",
      "loc 40 of 100\n",
      "loc 41 of 100\n",
      "loc 42 of 100\n",
      "loc 43 of 100\n",
      "loc 44 of 100\n",
      "loc 45 of 100\n",
      "loc 46 of 100\n",
      "loc 47 of 100\n",
      "loc 48 of 100\n",
      "loc 49 of 100\n",
      "loc 50 of 100\n",
      "loc 51 of 100\n",
      "loc 52 of 100\n",
      "loc 53 of 100\n",
      "loc 54 of 100\n",
      "loc 55 of 100\n",
      "loc 56 of 100\n",
      "loc 57 of 100\n",
      "loc 58 of 100\n",
      "loc 59 of 100\n",
      "loc 60 of 100\n",
      "loc 61 of 100\n",
      "loc 62 of 100\n",
      "loc 63 of 100\n",
      "loc 64 of 100\n",
      "loc 65 of 100\n",
      "loc 66 of 100\n",
      "loc 67 of 100\n",
      "loc 68 of 100\n",
      "loc 69 of 100\n",
      "loc 70 of 100\n",
      "loc 71 of 100\n",
      "loc 72 of 100\n",
      "loc 73 of 100\n",
      "loc 74 of 100\n",
      "loc 75 of 100\n",
      "loc 76 of 100\n",
      "loc 77 of 100\n",
      "loc 78 of 100\n",
      "loc 79 of 100\n",
      "loc 80 of 100\n",
      "loc 81 of 100\n",
      "loc 82 of 100\n",
      "loc 83 of 100\n",
      "loc 84 of 100\n",
      "loc 85 of 100\n",
      "loc 86 of 100\n",
      "loc 87 of 100\n",
      "loc 88 of 100\n",
      "loc 89 of 100\n",
      "loc 90 of 100\n",
      "loc 91 of 100\n",
      "loc 92 of 100\n",
      "loc 93 of 100\n",
      "loc 94 of 100\n",
      "loc 95 of 100\n",
      "loc 96 of 100\n",
      "loc 97 of 100\n",
      "loc 98 of 100\n",
      "loc 99 of 100\n"
     ]
    }
   ],
   "source": [
    "# figure(); imshow(medianImage); xlim([0, medianImage.shape[1]]); ylim([medianImage.shape[0], 0])\n",
    "# plot(trajectoryPoints[:, 0], trajectoryPoints[:, 1], color='r')\n",
    "\n",
    "# T = np.dot(cameraIntrinsics, cameraExtrinsics[:-1, [0, 1, 3]])\n",
    "# inverseT = np.linalg.inv(T)\n",
    "\n",
    "# numAngleDivisions = 16\n",
    "# ## set up object location in 3D world\n",
    "# forwardDir = np.array([[0.1], [0.0], [0.0], [1.0]]) # in object space\n",
    "\n",
    "# ## set up grid \n",
    "# spacing = float(1.0)\n",
    "# gridSpace = np.array([-5, 5], float)\n",
    "# gridPoints = np.mgrid[gridSpace[0]:gridSpace[1]:spacing, gridSpace[0]:gridSpace[1]:spacing]\n",
    "# gridPoints = gridPoints.reshape([2, gridPoints.shape[1]*gridPoints.shape[2]]).T\n",
    "# allDirections = []\n",
    "# allBestMatchScores = []\n",
    "# for i, loc in enumerate(gridPoints) :\n",
    "#     print(\"loc\", i, \"of\", len(gridPoints)); sys.stdout.flush()\n",
    "#     objPos = np.array([loc[0], loc[1], 0.0])\n",
    "#     directions = []\n",
    "#     bestMatchScores = []\n",
    "#     for angle in np.arange(0, np.pi*2, np.pi/numAngleDivisions*2)[0:] :\n",
    "#         ## set up orientation of object in 3D world\n",
    "#     #     print(\"angle:\", angle*180/np.pi)\n",
    "#         modelMat = quaternionTo4x4Rotation(angleAxisToQuaternion(angle, np.array([0.0, 0.0, -1.0])))\n",
    "#         modelMat[:-1, -1] = objPos\n",
    "\n",
    "#         ## find object location and direction in camera space\n",
    "#         objectPosWorld = np.dot(modelMat, np.array([[0.0], [0.0], [0.0], [1.0]])).flatten()\n",
    "#         objectPosWorld = objectPosWorld[:-1]/objectPosWorld[-1]\n",
    "#         objectPosCamera = np.dot(T, np.concatenate([objectPosWorld[:-1], [1.0]])).flatten()\n",
    "#         objectPosCamera = objectPosCamera[:-1]/objectPosCamera[-1]\n",
    "\n",
    "#         objectDirPosWorld = np.dot(modelMat, forwardDir).flatten()\n",
    "#         objectDirPosWorld = objectDirPosWorld[:-1]/objectDirPosWorld[-1]\n",
    "#         objectDirPosCamera = np.dot(T, np.concatenate([objectDirPosWorld[:-1], [1.0]])).flatten()\n",
    "#         objectDirPosCamera = objectDirPosCamera[:-1]/objectDirPosCamera[-1]\n",
    "\n",
    "#         directions.append([objectPosCamera, objectDirPosCamera])\n",
    "\n",
    "#         ## find best matching frame based on object orientation and existing views from captured scene\n",
    "#         camPos = getWorldSpacePosAndNorm(np.linalg.inv(cameraExtrinsics), posOnly=True)\n",
    "#         cameraToObjDir = objPos-camPos\n",
    "#         cameraToObjDir /= np.linalg.norm(cameraToObjDir)\n",
    "#         ## in object space from world space\n",
    "#         cameraPosObjSpace = np.dot(np.linalg.inv(modelMat), np.concatenate([objPos-cameraToObjDir, [1]]).reshape([4, 1])).flatten()\n",
    "#         cameraPosObjSpace = cameraPosObjSpace[:-1]/cameraPosObjSpace[-1]\n",
    "#         cameraToObjDir = np.zeros(3)-cameraPosObjSpace\n",
    "#         cameraToObjDir /= np.linalg.norm(cameraToObjDir)\n",
    "\n",
    "#         directionAngleDistances = np.abs(np.arccos(np.clip(np.dot(cameraToObjDir.reshape([1, 3]), tmpDirections.T), -1.0, 1.0))*180.0/np.pi)\n",
    "#         bestMatchScore = np.min(directionAngleDistances).flatten()\n",
    "#         bestMatchScores.append(bestMatchScore)\n",
    "#     #     print(bestMatchScore)\n",
    "\n",
    "\n",
    "#     ## plot all best matching scores for each direction\n",
    "#     bestMatchScores = np.array(bestMatchScores).flatten()\n",
    "    \n",
    "#     allDirections.append(directions)\n",
    "#     allBestMatchScores.append(bestMatchScores)\n",
    "    \n",
    "# allBestMatchScores = np.array(allBestMatchScores)\n",
    "# allBestMatchScores = allBestMatchScores/np.max(allBestMatchScores)\n",
    "\n",
    "# for directions, bestMatchScores in zip(allDirections, allBestMatchScores) :\n",
    "# #     print(np.dot(inverseT, np.concatenate([directions[0][0], [1.0]])).flatten()/np.dot(inverseT, np.concatenate([directions[0][0], [1.0]])).flatten()[-1])\n",
    "# #     print()\n",
    "#     for direction, bestMatchScore in zip(directions, bestMatchScores) : \n",
    "# #         scatter(direction[0][0], direction[0][1], marker=\"x\", color=\"yellow\")\n",
    "# #         print(cm.jet(bestMatchScore, bytes=True))\n",
    "#         plot([direction[0][0], direction[1][0]], [direction[0][1], direction[1][1]], c=cm.jet(bestMatchScore))\n",
    "# #     print(\"-----------------\")\n",
    "# # close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7f4599837d50>"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fig = figure()\n",
    "# ax = fig.add_subplot(111, aspect='equal', projection='3d')\n",
    "# ax.set_xlim(-3, 3)\n",
    "# ax.set_ylim(-3, 3)\n",
    "# ax.set_zlim(-3, 3)\n",
    "# numLongitudeLines = 5#numAngleDivisions+1\n",
    "# numLatitudeLines = 5#11\n",
    "# u, v = np.mgrid[0:2*np.pi:complex(0, numLongitudeLines), 0:np.pi:complex(0, numLatitudeLines)]\n",
    "# x=np.cos(u)*np.sin(v)\n",
    "# y=np.sin(u)*np.sin(v)\n",
    "# z=np.cos(v)\n",
    "# vertices = np.array([x.T.flatten(), y.T.flatten(), z.T.flatten()]).T\n",
    "# ## remove last vertex on each latitude line as it's a duplicate of the first one\n",
    "# vertices = np.delete(vertices, arange(numLongitudeLines, numLongitudeLines*numLatitudeLines+1, numLongitudeLines)-1, axis=0)\n",
    "# ## remove all vertices in the first and last tituted lines apart from one\n",
    "# vertices = vertices[numLongitudeLines-2:-numLongitudeLines+2]\n",
    "# ## build indices to triangulate the vertices of the sphere\n",
    "# ## triangles for top lid of the sphere\n",
    "# indices = np.array([np.array([0, i, j]) for i, j in zip(np.arange(1, numLongitudeLines),\n",
    "#                                                         np.concatenate([np.arange(2, numLongitudeLines), [1]]))]).flatten()\n",
    "# ## triangles for each row apart from lids\n",
    "# firstRowTriangleIndices = np.concatenate([np.array([np.array([0, numLongitudeLines-1, 1, 1, numLongitudeLines-1, numLongitudeLines])+1+i for i in np.arange(0, numLongitudeLines-2)]).flatten(),\n",
    "#                                           np.array([numLongitudeLines-1, (numLongitudeLines-1)*2, 1, 1, (numLongitudeLines-1)*2, numLongitudeLines])])\n",
    "# indices = np.concatenate([indices,\n",
    "#                           np.array([firstRowTriangleIndices+j*(numLongitudeLines-1) for j in arange(0, numLatitudeLines-3)]).flatten()])\n",
    "# ## triangles for bottom lid\n",
    "# indices = np.concatenate([indices,\n",
    "#                           np.array([np.array([len(vertices)-1, j, i]) for i, j in zip(np.arange(len(vertices)-numLongitudeLines, len(vertices)-1),\n",
    "#                                                                                       np.concatenate([np.arange(len(vertices)-numLongitudeLines+1, len(vertices)-1), [len(vertices)-numLongitudeLines]]))]).flatten()])\n",
    "# ax.scatter3D(vertices[:, 0], vertices[:, 1], vertices[:, 2], color=\"r\", linewidth=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f45f411e1d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # %pylab\n",
    "# filmedSceneLoc = \"/home/ilisescu/PhD/data/havana/\"\n",
    "# cameraExtrinsics = np.array([[0.820045839796, 0.57100067645, -0.0385103638868, 1.67922756789],\n",
    "#                                           [0.22275752409, -0.380450047102, -0.897572753108, -0.831720502302],\n",
    "#                                           [-0.527165918942, 0.727472328789, -0.439181175316, 6.76268742928],\n",
    "#                                           [0.0, 0.0, 0.0, 1.0]], np.float32)\n",
    "\n",
    "# cameraIntrinsics = np.array([[702.736053, 0.0, 640.0],\n",
    "#                                   [0.0, 702.736053, 360.0],\n",
    "#                                   [0.0, 0.0, 1.0]])\n",
    "# originalIntrinsics = np.copy(cameraIntrinsics)\n",
    "\n",
    "# medianImage = np.array(Image.open(filmedSceneLoc+\"median.png\"), np.uint8)\n",
    "\n",
    "# distortionParameter = -0.19\n",
    "# distortionRatio = -0.19\n",
    "# medianImage, cameraIntrinsics, distortionCoeff = undistortImage(distortionParameter, distortionRatio, medianImage, cameraIntrinsics)\n",
    "# figure(); imshow(medianImage)\n",
    "\n",
    "# usedFrame = np.array(Image.open(filmedSceneLoc+\"frame-{0:05d}.png\".format(2346+1)), np.uint8)\n",
    "# figure(); imshow(usedFrame)\n",
    "# usedFrame = undistortImage(distortionParameter, distortionRatio, usedFrame, originalIntrinsics)[0]\n",
    "# figure(); imshow(usedFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE TO ADJUST FOR CAMERA DISTORTIONS USING A BILLBOARD AND HOMOGRAPHIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING: /home/ilisescu/PhD/data/havana/semantic_sequence-blue_car1.npy\n",
      "LOADING: /home/ilisescu/PhD/data/havana/filmed_object-blue_car1.npy\n",
      "215\n"
     ]
    }
   ],
   "source": [
    "# if True :\n",
    "#     filmedSceneLoc = \"/home/ilisescu/PhD/data/havana/\"\n",
    "#     spriteIdx = 1; frameSubset = [5, -10]; segmentationThreshold = 0.8; filmedObjectIdx = 0  ## blue_car1\n",
    "# #     spriteIdx = 7; frameSubset = [5, -10]; segmentationThreshold = 0.8; filmedObjectIdx = 1 ## red_car1\n",
    "# #     spriteIdx = 9; frameSubset = [40, -120]; segmentationThreshold = 0.8; filmedObjectIdx = 2 ## white_bus1\n",
    "# else :\n",
    "#     filmedSceneLoc = \"/media/ilisescu/Data1/PhD/data/theme_park_sunny/\"\n",
    "#     spriteIdx = 10; frameSubset = [0, -1]; segmentationThreshold = 1.5; filmedObjectIdx = 0 ## person 2\n",
    "# filmedSceneData = np.load(glob.glob(filmedSceneLoc+\"filmed_scene-*.npy\")[0]).item()\n",
    "# cameraExtrinsics = filmedSceneData[DICT_CAMERA_EXTRINSICS].astype(np.float32)\n",
    "\n",
    "# cameraIntrinsics = filmedSceneData[DICT_CAMERA_INTRINSICS]\n",
    "# originalIntrinsics = np.copy(cameraIntrinsics)\n",
    "\n",
    "# medianImage = np.array(Image.open(filmedSceneLoc+\"median.png\"), np.uint8)\n",
    "# distortionParameter = filmedSceneData[DICT_DISTORTION_PARAMETER]\n",
    "# distortionRatio = filmedSceneData[DICT_DISTORTION_RATIO]\n",
    "# medianImage, cameraIntrinsics, distortionCoeff, _, _ = undistortImage(distortionParameter, distortionRatio, medianImage, cameraIntrinsics)\n",
    "\n",
    "\n",
    "# if False :\n",
    "#     ## OLD WAY OF DOING THINGS\n",
    "#     spriteIdx = 1 ## blue_car1\n",
    "#     # spriteIdx = 7 ## red_car1\n",
    "#     # spriteIdx = 9 ## white_bus1\n",
    "#     objectData = np.load(np.sort(glob.glob(filmedSceneLoc+\"semantic_sequence-*.npy\"))[spriteIdx]).item()\n",
    "#     trajectoryPoints = np.array([objectData[DICT_BBOX_CENTERS][key] for key in np.sort(objectData[DICT_BBOX_CENTERS].keys())])[frameSubset[0]:frameSubset[1]-1, :]\n",
    "#     trajectoryPoints = cv2.undistortPoints(trajectoryPoints.reshape((1, len(trajectoryPoints), 2)), originalIntrinsics, distortionCoeff, P=cameraIntrinsics)[0, :, :]\n",
    "#     figure(); imshow(medianImage)\n",
    "#     scatter(trajectoryPoints[:, 0], trajectoryPoints[:, 1])\n",
    "#     # print(np.sort(objectData[DICT_BBOX_CENTERS].keys())[frameSubset[0]:frameSubset[1]-1])\n",
    "#     if objectData[DICT_SEQUENCE_NAME] == \"blue_car1\" or objectData[DICT_SEQUENCE_NAME] == \"red_car1\" or objectData[DICT_SEQUENCE_NAME] == \"white_bus1\":\n",
    "#         print(\"READING NUKE TRACK FROM\", \"/home/ilisescu/PhD/data/havana/{0}-track.txt\".format(objectData[DICT_SEQUENCE_NAME]))\n",
    "#         f = open(\"/home/ilisescu/PhD/data/havana/{0}-track.txt\".format(objectData[DICT_SEQUENCE_NAME]), 'r')\n",
    "#         lines = f.readlines()\n",
    "#         vals = [np.array(i.split(\" \")).astype(float) for i in lines]\n",
    "#         vals = [(int(i[-1]), i[0:2]) for i in vals]\n",
    "#         tmp = dict(vals)\n",
    "#         trajectoryPoints = np.array([tmp[key] for key in np.sort(objectData[DICT_BBOX_CENTERS].keys())[frameSubset[0]:frameSubset[1]-1]])\n",
    "#     #     trajectoryPoints = trajectoryPoints + (np.array(medianImage.shape[0:2])[::-1].reshape([1, 2]) - np.array(np.array(Image.open(filmedSceneLoc+\"median.png\"), np.uint8).shape[0:-1])[::-1].reshape([1, 2]))/2\n",
    "#         ## the nuke tracks are defined in the original camera's coordinate system but after the undistortion\n",
    "#         trajectoryPoints = trajectoryPoints + cameraIntrinsics[:2, -1] - originalIntrinsics[:2, -1]\n",
    "#     # print(np.sort(objectData[DICT_BBOX_CENTERS].keys())[frameSubset[0]:frameSubset[1]-1])\n",
    "# else :\n",
    "#     print(\"LOADING:\", np.sort(glob.glob(filmedSceneLoc+\"semantic_sequence-*.npy\"))[spriteIdx])\n",
    "#     objectData = np.load(np.sort(glob.glob(filmedSceneLoc+\"semantic_sequence-*.npy\"))[spriteIdx]).item()\n",
    "#     print(\"LOADING:\", np.sort(glob.glob(filmedSceneLoc+\"filmed_object-*.npy\"))[filmedObjectIdx])\n",
    "#     filmedObjectData = np.load(np.sort(glob.glob(filmedSceneLoc+\"filmed_object-*.npy\"))[filmedObjectIdx]).item()\n",
    "#     f = open(filmedObjectData[DICT_TRACK_LOCATION], 'r')\n",
    "#     lines = f.readlines()\n",
    "#     vals = [np.array(i.split(\" \")).astype(float) for i in lines]\n",
    "#     vals = [(int(i[-1]), i[0:2]) for i in vals]\n",
    "#     tmp = dict(vals)\n",
    "#     sortedFrameKeys = np.sort(tmp.keys())[frameSubset[0]:frameSubset[1]-1]\n",
    "#     trajectoryPoints = np.array([tmp[key] for key in np.sort(tmp.keys())[frameSubset[0]:frameSubset[1]-1]])\n",
    "# #     trajectoryPoints = filmedObjectData[DICT_TRAJECTORY_POINTS][frameSubset[0]:frameSubset[1]-1]\n",
    "#     trajectoryPoints = trajectoryPoints + cameraIntrinsics[:2, -1] - originalIntrinsics[:2, -1]\n",
    "#     print(len(trajectoryPoints))\n",
    "\n",
    "# figure(); imshow(medianImage)\n",
    "# scatter(trajectoryPoints[:, 0], trajectoryPoints[:, 1], color='r')\n",
    "# scatter(trajectoryPoints[210, 0], trajectoryPoints[210, 1], color='b', marker=\"x\")\n",
    "    \n",
    "# trajectory = GLTrajectory(trajectoryPoints, cameraIntrinsics, cameraExtrinsics, objectData[DICT_REPRESENTATIVE_COLOR], doSmoothing=False)\n",
    "\n",
    "# preloadedPatches = np.load(objectData[DICT_PATCHES_LOCATION]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def searchWorldSpacePoint(worldTargetPoint, worldStartPoint, cameraStartPoint, worldDir, verbose=False) :\n",
    "#     cameraClosestPointToIntersection = np.zeros([1, 2])\n",
    "#     worldClosestPointToIntersection = np.zeros([1, 3])\n",
    "#     ## init ##\n",
    "#     pointDist = 1600.0\n",
    "#     dirRatio = 1.0\n",
    "#     increment = np.copy(dirRatio)\n",
    "# #     print(\"STARTING POINT\", worldTargetPoint, \"...\")\n",
    "#     worldCurrentPoint = worldStartPoint+worldDir*dirRatio\n",
    "#     foundInside = False\n",
    "#     iterNum = 0 \n",
    "#     while pointDist > 0.1 and iterNum < 100 :\n",
    "#         iterNum += 1\n",
    "#         cameraCurrentPoint = worldToScreenSpace(viewMat, projectionMat, worldCurrentPoint, width, height)\n",
    "#         cameraClosestPointToIntersection[0, :] = cameraCurrentPoint\n",
    "#         worldClosestPointToIntersection[0, :] = worldCurrentPoint\n",
    "\n",
    "#         dotProduct = np.dot(cameraCurrentPoint-cameraStartPoint, worldTargetPoint-cameraStartPoint)\n",
    "#         squaredDist = np.linalg.norm(cameraCurrentPoint-cameraStartPoint)**2\n",
    "\n",
    "#         if verbose :\n",
    "#             print(dotProduct, squaredDist, np.linalg.norm(cameraCurrentPoint-worldTargetPoint))\n",
    "#         ## flip dirRatio direction if the worldTargetPoint is outside of the line segment (cameraCurrentPoint-cameraStartPoint) in the direction of cameraStartPoint\n",
    "#         if dotProduct < 0 :\n",
    "#             if verbose :\n",
    "#                 print(\"FLIPPING\")\n",
    "#             dirRatio *= -1\n",
    "#             increment *= -1\n",
    "#             worldCurrentPoint = worldStartPoint+worldDir*dirRatio\n",
    "#             continue\n",
    "\n",
    "#         ## if worldTargetPoint is within the line segment then set the increment to half the current length and set currentPoint to the middle of the half segment closest to cameraStartPoint\n",
    "#         if dotProduct < squaredDist :\n",
    "#             increment *= 0.5\n",
    "#             foundInside = True\n",
    "#             dirRatio -= increment\n",
    "#         ## if the worldTargetPoint is outside the line segment\n",
    "#         else :\n",
    "#             ## set the increment to half the current length only if the worldTargetPoint has been within the line segment (otherwise don't split but keep increasing the length of the line segment I'm looking within)\n",
    "#             if foundInside :\n",
    "#                 increment *= 0.5\n",
    "#             ## if foundInside == True this sets currentPoint to the middle of the half segment furthest from cameraStartPoint, otherwise it doubles the length of the line segment\n",
    "#             dirRatio += increment\n",
    "\n",
    "#         if verbose :\n",
    "#             print(\"DIR RATIO\", dirRatio, increment, foundInside)\n",
    "\n",
    "#         worldCurrentPoint = worldStartPoint+worldDir*dirRatio\n",
    "\n",
    "#         pointDist = np.linalg.norm(cameraCurrentPoint-worldTargetPoint)\n",
    "#     if iterNum >= 100 :\n",
    "#         print(\"...REACHED MAXIMUM ITER COUNT\")\n",
    "# #     else :\n",
    "# #         print(\"...DONE\")\n",
    "\n",
    "#     return worldClosestPointToIntersection, cameraClosestPointToIntersection\n",
    "\n",
    "# def findBillboardSize(worldPos, worldOrientDir, worldUpDir, projectionMat, viewMat, worldToCameraHomography, patchData, width, height, verbose=False, doReturnExtraInfo=False) :    \n",
    "#     worldOrientDirPos = worldPos + worldOrientDir\n",
    "\n",
    "#     ## find projections of world coords into camera space\n",
    "#     cameraPos = worldToScreenSpace(viewMat, projectionMat, worldPos, width, height)\n",
    "#     cameraOrientDirPos = worldToScreenSpace(viewMat, projectionMat, worldOrientDirPos, width, height)\n",
    "    \n",
    "#     worldUpDirPos = worldPos+worldUpDir\n",
    "#     cameraUpDirPos = worldToScreenSpace(viewMat, projectionMat, worldUpDirPos, width, height)\n",
    "\n",
    "#     ########### FIND BILLBOARD WIDTH BASED ON HOW IT PROJECTS INTO SCREEN SPACE AND HOW IT THEN RELATES WITH THE SEGMENTED PATCH ###########\n",
    "#     cameraDirLeftIntersection = line2lineIntersection(np.array([cameraPos, cameraOrientDirPos]).flatten(),\n",
    "#                                                       np.array([patchData['top_left_pos'][::-1], np.array([patchData['top_left_pos'][0]+patchData['patch_size'][0], patchData['top_left_pos'][1]])[::-1]]).flatten())\n",
    "\n",
    "#     cameraDirRightIntersection = line2lineIntersection(np.array([cameraPos, cameraOrientDirPos]).flatten(),\n",
    "#                                                        np.array([(patchData['top_left_pos']+patchData['patch_size'])[::-1],\n",
    "#                                                                  np.array([patchData['top_left_pos'][0], patchData['top_left_pos'][1]+patchData['patch_size'][1]])[::-1]]).flatten())\n",
    "\n",
    "#     worldDirLeftIntersection = np.dot(np.linalg.inv(worldToCameraHomography), np.concatenate([cameraDirLeftIntersection, [1]]).reshape([3, 1])).flatten()\n",
    "#     worldDirLeftIntersection /= worldDirLeftIntersection[-1]\n",
    "#     worldDirLeftIntersection[-1] = 0\n",
    "\n",
    "#     worldDirRightIntersection = np.dot(np.linalg.inv(worldToCameraHomography), np.concatenate([cameraDirRightIntersection, [1]]).reshape([3, 1])).flatten()\n",
    "#     worldDirRightIntersection /= worldDirRightIntersection[-1]\n",
    "#     worldDirRightIntersection[-1] = 0\n",
    "\n",
    "#     billboardWidth = np.max([np.linalg.norm(worldPos-worldDirLeftIntersection), np.linalg.norm(worldPos-worldDirRightIntersection)])*2\n",
    "\n",
    "#     ########### FIND BILLBOARD HEIGHT IN A SIMILAR MANNER TO ITS WIDTH ###########\n",
    "#     cameraUpDirTopIntersection = line2lineIntersection(np.array([cameraPos, cameraUpDirPos]).flatten(),\n",
    "#                                                        np.array([patchData['top_left_pos'][::-1], np.array([patchData['top_left_pos'][0], patchData['top_left_pos'][1]+patchData['patch_size'][1]])[::-1]]).flatten())\n",
    "\n",
    "#     cameraUpDirBottomIntersection = line2lineIntersection(np.array([cameraPos, cameraUpDirPos]).flatten(),\n",
    "#                                                           np.array([(patchData['top_left_pos']+patchData['patch_size'])[::-1],\n",
    "#                                                                     np.array([patchData['top_left_pos'][0]+patchData['patch_size'][0], patchData['top_left_pos'][1]])[::-1]]).flatten())\n",
    "#     ## to find the height I can't do the same thing as I did for the width because I can't project screen space points back into the world (previously I could because I knew the points were on the ground plane)\n",
    "#     ## instead, do a binary search type thing along the worldUpDir to find the world space points that project closest to the screen space points found above (i.e cameraUpDirTopIntersection and cameraUpDirBottomIntersection)\n",
    "\n",
    "#     worldClosestPointsToIntersection = np.empty([0, 3])\n",
    "#     cameraClosestPointsToIntersection = np.empty([0, 2])\n",
    "#     for i, point in enumerate([cameraUpDirTopIntersection, cameraUpDirBottomIntersection]) :\n",
    "#         worldClosestPointToIntersection, cameraClosestPointToIntersection = searchWorldSpacePoint(point, worldPos, cameraPos, worldUpDir, verbose)\n",
    "#         worldClosestPointsToIntersection = np.concatenate([worldClosestPointsToIntersection, worldClosestPointToIntersection], axis=0)\n",
    "#         cameraClosestPointsToIntersection = np.concatenate([cameraClosestPointsToIntersection, cameraClosestPointToIntersection], axis=0)\n",
    "\n",
    "\n",
    "#     billboardHeight = np.max([np.linalg.norm(worldPos-worldClosestPointsToIntersection[0, :]), np.linalg.norm(worldPos-worldClosestPointsToIntersection[1, :])])*2\n",
    "    \n",
    "#     if doReturnExtraInfo :\n",
    "#         return (billboardWidth, billboardHeight, cameraPos, cameraOrientDirPos, cameraUpDirPos, cameraDirLeftIntersection,\n",
    "#                 cameraDirRightIntersection, cameraUpDirTopIntersection, cameraUpDirBottomIntersection, cameraClosestPointsToIntersection)\n",
    "#     else :\n",
    "#         return billboardWidth, billboardHeight\n",
    "    \n",
    "\n",
    "# def getUndistortedPatchDataWithThresholdedAlpha(patchImageLoc, patchAlphaLoc, medianImage, distortionParameter, distortionRatio, cameraIntrinsics, threshold=0.8) :\n",
    "#     patchImage = np.array(patchImageLoc).astype(np.uint8)\n",
    "#     patchImage = undistortImage(distortionParameter, distortionRatio, patchImage, cameraIntrinsics)[0]\n",
    "#     patchAlpha = np.array(patchAlphaLoc).astype(np.uint8)\n",
    "#     patchAlpha = undistortImage(distortionParameter, distortionRatio, patchAlpha, cameraIntrinsics)[0][:, :, -1]\n",
    "    \n",
    "#     ## threshold the alpha based on bg diff \n",
    "#     if True :\n",
    "#         visiblePixels = np.argwhere(patchAlpha != 0)\n",
    "#         diffs = np.sqrt(np.sum((patchImage[visiblePixels[:, 0], visiblePixels[:, 1], :] - medianImage[visiblePixels[:, 0], visiblePixels[:, 1], :])**2, axis=1))\n",
    "#         tmp = np.zeros([medianImage.shape[0], medianImage.shape[1]], np.uint8)\n",
    "#         tmp[visiblePixels[:, 0], visiblePixels[:, 1]] = diffs\n",
    "#         tmp = cv2.medianBlur(tmp, 7)\n",
    "#         tmp = tmp/float(np.max(tmp))\n",
    "#         med = np.median(tmp[visiblePixels[:, 0], visiblePixels[:, 1]])\n",
    "#         tmp[tmp<med*threshold] = 0\n",
    "#         tmp[tmp>0] = np.max(tmp)\n",
    "#         patchAlpha = (tmp/np.max(tmp)*255).astype(np.uint8)\n",
    "        \n",
    "\n",
    "#     visiblePixels = np.argwhere(patchAlpha != 0)\n",
    "#     topLeft = np.min(visiblePixels, axis=0)\n",
    "#     patchSize = np.max(visiblePixels, axis=0) - topLeft + 1\n",
    "\n",
    "#     colors = np.concatenate([patchImage[visiblePixels[:, 0], visiblePixels[:, 1], :], np.ones([len(visiblePixels), 1])*255], axis=1).astype(np.uint8)\n",
    "\n",
    "#     patchData = {'top_left_pos':topLeft, 'sprite_colors':colors[:, [2, 1, 0, 3]],\n",
    "#                  'visible_indices': visiblePixels-topLeft, 'patch_size': patchSize}\n",
    "    \n",
    "#     return patchImage, patchAlpha, patchData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW MAX WIDTH 0 0.651939180093\n",
      "NEW MAX HEIGHT 0 0.564453125\n",
      "0 2339 0.651939180093 0.564453125 0.651939180093 0.564453125\n",
      "NEW MAX WIDTH 1 0.652223940308\n",
      "NEW MAX HEIGHT 1 0.568359375\n",
      "1 2340 0.652223940308 0.568359375 0.652223940308 0.568359375\n",
      "NEW MAX WIDTH 2 0.666894622609\n",
      "2 2341 0.666894622609 0.55078125 0.666894622609 0.568359375\n",
      "NEW MAX WIDTH 3 0.674344425199\n",
      "3 2342 0.674344425199 0.54296875 0.674344425199 0.568359375\n",
      "4 2343 0.651075323873 0.548828125 0.674344425199 0.568359375\n",
      "5 2344 0.644417244398 0.54296875 0.674344425199 0.568359375\n",
      "6 2345 0.649177184326 0.548828125 0.674344425199 0.568359375\n",
      "7 2346 0.643927117167 0.5546875 0.674344425199 0.568359375\n",
      "8 2347 0.641503792031 0.53515625 0.674344425199 0.568359375\n",
      "9 2348 0.652232612026 0.541015625 0.674344425199 0.568359375\n",
      "10 2349 0.661450107296 0.5234375 0.674344425199 0.568359375\n",
      "11 2350 0.643261930932 0.51953125 0.674344425199 0.568359375\n",
      "12 2351 0.664576322748 0.54296875 0.674344425199 0.568359375\n",
      "13 2352 0.645124383598 0.5390625 0.674344425199 0.568359375\n",
      "14 2353 0.624870690387 0.546875 0.674344425199 0.568359375\n",
      "15 2354 0.644077344787 0.54296875 0.674344425199 0.568359375\n",
      "16 2355 0.638498861987 0.55078125 0.674344425199 0.568359375\n",
      "NEW MAX HEIGHT 17 0.572265625\n",
      "17 2356 0.648077408788 0.572265625 0.674344425199 0.572265625\n",
      "18 2357 0.665199047083 0.552734375 0.674344425199 0.572265625\n",
      "19 2358 0.647959649169 0.53125 0.674344425199 0.572265625\n",
      "NEW MAX WIDTH 20 0.688651302868\n",
      "20 2359 0.688651302868 0.552734375 0.688651302868 0.572265625\n",
      "21 2360 0.669840837052 0.55859375 0.688651302868 0.572265625\n",
      "NEW MAX WIDTH 22 0.717923916137\n",
      "22 2361 0.717923916137 0.56640625 0.717923916137 0.572265625\n",
      "23 2362 0.696953405746 0.54296875 0.717923916137 0.572265625\n",
      "24 2363 0.637241917381 0.533203125 0.717923916137 0.572265625\n",
      "25 2364 0.634256397538 0.5390625 0.717923916137 0.572265625\n",
      "26 2365 0.654356063541 0.54296875 0.717923916137 0.572265625\n",
      "27 2366 0.700688323776 0.548828125 0.717923916137 0.572265625\n",
      "28 2367 0.644033642682 0.5234375 0.717923916137 0.572265625\n",
      "29 2368 0.662853276736 0.52734375 0.717923916137 0.572265625\n",
      "30 2369 0.658834109434 0.53125 0.717923916137 0.572265625\n",
      "31 2370 0.659370111623 0.53515625 0.717923916137 0.572265625\n",
      "32 2371 0.677201593504 0.525390625 0.717923916137 0.572265625\n",
      "33 2372 0.667665953308 0.529296875 0.717923916137 0.572265625\n",
      "34 2373 0.676052509026 0.51953125 0.717923916137 0.572265625\n",
      "NEW MAX WIDTH 35 0.721916565455\n",
      "35 2374 0.721916565455 0.53515625 0.721916565455 0.572265625\n",
      "36 2375 0.654455343593 0.509765625 0.721916565455 0.572265625\n",
      "37 2376 0.665292971571 0.51171875 0.721916565455 0.572265625\n",
      "38 2377 0.642976989606 0.515625 0.721916565455 0.572265625\n",
      "39 2378 0.664539671365 0.50390625 0.721916565455 0.572265625\n",
      "40 2379 0.642214469396 0.51953125 0.721916565455 0.572265625\n",
      "41 2380 0.653038339565 0.5234375 0.721916565455 0.572265625\n",
      "42 2381 0.641699591427 0.5234375 0.721916565455 0.572265625\n",
      "43 2382 0.652890964649 0.541015625 0.721916565455 0.572265625\n",
      "44 2383 0.687296745638 0.51171875 0.721916565455 0.572265625\n",
      "45 2384 0.642742979521 0.52734375 0.721916565455 0.572265625\n",
      "46 2385 0.664164051003 0.515625 0.721916565455 0.572265625\n",
      "47 2386 0.652434927333 0.53125 0.721916565455 0.572265625\n",
      "48 2387 0.65234953511 0.53125 0.721916565455 0.572265625\n",
      "49 2388 0.652882591954 0.515625 0.721916565455 0.572265625\n",
      "50 2389 0.640866559717 0.53125 0.721916565455 0.572265625\n",
      "51 2390 0.630217300652 0.529296875 0.721916565455 0.572265625\n",
      "52 2391 0.656867536677 0.54296875 0.721916565455 0.572265625\n",
      "53 2392 0.662041970893 0.54296875 0.721916565455 0.572265625\n",
      "54 2393 0.657057691865 0.5546875 0.721916565455 0.572265625\n",
      "55 2394 0.638460503039 0.55078125 0.721916565455 0.572265625\n",
      "56 2395 0.685258966233 0.546875 0.721916565455 0.572265625\n",
      "NEW MAX WIDTH 57 0.796982932688\n",
      "NEW MAX HEIGHT 57 0.57421875\n",
      "57 2396 0.796982932688 0.57421875 0.796982932688 0.57421875\n",
      "58 2397 0.788991746615 0.5546875 0.796982932688 0.57421875\n",
      "NEW MAX WIDTH 59 0.857037296978\n",
      "59 2398 0.857037296978 0.5625 0.857037296978 0.57421875\n",
      "NEW MAX WIDTH 60 0.901036190065\n",
      "60 2399 0.901036190065 0.572265625 0.901036190065 0.57421875\n",
      "NEW MAX HEIGHT 61 0.58203125\n",
      "61 2400 0.651739673249 0.58203125 0.901036190065 0.58203125\n",
      "62 2401 0.669939278891 0.55859375 0.901036190065 0.58203125\n",
      "63 2402 0.667452684193 0.56640625 0.901036190065 0.58203125\n",
      "64 2403 0.66742951139 0.52734375 0.901036190065 0.58203125\n",
      "65 2404 0.65653175679 0.53125 0.901036190065 0.58203125\n",
      "NEW MAX HEIGHT 66 0.583984375\n",
      "66 2405 0.665190523295 0.583984375 0.901036190065 0.583984375\n",
      "67 2406 0.706973793591 0.52734375 0.901036190065 0.583984375\n",
      "68 2407 0.669022754439 0.533203125 0.901036190065 0.583984375\n",
      "69 2408 0.664362231135 0.5390625 0.901036190065 0.583984375\n",
      "70 2409 0.721425775668 0.54296875 0.901036190065 0.583984375\n",
      "71 2410 0.704794917321 0.53125 0.901036190065 0.583984375\n",
      "72 2411 0.750690153139 0.53515625 0.901036190065 0.583984375\n",
      "73 2412 0.721805107164 0.521484375 0.901036190065 0.583984375\n",
      "74 2413 0.682734599839 0.5078125 0.901036190065 0.583984375\n",
      "75 2414 0.72879498217 0.51171875 0.901036190065 0.583984375\n",
      "76 2415 0.759590309659 0.513671875 0.901036190065 0.583984375\n",
      "77 2416 0.807216222103 0.515625 0.901036190065 0.583984375\n",
      "78 2417 0.717682355179 0.515625 0.901036190065 0.583984375\n",
      "79 2418 0.704376150722 0.517578125 0.901036190065 0.583984375\n",
      "80 2419 0.721803616971 0.51953125 0.901036190065 0.583984375\n",
      "81 2420 0.754949336429 0.51953125 0.901036190065 0.583984375\n",
      "82 2421 0.725296664894 0.47265625 0.901036190065 0.583984375\n",
      "83 2422 0.720424690992 0.484375 0.901036190065 0.583984375\n",
      "84 2423 0.691926216607 0.4921875 0.901036190065 0.583984375\n",
      "85 2424 0.709628104378 0.4921875 0.901036190065 0.583984375\n",
      "86 2425 0.751502098673 0.49609375 0.901036190065 0.583984375\n",
      "87 2426 0.813909483212 0.498046875 0.901036190065 0.583984375\n",
      "88 2427 0.742321637271 0.5 0.901036190065 0.583984375\n",
      "89 2428 0.748344535441 0.50390625 0.901036190065 0.583984375\n",
      "90 2429 0.727666964054 0.5078125 0.901036190065 0.583984375\n",
      "91 2430 0.732941759119 0.51171875 0.901036190065 0.583984375\n",
      "92 2431 0.724586621415 0.48828125 0.901036190065 0.583984375\n",
      "93 2432 0.729190871924 0.494140625 0.901036190065 0.583984375\n",
      "94 2433 0.733534769339 0.486328125 0.901036190065 0.583984375\n",
      "95 2434 0.713624647516 0.505859375 0.901036190065 0.583984375\n",
      "96 2435 0.714406384038 0.498046875 0.901036190065 0.583984375\n",
      "97 2436 0.731085282576 0.50390625 0.901036190065 0.583984375\n",
      "98 2437 0.775407616206 0.49609375 0.901036190065 0.583984375\n",
      "99 2438 0.746750649633 0.490234375 0.901036190065 0.583984375\n",
      "100 2439 0.74536556082 0.49609375 0.901036190065 0.583984375\n",
      "101 2440 0.768618373877 0.50390625 0.901036190065 0.583984375\n",
      "102 2441 0.78041033773 0.5 0.901036190065 0.583984375\n",
      "103 2442 0.785122996284 0.5078125 0.901036190065 0.583984375\n",
      "104 2443 0.757550599916 0.5 0.901036190065 0.583984375\n",
      "105 2444 0.799827692296 0.509765625 0.901036190065 0.583984375\n",
      "106 2445 0.765899316623 0.4921875 0.901036190065 0.583984375\n",
      "107 2446 0.784377349662 0.5 0.901036190065 0.583984375\n",
      "108 2447 0.76765571996 0.5234375 0.901036190065 0.583984375\n",
      "109 2448 0.758373201666 0.50390625 0.901036190065 0.583984375\n",
      "110 2449 0.776031808683 0.513671875 0.901036190065 0.583984375\n",
      "111 2450 0.789518754355 0.509765625 0.901036190065 0.583984375\n",
      "112 2451 0.803035282646 0.50390625 0.901036190065 0.583984375\n",
      "113 2452 0.79660913874 0.48828125 0.901036190065 0.583984375\n",
      "114 2453 0.813591657182 0.484375 0.901036190065 0.583984375\n",
      "115 2454 0.791535530975 0.494140625 0.901036190065 0.583984375\n",
      "116 2455 0.821504718249 0.505859375 0.901036190065 0.583984375\n",
      "117 2456 0.785910094552 0.517578125 0.901036190065 0.583984375\n",
      "118 2457 0.797148285361 0.48828125 0.901036190065 0.583984375\n",
      "119 2458 0.825610967189 0.5 0.901036190065 0.583984375\n",
      "120 2459 0.890441179638 0.5 0.901036190065 0.583984375\n",
      "121 2460 0.818578776575 0.515625 0.901036190065 0.583984375\n",
      "122 2461 0.841604849094 0.517578125 0.901036190065 0.583984375\n",
      "123 2462 0.877446725607 0.51953125 0.901036190065 0.583984375\n",
      "124 2463 0.852377370779 0.521484375 0.901036190065 0.583984375\n",
      "125 2464 0.826749091336 0.51171875 0.901036190065 0.583984375\n",
      "126 2465 0.826409546924 0.515625 0.901036190065 0.583984375\n",
      "127 2466 0.833787015939 0.517578125 0.901036190065 0.583984375\n",
      "128 2467 0.845784519343 0.521484375 0.901036190065 0.583984375\n",
      "129 2468 0.898153786953 0.525390625 0.901036190065 0.583984375\n",
      "130 2469 0.876825518671 0.52734375 0.901036190065 0.583984375\n",
      "131 2470 0.900262400085 0.544921875 0.901036190065 0.583984375\n",
      "NEW MAX WIDTH 132 0.959775189471\n",
      "132 2471 0.959775189471 0.5625 0.959775189471 0.583984375\n",
      "133 2472 0.880678328678 0.52734375 0.959775189471 0.583984375\n",
      "134 2473 0.894558094968 0.54296875 0.959775189471 0.583984375\n",
      "135 2474 0.87684153749 0.546875 0.959775189471 0.583984375\n",
      "136 2475 0.890279266789 0.5390625 0.959775189471 0.583984375\n",
      "137 2476 0.887787175311 0.53125 0.959775189471 0.583984375\n",
      "138 2477 0.846823678324 0.5234375 0.959775189471 0.583984375\n",
      "139 2478 0.914479413248 0.541015625 0.959775189471 0.583984375\n",
      "140 2479 0.831820288758 0.52734375 0.959775189471 0.583984375\n",
      "141 2480 0.861005205941 0.560546875 0.959775189471 0.583984375\n",
      "142 2481 0.906628409746 0.578125 0.959775189471 0.583984375\n",
      "143 2482 0.887537484978 0.56640625 0.959775189471 0.583984375\n",
      "144 2483 0.941645421354 0.5546875 0.959775189471 0.583984375\n",
      "145 2484 0.930253385967 0.548828125 0.959775189471 0.583984375\n",
      "NEW MAX HEIGHT 146 0.5859375\n",
      "146 2485 0.894414621959 0.5859375 0.959775189471 0.5859375\n",
      "147 2486 0.900907032035 0.5859375 0.959775189471 0.5859375\n",
      "NEW MAX HEIGHT 148 0.615234375\n",
      "148 2487 0.923661372591 0.615234375 0.959775189471 0.615234375\n",
      "NEW MAX WIDTH 149 0.962441291562\n",
      "149 2488 0.962441291562 0.5859375 0.962441291562 0.615234375\n",
      "NEW MAX HEIGHT 150 0.640625\n",
      "150 2489 0.921347190223 0.640625 0.962441291562 0.640625\n",
      "151 2490 0.860463144025 0.640625 0.962441291562 0.640625\n",
      "152 2491 0.872725655282 0.63671875 0.962441291562 0.640625\n",
      "153 2492 0.949406202506 0.619140625 0.962441291562 0.640625\n",
      "154 2493 0.896738572244 0.6015625 0.962441291562 0.640625\n",
      "155 2494 0.892430145183 0.611328125 0.962441291562 0.640625\n",
      "156 2495 0.884642405308 0.63671875 0.962441291562 0.640625\n",
      "NEW MAX WIDTH 157 0.979010741983\n",
      "157 2496 0.979010741983 0.6015625 0.979010741983 0.640625\n",
      "158 2497 0.973794055352 0.61328125 0.979010741983 0.640625\n",
      "NEW MAX HEIGHT 159 0.650390625\n",
      "159 2498 0.905312378898 0.650390625 0.979010741983 0.650390625\n",
      "160 2499 0.915806054672 0.62890625 0.979010741983 0.650390625\n",
      "NEW MAX WIDTH 161 0.988584302945\n",
      "NEW MAX HEIGHT 161 0.66796875\n",
      "161 2500 0.988584302945 0.66796875 0.988584302945 0.66796875\n",
      "NEW MAX WIDTH 162 1.01420644679\n",
      "NEW MAX HEIGHT 162 0.703125\n",
      "162 2501 1.01420644679 0.703125 1.01420644679 0.703125\n",
      "NEW MAX HEIGHT 163 0.712890625\n",
      "163 2502 0.928748437038 0.712890625 1.01420644679 0.712890625\n",
      "NEW MAX HEIGHT 164 0.720703125\n",
      "164 2503 0.972530152352 0.720703125 1.01420644679 0.720703125\n",
      "NEW MAX HEIGHT 165 0.7265625\n",
      "165 2504 0.891752828978 0.7265625 1.01420644679 0.7265625\n",
      "NEW MAX HEIGHT 166 0.763671875\n",
      "166 2505 0.828104730691 0.763671875 1.01420644679 0.763671875\n",
      "NEW MAX HEIGHT 167 0.78515625\n",
      "167 2506 0.959942849404 0.78515625 1.01420644679 0.78515625\n",
      "NEW MAX HEIGHT 168 0.8046875\n",
      "168 2507 1.00201398779 0.8046875 1.01420644679 0.8046875\n",
      "NEW MAX WIDTH 169 1.08652131525\n",
      "NEW MAX HEIGHT 169 0.80859375\n",
      "169 2508 1.08652131525 0.80859375 1.08652131525 0.80859375\n",
      "NEW MAX WIDTH 170 1.14065313265\n",
      "NEW MAX HEIGHT 170 0.84375\n",
      "170 2509 1.14065313265 0.84375 1.14065313265 0.84375\n",
      "NEW MAX WIDTH 171 1.20706662187\n",
      "NEW MAX HEIGHT 171 0.84765625\n",
      "171 2510 1.20706662187 0.84765625 1.20706662187 0.84765625\n",
      "NEW MAX WIDTH 172 1.2664100472\n",
      "172 2511 1.2664100472 0.8359375 1.2664100472 0.84765625\n",
      "NEW MAX WIDTH 173 1.32638041909\n",
      "173 2512 1.32638041909 0.82421875 1.32638041909 0.84765625\n",
      "NEW MAX WIDTH 174 1.38700076788\n",
      "174 2513 1.38700076788 0.826171875 1.38700076788 0.84765625\n",
      "NEW MAX WIDTH 175 1.44297308046\n",
      "175 2514 1.44297308046 0.8125 1.44297308046 0.84765625\n",
      "NEW MAX WIDTH 176 1.52665443859\n",
      "176 2515 1.52665443859 0.83203125 1.52665443859 0.84765625\n",
      "NEW MAX WIDTH 177 1.68616450704\n",
      "177 2516 1.68616450704 0.8125 1.68616450704 0.84765625\n",
      "178 2517 1.62237360423 0.810546875 1.68616450704 0.84765625\n",
      "179 2518 0.866979156041 0.765625 1.68616450704 0.84765625\n",
      "180 2519 0.855432443244 0.791015625 1.68616450704 0.84765625\n",
      "181 2520 0.817628352246 0.81640625 1.68616450704 0.84765625\n",
      "182 2521 0.875159057982 0.837890625 1.68616450704 0.84765625\n",
      "183 2522 0.893615295299 0.83203125 1.68616450704 0.84765625\n",
      "184 2523 0.911139753485 0.798828125 1.68616450704 0.84765625\n",
      "185 2524 0.888643735286 0.8046875 1.68616450704 0.84765625\n",
      "NEW MAX HEIGHT 186 0.8515625\n",
      "186 2525 0.919375055703 0.8515625 1.68616450704 0.8515625\n",
      "187 2526 0.955643622651 0.828125 1.68616450704 0.8515625\n",
      "188 2527 0.855024317058 0.83203125 1.68616450704 0.8515625\n",
      "189 2528 0.913287986652 0.8359375 1.68616450704 0.8515625\n",
      "NEW MAX HEIGHT 190 0.865234375\n",
      "190 2529 0.91928326039 0.865234375 1.68616450704 0.865234375\n",
      "NEW MAX HEIGHT 191 0.8671875\n",
      "191 2530 0.874876725216 0.8671875 1.68616450704 0.8671875\n",
      "NEW MAX HEIGHT 192 0.89453125\n",
      "192 2531 0.907482131257 0.89453125 1.68616450704 0.89453125\n",
      "NEW MAX HEIGHT 193 0.91015625\n",
      "193 2532 0.855989299256 0.91015625 1.68616450704 0.91015625\n",
      "194 2533 0.878128055525 0.89453125 1.68616450704 0.91015625\n",
      "NEW MAX HEIGHT 195 0.966796875\n",
      "195 2534 0.850421482094 0.966796875 1.68616450704 0.966796875\n",
      "NEW MAX HEIGHT 196 1.044921875\n",
      "196 2535 0.846679159852 1.044921875 1.68616450704 1.044921875\n",
      "197 2536 0.857470318033 0.9453125 1.68616450704 1.044921875\n",
      "198 2537 0.842471366169 0.9296875 1.68616450704 1.044921875\n",
      "199 2538 0.863550668523 0.912109375 1.68616450704 1.044921875\n",
      "200 2539 0.829502461712 0.94921875 1.68616450704 1.044921875\n",
      "201 2540 0.830530660733 0.97265625 1.68616450704 1.044921875\n",
      "202 2541 0.819318871945 0.927734375 1.68616450704 1.044921875\n",
      "203 2542 0.821025074046 0.91015625 1.68616450704 1.044921875\n",
      "204 2543 0.868503255314 0.876953125 1.68616450704 1.044921875\n",
      "205 2544 0.84847076201 0.96484375 1.68616450704 1.044921875\n",
      "206 2545 0.817744566414 0.943359375 1.68616450704 1.044921875\n",
      "207 2546 0.842491961286 0.98828125 1.68616450704 1.044921875\n",
      "208 2547 0.812507356707 1.033203125 1.68616450704 1.044921875\n",
      "NEW MAX HEIGHT 209 1.05078125\n",
      "209 2548 0.848101359927 1.05078125 1.68616450704 1.05078125\n",
      "NEW MAX HEIGHT 210 1.078125\n",
      "210 2549 0.819960332872 1.078125 1.68616450704 1.078125\n",
      "NEW MAX HEIGHT 211 1.080078125\n",
      "211 2550 0.813320082103 1.080078125 1.68616450704 1.080078125\n",
      "212 2551 0.817882063417 1.052734375 1.68616450704 1.080078125\n",
      "NEW MAX HEIGHT 213 1.15625\n",
      "213 2552 0.799530961564 1.15625 1.68616450704 1.15625\n",
      "214 2553 0.798856464574 1.09765625 1.68616450704 1.15625\n"
     ]
    }
   ],
   "source": [
    "# ## find max billboard size\n",
    "# height, width = medianImage.shape[:2]\n",
    "# viewMat, projectionMat = cvCameraToOpenGL(cameraExtrinsics, cameraIntrinsics, medianImage.shape)\n",
    "# verbose = False\n",
    "\n",
    "# maxBillboardWidth = 0\n",
    "# maxBillboardHeight = 0\n",
    "# usedOrientationsAndSizes = {}\n",
    "# for frameIdx in arange(len(trajectoryPoints))[0:] :\n",
    "#     patchKey = sortedFrameKeys[frameIdx]\n",
    "#     patchFrameName = \"frame-{0:05}.png\".format(patchKey+1)\n",
    "#     patchImage, patchAlpha, patchData = getUndistortedPatchDataWithThresholdedAlpha(Image.open(filmedSceneLoc+patchFrameName), Image.open(objectData[DICT_MASK_LOCATION]+patchFrameName),\n",
    "#                                                                                     medianImage, distortionParameter, distortionRatio, originalIntrinsics, segmentationThreshold)\n",
    "    \n",
    "#     ## find billboard width and height: first align it using tangent and then normal of the trajectory, and keep track of which orientation dir give the billboard with smallest area along with width and height\n",
    "#     worldPos = np.copy(trajectory.worldTrajectoryPoints[frameIdx, :])\n",
    "#     worldMovingDir = np.copy(trajectory.worldTrajectoryDirections[frameIdx, :])\n",
    "#     worldMoveNormalDir = np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(np.pi/2, np.array([0.0, 0.0, 1.0]))), np.concatenate([worldMovingDir, [1]]))\n",
    "#     worldMoveNormalDir = worldMoveNormalDir[:-1]/np.linalg.norm(worldMoveNormalDir[:-1])\n",
    "#     currentBillboardArea = 10000000000.0\n",
    "#     for currentWorldOrientDir in [worldMoveNormalDir, worldMovingDir] :\n",
    "#         ## check if the projection of the orientation direction into image space has a positive x coordinate; if it doesn't, I need to flip the orientation direction, which will produce the same exact billboard, but\n",
    "#         ## it will ensure it projects into image space with the front face visible\n",
    "#         currentDirMultiplier = 1.0\n",
    "#         if (worldToScreenSpace(viewMat, projectionMat, worldPos + currentWorldOrientDir, width, height)-worldToScreenSpace(viewMat, projectionMat, worldPos, width, height))[0] < 0 :\n",
    "#             currentWorldOrientDir *= -1.0\n",
    "#             currentDirMultiplier = -1.0\n",
    "#         worldUpDir = np.array([0.0, 0.0, 1.0])\n",
    "#         currentBillboardWidth, currentBillboardHeight = findBillboardSize(worldPos, currentWorldOrientDir, worldUpDir, projectionMat, viewMat, np.dot(cameraIntrinsics, cameraExtrinsics[:-1, [0, 1, 3]]),\n",
    "#                                                                           patchData, width, height, verbose)\n",
    "    \n",
    "#         if currentBillboardWidth*currentBillboardHeight < currentBillboardArea :\n",
    "# #             print(\"NEW AREA\", currentBillboardWidth*currentBillboardHeight, currentBillboardWidth, currentBillboardHeight, currentWorldOrientDir)\n",
    "#             currentBillboardArea = currentBillboardWidth*currentBillboardHeight\n",
    "#             billboardWidth = currentBillboardWidth\n",
    "#             billboardHeight = currentBillboardHeight\n",
    "#             worldOrientDir = currentWorldOrientDir\n",
    "#         ## I'm really only interested in saving the dirMultiplier for the tangent direction, worldMovingDir\n",
    "#         dirMultiplier = currentDirMultiplier\n",
    "            \n",
    "#     usedOrientationsAndSizes[frameIdx] = [worldOrientDir, billboardWidth, billboardHeight, dirMultiplier]\n",
    "#     if billboardWidth > maxBillboardWidth :\n",
    "#         maxBillboardWidth = billboardWidth\n",
    "#         print(\"NEW MAX WIDTH\", frameIdx, maxBillboardWidth)\n",
    "#     if billboardHeight > maxBillboardHeight :\n",
    "#         maxBillboardHeight = billboardHeight\n",
    "#         print(\"NEW MAX HEIGHT\", frameIdx, billboardHeight)\n",
    "#     print(frameIdx, patchKey, billboardWidth, billboardHeight, maxBillboardWidth, maxBillboardHeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 242.775749704 351.092670691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilisescu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:37: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/ilisescu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:50: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# ## once max billboard size is found, perform the undistortion thingy and such using the thingy\n",
    "# updatedPatches = {}  \n",
    "# for frameIdx in np.sort(usedOrientationsAndSizes.keys())[[213]] :\n",
    "#     patchKey = sortedFrameKeys[frameIdx]\n",
    "#     patchFrameName = \"frame-{0:05}.png\".format(patchKey+1)\n",
    "#     patchImage, patchAlpha, patchData = getUndistortedPatchDataWithThresholdedAlpha(Image.open(filmedSceneLoc+patchFrameName), Image.open(objectData[DICT_MASK_LOCATION]+patchFrameName),\n",
    "#                                                                                     medianImage, distortionParameter, distortionRatio, originalIntrinsics, segmentationThreshold)\n",
    "    \n",
    "    \n",
    "#     ### HERE NEED TO ACTUALLY CHANGE worldOrientDir SO THAT I PICK THE SMALLEST AREA BILLBOARD ###\n",
    "#     worldPos = np.copy(trajectory.worldTrajectoryPoints[frameIdx, :])\n",
    "#     worldOrientDir, billboardWidth, billboardHeight, dirMultiplier = usedOrientationsAndSizes[frameIdx]\n",
    "    \n",
    "# #     ## find billboard width and height --> keep track of worldOrientDir and width and height in the loop above instead of recomputing width and height    \n",
    "    \n",
    "# #     worldOrientDir = np.copy(trajectory.worldTrajectoryDirections[frameIdx, :])\n",
    "# #     worldOrientDir = np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(np.pi/2, np.array([0.0, 0.0, 1.0]))), np.concatenate([worldOrientDir, [0]]))\n",
    "# #     worldOrientDir = worldOrientDir[:-1]/np.linalg.norm(worldOrientDir[:-1])\n",
    "# #     ## check if the projection of the orientation direction into image space has a positive x coordinate; if it doesn't, I need to flip the orientation direction, which will produce the same exact billboard, but\n",
    "# #     ## it will ensure it projects into image space with the front face visible\n",
    "# #     if (worldToScreenSpace(viewMat, projectionMat, worldPos + worldOrientDir, width, height)-worldToScreenSpace(viewMat, projectionMat, worldPos, width, height))[0] < 0 :\n",
    "# #         worldOrientDir *= -1.0\n",
    "# #     worldUpDir = np.array([0.0, 0.0, 1.0])\n",
    "# #     billboardWidth, billboardHeight = findBillboardSize(worldPos, worldOrientDir, worldUpDir, projectionMat, viewMat, np.dot(cameraIntrinsics, cameraExtrinsics[:-1, [0, 1, 3]]), patchData, width, height, verbose)\n",
    "    \n",
    "#     ###############################################################################################\n",
    "    \n",
    "    \n",
    "#     ########### ROTATE BILLBOARD TO ALIGN WITH MOVING DIRECTION AND PLACE AT POINT ON TRAJECTORY ###########\n",
    "#     billboardModelMat = quaternionTo4x4Rotation(angleAxisToQuaternion(-np.pi/2.0, np.array([1.0, 0.0, 0.0]))) ## rotate billboard ccw along x axis to put it up\n",
    "#     adjustAngle = np.arccos(np.clip(np.dot(np.array([1.0, 0.0, 0.0]), worldOrientDir), -1, 1))\n",
    "#     adjustAxis = np.cross(worldOrientDir, np.array([1.0, 0.0, 0.0]))\n",
    "#     adjustAxis /= np.linalg.norm(adjustAxis)\n",
    "#     billboardModelMat = np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(adjustAngle, adjustAxis)), billboardModelMat)\n",
    "#     billboardModelMat[:-1, -1] = worldPos\n",
    "\n",
    "#     billboard = GLBillboard(np.zeros([500, np.ceil(500*billboardWidth/billboardHeight), 4], np.uint8), billboardHeight, modelMat=billboardModelMat)\n",
    "\n",
    "#     worldBillboardVertices = np.dot(billboard.modelMat, np.concatenate([billboard.vertices, np.ones([len(billboard.vertices), 1])], axis=1).T).T[:, :-1]\n",
    "\n",
    "#     ## this could be done with one matrix computation but cba right now\n",
    "#     screenBillboardVertices = np.zeros([len(worldBillboardVertices), 2])\n",
    "#     for i, vertex in enumerate(worldBillboardVertices) :\n",
    "#         screenBillboardVertices[i, :] = worldToScreenSpace(viewMat, projectionMat, vertex, width, height)\n",
    "#     #     print(vertex, screenBillboardVertices[i, :])\n",
    "\n",
    "#     footprintBillboardModelMat = quaternionTo4x4Rotation(angleAxisToQuaternion(adjustAngle, adjustAxis))\n",
    "#     footprintBillboardModelMat[:-1, -1] = worldPos\n",
    "#     ## this is for the havana cars\n",
    "#     footprintBillboard = GLBillboard(np.zeros([1000*0.081, 1000*0.18, 4], np.uint8), 0.265, modelMat=footprintBillboardModelMat)\n",
    "#     worldFootprintBillboardVertices = np.dot(footprintBillboard.modelMat, np.concatenate([footprintBillboard.vertices, np.ones([len(footprintBillboard.vertices), 1])], axis=1).T).T[:, :-1]\n",
    "#     ## this could be done with one matrix computation but cba right now\n",
    "#     screenFootprintBillboardVertices = np.zeros([len(worldFootprintBillboardVertices), 2])\n",
    "#     for i, vertex in enumerate(worldFootprintBillboardVertices) :\n",
    "#         screenFootprintBillboardVertices[i, :] = worldToScreenSpace(viewMat, projectionMat, vertex, width, height)\n",
    "        \n",
    "#     texHeight = 0\n",
    "#     texWidth = 0\n",
    "#     if maxBillboardWidth > maxBillboardHeight :\n",
    "#         texWidth = 512\n",
    "#         texHeight = texWidth*maxBillboardHeight/maxBillboardWidth\n",
    "#     else :\n",
    "#         texHeight = 512\n",
    "#         texWidth = texHeight*maxBillboardWidth/maxBillboardHeight#*billboardWidth/billboardHeight\n",
    "        \n",
    "#     ######################### SCALE COMPENSATION BASED ON BILLBOARD WIDTH IN WORLD SPACE #########################\n",
    "#     if True :\n",
    "#         widthScale = billboardWidth/maxBillboardWidth\n",
    "#         heightScale = billboardHeight/maxBillboardHeight\n",
    "#         scaledTexHeight = texHeight*heightScale\n",
    "#         scaledTexWidth = scaledTexHeight*billboardWidth/billboardHeight#texWidth*widthScale\n",
    "#         print(frameIdx, scaledTexWidth, scaledTexHeight)\n",
    "#     ######################### SCALE COMPENSATION BASED ON WIDTH OF PATCH BILLBOARD PROJECTS TO IN CAMERA SPACE ######################### (PROBABLY OBSOLETE NOW)\n",
    "#     else :\n",
    "#         billboardWidth = np.max(screenFootprintBillboardVertices[:, 0]) - np.min(screenFootprintBillboardVertices[:, 0])\n",
    "#         billboardHeight = np.max(screenFootprintBillboardVertices[:, 1]) - np.min(screenFootprintBillboardVertices[:, 1])\n",
    "#         patchScale = billboardWidth/maxBillboardWidth\n",
    "#         print(frameIdx, billboardWidth, maxBillboardWidth, patchScale)\n",
    "#         scaledTexHeight = texHeight*patchScale\n",
    "#         scaledTexWidth = texWidth*patchScale\n",
    "    \n",
    "#     ## when defining the rectangle in texture space, need to make sure that it uses the same conventions as screenBillboardVertices, which in this case, it means y goes down and x goes left\n",
    "#     billboardHomography = cv2.findHomography(screenBillboardVertices[[0, 2, 4, 1], :], np.array([[texWidth-(texWidth-scaledTexWidth)/2.0, texHeight-(texHeight-scaledTexHeight)/2.0],\n",
    "#                                                                                                  [(texWidth-scaledTexWidth)/2.0, texHeight-(texHeight-scaledTexHeight)/2.0],\n",
    "#                                                                                                  [(texWidth-scaledTexWidth)/2.0, (texHeight-scaledTexHeight)/2.0],\n",
    "#                                                                                                  [texWidth-(texWidth-scaledTexWidth)/2.0, (texHeight-scaledTexHeight)/2.0]], dtype=float))[0]\n",
    "#     tmp = cv2.warpPerspective(np.concatenate([patchImage, patchAlpha.reshape([patchAlpha.shape[0], patchAlpha.shape[1], 1])], axis=-1), billboardHomography, (int(np.ceil(texWidth)), int(np.ceil(texHeight))))\n",
    "# #     figure(); imshow(tmp)\n",
    "# #     print(tmp.shape, billboardWidth, billboardHeight, texWidth)\n",
    "# #     print(screenBillboardVertices)\n",
    "\n",
    "# #     print(frameIdx)\n",
    "    \n",
    "#     visiblePixels = np.argwhere(tmp[:, :, -1] != 0)\n",
    "    \n",
    "#     colors = np.concatenate([tmp[visiblePixels[:, 0], visiblePixels[:, 1], :], np.ones([len(visiblePixels), 1])*255], axis=1).astype(np.uint8)\n",
    "\n",
    "#     updatedPatches[patchKey] = {'top_left_pos':np.zeros(2, int), 'sprite_colors':colors[:, [2, 1, 0, 3]],\n",
    "#                                 'visible_indices': visiblePixels, 'patch_size': np.array([int(np.ceil(texHeight)), int(np.ceil(texWidth))], int)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 383.805239547 0.799670991879 1.15625 1.54244897933 1.15625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa9b6850550>]"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(texWidth, texHeight, billboardWidth, billboardHeight, maxBillboardWidth, maxBillboardHeight)\n",
    "# tmpBillboard = GLBillboard(np.zeros([texHeight, texWidth, 4], np.uint8), 1.0, modelMat=billboardModelMat)\n",
    "# tmpWorldBillboardVertices = np.dot(tmpBillboard.modelMat, np.concatenate([tmpBillboard.vertices, np.ones([len(tmpBillboard.vertices), 1])], axis=1).T).T[:, :-1]\n",
    "# ## this could be done with one matrix computation but cba right now\n",
    "# tmpScreenBillboardVertices = np.zeros([len(tmpWorldBillboardVertices), 2])\n",
    "# for i, vertex in enumerate(tmpWorldBillboardVertices) :\n",
    "#     tmpScreenBillboardVertices[i, :] = worldToScreenSpace(viewMat, projectionMat, vertex, width, height)\n",
    "    \n",
    "# tmpBillboardHomography = cv2.findHomography(np.array([[texWidth, texHeight], [0, texHeight], [0, 0], [texWidth, 0]], dtype=float), tmpScreenBillboardVertices[[0, 2, 4, 1], :])[0]\n",
    "\n",
    "# tmp = cv2.warpPerspective(patchColors, tmpBillboardHomography, (int(compositedImage.shape[1]), int(compositedImage.shape[0])))\n",
    "# figure(); imshow(tmp)\n",
    "# figure(); imshow(compositedImage)\n",
    "# xlim([0, medianImage.shape[1]])\n",
    "# ylim([medianImage.shape[0], 0])\n",
    "# plot(tmpScreenBillboardVertices[[0, 1, 4, 2, 0], 0], tmpScreenBillboardVertices[[0, 1, 4, 2, 0], 1], color='magenta', linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.33681464195\n",
      "1.1538241211\n"
     ]
    }
   ],
   "source": [
    "# print(np.linalg.norm(tmpWorldBillboardVertices[0, :]-tmpWorldBillboardVertices[2, :]))\n",
    "# print(maxBillboardWidth/np.linalg.norm(tmpWorldBillboardVertices[0, :]-tmpWorldBillboardVertices[2, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.15625\n"
     ]
    }
   ],
   "source": [
    "# print(np.linalg.norm(tmpWorldBillboardVertices[4, :]-tmpWorldBillboardVertices[2, :]))\n",
    "# print(maxBillboardHeight/np.linalg.norm(tmpWorldBillboardVertices[4, :]-tmpWorldBillboardVertices[2, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f75f41244d0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tmp = updatedPatches[np.sort(updatedPatches.keys())[-1]]\n",
    "# patchColors = np.zeros(np.concatenate([tmp['patch_size'], [4]]), dtype=np.uint8)\n",
    "# patchColors[tmp['visible_indices'][:, 0], tmp['visible_indices'][:, 1], :] = tmp['sprite_colors'][:, [2, 1, 0, 3]]\n",
    "# figure(); imshow(patchColors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDf;asdhfgasrdgoadjfg True\n",
      "BIATCH\n",
      "[ 454.49999224  779.49999395  642.98472748  637.45065973]\n",
      "[348 707 348 873]\n",
      "BIATCH1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75ecfcbf90>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### VISUALIZE BILLBOARD AND STUFF ###\n",
    "# (billboardWidth, billboardHeight, cameraPos, cameraOrientDirPos, cameraUpDirPos, cameraDirLeftIntersection,\n",
    "#  cameraDirRightIntersection, cameraUpDirTopIntersection, cameraUpDirBottomIntersection, cameraClosestPointsToIntersection) = findBillboardSize(worldPos, worldOrientDir, worldUpDir, projectionMat,\n",
    "#                                                                                                                                                viewMat, np.dot(cameraIntrinsics, cameraExtrinsics[:-1, [0, 1, 3]]),\n",
    "#                                                                                                                                                patchData, width, height, verbose, True)\n",
    "\n",
    "# compositedImage = np.copy(medianImage)\n",
    "# patchColors = np.zeros(np.concatenate([patchData['patch_size'], [4]]), dtype=np.uint8)\n",
    "# patchColors[patchData['visible_indices'][:, 0], patchData['visible_indices'][:, 1], :] = patchData['sprite_colors'][:, [2, 1, 0, 3]]\n",
    "\n",
    "# compositedImage[patchData['top_left_pos'][0]:patchData['top_left_pos'][0]+patchData['patch_size'][0],\n",
    "#                 patchData['top_left_pos'][1]:patchData['top_left_pos'][1]+patchData['patch_size'][1], :] = (compositedImage[patchData['top_left_pos'][0]:patchData['top_left_pos'][0]+patchData['patch_size'][0],\n",
    "#                                                                                                                             patchData['top_left_pos'][1]:patchData['top_left_pos'][1]+patchData['patch_size'][1], :]*\n",
    "#                                                                                                            (1.0-patchColors[:, :, -1]/255.0).reshape([patchColors.shape[0], patchColors.shape[1], 1]) +\n",
    "#                                                                                                            patchColors[:, :, :-1]*(patchColors[:, :, -1]/255.0).reshape([patchColors.shape[0], patchColors.shape[1], 1]))\n",
    "\n",
    "\n",
    "# figure(); imshow(compositedImage)\n",
    "# xlim([0, medianImage.shape[1]])\n",
    "# ylim([medianImage.shape[0], 0])\n",
    "# # xlim([(medianImage.shape[1]-1280)/2, 1280+(medianImage.shape[1]-1280)/2])\n",
    "# # ylim([720+(medianImage.shape[0]-720)/2, (medianImage.shape[0]-720)/2])\n",
    "\n",
    "# scatter(trajectory.cameraTrajectoryPoints[:, 0], trajectory.cameraTrajectoryPoints[:, 1], color=tuple(trajectory.drawColor/255.0), marker='o', facecolors='none', s=90)\n",
    "# scatter(trajectoryPoints[:, 0], trajectoryPoints[:, 1], color='red', marker='x', s=90)\n",
    "# plot([cameraPos[0], cameraOrientDirPos[0]], [cameraPos[1], cameraOrientDirPos[1]], color='yellow', linewidth=2)\n",
    "# plot([cameraPos[0], cameraUpDirPos[0]], [cameraPos[1], cameraUpDirPos[1]], color='yellow', linewidth=2)\n",
    "# plot([patchData['top_left_pos'][1], patchData['top_left_pos'][1], patchData['top_left_pos'][1]+patchData['patch_size'][1],\n",
    "#       patchData['top_left_pos'][1]+patchData['patch_size'][1], patchData['top_left_pos'][1]], [patchData['top_left_pos'][0], patchData['top_left_pos'][0]+patchData['patch_size'][0],\n",
    "#                                                                                                patchData['top_left_pos'][0]+patchData['patch_size'][0], patchData['top_left_pos'][0],\n",
    "#                                                                                                patchData['top_left_pos'][0]], color='red', linewidth=2)\n",
    "\n",
    "# scatter([cameraDirLeftIntersection[0], cameraDirRightIntersection[0], cameraUpDirTopIntersection[0], cameraUpDirBottomIntersection[0]],\n",
    "#         [cameraDirLeftIntersection[1], cameraDirRightIntersection[1], cameraUpDirTopIntersection[1], cameraUpDirBottomIntersection[1]], color='blue', s=90)\n",
    "# scatter([cameraClosestPointsToIntersection[:, 0]], [cameraClosestPointsToIntersection[:, 1]], color=\"yellow\", marker=\"x\", s=90)\n",
    "# plot(screenBillboardVertices[[0, 1, 4, 2, 0], 0], screenBillboardVertices[[0, 1, 4, 2, 0], 1], color='magenta', linewidth=2)\n",
    "# plot(screenFootprintBillboardVertices[[0, 1, 4, 2, 0], 0], screenFootprintBillboardVertices[[0, 1, 4, 2, 0], 1], color='cyan', linewidth=2)\n",
    "\n",
    "# # xlim([patchData['top_left_pos'][1]-patchData['patch_size'][1]*0.5, patchData['top_left_pos'][1]+patchData['patch_size'][1]*1.5])\n",
    "# # ylim([patchData['top_left_pos'][0]+patchData['patch_size'][0]*1.5, patchData['top_left_pos'][0]-patchData['patch_size'][0]*0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24267578125\n"
     ]
    }
   ],
   "source": [
    "# # SAVE THE UPDATED PATCHES AND UPDATE THE FILMED OBJECT DICTIONARY TO INCLUDE THE CORRECT PATH AND ORIENTATION ANGLES\n",
    "# patchesName = \"thresh_camera_adjusted_using_billboard_homography_scale-based-on-maxsize-world-billboard_preloaded_patches-\"\n",
    "# updatedPatchesLoc = filmedSceneData[DICT_FILMED_SCENE_BASE_LOC]+patchesName+\"{}.npy\".format(filmedObjectData[DICT_FILMED_OBJECT_NAME])\n",
    "# np.save(updatedPatchesLoc, updatedPatches)\n",
    "# filmedObjectData[DICT_PATCHES_LOCATION] = updatedPatchesLoc\n",
    "\n",
    "# orientationAngles = np.zeros(len(usedOrientationsAndSizes))\n",
    "# for frameIdx in np.arange(len(usedOrientationsAndSizes)) :\n",
    "#     worldPos = np.copy(trajectory.worldTrajectoryPoints[frameIdx, :])\n",
    "#     worldMovingDir = np.copy(trajectory.worldTrajectoryDirections[frameIdx, :])\n",
    "#     worldMoveNormalDir = np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(np.pi/2, np.array([0.0, 0.0, 1.0]))), np.concatenate([worldMovingDir, [1]]))\n",
    "#     worldMoveNormalDir = worldMoveNormalDir[:-1]/np.linalg.norm(worldMoveNormalDir[:-1])\n",
    "#     worldOrientDir, billboardWidth, billboardHeight, dirMultiplier = usedOrientationsAndSizes[frameIdx]\n",
    "#     ## check if the chosen orienation direction is the opposite of the moving direction in which case, the desired angle should be 0.0 (I will add the 180.0 to flip it later on when checking the adjust axis)\n",
    "#     if np.sum(np.sqrt((worldMovingDir+worldOrientDir)**2)) < 1e-10 :\n",
    "#         adjustAngle = 0.0\n",
    "#     else :\n",
    "#         adjustAngle = np.arccos(np.clip(np.dot(worldMovingDir, worldOrientDir), -1, 1))\n",
    "#     ## if the adjust angle is not 0, it means I'm picking the normal to the trajectory as orientation and thus I can compute the adjust axis (which will tell me if I need to flip)\n",
    "#     if adjustAngle != 0.0 :\n",
    "#         adjustAxis = np.cross(worldOrientDir, worldMovingDir)\n",
    "#         adjustAxis /= np.linalg.norm(adjustAxis)\n",
    "#     ## otherwise the adjust axis depends on the dirMultiplier which tells me whether I need to flip the billboard oriented using the tangent to the trajectory\n",
    "#     else :\n",
    "#         adjustAxis = np.array([0.0, 0.0, dirMultiplier])\n",
    "#     orientationAngles[frameIdx] = adjustAngle\n",
    "#     ## I can achieve the same rotation as using the flipped z axis, by adding 180 degrees to the current rotation\n",
    "#     if adjustAxis[-1] < 0.0 :\n",
    "#         orientationAngles[frameIdx] += np.pi\n",
    "# filmedObjectData[DICT_OBJECT_BILLBOARD_ORIENTATION] = orientationAngles\n",
    "# ## the scale of the billboard is the same as maxBillboardHeight because the way I define billboards in my app is by keeping the height fixed to 1 and setting the width based on the aspect ratio of the \n",
    "# ## texture; the size of the texture is based on maxBillboardHeight and maxBillboardWidth and all patches are mapped to the exact same size texture; then I map the smallest billboard size for each frame to a rectangle\n",
    "# ## centerd within the texture, with the same aspect ratio and scaled down to make sure that its height is the same relative to maxBillboardHeight; it's analogous to instead always mapping the max size billboard to the \n",
    "# ## texture rectangle (which would probably be easier in retrospect); the problem is then that I always map a billboard of height maxBillboardHeight and correct aspect ratio, to the texture rectangle with the same \n",
    "# ## aspect ratio, but if I just use the default GLBillboard, I artificially map the texture onto a bigger or smaller billboard than the one used when it was computed, resulting in bigger or smaller sprites; to solve this\n",
    "# ## then, all I need to do is scale the whole GLBillboard using maxBillboardHeight which will uniformly scale the full billboard to have the correct height and aspect ratio; alternatively, I could have computed the\n",
    "# ## max billboard size to get the aspect ratio and then used a billboard of height=1 and of width=ratio and mapped that to the texture rectangle and then I wouldn't have had to scale the GLBillboard\n",
    "# filmedObjectData[DICT_OBJECT_BILLBOARD_SCALE] = maxBillboardHeight\n",
    "# print(maxBillboardHeight)\n",
    "\n",
    "\n",
    "# filmedObjectData[DICT_TRAJECTORY_POINTS] = trajectoryPoints + originalIntrinsics[:2, -1] - cameraIntrinsics[:2, -1]\n",
    "# np.save(np.sort(glob.glob(filmedSceneLoc+\"filmed_object-*.npy\"))[filmedObjectIdx], filmedObjectData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(len(np.load(np.sort(glob.glob(filmedSceneLoc+\"filmed_object-*.npy\"))[filmedObjectIdx]).item()[DICT_TRAJECTORY_POINTS]))\n",
    "# print(np.load(np.sort(glob.glob(filmedSceneLoc+\"filmed_object-*.npy\"))[filmedObjectIdx]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(len(filmedObjectData[DICT_TRAJECTORY_POINTS]))\n",
    "# print(filmedObjectData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW MAX WIDTH 0 22.52330697\n",
      "NEW MAX HEIGHT 0 0.330078125\n",
      "0 1607 22.52330697 0.330078125 22.52330697 0.330078125 0 0 0.0 0.0\n",
      "NEW MAX HEIGHT 1 0.337890625\n",
      "1 1608 21.382423778 0.337890625 22.52330697 0.337890625 0 0 0.0 0.0\n",
      "NEW MAX HEIGHT 2 0.3427734375\n",
      "2 1609 21.3982617262 0.3427734375 22.52330697 0.3427734375 0 0 0.0 0.0\n",
      "NEW MAX HEIGHT 3 0.34716796875\n",
      "3 1610 21.123937558 0.34716796875 22.52330697 0.34716796875 0 0 0.0 0.0\n",
      "NEW MAX WIDTH 4 24.3448384556\n",
      "NEW MAX HEIGHT 4 0.3515625\n",
      "4 1611 24.3448384556 0.3515625 24.3448384556 0.3515625 0 0 0.0 0.0\n",
      "NEW MAX WIDTH 5 25.6122250419\n",
      "NEW MAX HEIGHT 5 0.3564453125\n",
      "5 1612 25.6122250419 0.3564453125 25.6122250419 0.3564453125 0 0 0.0 0.0\n",
      "NEW MAX WIDTH 6 25.6283764582\n",
      "NEW MAX HEIGHT 6 0.361328125\n",
      "6 1613 25.6283764582 0.361328125 25.6283764582 0.361328125 0 0 0.0 0.0\n",
      "NEW MAX WIDTH 7 33.4186914163\n",
      "NEW MAX HEIGHT 7 0.36572265625\n",
      "7 1614 33.4186914163 0.36572265625 33.4186914163 0.36572265625 0 0 0.0 0.0\n",
      "NEW MAX WIDTH 8 33.4349402865\n",
      "NEW MAX HEIGHT 8 0.3701171875\n",
      "8 1615 33.4349402865 0.3701171875 33.4349402865 0.3701171875 0 0 0.0 0.0\n",
      "NEW MAX WIDTH 9 33.4484805212\n",
      "NEW MAX HEIGHT 9 0.375\n",
      "9 1616 33.4484805212 0.375 33.4484805212 0.375 0 0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AttributeError: \"GLBillboard instance has no attribute 'tex'\" in <bound method GLBillboard.__del__ of <__main__.GLBillboard instance at 0x7f0c247f2a28>> ignored\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-8298358651d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mbillboardModelMat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworldPos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mbillboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGLBillboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbillboardWidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbillboardHeight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbillboardHeight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelMat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbillboardModelMat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mworldBillboardVertices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbillboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelMat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbillboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbillboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d020999153c9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img, scale, modelMat, isFrontoParallel, rotateAboutPlaneNormal, normalizeToPixelSize)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelMat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetTexture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetGeometryAndBuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d020999153c9>\u001b[0m in \u001b[0;36msetTexture\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetTexture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mpossibleTexSizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1204\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mtexSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpossibleTexSizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibleTexSizes\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtexSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# height, width = medianImage.shape[:2]\n",
    "# viewMat, projectionMat = cvCameraToOpenGL(cameraExtrinsics, cameraIntrinsics, medianImage.shape)\n",
    "# verbose = False\n",
    "\n",
    "\n",
    "# updatedPatches = {}\n",
    "\n",
    "# doFindMaxBillboardSize = True\n",
    "# if doFindMaxBillboardSize :\n",
    "#     maxBillboardWidth = 0\n",
    "#     maxBillboardHeight = 0\n",
    "# for patchIdx in arange(len(np.sort(preloadedPatches.keys())[frameSubset[0]:frameSubset[1]-1]))[0:] :\n",
    "#     patchKey = np.sort(preloadedPatches.keys())[frameSubset[0]:frameSubset[1]-1][patchIdx]-1528+1607\n",
    "#     patchFrameName = \"frame-{0:05}.png\".format(patchKey+1)\n",
    "#     patchImage = np.array(Image.open(filmedSceneLoc+patchFrameName)).astype(np.uint8)\n",
    "#     patchImage = undistortImage(distortionParameter, distortionRatio, patchImage, originalIntrinsics)[0]\n",
    "#     patchAlpha = np.array(Image.open(objectData[DICT_MASK_LOCATION]+patchFrameName)).astype(np.uint8)\n",
    "#     patchAlpha = undistortImage(distortionParameter, distortionRatio, patchAlpha, originalIntrinsics)[0][:, :, -1]\n",
    "    \n",
    "# #     figure(); imshow(patchImage)\n",
    "#     ## threshold the alpha based on bg diff \n",
    "#     if True :\n",
    "#         visiblePixels = np.argwhere(patchAlpha != 0)\n",
    "#         diffs = np.sqrt(np.sum((patchImage[visiblePixels[:, 0], visiblePixels[:, 1], :] - medianImage[visiblePixels[:, 0], visiblePixels[:, 1], :])**2, axis=1))\n",
    "#         tmp = np.zeros([medianImage.shape[0], medianImage.shape[1]], np.uint8)\n",
    "#         tmp[visiblePixels[:, 0], visiblePixels[:, 1]] = diffs\n",
    "#         tmp = cv2.medianBlur(tmp, 7)\n",
    "#         tmp = tmp/float(np.max(tmp))\n",
    "#         med = np.median(tmp[visiblePixels[:, 0], visiblePixels[:, 1]])\n",
    "#         tmp[tmp<med*0.8] = 0\n",
    "#         tmp[tmp>0] = np.max(tmp)\n",
    "# #         figure(); imshow(tmp, clim=(0.0, np.max(tmp)))\n",
    "# #         figure(); imshow(patchAlpha)\n",
    "#         patchAlpha = (tmp/np.max(tmp)*255).astype(np.uint8)\n",
    "        \n",
    "\n",
    "#     visiblePixels = np.argwhere(patchAlpha != 0)\n",
    "#     topLeft = np.min(visiblePixels, axis=0)\n",
    "#     patchSize = np.max(visiblePixels, axis=0) - topLeft + 1\n",
    "\n",
    "#     colors = np.concatenate([patchImage[visiblePixels[:, 0], visiblePixels[:, 1], :], np.ones([len(visiblePixels), 1])*255], axis=1).astype(np.uint8)\n",
    "\n",
    "#     patchData = {'top_left_pos':topLeft, 'sprite_colors':colors[:, [2, 1, 0, 3]],\n",
    "#                  'visible_indices': visiblePixels-topLeft, 'patch_size': patchSize}\n",
    "\n",
    "#     # patchData = preloadedPatches[np.sort(preloadedPatches.keys())[frameSubset[0]:frameSubset[1]-1][0]]\n",
    "#     patchColors = np.zeros(np.concatenate([patchData['patch_size'], [4]]), dtype=np.uint8)\n",
    "#     patchColors[patchData['visible_indices'][:, 0], patchData['visible_indices'][:, 1], :] = patchData['sprite_colors'][:, [2, 1, 0, 3]]\n",
    "#     # figure(); imshow(patchColors)\n",
    "\n",
    "#     ## find billboard width and height\n",
    "#     worldPos = trajectory.worldTrajectoryPoints[patchIdx, :]\n",
    "#     worldOrientDir = trajectory.worldTrajectoryDirections[patchIdx, :]\n",
    "#     worldUpDir = np.array([0.0, 0.0, 1.0])\n",
    "#     billboardWidth, billboardHeight = findBillboardSize(worldPos, worldOrientDir, worldUpDir, projectionMat, viewMat, np.dot(cameraIntrinsics, cameraExtrinsics[:-1, [0, 1, 3]]), verbose)\n",
    "\n",
    "\n",
    "#     ########### ROTATE BILLBOARD TO ALIGN WITH MOVING DIRECTION AND PLACE AT POINT ON TRAJECTORY ###########\n",
    "#     billboardModelMat = quaternionTo4x4Rotation(angleAxisToQuaternion(np.pi/2.0, np.array([1.0, 0.0, 0.0])))\n",
    "#     adjustAngle = np.arccos(np.clip(np.dot(np.array([-1.0, 0.0, 0.0]), worldOrientDir), -1, 1))\n",
    "#     adjustAxis = np.cross(worldOrientDir, np.array([-1.0, 0.0, 0.0]))\n",
    "#     adjustAxis /= np.linalg.norm(adjustAxis)\n",
    "#     billboardModelMat = np.dot(quaternionTo4x4Rotation(angleAxisToQuaternion(adjustAngle, adjustAxis)), billboardModelMat)\n",
    "#     billboardModelMat[:-1, -1] = worldPos\n",
    "\n",
    "#     billboard = GLBillboard(np.zeros([10, 10*billboardWidth/billboardHeight, 4], np.uint8), billboardHeight, modelMat=billboardModelMat)\n",
    "\n",
    "#     worldBillboardVertices = np.dot(billboard.modelMat, np.concatenate([billboard.vertices, np.ones([len(billboard.vertices), 1])], axis=1).T).T[:, :-1]\n",
    "\n",
    "#     ## this could be done with one matrix computation but cba right now\n",
    "#     screenBillboardVertices = np.zeros([len(worldBillboardVertices), 2])\n",
    "#     for i, vertex in enumerate(worldBillboardVertices) :\n",
    "#         screenBillboardVertices[i, :] = worldToScreenSpace(viewMat, projectionMat, vertex, width, height)\n",
    "#     #     print(vertex, screenBillboardVertices[i, :])\n",
    "\n",
    "#     footprintBillboardModelMat = quaternionTo4x4Rotation(angleAxisToQuaternion(adjustAngle, adjustAxis))\n",
    "#     footprintBillboardModelMat[:-1, -1] = worldPos\n",
    "#     footprintBillboard = GLBillboard(np.zeros([1000*0.081, 1000*0.18, 4], np.uint8), 0.265, modelMat=footprintBillboardModelMat)\n",
    "#     worldFootprintBillboardVertices = np.dot(footprintBillboard.modelMat, np.concatenate([footprintBillboard.vertices, np.ones([len(footprintBillboard.vertices), 1])], axis=1).T).T[:, :-1]\n",
    "#     ## this could be done with one matrix computation but cba right now\n",
    "#     screenFootprintBillboardVertices = np.zeros([len(worldFootprintBillboardVertices), 2])\n",
    "#     for i, vertex in enumerate(worldFootprintBillboardVertices) :\n",
    "#         screenFootprintBillboardVertices[i, :] = worldToScreenSpace(viewMat, projectionMat, vertex, width, height)\n",
    "        \n",
    "#     texHeight = 0\n",
    "#     texWidth = 0\n",
    "#     if not doFindMaxBillboardSize :\n",
    "#         if maxBillboardWidth > maxBillboardHeight :\n",
    "#             texWidth = 512\n",
    "#             texHeight = texWidth*maxBillboardHeight/maxBillboardWidth\n",
    "#         else :\n",
    "#             texHeight = 512\n",
    "#             texWidth = texHeight*maxBillboardWidth/maxBillboardHeight#*billboardWidth/billboardHeight\n",
    "    \n",
    "#     ######################### SCALE COMPENSATION BASED ON BILLBOARD WIDTH IN WORLD SPACE #########################\n",
    "#     if True :\n",
    "#         if doFindMaxBillboardSize and billboardWidth > maxBillboardWidth :\n",
    "#             maxBillboardWidth = billboardWidth\n",
    "#             maxBillboardWidthOnHeight = billboardWidth/billboardHeight\n",
    "#             print(\"NEW MAX WIDTH\", patchIdx, maxBillboardWidth)\n",
    "#         if doFindMaxBillboardSize and billboardHeight > maxBillboardHeight :\n",
    "#             maxBillboardHeight = billboardHeight\n",
    "#             print(\"NEW MAX HEIGHT\", patchIdx, billboardHeight)\n",
    "#         widthScale = billboardWidth/maxBillboardWidth\n",
    "#         heightScale = billboardHeight/maxBillboardHeight\n",
    "# #         patchScale = patchScale*(billboardWidth/billboardHeight)/maxBillboardWidthOnHeight\n",
    "#         scaledTexHeight = texHeight*heightScale\n",
    "#         scaledTexWidth = scaledTexHeight*billboardWidth/billboardHeight#texWidth*widthScale\n",
    "#         print(patchIdx, patchKey, billboardWidth, billboardHeight, maxBillboardWidth, maxBillboardHeight, texHeight, texWidth, scaledTexHeight, scaledTexWidth)\n",
    "    \n",
    "#     ######################### SCALE COMPENSATION BASED ON WIDTH OF PATCH BILLBOARD PROJECTS TO IN CAMERA SPACE #########################\n",
    "#     else :\n",
    "#         billboardWidth = np.max(screenFootprintBillboardVertices[:, 0]) - np.min(screenFootprintBillboardVertices[:, 0])\n",
    "#         billboardHeight = np.max(screenFootprintBillboardVertices[:, 1]) - np.min(screenFootprintBillboardVertices[:, 1])\n",
    "#         if doFindMaxBillboardSize and billboardWidth > maxBillboardWidth :\n",
    "#             maxBillboardWidth = billboardWidth\n",
    "#             maxBillboardWidthOnHeight = billboardWidth/billboardHeight\n",
    "#             print(patchIdx, maxBillboardWidth)\n",
    "#         patchScale = billboardWidth/maxBillboardWidth\n",
    "\n",
    "# #         patchScale = patchScale*(billboardWidth/billboardHeight)/maxBillboardWidthOnHeight\n",
    "#         print(patchIdx, billboardWidth, maxBillboardWidth, patchScale)\n",
    "#         scaledTexHeight = texHeight*patchScale\n",
    "#         scaledTexWidth = texWidth*patchScale\n",
    "    \n",
    "# #     billboardHomography = cv2.findHomography(screenBillboardVertices[[2, 0, 1, 4], :], np.array([[0, 0], [texWidth, 0], [texWidth, texHeight], [0, texHeight]], dtype=float))[0]\n",
    "#     billboardHomography = cv2.findHomography(screenBillboardVertices[[2, 0, 1, 4], :], np.array([[(texWidth-scaledTexWidth)/2.0, (texHeight-scaledTexHeight)/2.0],\n",
    "#                                                                                                  [texWidth-(texWidth-scaledTexWidth)/2.0, (texHeight-scaledTexHeight)/2.0],\n",
    "#                                                                                                  [texWidth-(texWidth-scaledTexWidth)/2.0, texHeight-(texHeight-scaledTexHeight)/2.0],\n",
    "#                                                                                                  [(texWidth-scaledTexWidth)/2.0, texHeight-(texHeight-scaledTexHeight)/2.0]], dtype=float))[0]\n",
    "#     tmp = cv2.warpPerspective(np.concatenate([patchImage, patchAlpha.reshape([patchAlpha.shape[0], patchAlpha.shape[1], 1])], axis=-1), billboardHomography, (int(np.ceil(texWidth)), int(np.ceil(texHeight))))\n",
    "# #     figure(); imshow(tmp)\n",
    "# #     print(tmp.shape, billboardWidth, billboardHeight, texWidth)\n",
    "# #     print(screenBillboardVertices)\n",
    "# #     print(patchIdx)\n",
    "    \n",
    "#     visiblePixels = np.argwhere(tmp[:, :, -1] != 0)\n",
    "    \n",
    "#     colors = np.concatenate([tmp[visiblePixels[:, 0], visiblePixels[:, 1], :], np.ones([len(visiblePixels), 1])*255], axis=1).astype(np.uint8)\n",
    "# #     print(colors.shape)\n",
    "\n",
    "#     updatedPatches[patchKey] = {'top_left_pos':np.zeros(2, int), 'sprite_colors':colors[:, [2, 1, 0, 3]],\n",
    "#                                 'visible_indices': visiblePixels, 'patch_size': np.array([int(np.ceil(texHeight)), int(np.ceil(texWidth))], int)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.save(\"/home/ilisescu/PhD/data/havana/thresh_camera_adjusted_using_billboard_homography_scale-based-on-maxsize-world-billboard_preloaded_patches-white_bus1.npy\", updatedPatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faa52dd1910>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compositedImage = np.copy(medianImage)\n",
    "# patchColors = np.zeros(np.concatenate([patchData['patch_size'], [4]]), dtype=np.uint8)\n",
    "# patchColors[patchData['visible_indices'][:, 0], patchData['visible_indices'][:, 1], :] = patchData['sprite_colors'][:, [2, 1, 0, 3]]\n",
    "\n",
    "# compositedImage[patchData['top_left_pos'][0]:patchData['top_left_pos'][0]+patchData['patch_size'][0],\n",
    "#                 patchData['top_left_pos'][1]:patchData['top_left_pos'][1]+patchData['patch_size'][1], :] = (compositedImage[patchData['top_left_pos'][0]:patchData['top_left_pos'][0]+patchData['patch_size'][0],\n",
    "#                                                                                                                             patchData['top_left_pos'][1]:patchData['top_left_pos'][1]+patchData['patch_size'][1], :]*\n",
    "#                                                                                                            (1.0-patchColors[:, :, -1]/255.0).reshape([patchColors.shape[0], patchColors.shape[1], 1]) +\n",
    "#                                                                                                            patchColors[:, :, :-1]*(patchColors[:, :, -1]/255.0).reshape([patchColors.shape[0], patchColors.shape[1], 1]))\n",
    "\n",
    "\n",
    "# figure(); imshow(compositedImage)\n",
    "# xlim([0, medianImage.shape[1]])\n",
    "# ylim([medianImage.shape[0], 0])\n",
    "# # xlim([(medianImage.shape[1]-1280)/2, 1280+(medianImage.shape[1]-1280)/2])\n",
    "# # ylim([720+(medianImage.shape[0]-720)/2, (medianImage.shape[0]-720)/2])\n",
    "\n",
    "# scatter(trajectory.cameraTrajectoryPoints[:, 0], trajectory.cameraTrajectoryPoints[:, 1], color=tuple(trajectory.drawColor/255.0), marker='o', facecolors='none', s=90)\n",
    "# scatter(trajectoryPoints[:, 0], trajectoryPoints[:, 1], color='red', marker='x', s=90)\n",
    "# plot([cameraPos[0], cameraDirPos[0]], [cameraPos[1], cameraDirPos[1]], color='yellow', linewidth=2)\n",
    "# plot([cameraPos[0], cameraUpDirPos[0]], [cameraPos[1], cameraUpDirPos[1]], color='yellow', linewidth=2)\n",
    "# plot([patchData['top_left_pos'][1], patchData['top_left_pos'][1], patchData['top_left_pos'][1]+patchData['patch_size'][1],\n",
    "#       patchData['top_left_pos'][1]+patchData['patch_size'][1], patchData['top_left_pos'][1]], [patchData['top_left_pos'][0], patchData['top_left_pos'][0]+patchData['patch_size'][0],\n",
    "#                                                                                                  patchData['top_left_pos'][0]+patchData['patch_size'][0], patchData['top_left_pos'][0],\n",
    "#                                                                                                  patchData['top_left_pos'][0]], color='red', linewidth=2)\n",
    "\n",
    "# scatter([cameraDirLeftIntersection[0], cameraDirRightIntersection[0], cameraUpDirTopIntersection[0], cameraUpDirBottomIntersection[0]],\n",
    "#         [cameraDirLeftIntersection[1], cameraDirRightIntersection[1], cameraUpDirTopIntersection[1], cameraUpDirBottomIntersection[1]], color='blue', s=90)\n",
    "# scatter([cameraClosestPointsToIntersection[:, 0]], [cameraClosestPointsToIntersection[:, 1]], color=\"yellow\", marker=\"x\", s=90)\n",
    "# plot(screenBillboardVertices[[0, 1, 4, 2, 0], 0], screenBillboardVertices[[0, 1, 4, 2, 0], 1], color='magenta', linewidth=2)\n",
    "# plot(screenFootprintBillboardVertices[[0, 1, 4, 2, 0], 0], screenFootprintBillboardVertices[[0, 1, 4, 2, 0], 1], color='cyan', linewidth=2)\n",
    "\n",
    "# xlim([patchData['top_left_pos'][1]-patchData['patch_size'][1]*0.5, patchData['top_left_pos'][1]+patchData['patch_size'][1]*1.5])\n",
    "# ylim([patchData['top_left_pos'][0]+patchData['patch_size'][0]*1.5, patchData['top_left_pos'][0]-patchData['patch_size'][0]*0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR GETTING CAMERA MATRICES FOR NUKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filmedSceneLoc = \"/media/ilisescu/Data1/PhD/data/theme_park_sunny/\"\n",
    "# filmedSceneData = np.load(filmedSceneLoc+\"filmed_scene-theme_park_sunny.npy\").item()\n",
    "filmedSceneLoc = \"/home/ilisescu/PhD/data/havana/\"\n",
    "filmedSceneData = np.load(filmedSceneLoc+\"filmed_scene-havana.npy\").item()\n",
    "cameraExtrinsics = filmedSceneData[DICT_CAMERA_EXTRINSICS]\n",
    "\n",
    "cameraIntrinsics = filmedSceneData[DICT_CAMERA_INTRINSICS]\n",
    "originalIntrinsics = np.copy(cameraIntrinsics)\n",
    "\n",
    "medianImage = np.array(Image.open(filmedSceneLoc+\"median.png\"), np.uint8)\n",
    "distortionParameter = filmedSceneData[DICT_DISTORTION_PARAMETER]\n",
    "distortionRatio = filmedSceneData[DICT_DISTORTION_RATIO]\n",
    "medianImage, cameraIntrinsics, distortionCoeff, _, _ = undistortImage(distortionParameter, distortionRatio, medianImage, cameraIntrinsics)\n",
    "viewMat, projectionMat = cvCameraToOpenGL(cameraExtrinsics, cameraIntrinsics, medianImage.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 702.736053      0.          828.        ]\n",
      " [   0.          702.30871163  466.        ]\n",
      " [   0.            0.            1.        ]]\n",
      "[[ 702.736053    0.        640.      ]\n",
      " [   0.        702.736053  360.      ]\n",
      " [   0.          0.          1.      ]]\n",
      "67.1306062333 702.308711626 316.038920232 (932, 1656, 3) 1.77682403433 1.77777777778\n"
     ]
    }
   ],
   "source": [
    "## finding focal length to use in nuke\n",
    "np.dot(viewMat, np.linalg.inv(viewMat)[:, -1].reshape([4, 1]))\n",
    "print(cameraIntrinsics)\n",
    "print(originalIntrinsics)\n",
    "vFov = np.arctan2(1.0, projectionMat[1, 1])*2.0*180.0/np.pi\n",
    "vFocalLen = cameraIntrinsics[1, -1]*2/(2.0*np.tan(np.pi*vFov/360.0))\n",
    "print(vFov, vFocalLen, vFocalLen*20.25/cameraIntrinsics[1, -1]*2*(cameraIntrinsics[1, -1]*2/originalIntrinsics[1, -1]*2),\n",
    "      medianImage.shape, cameraIntrinsics[0, -1]*2/(cameraIntrinsics[1, -1]*2), originalIntrinsics[0, -1]*2/(originalIntrinsics[1, -1]*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print Exception(\"lalala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.22377173e-03   1.64274416e-03  -1.85045216e+00]\n",
      " [  6.64174320e-04  -4.00180580e-03   8.53355722e-01]\n",
      " [  2.39493979e-05   5.58535603e-04  -8.81732211e-02]]\n",
      "[ 0.13092548 -1.77040281  1.        ]\n",
      "[[ 702.736053      0.          828.        ]\n",
      " [   0.          702.30871163  466.        ]\n",
      " [   0.            0.            1.        ]]\n"
     ]
    }
   ],
   "source": [
    "## NEED this to compute the location and projection of the footprint\n",
    "inverseT = np.linalg.inv(np.dot(cameraIntrinsics, cameraExtrinsics[:-1, [0, 1, 3]]))\n",
    "print(inverseT)\n",
    "print(np.dot(inverseT, np.array([928.83824361, 449.23967789, 1.0]))/np.dot(inverseT, np.array([928.83824361, 449.23967789, 1.0]))[-1])\n",
    "print(cameraIntrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.82004584  0.52716595  0.22275754  2.37328686]\n",
      " [ 0.57100067 -0.72747234 -0.38045006 -6.19493611]\n",
      " [-0.03851036  0.43918118 -0.89757275  2.28818292]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[[ 0.82004583 -0.22275755  0.52716595  2.37328696]\n",
      " [ 0.5710007   0.38045007 -0.72747236 -6.19493628]\n",
      " [-0.03851036  0.89757276  0.43918118  2.28818297]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[[ 0.82004583  0.22275755 -0.52716595  2.37328696]\n",
      " [ 0.5710007  -0.38045007  0.72747236 -6.19493628]\n",
      " [-0.03851036 -0.89757276 -0.43918118  2.28818297]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "\n",
      "\n",
      "67.1306062333\n",
      "\n",
      "[[-0.43918118  0.03851036 -0.89757276 -2.28818297]\n",
      " [ 0.52716595  0.82004583 -0.22275755  2.37328696]\n",
      " [ 0.72747236 -0.5710007  -0.38045007  6.19493628]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "\n",
      "[[-0.43918118  0.03851036 -0.89757276 -2.28818297]\n",
      " [ 0.52716595  0.82004583 -0.22275755  2.37328696]\n",
      " [ 0.72747236 -0.5710007  -0.38045007  6.19493628]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "\n",
      "[[ 0.82004583 -0.22275755  0.52716595  2.37328696]\n",
      " [ 0.5710007   0.38045007 -0.72747236 -6.19493628]\n",
      " [-0.03851036  0.89757276  0.43918118  2.28818297]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[[ 0.82004583  0.5710007  -0.03851036  1.67922759]\n",
      " [-0.22275752  0.38045004  0.89757276  0.83172053]\n",
      " [ 0.52716589 -0.72747231  0.43918118 -6.76268721]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[[ 0.82004583 -0.22275755  0.52716595  2.37328696]\n",
      " [-0.03851036  0.89757276  0.43918118  2.28818297]\n",
      " [-0.5710007  -0.38045007  0.72747236  6.19493628]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "## trying to get the model mat for a camera in Nuke's coordinate system\n",
    "print(np.linalg.inv(np.dot(np.array([[1, 0, 0, 0],\n",
    "                                     [0, np.cos(np.pi/2.0), -np.sin(np.pi/2.0), 0],\n",
    "                                     [0, np.sin(np.pi/2.0), np.cos(np.pi/2.0), 0],\n",
    "                                     [0, 0, 0, 1]]), cameraExtrinsics)))\n",
    "print(np.linalg.inv(viewMat))\n",
    "print(np.linalg.inv(cameraExtrinsics))\n",
    "print(\"\\n\")\n",
    "## camera transform matrix is the inverse of the cameraExtrinsics which is defined in my custom coordinate system with z up\n",
    "## rotate by 90 around z axis\n",
    "tMat1 = np.array([[np.cos(np.pi/2.0), -np.sin(np.pi/2.0), 0, 0],\n",
    "                  [np.sin(np.pi/2.0), np.cos(np.pi/2.0), 0, 0],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1]])\n",
    "## rotate by -90 around x axis\n",
    "tMat2 = np.array([[1, 0, 0, 0],\n",
    "                  [0, np.cos(-np.pi/2.0), -np.sin(-np.pi/2.0), 0],\n",
    "                  [0, np.sin(-np.pi/2.0), np.cos(-np.pi/2.0), 0],\n",
    "                  [0, 0, 0, 1]])\n",
    "## rotate by 90 around y axis\n",
    "tMat3 = np.array([[np.cos(np.pi/2.0), 0, np.sin(np.pi/2.0), 0],\n",
    "                  [0, 1, 0, 0],\n",
    "                  [-np.sin(np.pi/2.0), 0, np.cos(np.pi/2.0), 0],\n",
    "                  [0, 0, 0, 1]])\n",
    "print(np.arctan2(1.0, projectionMat[1, 1])*2.0*180.0/np.pi)\n",
    "# print()\n",
    "# print(np.dot(np.dot(tMat2, tMat1), np.linalg.inv(cameraExtrinsics)))\n",
    "# print()\n",
    "# print(np.dot(np.dot(tMat1, tMat3), np.linalg.inv(cameraExtrinsics)))\n",
    "# print()\n",
    "# print(np.dot(np.linalg.inv(np.dot(tMat2, tMat1)), np.linalg.inv(cameraExtrinsics)))\n",
    "# print()\n",
    "# print(np.dot(np.linalg.inv(np.dot(tMat1, tMat2)), np.linalg.inv(cameraExtrinsics)))\n",
    "# print()\n",
    "# print(np.dot(np.linalg.inv(cameraExtrinsics), np.linalg.inv(np.dot(tMat2, tMat1))))\n",
    "print()\n",
    "print(np.dot(np.dot(tMat1, np.dot(tMat2, np.dot(np.linalg.inv(cameraExtrinsics), np.linalg.inv(tMat2)))), np.linalg.inv(tMat1)))\n",
    "print()\n",
    "print(np.dot(np.dot(tMat1, tMat2), np.dot(np.linalg.inv(cameraExtrinsics), np.linalg.inv(np.dot(tMat1, tMat2)))))\n",
    "\n",
    "print()\n",
    "print(np.linalg.inv(viewMat))\n",
    "print(viewMat)\n",
    "# print(np.dot(np.linalg.inv(tMat2), np.linalg.inv(viewMat)))\n",
    "print(np.dot(tMat2, np.linalg.inv(viewMat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENTS FOR SMOOTHING TRAJECTORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def _vec2d_dist(p1, p2):\n",
    "#     return (p1[0] - p2[0])**2 + (p1[1] - p2[1])**2\n",
    "\n",
    "\n",
    "# def _vec2d_sub(p1, p2):\n",
    "#     return (p1[0]-p2[0], p1[1]-p2[1])\n",
    "\n",
    "\n",
    "# def _vec2d_mult(p1, p2):\n",
    "#     return p1[0]*p2[0] + p1[1]*p2[1]\n",
    "\n",
    "\n",
    "# def ramerdouglas(line, dist):\n",
    "#     \"\"\"Does Ramer-Douglas-Peucker simplification of a curve with `dist`\n",
    "#     threshold.\n",
    "\n",
    "#     `line` is a list-of-tuples, where each tuple is a 2D coordinate\n",
    "\n",
    "#     Usage is like so:\n",
    "\n",
    "#     >>> myline = [(0.0, 0.0), (1.0, 2.0), (2.0, 1.0)]\n",
    "#     >>> simplified = ramerdouglas(myline, dist = 1.0)\n",
    "#     \"\"\"\n",
    "\n",
    "#     if len(line) < 3:\n",
    "#         return line\n",
    "\n",
    "#     (begin, end) = (line[0], line[-1]) if line[0] != line[-1] else (line[0], line[-2])\n",
    "\n",
    "#     distSq = []\n",
    "#     for curr in line[1:-1]:\n",
    "#         tmp = (\n",
    "#             _vec2d_dist(begin, curr) - _vec2d_mult(_vec2d_sub(end, begin), _vec2d_sub(curr, begin)) ** 2 / _vec2d_dist(begin, end))\n",
    "#         distSq.append(tmp)\n",
    "\n",
    "#     maxdist = max(distSq)\n",
    "#     if maxdist < dist ** 2:\n",
    "#         return [begin, end]\n",
    "\n",
    "#     pos = distSq.index(maxdist)\n",
    "#     return (ramerdouglas(line[:pos + 2], dist) + \n",
    "#             ramerdouglas(line[pos + 1:], dist)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def spline_4p( t, p_1, p0, p1, p2 ):\n",
    "#     \"\"\" Catmull-Rom\n",
    "#         (Ps can be numpy vectors or arrays too: colors, curves ...)\n",
    "#     \"\"\"\n",
    "#         # wikipedia Catmull-Rom -> Cubic_Hermite_spline\n",
    "#         # 0 -> p0,  1 -> p1,  1/2 -> (- p_1 + 9 p0 + 9 p1 - p2) / 16\n",
    "#     # assert 0 <= t <= 1\n",
    "#     return (\n",
    "#           t*((2-t)*t - 1)   * p_1\n",
    "#         + (t*t*(3*t - 5) + 2) * p0\n",
    "#         + t*((4 - 3*t)*t + 1) * p1\n",
    "#         + (t-1)*t*t         * p2 ) / 2\n",
    "# tmp2 = [np.array([i[0], i[1]]) for i in tmp2]\n",
    "# numTs = 10.0\n",
    "# interpolatedPoints = []\n",
    "# for j in np.arange(1, len(tmp2)-2 ):  # skip the ends\n",
    "#     for t in np.arange(numTs):  # t: 0 .1 .2 .. .9\n",
    "#         p = spline_4p(t/numTs, tmp2[j-1], tmp2[j], tmp2[j+1], tmp2[j+2] )\n",
    "#         # draw p\n",
    "#         interpolatedPoints.append(p)\n",
    "        \n",
    "# interpolatedPoints = np.array(interpolatedPoints)        \n",
    "# plot(interpolatedPoints[:, 0], interpolatedPoints[:, 1], color=\"magenta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # import scipy.interpolate as si\n",
    "\n",
    "# points = [[i[0], i[1]] for i in tmp2] #[[0, 0], [0, 2], [2, 3], [4, 0], [6, 3], [8, 2], [8, 0]];\n",
    "# points = np.array(points)\n",
    "# x = points[:,0]\n",
    "# y = points[:,1]\n",
    "\n",
    "# t = range(len(points))\n",
    "# ipl_t = np.linspace(0.0, len(points) - 1, 100)\n",
    "\n",
    "# x_tup = si.splrep(t, x, k=3)\n",
    "# y_tup = si.splrep(t, y, k=3)\n",
    "\n",
    "# x_list = list(x_tup)\n",
    "# xl = x.tolist()\n",
    "# x_list[1] = xl + [0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "# y_list = list(y_tup)\n",
    "# yl = y.tolist()\n",
    "# y_list[1] = yl + [0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "# x_i = si.splev(ipl_t, x_list)\n",
    "# y_i = si.splev(ipl_t, y_list)\n",
    "\n",
    "# #==============================================================================\n",
    "# # Plot\n",
    "# #==============================================================================\n",
    "\n",
    "# fig = plt.figure()\n",
    "\n",
    "# ax = fig.add_subplot(231)\n",
    "# plt.plot(t, x, '-og')\n",
    "# plt.plot(ipl_t, x_i, 'r')\n",
    "# plt.xlim([0.0, max(t)])\n",
    "# plt.title('Splined x(t)')\n",
    "\n",
    "# ax = fig.add_subplot(232)\n",
    "# plt.plot(t, y, '-og')\n",
    "# plt.plot(ipl_t, y_i, 'r')\n",
    "# plt.xlim([0.0, max(t)])\n",
    "# plt.title('Splined y(t)')\n",
    "\n",
    "# ax = fig.add_subplot(233)\n",
    "# plt.plot(x, y, '-og')\n",
    "# plt.plot(x_i, y_i, 'r')\n",
    "# plt.xlim([min(x) - 0.3, max(x) + 0.3])\n",
    "# plt.ylim([min(y) - 0.3, max(y) + 0.3])\n",
    "# plt.title('Splined f(x(t), y(t))')\n",
    "\n",
    "# ax = fig.add_subplot(234)\n",
    "# for i in range(7):\n",
    "#     vec = np.zeros(11)\n",
    "#     vec[i] = 1.0\n",
    "#     x_list = list(x_tup)\n",
    "#     x_list[1] = vec.tolist()\n",
    "#     x_i = si.splev(ipl_t, x_list)\n",
    "#     plt.plot(ipl_t, x_i)\n",
    "# plt.xlim([0.0, max(t)])\n",
    "# plt.title('Basis splines')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def smoothDirections(filterSize, directions, useUniformWeights = False) :\n",
    "    coeff = special.binom(filterSize*2, range(0, filterSize*2 +1))\n",
    "    coeff /= np.sum(coeff)\n",
    "    ##\n",
    "    if useUniformWeights :\n",
    "        coeff = np.ones_like(coeff)/len(coeff)\n",
    "        \n",
    "    neighbourIdxs = np.arange(-filterSize, filterSize+1)\n",
    "    smoothed = np.copy(directions)\n",
    "    \n",
    "    for i, point in enumerate(directions) :\n",
    "        validIdxs = np.all(np.array([i+neighbourIdxs >= 0, i+neighbourIdxs < len(directions)]), axis=0)\n",
    "        closenessToEdge = filterSize*2+1-len(np.argwhere(validIdxs).flatten())\n",
    "        filterCoeffs = coeff[validIdxs]\n",
    "        filterCoeffs /= np.sum(filterCoeffs)\n",
    "        smoothed[i, :] = np.sum(directions[i+neighbourIdxs[validIdxs]]*filterCoeffs.reshape([len(filterCoeffs), 1]), axis=0)\n",
    "        smoothed[i, :] /= np.linalg.norm(smoothed[i, :])\n",
    "        if np.linalg.norm(smoothed[i, :]) != 1.0 and i > 0:\n",
    "            print(i, np.linalg.norm(smoothed[i, :]), smoothed[i, :])\n",
    "            smoothed[i, :] = smoothed[i-1, :]\n",
    "    \n",
    "    return smoothed\n",
    "\n",
    "# print(trajectory.worldTrajectoryDirections)\n",
    "# worldTrajectorySmoothDirections = smoothDirections(15, trajectory.worldTrajectoryDirections, True)\n",
    "# print(worldTrajectorySmoothDirections)\n",
    "# worldTrajectoryPointsDistances = np.ones(len(trajectory.worldTrajectoryPoints))*0.01\n",
    "# worldTrajectoryPointsDistances[:-1] = np.linalg.norm(trajectory.worldTrajectoryPoints[:-1, :]-trajectory.worldTrajectoryPoints[1:, :], axis=1)\n",
    "# worldTrajectoryPointsDistances = spimg.filters.gaussian_filter1d(worldTrajectoryPointsDistances, 11, axis=0)\n",
    "# print(worldTrajectoryPointsDistances.shape)\n",
    "# smoothedWorldTrajectoryPoints = np.zeros_like(trajectory.worldTrajectoryPoints)\n",
    "# smoothedWorldTrajectoryPoints[0, :] = trajectory.worldTrajectoryPoints[0, :]\n",
    "# for i in np.arange(1, len(smoothedWorldTrajectoryPoints)) :\n",
    "#     ## the smooth trajectory is found by moving the previous point along the smooth direction by the amount of space between the previous point and the current in the original trajectory\n",
    "# #     smoothedWorldTrajectoryPoints[i, :] = smoothedWorldTrajectoryPoints[i-1, :]+worldTrajectorySmoothDirections[i-1, :]*worldTrajectoryPointsDistances[i-1]\n",
    "\n",
    "#     ## the smooth trajectory is found by moving the previous point along the smooth direction by the amount of space between the previous point in the smooth trajectory and the current one in the original trajectory\n",
    "# #     smoothedWorldTrajectoryPoints[i, :] = smoothedWorldTrajectoryPoints[i-1, :]+worldTrajectorySmoothDirections[i-1, :]*np.linalg.norm(smoothedWorldTrajectoryPoints[i-1, :]-trajectory.worldTrajectoryPoints[i, :])\n",
    "\n",
    "#     ## the smooth trajectory is found by projecting the current point in the original trajectory onto the smooth direction\n",
    "#     a = smoothedWorldTrajectoryPoints[i-1, :]\n",
    "#     b = smoothedWorldTrajectoryPoints[i-1, :]+worldTrajectorySmoothDirections[i-1, :]\n",
    "#     p = trajectory.worldTrajectoryPoints[i, :]\n",
    "#     ap = p-a\n",
    "#     ab = b-a\n",
    "#     smoothedWorldTrajectoryPoints[i, :] = a + np.dot(ap,ab)/np.dot(ab,ab) * ab\n",
    "    \n",
    "# # smoothWorldTrajectoryPointsDistances = np.ones(len(smoothedWorldTrajectoryPoints))*0.01\n",
    "# # smoothWorldTrajectoryPointsDistances[:-1] = np.linalg.norm(smoothedWorldTrajectoryPoints[:-1, :]-smoothedWorldTrajectoryPoints[1:, :], axis=1)\n",
    "# # smoothWorldTrajectoryPointsDistances = spimg.filters.gaussian_filter1d(smoothWorldTrajectoryPointsDistances, 11, axis=0)\n",
    "\n",
    "# # for i in np.arange(1, len(smoothedWorldTrajectoryPoints)-1) :\n",
    "# #     ## the smooth trajectory is found by moving the previous point along the smooth direction by the amount of space between the previous point and the current in the original trajectory\n",
    "# #     smoothedWorldTrajectoryPoints[i, :] = smoothedWorldTrajectoryPoints[i-1, :]+worldTrajectorySmoothDirections[i-1, :]*smoothWorldTrajectoryPointsDistances[i-1]\n",
    "    \n",
    "\n",
    "# figure(); xlim(-1, 4); ylim(-6, -1)\n",
    "# # figure(); xlim(2.3, 2.9); ylim(-1.9, -2.3)\n",
    "# # figure(); xlim(-1, -0.5); ylim(-1.5, -1)\n",
    "# scatter(trajectory.worldTrajectoryPoints[:, 0], trajectory.worldTrajectoryPoints[:, 1], color=\"blue\", marker='o', facecolors='none')\n",
    "# scatter(smoothedWorldTrajectoryPoints[:, 0], smoothedWorldTrajectoryPoints[:, 1], color=\"magenta\", marker='x', s=100)\n",
    "# for i in xrange(len(worldTrajectorySmoothDirections)) :\n",
    "#     plot([trajectory.worldTrajectoryPoints[i, 0], trajectory.worldTrajectoryPoints[i, 0]+trajectory.worldTrajectoryDirections[i, 0]*0.01],\n",
    "#          [trajectory.worldTrajectoryPoints[i, 1], trajectory.worldTrajectoryPoints[i, 1]+trajectory.worldTrajectoryDirections[i, 1]*0.01], color=\"red\")\n",
    "#     plot([trajectory.worldTrajectoryPoints[i, 0], trajectory.worldTrajectoryPoints[i, 0]+worldTrajectorySmoothDirections[i, 0]*worldTrajectoryPointsDistances[i]],\n",
    "#          [trajectory.worldTrajectoryPoints[i, 1], trajectory.worldTrajectoryPoints[i, 1]+worldTrajectorySmoothDirections[i, 1]*worldTrajectoryPointsDistances[i]], color=\"magenta\")\n",
    "#     plot([trajectory.worldTrajectoryPoints[i, 0], smoothedWorldTrajectoryPoints[i, 0]],\n",
    "#          [trajectory.worldTrajectoryPoints[i, 1], smoothedWorldTrajectoryPoints[i, 1]], \"y--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR DOING THE ADJUSTMENT BASED ON THE TRAJECTORY AND THE STUFF I TALKED ABOUT IN MY TRANSFER VIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fec69c649d0>]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [-0.90505216  0.42530058]\n",
    "# print(np.array([-0.90343641, 0.42872211])/np.array([1.4828125, 1.45694444])/np.linalg.norm(np.array([-0.90343641, 0.42872211])/np.array([1.4828125, 1.45694444])))\n",
    "# print(1280/720.0, 1898/1050.0)\n",
    "# print(832*2, 468*2)\n",
    "# print(1664/936.0, 1280/720.0, 1898/1050.0)\n",
    "\n",
    "\n",
    "# figure();\n",
    "# xlim([0, 1664])\n",
    "# ylim([936, 0])\n",
    "# plot(np.array([(newFrameSize/2)[0], (newFrameSize/2)[0]+jack[0]*50]), np.array([(newFrameSize/2)[1], (newFrameSize/2)[1]+jack[1]*50]))\n",
    "\n",
    "# figure();\n",
    "# xlim([0, 1898])\n",
    "# ylim([1050, 0])\n",
    "# plot(np.array([(np.array([1898, 1050.0])/2)[0], (np.array([1898, 1050.0])/2)[0]+jack[0]*50]), np.array([(np.array([1898, 1050.0])/2)[1], (np.array([1898, 1050.0])/2)[1]+jack[1]*50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fec6b833bd0>]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(tmpTrajectoryCameraSpace-trajectoryPointsCameraSpace)\n",
    "# figure(); plot(tmpTrajectoryCameraSpace[:, 0], tmpTrajectoryCameraSpace[:, 1])\n",
    "# plot(trajectoryPointsCameraSpace[:, 0], trajectoryPointsCameraSpace[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trajectoryPointsCameraSpace', 'trajectoryDirectionsWorldSpace', 'trajectoryPointsWorldSpace', 'extrinsics', 'intrinsics']\n",
      "LOADED blue_car1\n",
      "Trajectory points and directions (193, 2) (193, 3) (193, 3)\n",
      "0 dist 5.0967182157 7.01751435948 frame-02347.png\n",
      "98 dist 4.69192574399 7.01751435948 frame-02445.png\n"
     ]
    }
   ],
   "source": [
    "# ## UNDISTORT EACH IMAGE WHERE A SPRITE IS PRESENT AND SAVE CORRECTED PATCHES ##\n",
    "\n",
    "# ## load camera data\n",
    "# trajectorySmoothness = 5\n",
    "# data3D = np.load(\"tmp_trajectory_3D.npy\").item()\n",
    "# print(data3D.keys())\n",
    "# cameraExtrinsics = data3D['extrinsics']\n",
    "# cameraIntrinsics = data3D['intrinsics']\n",
    "# distortionParameter = -0.19\n",
    "# distortionRatio = -0.19\n",
    "# distortionCoeff = np.array([distortionParameter, distortionParameter*distortionRatio, 0.0, 0.0, 0.0])\n",
    "# originalIntrinsics = np.array([[702.736053, 0.0, 640.0],\n",
    "#                                [0.0, 702.736053, 360.0],\n",
    "#                                [0.0, 0.0, 1.0]])\n",
    "\n",
    "# objectData = np.load(\"/home/ilisescu/PhD/data/havana/semantic_sequence-blue_car1.npy\").item()\n",
    "# print(\"LOADED\", objectData[DICT_SEQUENCE_NAME])\n",
    "# patches = np.load(objectData[DICT_PATCHES_LOCATION]).item()\n",
    "# sortedPatchKeys = np.sort(patches.keys())\n",
    "\n",
    "\n",
    "# ## get trajectory points and directions in both camera and world space\n",
    "# frameSubset = [30, -50]\n",
    "# # frameSubset = [0, 0]\n",
    "# trajectoryPointsCameraSpace = np.array([objectData[DICT_BBOX_CENTERS][key] for key in sort(objectData[DICT_BBOX_CENTERS].keys())])[frameSubset[0]:frameSubset[1]-1, :]\n",
    "# ## undistort points\n",
    "# trajectoryPointsCameraSpace = cv2.undistortPoints(trajectoryPointsCameraSpace.reshape((1, len(trajectoryPointsCameraSpace), 2)), originalIntrinsics, distortionCoeff, P=cameraIntrinsics)[0, :, :]\n",
    "\n",
    "# inverseT = np.linalg.inv(np.dot(cameraIntrinsics, cameraExtrinsics[:-1, [0, 1, 3]]))\n",
    "# trajectoryPointsWorldSpace = np.dot(inverseT, np.concatenate([trajectoryPointsCameraSpace, np.ones([len(trajectoryPointsCameraSpace), 1], np.float32)], axis=1).T)\n",
    "# trajectoryPointsWorldSpace /= trajectoryPointsWorldSpace[-1, :]\n",
    "# trajectoryPointsWorldSpace[-1, :] = 0\n",
    "# trajectoryPointsWorldSpace = trajectoryPointsWorldSpace.T.astype(np.float32)\n",
    "        \n",
    "# ## smooth trajectory\n",
    "# trajectoryPointsWorldSpace = np.array([spimg.filters.gaussian_filter1d(trajectoryPointsWorldSpace[:, 0], trajectorySmoothness, axis=0),\n",
    "#                                        spimg.filters.gaussian_filter1d(trajectoryPointsWorldSpace[:, 1], trajectorySmoothness, axis=0), \n",
    "#                                        spimg.filters.gaussian_filter1d(trajectoryPointsWorldSpace[:, 2], trajectorySmoothness, axis=0)]).T.astype(np.float32)\n",
    "\n",
    "# ## reproject points into image space after smoothing\n",
    "# T = np.dot(cameraIntrinsics, cameraExtrinsics[:-1, [0, 1, 3]])\n",
    "# trajectoryPointsCameraSpace = np.dot(T, np.concatenate([trajectoryPointsWorldSpace[:, :-1], np.ones([len(trajectoryPointsWorldSpace), 1])], axis=1).T)\n",
    "# trajectoryPointsCameraSpace = (trajectoryPointsCameraSpace[:-1, :]/trajectoryPointsCameraSpace[-1, :]).T\n",
    "\n",
    "\n",
    "# trajectoryDirectionsWorldSpace = np.array([trajectoryPointsWorldSpace[i, :]-trajectoryPointsWorldSpace[j, :] for i, j in zip(xrange(1, len(trajectoryPointsWorldSpace)),\n",
    "#                                                                                                                              xrange(0, len(trajectoryPointsWorldSpace)-1))])\n",
    "# trajectoryDirectionsWorldSpace /= np.linalg.norm(trajectoryDirectionsWorldSpace, axis=1).reshape([len(trajectoryDirectionsWorldSpace), 1])\n",
    "# ## use direction of second to last point as the direction for the last point\n",
    "# trajectoryDirectionsWorldSpace = np.concatenate([trajectoryDirectionsWorldSpace, trajectoryDirectionsWorldSpace[-1, :].reshape([1, trajectoryDirectionsWorldSpace.shape[1]])], axis=0)\n",
    "# print(\"Trajectory points and directions\", trajectoryPointsCameraSpace.shape, trajectoryPointsWorldSpace.shape, trajectoryDirectionsWorldSpace.shape)\n",
    "\n",
    "\n",
    "# ## find directions from center of the car to the center of the camera\n",
    "# cameraPos = getWorldSpacePosAndNorm(np.linalg.inv(cameraExtrinsics), posOnly=True)\n",
    "# pointToCameraDirectionsWorldSpace = cameraPos.reshape([1, 3]) - trajectoryPointsWorldSpace\n",
    "# pointToCameraDistances = np.linalg.norm(pointToCameraDirectionsWorldSpace, axis=1)\n",
    "# pointToCameraDirectionsWorldSpace /= pointToCameraDistances.reshape([len(pointToCameraDistances), 1])\n",
    "\n",
    "# spacing = 98#1\n",
    "# subset = spacing+1#400\n",
    "# # for each point in the trajectory\n",
    "# preloadedPatches = {}\n",
    "# for idx, direction in enumerate(trajectoryDirectionsWorldSpace[:subset:spacing, :]) :\n",
    "#     i = idx*spacing\n",
    "#     rotAxis = np.cross(np.array([1, 0, 0]), direction)\n",
    "#     rotAxis /= np.linalg.norm(rotAxis)\n",
    "#     rotAngle = np.arccos(np.dot(direction, np.array([1, 0, 0])))\n",
    "    \n",
    "    \n",
    "#     ################ figure out how to turn the camera to look at the object ################\n",
    "#     ## undo rotation of car wrt camera\n",
    "#     M = quaternionTo4x4Rotation(angleAxisToQuaternion(rotAngle, rotAxis))\n",
    "#     rotatedDir = np.dot(M, np.array([[pointToCameraDirectionsWorldSpace[i, 0], pointToCameraDirectionsWorldSpace[i, 1], pointToCameraDirectionsWorldSpace[i, 2], 1]]).T)\n",
    "#     rotatedDir = rotatedDir[:-1, 0]/rotatedDir[-1, 0]\n",
    "#     rotatedDir /= np.linalg.norm(rotatedDir)\n",
    "    \n",
    "#     ## this turns the camera towards the object\n",
    "#     adjustCamPos, adjustCamNorm = getWorldSpacePosAndNorm(np.linalg.inv(cameraExtrinsics))\n",
    "#     adjustAxis = np.cross(-pointToCameraDirectionsWorldSpace[i, :], adjustCamNorm)\n",
    "#     adjustAxis /= np.linalg.norm(adjustAxis)\n",
    "#     adjustAngle = np.arccos(np.clip(np.dot(adjustCamNorm, -pointToCameraDirectionsWorldSpace[i, :]), -1, 1))\n",
    "#     adjustM = quaternionTo4x4Rotation(angleAxisToQuaternion(adjustAngle, adjustAxis))\n",
    "\n",
    "#     camMat = np.eye(4)\n",
    "#     camMat[:-1, -1] = rotatedDir\n",
    "#     camMat[:-1, :-1] = np.dot(adjustM[:-1, :-1], np.linalg.inv(cameraExtrinsics)[:-1, :-1])\n",
    "\n",
    "#     ## this rotates camera to align with ground plane (and the car itself)\n",
    "#     _, adjustCamRightVec2 = getWorldSpacePosAndNorm(camMat, np.array([[1, 0, 0, 1]], float).T)\n",
    "#     _, adjustCamUpVec2 = getWorldSpacePosAndNorm(camMat, np.array([[0, -1, 0, 1]], float).T)\n",
    "#     _, adjustCamNorm2 = getWorldSpacePosAndNorm(camMat)\n",
    "#     adjustAxis2 = np.copy(adjustCamNorm2)\n",
    "# #         adjustAngle2 = np.arccos(np.clip(np.dot(adjustCamRightVec2, adjustCamRightVec2-np.dot(adjustCamRightVec2, np.array([0.0, 0.0, 1.0]))*np.array([0.0, 0.0, 1.0])), -1, 1)) ## aligns camera right vector to ground plane\n",
    "# #         adjustAngle2 = np.arccos(np.clip(np.dot(adjustCamRightVec2, np.array([1, 0, 0], float)), -1, 1)) ## not sure what this does\n",
    "#     if i < len(trajectoryPointsCameraSpace)-1 :\n",
    "#         trajDir = trajectoryPointsCameraSpace[i, :]-trajectoryPointsCameraSpace[i+1, :]\n",
    "#     else :\n",
    "#         trajDir = trajectoryPointsCameraSpace[i-1, :]-trajectoryPointsCameraSpace[i, :]\n",
    "# #     print(i, np.linalg.norm(trajDir))\n",
    "#     trajDir /= np.linalg.norm(trajDir)\n",
    "#     adjustAngle2 = np.arccos(np.clip(np.dot(trajDir, np.array([1, 0], float)), -1, 1)) ## align camera space direction to x axis (does it even make sense?)\n",
    "#     if np.cross(trajDir, np.array([1, 0], float)) < 0 :\n",
    "#         adjustAxis2 *= -1.0\n",
    "\n",
    "\n",
    "#     adjustM2 = quaternionTo4x4Rotation(angleAxisToQuaternion(adjustAngle2, adjustAxis2))\n",
    "#     camMat[:-1, :-1] = np.dot(M[:-1, :-1], np.dot(adjustM2[:-1, :-1], camMat[:-1, :-1]))\n",
    "    \n",
    "#     #########################################################################################\n",
    "    \n",
    "    \n",
    "#     ################ rotate the camera to look at the car ################\n",
    "#     camPos = getWorldSpacePosAndNorm(np.linalg.inv(cameraExtrinsics), posOnly=True)\n",
    "#     rotatedCamTransform = rotateAboutPoint(np.linalg.inv(cameraExtrinsics), angleAxisToQuaternion(adjustAngle, adjustAxis), camPos)\n",
    "# #     rotatedCamTransform = rotateAboutPoint(rotatedCamTransform, angleAxisToQuaternion(adjustAngle2, adjustAxis2), camPos)\n",
    "\n",
    "\n",
    "#     _, camDir = getWorldSpacePosAndNorm(rotatedCamTransform, np.array([[0.0], [0.0], [1.0], [1.0]]))\n",
    "#     desiredDist = np.linalg.norm(camPos)#1.0\n",
    "#     t = camDir*(np.linalg.norm(trajectoryPointsWorldSpace[i, :]-camPos)-desiredDist)\n",
    "#     tMat = np.array([[1, 0, 0, t[0]],\n",
    "#                      [0, 1, 0, t[1]],\n",
    "#                      [0, 0, 1, t[2]],\n",
    "#                      [0, 0, 0, 1]])\n",
    "#     ################################### can use this to do the scale normalization thing ###################################\n",
    "#     tMat = np.eye(4)\n",
    "#     rotatedExtrinsics = np.dot(np.linalg.inv(rotatedCamTransform), np.linalg.pinv(tMat))\n",
    "# #     print(\"dist after tMat\", np.linalg.norm(trajectoryPointsWorldSpace[i, :]-getWorldSpacePosAndNorm(np.linalg.inv(rotatedExtrinsics), posOnly=True)))\n",
    "    \n",
    "#     #########################################################################################\n",
    "    \n",
    "#     frameName = \"frame-{0:05}.png\".format(sortedPatchKeys[i+frameSubset[0]]+1)\n",
    "#     frameImg = np.array(Image.open(\"/home/ilisescu/PhD/data/havana/\"+frameName)).astype(np.uint8)\n",
    "# #     figure(); imshow(frameImg)\n",
    "# #     scatter(objectData[DICT_BBOX_CENTERS][sortedPatchKeys[i]][0], objectData[DICT_BBOX_CENTERS][sortedPatchKeys[i]][1])\n",
    "\n",
    "#     frameSize = np.array([frameImg.shape[1], frameImg.shape[0]])\n",
    "#     print(i, \"dist\", np.linalg.norm(trajectoryPointsWorldSpace[i, :]-camPos), desiredDist, frameName)\n",
    "\n",
    "#     ## undistort image\n",
    "#     sizeDelta = 0.3\n",
    "#     newFrameSize = (frameSize*(1+sizeDelta)).astype(int)\n",
    "\n",
    "#     map1, map2 = cv2.initUndistortRectifyMap(originalIntrinsics, distortionCoeff, None, cameraIntrinsics, tuple(newFrameSize), cv2.CV_16SC2)\n",
    "#     undistortedUncropped = cv2.remap(frameImg, map1, map2, cv2.INTER_LINEAR)\n",
    "#     figure(); imshow(undistortedUncropped)\n",
    "#     scatter(trajectoryPointsCameraSpace[i, 0], trajectoryPointsCameraSpace[i, 1])\n",
    "#     jack = trajectoryPointsCameraSpace[i+1, :]-trajectoryPointsCameraSpace[i, :]\n",
    "#     jack /= np.linalg.norm(jack)\n",
    "#     plot(np.array([trajectoryPointsCameraSpace[i, 0], trajectoryPointsCameraSpace[i, 0]+jack[0]*50]), np.array([trajectoryPointsCameraSpace[i, 1], trajectoryPointsCameraSpace[i, 1]+jack[1]*50]))\n",
    "\n",
    "#     ## get grid points into world space and back into image space using the rotate extrinsics\n",
    "#     gridDownsample = 1\n",
    "#     imageGridPoints = np.indices(newFrameSize/gridDownsample).reshape([2, np.prod(newFrameSize/gridDownsample)]).T*gridDownsample\n",
    "    \n",
    "#     ## figure out mapping between original camera matrix and the new one that looks at the car\n",
    "#     rotatedToWorld = np.linalg.inv(np.dot(cameraIntrinsics, rotatedExtrinsics[:-1, [0, 1, 3]]))\n",
    "#     worldToOriginal = np.dot(cameraIntrinsics, cameraExtrinsics[:-1, :])\n",
    "\n",
    "#     rotatedGridWorldSpace = np.dot(rotatedToWorld, np.concatenate([imageGridPoints, np.ones([len(imageGridPoints), 1], np.float64)], axis=1).T)\n",
    "#     rotatedGridWorldSpace /= rotatedGridWorldSpace[-1, :]\n",
    "#     rotatedGridWorldSpace[-1, :] = 0\n",
    "#     rotatedGridWorldSpace = rotatedGridWorldSpace.T.astype(np.float64)\n",
    "\n",
    "#     rotatedGridInOriginalCamera = np.dot(worldToOriginal, np.concatenate([rotatedGridWorldSpace, np.ones([len(rotatedGridWorldSpace), 1], np.float64)], axis=1).T)\n",
    "#     rotatedGridInOriginalCamera = (rotatedGridInOriginalCamera[:-1, :]/rotatedGridInOriginalCamera[-1, :]).T\n",
    "#     rotatedGridInOriginalCamera = rotatedGridInOriginalCamera.T.reshape([2, (newFrameSize/gridDownsample)[0], (newFrameSize/gridDownsample)[1]]).T.astype(np.float32)\n",
    "#     mapPoints1, mapPoints2 = cv2.convertMaps(rotatedGridInOriginalCamera, None, cv2.CV_16SC2)\n",
    "#     rotatedFrameImg = cv2.remap(undistortedUncropped, mapPoints1, mapPoints2, cv2.INTER_LINEAR)\n",
    "#     figure(); imshow(rotatedFrameImg)\n",
    "#     scatter((newFrameSize/2)[0], (newFrameSize/2)[1])\n",
    "#     plot(np.array([(newFrameSize/2)[0], (newFrameSize/2)[0]+jack[0]*50]), np.array([(newFrameSize/2)[1], (newFrameSize/2)[1]+jack[1]*50]))\n",
    "    \n",
    "#     rotatedFrameAlpha = cv2.remap(cv2.remap(np.array(Image.open(\"/home/ilisescu/PhD/data/havana/blue_car1-maskedFlow-blended/\"+frameName)).astype(np.uint8),\n",
    "#                                             map1, map2, cv2.INTER_LINEAR), mapPoints1, mapPoints2, cv2.INTER_LINEAR)\n",
    "# #     figure(); imshow(rotatedFrameAlpha)\n",
    "    \n",
    "#     ## find patchsize and top left such that the center of the image is in the center of the patch\n",
    "#     visiblePixels = np.argwhere(rotatedFrameAlpha[:, :, -1] != 0)\n",
    "#     imgCenter = np.array(rotatedFrameAlpha.shape[:2])/2\n",
    "#     halfSize = np.max(np.array([imgCenter-np.min(visiblePixels, axis=0), np.max(visiblePixels, axis=0)-imgCenter]), axis=0)\n",
    "    \n",
    "#     topLeft = imgCenter-halfSize #np.min(visiblePixels, axis=0)\n",
    "#     patchSize = halfSize*2 + 1 #np.max(visiblePixels, axis=0) - topLeft + 1\n",
    "    \n",
    "#     colors = np.concatenate([rotatedFrameImg[visiblePixels[:, 0], visiblePixels[:, 1], :], np.ones([len(visiblePixels), 1])*255], axis=1).astype(np.uint8)\n",
    "# #     print(colors.shape)\n",
    "\n",
    "#     preloadedPatches[sortedPatchKeys[i]] = {'top_left_pos':topLeft, 'sprite_colors':colors[:, [2, 1, 0, 3]],\n",
    "#                                             'visible_indices': visiblePixels-topLeft, 'patch_size': patchSize}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.36229266,  5.36090167,  5.35816336,  5.35416042,  5.34900275,\n",
       "        5.34281695,  5.33573538,  5.32788649,  5.31939155,  5.31036119,\n",
       "        5.3008969 ,  5.29109054,  5.28102663,  5.2707823 ,  5.26042801,\n",
       "        5.25002809,  5.23964023,  5.22931819,  5.21911197,  5.20906747,\n",
       "        5.19922791,  5.18963352,  5.18031921,  5.17131499,  5.16264382,\n",
       "        5.15432099,  5.1463535 ,  5.13874093,  5.13147729,  5.12455117,\n",
       "        5.11794761,  5.11164927,  5.10563689,  5.09989024,  5.09438758,\n",
       "        5.08910769,  5.08402963,  5.07913549,  5.07441127,  5.06984932,\n",
       "        5.06544912,  5.06121679,  5.05716435,  5.05330635,  5.04965591,\n",
       "        5.04622148,  5.0430033 ,  5.03999116,  5.03716533,  5.03449793,\n",
       "        5.03195698,  5.02951011,  5.0271293 ,  5.02479266,  5.02248625,\n",
       "        5.02020235,  5.01793818,  5.01569273,  5.01346533,  5.01125341,\n",
       "        5.0090533 ,  5.00686063,  5.00467211,  5.00248694,  5.00030693,\n",
       "        4.99813764,  4.9959872 ,  4.9938658 ,  4.99178448,  4.98975402,\n",
       "        4.98778446,  4.98588524,  4.98406225,  4.98231911,  4.98065477,\n",
       "        4.97906382,  4.97753499,  4.97605091,  4.97458752,  4.97311428,\n",
       "        4.97159478,  4.96998647,  4.96824445,  4.96632334,  4.96418161,\n",
       "        4.9617898 ,  4.95913277,  4.95621456,  4.95305858,  4.94970278,\n",
       "        4.94619224,  4.94256987,  4.93886563,  4.93508995,  4.93123143,\n",
       "        4.92725879,  4.92312795,  4.91879273,  4.91421355,  4.9093651 ,\n",
       "        4.90424045,  4.89884959,  4.89321637,  4.88737484,  4.88136354,\n",
       "        4.87522398,  4.86899881,  4.86273232,  4.85646825,  4.85024701,\n",
       "        4.844103  ,  4.83805522,  4.83210109,  4.82621362,  4.82033717,\n",
       "        4.81439119,  4.8082749 ,  4.80187646,  4.79508034,  4.78777763,\n",
       "        4.77987131,  4.77128315,  4.76196026,  4.75188026,  4.74105661,\n",
       "        4.72954268,  4.71742897,  4.70484088,  4.69192574,  4.67883748,\n",
       "        4.66572001,  4.65269181,  4.63983523,  4.6271949 ,  4.61478054,\n",
       "        4.60257729,  4.59055833,  4.57869403,  4.56695972,  4.55533694,\n",
       "        4.54381295,  4.53237546,  4.52100649,  4.50968291,  4.49837303,\n",
       "        4.4870411 ,  4.47564874,  4.46416108,  4.45254721,  4.44078064,\n",
       "        4.42883773,  4.41669382,  4.4043218 ,  4.39169241,  4.37877334,\n",
       "        4.3655388 ,  4.3519709 ,  4.33806773,  4.32384529,  4.30934184,\n",
       "        4.2946137 ,  4.27973166,  4.26477668,  4.24983233,  4.23498093,\n",
       "        4.22029821,  4.20585051,  4.19169309,  4.17786698,  4.1643977 ,\n",
       "        4.15129458,  4.13855056,  4.12613876,  4.11401308,  4.10210993,\n",
       "        4.09034836,  4.07863379,  4.06686586,  4.05494748,  4.04279461,\n",
       "        4.03034885,  4.01758384,  4.00451266,  3.99118694,  3.97768887,\n",
       "        3.96412397,  3.95060373,  3.93723404,  3.92409938,  3.91125742,\n",
       "        3.89873382,  3.88652647,  3.87460885,  3.86293923,  3.85146836,\n",
       "        3.84014974,  3.82893972,  3.81780853,  3.80673532,  3.79571165,\n",
       "        3.78473672,  3.77381881,  3.76297008,  3.75220497,  3.74153766,\n",
       "        3.73097966,  3.72053806,  3.71021259,  3.69999455,  3.68986507,\n",
       "        3.67979643,  3.66975159,  3.65968948,  3.64957082,  3.63936335,\n",
       "        3.62904901,  3.61863065,  3.60813471,  3.59761062,  3.5871263 ,\n",
       "        3.57676185,  3.56659909,  3.55671355,  3.54716643,  3.53799978,\n",
       "        3.52923504,  3.52087386,  3.51290298,  3.50529771,  3.49802816,\n",
       "        3.49106316,  3.48437395,  3.47793611,  3.47173042,  3.46574239,\n",
       "        3.45996189,  3.45438196,  3.44899842,  3.4438088 ,  3.43881357,\n",
       "        3.43401659,  3.42942482,  3.42504999,  3.42090749,  3.41701625,\n",
       "        3.41339786,  3.41007488,  3.40706758,  3.40439356,  3.40206357,\n",
       "        3.40008113,  3.39844097,  3.39713099,  3.39613315,  3.39542631,\n",
       "        3.39498886,  3.39479989,  3.39484084,  3.39509338,  3.39553941,\n",
       "        3.39615611,  3.39691559,  3.39778323,  3.39871831,  3.39967687,\n",
       "        3.40061608,  3.40149708,  3.40228819,  3.40296634,  3.40351694,\n",
       "        3.40393235,  3.40420948,  3.40434791])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# figure(); plot(np.linalg.norm(trajectoryPointsWorldSpace-camPos, axis=1))\n",
    "# np.linalg.norm(trajectoryPointsWorldSpace-camPos, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.save(\"/home/ilisescu/PhD/data/havana/camera_adjusted_plus_scale_preloaded_patches-blue_car1.npy\", preloadedPatches)\n",
    "# print(trajectoryDirectionsWorldSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6061914b90>"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # print(len(preloadedPatches))\n",
    "# # figure(); imshow(rotatedFrameAlpha)\n",
    "# # print(np.min(visiblePixels, axis=0))\n",
    "# # print(len(sortedPatchKeys))\n",
    "# # print(patches[sortedPatchKeys[i]])\n",
    "# figure(); imshow(rotatedFrameImg)\n",
    "# # print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2560, 2561, 2562, 2563, 2564, 2565, 2566, 2567, 2568, 2569, 2570, 2571, 2572, 2573, 2574, 2575, 2576, 2577, 2578, 2579, 2580, 2581, 2582, 2583, 2584, 2585, 2586, 2587, 2588, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407, 2408, 2409, 2410, 2411, 2412, 2413, 2414, 2415, 2416, 2417, 2418, 2419, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2432, 2433, 2434, 2435, 2436, 2437, 2438, 2439, 2440, 2441, 2442, 2443, 2444, 2445, 2446, 2447, 2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2460, 2461, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484, 2485, 2486, 2487, 2488, 2489, 2490, 2491, 2492, 2493, 2494, 2495, 2496, 2497, 2498, 2499, 2500, 2501, 2502, 2503, 2504, 2505, 2506, 2507, 2508, 2509, 2510, 2511, 2512, 2513, 2514, 2515, 2516, 2517, 2518, 2519, 2520, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2528, 2529, 2530, 2531, 2532, 2533, 2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2550, 2551, 2552, 2553, 2554, 2555, 2556, 2557, 2558, 2559]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6069715910>"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(preloadedPatches.keys())\n",
    "# patch = preloadedPatches[sortedPatchKeys[193]]\n",
    "# img = np.zeros([patch['patch_size'][0], patch['patch_size'][1], 4], dtype=np.int8)\n",
    "# img[patch['visible_indices'][:, 0], patch['visible_indices'][:, 1], :] = patch['sprite_colors']\n",
    "# img = img[:, :, [2, 1, 0, 3]]\n",
    "# figure(); imshow(img.astype(np.uint8))\n",
    "# scatter((patch['patch_size']/2)[1], (patch['patch_size']/2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40 55]\n"
     ]
    }
   ],
   "source": [
    "# print(patch['patch_size']/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[468 832] [53 51]\n",
      "[433 780] [508 887] \n",
      "\n",
      "[415 781] [522 884]\n",
      "[433 780] [508 887] \n",
      "\n",
      "[[35 52]\n",
      " [40 55]]\n",
      "[35 52] [40 55]\n",
      "[40 55]\n"
     ]
    }
   ],
   "source": [
    "# print(imgCenter, halfSize)\n",
    "# print(np.min(visiblePixels, axis=0), np.max(visiblePixels, axis=0), \"\\n\")\n",
    "\n",
    "# print(topLeft, topLeft+patchSize)\n",
    "# print(np.min(visiblePixels, axis=0), np.max(visiblePixels, axis=0), \"\\n\")\n",
    "\n",
    "# print(np.array([imgCenter-np.min(visiblePixels, axis=0), np.max(visiblePixels, axis=0)-imgCenter]))\n",
    "# print(imgCenter-np.min(visiblePixels, axis=0), np.max(visiblePixels, axis=0)-imgCenter)\n",
    "# print(np.max(np.array([imgCenter-np.min(visiblePixels, axis=0), np.max(visiblePixels, axis=0)-imgCenter]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1520.7307387    579.44701166]\n",
      "[ 377.5  581.5]\n",
      "[ 1.6672163  -1.59144568  0.        ] [[ 1.6672163  -1.59144568  0.          1.        ]]\n",
      "[832 468] [ 832.  468.    1.]\n"
     ]
    }
   ],
   "source": [
    "# ## check if the trajectory point projects to the center of the image using the rotatedExtrinsics\n",
    "# print(trajectoryPointsCameraSpace[i, :])\n",
    "# print(objectData[DICT_BBOX_CENTERS][sortedPatchKeys[frameIdx]])\n",
    "# trajPoint = np.concatenate([trajectoryPointsWorldSpace[i, :], [1]]).reshape([1, 4])\n",
    "# print(trajectoryPointsWorldSpace[i, :], trajPoint)\n",
    "# projTrajPoint = np.dot(np.dot(cameraIntrinsics, rotatedExtrinsics[:-1, :]), np.concatenate([trajectoryPointsWorldSpace[i, :], [1]]).reshape([1, 4]).T)\n",
    "# projTrajPoint /= projTrajPoint[-1, 0]\n",
    "# print(np.array(rotatedFrameAlpha.shape[:2])[::-1]/2, projTrajPoint.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trajectoryPointsCameraSpace', 'trajectoryDirectionsWorldSpace', 'trajectoryPointsWorldSpace', 'extrinsics', 'intrinsics']\n",
      "0 [-0.17377327 -0.87649572 -0.44895222] [-0.14176993 -0.8822376   0.44895222] [-0.99933797 -0.03638116  0.        ]\n",
      "10 [-0.14413684 -0.88042536 -0.45174745] [-0.10345795 -0.88612679  0.45174745] [-0.99894005 -0.04603021  0.        ]\n",
      "20 [-0.08863161 -0.88620813 -0.45473023] [-0.04628681 -0.88942563  0.45473023] [-0.99886322 -0.04766785  0.        ]\n",
      "30 [-0.08312164 -0.88567257 -0.45680947] [ 0.00888279 -0.88952021  0.45680947] [-0.99464214 -0.10337811  0.        ]\n",
      "40 [-0.06988453 -0.88580913 -0.45875739] [ 0.06374952 -0.88627177  0.45875739] [-0.98869073 -0.14996871  0.        ]\n",
      "50 [-0.0608947  -0.88569779 -0.4602513 ] [ 0.12036892 -0.87959085  0.4602513 ] [-0.97913277 -0.20322168  0.        ]\n",
      "60 [-0.14184121 -0.87513907 -0.46261505] [ 0.17301693 -0.86951277  0.46261505] [-0.93691546 -0.34955594  0.        ]\n",
      "70 [-0.1853103  -0.86485278 -0.46657235] [ 0.22492723 -0.85540516  0.46657235] [-0.89238024 -0.45128429  0.        ]\n",
      "80 [-0.21483249 -0.85482083 -0.47236464] [ 0.28160135 -0.83520795  0.47236464] [-0.84113771 -0.54082096  0.        ]\n",
      "90 [-0.32069696 -0.81730535 -0.47871225] [ 0.33111807 -0.81313923  0.47871225] [-0.72440249 -0.68937719  0.        ]\n",
      "100 [-0.42732629 -0.75952363 -0.49042441] [ 0.3790999  -0.78470833  0.49042441] [-0.57144749 -0.82063866  0.        ]\n",
      "110 [-0.39960351 -0.76597786 -0.50358212] [ 0.42611657 -0.75155154  0.50358212] [-0.54312891 -0.83964938  0.        ]\n",
      "120 [-0.42935496 -0.74075739 -0.51665541] [ 0.46922751 -0.71616529  0.51665541] [-0.44885322 -0.89360547  0.        ]\n",
      "130 [-0.47668495 -0.69920844 -0.53280298] [ 0.51132415 -0.67429118  0.53280298] [-0.31800431 -0.9480893   0.        ]\n",
      "140 [-0.45361481 -0.70029635 -0.55119745] [ 0.54964346 -0.62775269  0.55119745] [-0.27332893 -0.96192062  0.        ]\n",
      "150 [-0.46901744 -0.67653232 -0.56773819] [ 0.5823793  -0.58181414  0.56773819] [-0.17777005 -0.98407203  0.        ]\n",
      "160 [-0.44366015 -0.67728075 -0.58690413] [ 0.61343475 -0.52843292  0.58690413] [-0.13079359 -0.9914096   0.        ]\n",
      "170 [-0.42452217 -0.67398944 -0.60458181] [ 0.63893349 -0.47565201  0.60458181] [-0.0777691  -0.99697137  0.        ]\n",
      "180 [-0.35086202 -0.70020399 -0.62177987] [ 0.66317476 -0.41664017  0.62177987] [-0.09626876 -0.99535531  0.        ]\n",
      "190 [-0.3104505 -0.706549  -0.6359316] [ 0.68426209 -0.3568983   0.6359316 ] [-0.06671798 -0.99777192  0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Line3DCollection at 0x7fb709626a50>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frustumEdges = np.array(np.array([[0, 0, 0, 1],\n",
    "#                                   [.25, .25, 1, 1],\n",
    "#                                   [.25, -.25, 1, 1],\n",
    "#                                   [-.25, -.25, 1, 1],\n",
    "#                                   [-.25, .25, 1, 1]]))\n",
    "# ## load 3D data\n",
    "# data3D = np.load(\"tmp_trajectory_3D.npy\").item()\n",
    "# print(data3D.keys())\n",
    "# cameraExtrinsics = data3D['extrinsics']\n",
    "# cameraIntrinsics = data3D['intrinsics']\n",
    "# ### NEED TO SAVE THIS IN THE 3D DATA BUT WHATEVS, FOR NOW IT'S HARDCODED FOR BLUE_CAR1\n",
    "# # frameSubset = [30, -50]\n",
    "# # frameSubset = [0, -1]\n",
    "\n",
    "# # trajectoryPointsCameraSpace = data3D['trajectoryPointsCameraSpace']\n",
    "# # trajectoryPointsWorldSpace = data3D['trajectoryPointsWorldSpace']\n",
    "# # trajectoryDirectionsWorldSpace = data3D['trajectoryDirectionsWorldSpace']\n",
    "\n",
    "# ## set up figure\n",
    "# fig = figure()\n",
    "# ax = fig.add_subplot(111, aspect='equal', projection='3d')\n",
    "# ax.set_xlim(-3, 3)\n",
    "# ax.set_ylim(-3, 3)\n",
    "# ax.set_zlim(-3, 3)\n",
    "# cols = cm.jet(np.arange(len(trajectoryPointsWorldSpace), dtype=float)/len(trajectoryPointsWorldSpace))\n",
    "\n",
    "# ## plot car footprint and look direction as [1, 0, 0]\n",
    "# if True :\n",
    "#     footprint = np.array([[0.8, 0.5, 0.0],\n",
    "#                           [0.8, -0.5, 0.0],\n",
    "#                           [-0.8, -0.5, 0.0],\n",
    "#                           [-0.8, 0.5, 0.0],\n",
    "#                           [0.0, 0.0, 0.0],\n",
    "#                           [0.8, 0.0, 0.0]]).T*0.5\n",
    "#     for i, j in zip([0, 1, 2, 3, 4], [1, 2, 3, 0, 5]) :\n",
    "#         ax.plot(np.array([footprint[0, i], footprint[0, j]]), np.array([footprint[1, i], footprint[1, j]]), np.array([footprint[2, i], footprint[2, j]]), c=\"magenta\")\n",
    "\n",
    "# ## plot normalized directions\n",
    "# if False :\n",
    "#     for i, direction in enumerate(trajectoryDirectionsWorldSpace) :\n",
    "#         ax.plot(np.array([0, direction[0]]), np.array([0, direction[1]]), np.zeros(2), c=cols[i, :])\n",
    "    \n",
    "# ## plot trajectory\n",
    "# if True :\n",
    "#     ax.plot(trajectoryPointsWorldSpace[:, 0], trajectoryPointsWorldSpace[:, 1], np.zeros(len(trajectoryPointsWorldSpace)), c=\"cyan\")\n",
    "\n",
    "# ## find directions from center of the car to the center of the camera\n",
    "# cameraPos = getWorldSpacePosAndNorm(np.linalg.inv(cameraExtrinsics), posOnly=True)\n",
    "# pointToCameraDirectionsWorldSpace = cameraPos.reshape([1, 3]) - trajectoryPointsWorldSpace\n",
    "# pointToCameraDistances = np.linalg.norm(pointToCameraDirectionsWorldSpace, axis=1)\n",
    "# pointToCameraDirectionsWorldSpace /= pointToCameraDistances.reshape([len(pointToCameraDistances), 1])\n",
    "\n",
    "# ## plot pointToCameraDistances\n",
    "# if False :\n",
    "#     for i, [direction, position] in enumerate(zip(pointToCameraDirectionsWorldSpace[:, :], trajectoryPointsWorldSpace[:, :])) :\n",
    "#         ax.plot(np.array([position[0], direction[0]*pointToCameraDistances[i]+position[0]]),\n",
    "#                 np.array([position[1], direction[1]*pointToCameraDistances[i]+position[1]]),\n",
    "#                 np.array([position[2], direction[2]*pointToCameraDistances[i]+position[2]]), c=cols[i, :])\n",
    "        \n",
    "\n",
    "# ## find rotation to align trajectory directions to [1, 0, 0] and use it to rotate the pointToCameraDirections\n",
    "# spacing = 10\n",
    "# subset = 400\n",
    "# scaledFrustumEdges = np.copy(frustumEdges.T)\n",
    "# scaledFrustumEdges[0:2, :] *= .04\n",
    "# scaledFrustumEdges[2, :] *= .05\n",
    "# for idx, direction in enumerate(trajectoryDirectionsWorldSpace[:subset:spacing, :]) :\n",
    "#     i = idx*spacing\n",
    "#     lastI = np.copy(i)\n",
    "#     rotAxis = np.cross(np.array([1, 0, 0]), direction)\n",
    "#     rotAxis /= np.linalg.norm(rotAxis)\n",
    "#     rotAngle = np.arccos(np.dot(direction, np.array([1, 0, 0])))\n",
    "    \n",
    "#     M = quaternionTo4x4Rotation(angleAxisToQuaternion(rotAngle, rotAxis))\n",
    "#     rotatedDir = np.dot(M, np.array([[pointToCameraDirectionsWorldSpace[i, 0], pointToCameraDirectionsWorldSpace[i, 1], pointToCameraDirectionsWorldSpace[i, 2], 1]]).T)\n",
    "#     rotatedDir = rotatedDir[:-1, 0]/rotatedDir[-1, 0]\n",
    "#     rotatedDir /= np.linalg.norm(rotatedDir)\n",
    "#     if False :\n",
    "#         ax.plot(np.array([0, rotatedDir[0]]), np.array([0, rotatedDir[1]]), np.array([0, rotatedDir[2]]), c=cols[i, :])\n",
    "        \n",
    "#     if True :\n",
    "#         ## plot footprint at current trajectory point\n",
    "#         frameFootprint = np.array([[0.8, 0.5],\n",
    "#                                    [0.8, -0.5],\n",
    "#                                    [-0.8, -0.5],\n",
    "#                                    [-0.8, 0.5],\n",
    "#                                    [0.0, 0.0],\n",
    "#                                    [0.8, 0.0]]).T*0.1\n",
    "#         footprintRotAngle = -np.arccos(np.dot(direction, np.array([1, 0, 0])))\n",
    "#         footprintRotMat = np.array([[np.cos(footprintRotAngle), -np.sin(footprintRotAngle)],\n",
    "#                                     [np.sin(footprintRotAngle), np.cos(footprintRotAngle)]])\n",
    "#         frameFootprint = np.dot(footprintRotMat, frameFootprint)\n",
    "#         frameFootprint += trajectoryPointsWorldSpace[i, :-1].reshape([2, 1])\n",
    "#         for fi, fj in zip([0, 1, 2, 3, 4], [1, 2, 3, 0, 5]) :\n",
    "#             ax.plot(np.array([frameFootprint[0, fi], frameFootprint[0, fj]]), np.array([frameFootprint[1, fi], frameFootprint[1, fj]]), np.array([0.0, 0.0]), c=\"magenta\")\n",
    "    \n",
    "#     if True :\n",
    "#         ## this turns the camera towards the object\n",
    "#         adjustCamPos, adjustCamNorm = getWorldSpacePosAndNorm(np.linalg.inv(cameraExtrinsics))\n",
    "#         adjustAxis = np.cross(-pointToCameraDirectionsWorldSpace[i, :], adjustCamNorm)\n",
    "#         adjustAxis /= np.linalg.norm(adjustAxis)\n",
    "#         adjustAngle = np.arccos(np.clip(np.dot(adjustCamNorm, -pointToCameraDirectionsWorldSpace[i, :]), -1, 1))\n",
    "#         adjustM = quaternionTo4x4Rotation(angleAxisToQuaternion(adjustAngle, adjustAxis))\n",
    "#         print(i, -rotatedDir, pointToCameraDirectionsWorldSpace[i, :], direction)\n",
    "        \n",
    "#         camMat = np.eye(4)\n",
    "#         camMat[:-1, -1] = rotatedDir\n",
    "#         camMat[:-1, :-1] = np.dot(adjustM[:-1, :-1], np.linalg.inv(cameraExtrinsics)[:-1, :-1])\n",
    "# #         camMat[:-1, :-1] = np.dot(M[:-1, :-1], np.dot(adjustM2[:-1, :-1], np.dot(adjustM[:-1, :-1], np.linalg.inv(cameraExtrinsics)[:-1, :-1])))\n",
    "        \n",
    "#         ## this rotates camera to align with ground plane (and the car itself)\n",
    "#         _, adjustCamRightVec2 = getWorldSpacePosAndNorm(camMat, np.array([[1, 0, 0, 1]], float).T)\n",
    "#         _, adjustCamUpVec2 = getWorldSpacePosAndNorm(camMat, np.array([[0, -1, 0, 1]], float).T)\n",
    "#         _, adjustCamNorm2 = getWorldSpacePosAndNorm(camMat)\n",
    "#         adjustAxis2 = np.copy(adjustCamNorm2)\n",
    "# #         adjustAngle2 = np.arccos(np.clip(np.dot(adjustCamRightVec2, adjustCamRightVec2-np.dot(adjustCamRightVec2, np.array([0.0, 0.0, 1.0]))*np.array([0.0, 0.0, 1.0])), -1, 1)) ## aligns camera right vector to ground plane\n",
    "# #         adjustAngle2 = np.arccos(np.clip(np.dot(adjustCamRightVec2, np.array([1, 0, 0], float)), -1, 1)) ## not sure what this does\n",
    "#         trajDir = trajectoryPointsCameraSpace[i, :]-trajectoryPointsCameraSpace[i+1, :]\n",
    "#         trajDir /= np.linalg.norm(trajDir)\n",
    "#         adjustAngle2 = np.arccos(np.clip(np.dot(trajDir, np.array([1, 0], float)), -1, 1)) ## align camera space direction to x axis (does it even make sense?)\n",
    "#         if np.cross(trajDir, np.array([1, 0], float)) < 0 :\n",
    "#             adjustAxis2 *= -1.0\n",
    "        \n",
    "        \n",
    "#         adjustM2 = quaternionTo4x4Rotation(angleAxisToQuaternion(adjustAngle2, adjustAxis2))\n",
    "#         camMat[:-1, :-1] = np.dot(M[:-1, :-1], np.dot(adjustM2[:-1, :-1], camMat[:-1, :-1]))\n",
    "        \n",
    "#         camFrustum = np.dot(camMat, np.concatenate([scaledFrustumEdges, np.array([[0, 0, 1, 1]]).T], axis=1))\n",
    "#         camFrustum = camFrustum[:-1, :]/camFrustum[-1, :]\n",
    "#         for idxI, idxJ in zip([0, 0, 0, 0, 1, 2, 3, 4, 0], [1, 2, 3, 4, 2, 3, 4, 1, 5]) :\n",
    "#             ax.plot(np.array([camFrustum[0, idxI], camFrustum[0, idxJ]]), np.array([camFrustum[1, idxI], camFrustum[1, idxJ]]), np.array([camFrustum[2, idxI], camFrustum[2, idxJ]]), c=cols[i, :], linewidth=.5)\n",
    "            \n",
    "#         camPos, camUp = getWorldSpacePosAndNorm(camMat, np.array([[0.0, -1.0, 0.0, 1.0]]).T)\n",
    "#         camUp *=0.05\n",
    "#         ax.plot(np.array([camPos[0], camPos[0]+camUp[0]]), np.array([camPos[1], camPos[1]+camUp[1]]), np.array([camPos[2], camPos[2]+camUp[2]]), c=\"green\")\n",
    "        \n",
    "#         _, bob = getWorldSpacePosAndNorm(camMat, np.array([[1, 0, 0, 1]], float).T)\n",
    "# #         print(adjustAngle2, bob, adjustCamRightVec2, adjustCamRightVec2-np.dot(adjustCamRightVec2, np.array([0.0, 0.0, 1.0]))*np.array([0.0, 0.0, 1.0]),\n",
    "# #               np.arccos(np.clip(np.dot(bob, bob-np.dot(bob, np.array([0.0, 0.0, 1.0]))*np.array([0.0, 0.0, 1.0])), -1, 1)))\n",
    "    \n",
    "# #     ax.scatter(-tmpDirections[lastI, 0], -tmpDirections[lastI, 1], -tmpDirections[lastI, 2])\n",
    "        \n",
    "        \n",
    "# ## plot captured camera frustum\n",
    "# if True :\n",
    "#     camFrustum = np.dot(np.linalg.inv(cameraExtrinsics), frustumEdges.T)\n",
    "#     camFrustum = camFrustum[:-1, :]/camFrustum[-1, :]\n",
    "#     camPos, camUp = getWorldSpacePosAndNorm(np.linalg.inv(cameraExtrinsics), np.array([[0.0, -1.0, 0.0, 1.0]]).T)\n",
    "#     for i, j in zip([0, 0, 0, 0, 1, 2, 3, 4], [1, 2, 3, 4, 2, 3, 4, 1]) :\n",
    "#         ax.plot(np.array([camFrustum[0, i], camFrustum[0, j]]), np.array([camFrustum[1, i], camFrustum[1, j]]), np.array([camFrustum[2, i], camFrustum[2, j]]), c=\"blue\")\n",
    "#     ax.plot(np.array([camPos[0], camPos[0]+camUp[0]]), np.array([camPos[1], camPos[1]+camUp[1]]), np.array([camPos[2], camPos[2]+camUp[2]]))\n",
    "        \n",
    "        \n",
    "# ## draw sphere\n",
    "# u, v = np.mgrid[0:2*np.pi:20j, 0:np.pi:20j]\n",
    "# x=np.cos(u)*np.sin(v)\n",
    "# y=np.sin(u)*np.sin(v)\n",
    "# z=np.cos(v)\n",
    "# ax.plot_wireframe(x, y, z, color=\"r\", linewidth=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.48596337  0.66044682 -0.57240684  0.56740576]\n",
      " [ 0.82187036 -0.12256917  0.5563325  -3.97315121]\n",
      " [ 0.2972686  -0.74080147 -0.60236583  0.84087688]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[[ 0.91091156  0.20145239 -0.36007914  0.56740576]\n",
      " [ 0.40679979 -0.29266229  0.86536855 -3.97315121]\n",
      " [ 0.06894898 -0.93475437 -0.34854028  0.84087688]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x7f60694d3210>]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# objectData = np.load(\"/home/ilisescu/PhD/data/havana/semantic_sequence-blue_car1.npy\").item()\n",
    "# patches = np.load(objectData[DICT_PATCHES_LOCATION]).item()\n",
    "# sortedPatchKeys = np.sort(patches.keys())\n",
    "\n",
    "# frameIdx = lastI+frameSubset[0]\n",
    "# patch = patches[sortedPatchKeys[frameIdx]]\n",
    "# img = np.zeros([patch['patch_size'][0], patch['patch_size'][1], 4], dtype=np.int8)\n",
    "# img[patch['visible_indices'][:, 0], patch['visible_indices'][:, 1], :] = patch['sprite_colors']\n",
    "# img = img[:, :, [2, 1, 0, 3]]\n",
    "\n",
    "# # figure(); imshow(img[:, :, :-1].astype(np.uint8))\n",
    "\n",
    "# camPos = getWorldSpacePosAndNorm(np.linalg.inv(cameraExtrinsics), posOnly=True)\n",
    "# rotatedCamTransform = rotateAboutPoint(np.linalg.inv(cameraExtrinsics), angleAxisToQuaternion(adjustAngle, adjustAxis), camPos)\n",
    "# rotatedCamTransform = rotateAboutPoint(rotatedCamTransform, angleAxisToQuaternion(adjustAngle2, adjustAxis2), camPos)\n",
    "\n",
    "\n",
    "# _, camDir = getWorldSpacePosAndNorm(rotatedCamTransform, np.array([[0.0], [0.0], [1.0], [1.0]]))\n",
    "# t = camDir*1.3\n",
    "# tMat = np.array([[1, 0, 0, t[0]],\n",
    "#                  [0, 1, 0, t[1]],\n",
    "#                  [0, 0, 1, t[2]],\n",
    "#                  [0, 0, 0, 1]])\n",
    "# ################################### can use this to do the scale normalization thing ###################################\n",
    "# tMat = np.eye(4)\n",
    "# rotatedExtrinsics = np.dot(np.linalg.inv(rotatedCamTransform), np.linalg.pinv(tMat))\n",
    "\n",
    "# print(np.linalg.inv(rotatedExtrinsics))\n",
    "# print(np.linalg.inv(cameraExtrinsics))\n",
    "\n",
    "# camFrustum = np.dot(np.linalg.inv(rotatedExtrinsics), frustumEdges.T)\n",
    "# camFrustum = camFrustum[:-1, :]/camFrustum[-1, :]\n",
    "# camPos, camUp = getWorldSpacePosAndNorm(np.linalg.inv(rotatedExtrinsics), np.array([[0.0, -1.0, 0.0, 1.0]]).T)\n",
    "# for i, j in zip([0, 0, 0, 0, 1, 2, 3, 4], [1, 2, 3, 4, 2, 3, 4, 1]) :\n",
    "#     ax.plot(np.array([camFrustum[0, i], camFrustum[0, j]]), np.array([camFrustum[1, i], camFrustum[1, j]]), np.array([camFrustum[2, i], camFrustum[2, j]]), c=\"magenta\")\n",
    "# ax.plot(np.array([camPos[0], camPos[0]+camUp[0]]), np.array([camPos[1], camPos[1]+camUp[1]]), np.array([camPos[2], camPos[2]+camUp[2]]), c=\"magenta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using opencv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6068175a90>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distortionParameter = -0.19\n",
    "# distortionRatio = -0.19\n",
    "# distortionCoeff = np.array([distortionParameter, distortionParameter*distortionRatio, 0.0, 0.0, 0.0])\n",
    "\n",
    "        \n",
    "# originalIntrinsics = np.array([[702.736053, 0.0, 640.0],\n",
    "#                                [0.0, 702.736053, 360.0],\n",
    "#                                [0.0, 0.0, 1.0]])\n",
    "\n",
    "# frameImg = np.array(Image.open(\"/home/ilisescu/PhD/data/havana/frame-{0:05}.png\".format(sortedPatchKeys[frameIdx]+1))).astype(np.uint8)\n",
    "# figure(); imshow(frameImg)\n",
    "# scatter(objectData[DICT_BBOX_CENTERS][sortedPatchKeys[frameIdx]][0], objectData[DICT_BBOX_CENTERS][sortedPatchKeys[frameIdx]][1])\n",
    "\n",
    "# frameSize = np.array([frameImg.shape[1], frameImg.shape[0]])\n",
    "\n",
    "# ## undistort image\n",
    "# sizeDelta = 0.3\n",
    "# newFrameSize = (frameSize*(1+sizeDelta)).astype(int)\n",
    "\n",
    "# map1, map2 = cv2.initUndistortRectifyMap(originalIntrinsics, distortionCoeff, None, cameraIntrinsics, tuple(newFrameSize), cv2.CV_16SC2)\n",
    "# undistortedUncropped = cv2.remap(frameImg, map1, map2, cv2.INTER_LINEAR)\n",
    "# figure(); imshow(undistortedUncropped)\n",
    "# scatter(trajectoryPointsCameraSpace[lastI, 0], trajectoryPointsCameraSpace[lastI, 1])\n",
    "\n",
    "# ## get grid points into world space and back into image space using the rotate extrinsics\n",
    "# gridDownsample = 1\n",
    "# imageGridPoints = np.indices(newFrameSize/gridDownsample).reshape([2, np.prod(newFrameSize/gridDownsample)]).T*gridDownsample\n",
    "\n",
    "# if False :\n",
    "#     print(\"using old way\")\n",
    "#     inverseT = np.linalg.inv(np.dot(cameraIntrinsics, cameraExtrinsics[:-1, [0, 1, 3]]))\n",
    "#     projectedImageGridPoints = np.dot(inverseT, np.concatenate([imageGridPoints, np.ones([len(imageGridPoints), 1], np.float64)], axis=1).T)\n",
    "#     projectedImageGridPoints /= projectedImageGridPoints[-1, :]\n",
    "\n",
    "#     projectedImageGridPoints[-1, :] = 0\n",
    "#     projectedImageGridPoints = projectedImageGridPoints.T.astype(np.float64)\n",
    "\n",
    "#     T = np.dot(cameraIntrinsics, rotatedExtrinsics[:-1, :])\n",
    "#     rotatedGridPoints = np.dot(T, np.concatenate([projectedImageGridPoints, np.ones([len(projectedImageGridPoints), 1], np.float64)], axis=1).T)\n",
    "#     mapPoints1, mapPoints2 = cv2.convertMaps((rotatedGridPoints[:-1, :]/rotatedGridPoints[-1, :]).T.reshape([2, (newFrameSize/gridDownsample)[0], (newFrameSize/gridDownsample)[1]]).T.astype(np.float32), None, cv2.CV_16SC2)\n",
    "#     rotatedGridPoints = np.round((rotatedGridPoints[:-1, :]/rotatedGridPoints[-1, :]).T).astype(int)\n",
    "\n",
    "\n",
    "#     validCoords = np.all(np.concatenate([rotatedGridPoints >= 0,\n",
    "#                                          (rotatedGridPoints[:, 0] < newFrameSize[0]).reshape([len(rotatedGridPoints), 1]),\n",
    "#                                          (rotatedGridPoints[:, 1] < newFrameSize[1]).reshape([len(rotatedGridPoints), 1])], axis=1), axis=1)\n",
    "\n",
    "#     rotatedFrameImg = np.zeros(undistortedUncropped.shape, np.uint8)\n",
    "#     rotatedFrameImg[rotatedGridPoints[validCoords, 1], rotatedGridPoints[validCoords, 0], :] = undistortedUncropped[imageGridPoints[validCoords, 1], imageGridPoints[validCoords, 0], :]\n",
    "# else :\n",
    "#     print(\"using opencv\")\n",
    "#     rotatedToWorld = np.linalg.inv(np.dot(cameraIntrinsics, rotatedExtrinsics[:-1, [0, 1, 3]]))\n",
    "#     worldToOriginal = np.dot(cameraIntrinsics, cameraExtrinsics[:-1, :])\n",
    "\n",
    "#     rotatedGridWorldSpace = np.dot(rotatedToWorld, np.concatenate([imageGridPoints, np.ones([len(imageGridPoints), 1], np.float64)], axis=1).T)\n",
    "#     rotatedGridWorldSpace /= rotatedGridWorldSpace[-1, :]\n",
    "#     rotatedGridWorldSpace[-1, :] = 0\n",
    "#     rotatedGridWorldSpace = rotatedGridWorldSpace.T.astype(np.float64)\n",
    "\n",
    "#     rotatedGridInOriginalCamera = np.dot(worldToOriginal, np.concatenate([rotatedGridWorldSpace, np.ones([len(rotatedGridWorldSpace), 1], np.float64)], axis=1).T)\n",
    "#     rotatedGridInOriginalCamera = (rotatedGridInOriginalCamera[:-1, :]/rotatedGridInOriginalCamera[-1, :]).T\n",
    "#     rotatedGridInOriginalCamera = rotatedGridInOriginalCamera.T.reshape([2, (newFrameSize/gridDownsample)[0], (newFrameSize/gridDownsample)[1]]).T.astype(np.float32)\n",
    "#     mapPoints1, mapPoints2 = cv2.convertMaps(rotatedGridInOriginalCamera, None, cv2.CV_16SC2)\n",
    "#     rotatedFrameImg = cv2.remap(undistortedUncropped, mapPoints1, mapPoints2, cv2.INTER_LINEAR)\n",
    "# figure(); imshow(rotatedFrameImg)\n",
    "\n",
    "# scatter((newFrameSize/2)[0], (newFrameSize/2)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README [[ 0.9109116   0.40679982  0.06894898  1.04144314]\n",
      " [ 0.2014524  -0.2926623  -0.93475436 -0.49108347]\n",
      " [-0.36007914  0.86536853 -0.34854028  3.93563077]\n",
      " [-0.          0.         -0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# modelMat = QtGui.QMatrix4x4(0.910911599349, 0.406799823245, 0.0689489809887, 1.04144313517,\n",
    "#                             0.201452403084, -0.292662295856, -0.934754358041, -0.491083466897,\n",
    "#                             -0.360079140556, 0.865368525191, -0.348540281954, 3.93563077185,\n",
    "#                             0.0, 0.0, 0.0, 1.0).inverted()[0]\n",
    "\n",
    "# cameraIntrinsics = np.array([[702.736053, 0.0, 640.0],\n",
    "#                              [0.0, 702.736053, 360.0],\n",
    "#                              [0.0, 0.0, 1.0]])\n",
    "# cameraExtrinsics = np.array(modelMat.inverted()[0].data()).reshape([4, 4]).T\n",
    "# print(\"README\", cameraExtrinsics)\n",
    "\n",
    "# frameSize = np.array([1280, 720])\n",
    "# gridDownsample = 1\n",
    "# projectedImageGridPoints = np.indices(frameSize/gridDownsample).reshape([2, np.prod(frameSize/gridDownsample)]).T*gridDownsample\n",
    "# # projectedImageGridColors = img[projectedImageGridPoints[:, 1], projectedImageGridPoints[:, 0], :].astype(np.float32)/np.float32(255.0)\n",
    "# tmp = np.copy(projectedImageGridPoints)\n",
    "\n",
    "# inverseT = np.linalg.inv(np.dot(cameraIntrinsics, cameraExtrinsics[:-1, [0, 1, 3]]))\n",
    "# projectedImageGridPoints = np.dot(inverseT, np.concatenate([projectedImageGridPoints, np.ones([len(projectedImageGridPoints), 1], np.float64)], axis=1).T)\n",
    "# projectedImageGridPoints /= projectedImageGridPoints[-1, :]\n",
    "# projectedImageGridPoints[-1, :] = 0\n",
    "# projectedImageGridPoints = projectedImageGridPoints.T.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x7f606865bed0>]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## USED TO FIGURE OUT HOW TO ALIGN A CAMERA TO THE GROUND PLANE\n",
    "# fig = figure()\n",
    "# ax = fig.add_subplot(111, aspect='equal', projection='3d')\n",
    "# ax.set_xlim(-3, 3)\n",
    "# ax.set_ylim(-3, 3)\n",
    "# ax.set_zlim(-3, 3)\n",
    "\n",
    "# camFrustum = np.dot(np.linalg.inv(cameraExtrinsics), frustumEdges.T)\n",
    "# camFrustum = camFrustum[:-1, :]/camFrustum[-1, :]\n",
    "# camPos, camUp = getWorldSpacePosAndNorm(np.linalg.inv(cameraExtrinsics), np.array([[0.0, -1.0, 0.0, 1.0]]).T)\n",
    "# _, camNorm = getWorldSpacePosAndNorm(np.linalg.inv(cameraExtrinsics), np.array([[0.0, 0.0, 1.0, 1.0]]).T)\n",
    "# for i, j in zip([0, 0, 0, 0, 1, 2, 3, 4], [1, 2, 3, 4, 2, 3, 4, 1]) :\n",
    "#     ax.plot(np.array([camFrustum[0, i], camFrustum[0, j]]), np.array([camFrustum[1, i], camFrustum[1, j]]), np.array([camFrustum[2, i], camFrustum[2, j]]), c=\"blue\")\n",
    "# ax.plot(np.array([camPos[0], camPos[0]+camUp[0]]), np.array([camPos[1], camPos[1]+camUp[1]]), np.array([camPos[2], camPos[2]+camUp[2]]))\n",
    "\n",
    "# frustumCenter = np.average(camFrustum[:, 1:], axis=1)\n",
    "# ax.plot(np.array([frustumCenter[0], frustumCenter[0]+camUp[0]]), np.array([frustumCenter[1], frustumCenter[1]+camUp[1]]), np.array([frustumCenter[2], frustumCenter[2]+camUp[2]]), c=\"magenta\")\n",
    "# planeNorm = np.array([0.0, 0.0, 1.0])\n",
    "# ax.plot(np.array([frustumCenter[0], frustumCenter[0]+planeNorm[0]]), np.array([frustumCenter[1], frustumCenter[1]+planeNorm[1]]), np.array([frustumCenter[2], frustumCenter[2]+planeNorm[2]]), c=\"cyan\")\n",
    "# ax.plot(np.array([frustumCenter[0], frustumCenter[0]+camNorm[0]]), np.array([frustumCenter[1], frustumCenter[1]+camNorm[1]]), np.array([frustumCenter[2], frustumCenter[2]+camNorm[2]]), c=\"blue\")\n",
    "\n",
    "# projNorm = planeNorm - np.dot(planeNorm, camNorm)*camNorm\n",
    "# projNorm /= np.linalg.norm(projNorm)\n",
    "# ax.plot(np.array([frustumCenter[0], frustumCenter[0]+projNorm[0]]), np.array([frustumCenter[1], frustumCenter[1]+projNorm[1]]), np.array([frustumCenter[2], frustumCenter[2]+projNorm[2]]), c=\"black\")\n",
    "\n",
    "# adjustAngle3 = np.arccos(np.clip(np.dot(projNorm, camUp), -1, 1))\n",
    "# adjustAxis3 = np.cross(projNorm, camUp)\n",
    "# adjustAxis3 /= np.linalg.norm(adjustAxis3)\n",
    "# rotatedCamTransform = rotateAboutPoint(np.linalg.inv(cameraExtrinsics), angleAxisToQuaternion(adjustAngle3, adjustAxis3), camPos)\n",
    "# camFrustum = np.dot(rotatedCamTransform, frustumEdges.T)\n",
    "# camFrustum = camFrustum[:-1, :]/camFrustum[-1, :]\n",
    "# camPos, camUp = getWorldSpacePosAndNorm(np.linalg.inv(rotatedExtrinsics), np.array([[0.0, -1.0, 0.0, 1.0]]).T)\n",
    "# for i, j in zip([0, 0, 0, 0, 1, 2, 3, 4], [1, 2, 3, 4, 2, 3, 4, 1]) :\n",
    "#     ax.plot(np.array([camFrustum[0, i], camFrustum[0, j]]), np.array([camFrustum[1, i], camFrustum[1, j]]), np.array([camFrustum[2, i], camFrustum[2, j]]), c=\"magenta\")\n",
    "# ax.plot(np.array([camPos[0], camPos[0]+camUp[0]]), np.array([camPos[1], camPos[1]+camUp[1]]), np.array([camPos[2], camPos[2]+camUp[2]]), c=\"magenta\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
